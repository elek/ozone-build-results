Attaching to ozonesecure-ha_s3g_1, ozonesecure-ha_scm3.org_1, ozonesecure-ha_datanode3_1, ozonesecure-ha_om1_1, ozonesecure-ha_om2_1, ozonesecure-ha_datanode1_1, ozonesecure-ha_kms_1, ozonesecure-ha_datanode2_1, ozonesecure-ha_scm1.org_1, ozonesecure-ha_recon_1, ozonesecure-ha_scm2.org_1, ozonesecure-ha_om3_1, ozonesecure-ha_kdc_1
datanode1_1  | Sleeping for 5 seconds
datanode1_1  | Waiting for the service scm3.org:9894
datanode1_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
datanode1_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode1_1  | 2022-10-20 02:09:09,769 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode1_1  | /************************************************************
datanode1_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode1_1  | STARTUP_MSG:   host = 99666f78dec4/172.25.0.102
datanode1_1  | STARTUP_MSG:   args = []
datanode1_1  | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
datanode1_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.2.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.4.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.4.0.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.4.0.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.4.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.4.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.32.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.4.5.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.4.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.4.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.4.0.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.4.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.4.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.3.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.4.0.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.3.0-SNAPSHOT.jar
datanode1_1  | STARTUP_MSG:   build = https://github.com/apache/ozone/ff6d15f5df822a5a3c776320b032fad3dd380f95 ; compiled by 'runner' on 2022-10-20T01:41Z
datanode1_1  | STARTUP_MSG:   java = 11.0.14.1
datanode1_1  | ************************************************************/
datanode1_1  | 2022-10-20 02:09:09,860 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode1_1  | 2022-10-20 02:09:10,192 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode1_1  | 2022-10-20 02:09:10,834 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode1_1  | 2022-10-20 02:09:11,627 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode1_1  | 2022-10-20 02:09:11,628 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode1_1  | 2022-10-20 02:09:12,282 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:99666f78dec4 ip:172.25.0.102
datanode1_1  | 2022-10-20 02:09:15,206 [main] INFO ozone.HddsDatanodeService: Ozone security is enabled. Attempting login for Hdds Datanode user. Principal: dn/dn@EXAMPLE.COM,keytab: /etc/security/keytabs/dn.keytab
datanode1_1  | 2022-10-20 02:09:16,200 [main] INFO security.UserGroupInformation: Login successful for user dn/dn@EXAMPLE.COM using keytab file dn.keytab. Keytab auto renewal enabled : false
datanode1_1  | 2022-10-20 02:09:16,201 [main] INFO ozone.HddsDatanodeService: Hdds Datanode login successful.
datanode1_1  | 2022-10-20 02:09:18,310 [main] INFO ozone.HddsDatanodeService: Initializing secure Datanode.
datanode1_1  | 2022-10-20 02:09:18,355 [main] ERROR client.DNCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
datanode1_1  | 2022-10-20 02:09:18,355 [main] INFO client.DNCertificateClient: Certificate client init case: 0
datanode1_1  | 2022-10-20 02:09:18,357 [main] INFO client.DNCertificateClient: Creating keypair for client as keypair and certificate not found.
datanode1_1  | 2022-10-20 02:09:23,973 [main] INFO ozone.HddsDatanodeService: Init response: GETCERT
datanode1_1  | 2022-10-20 02:09:24,048 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.102,host:99666f78dec4
datanode1_1  | 2022-10-20 02:09:24,053 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
datanode1_1  | 2022-10-20 02:09:24,069 [main] ERROR client.DNCertificateClient: Invalid domain 99666f78dec4
datanode1_1  | 2022-10-20 02:09:24,075 [main] INFO ozone.HddsDatanodeService: Creating csr for DN-> subject:dn@99666f78dec4
datanode1_1  | 2022-10-20 02:09:27,777 [main] INFO client.DNCertificateClient: Loading certificate from location:/data/metadata/dn/certs.
datanode1_1  | 2022-10-20 02:09:27,830 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/1083227860558.crt.
datanode1_1  | 2022-10-20 02:09:27,857 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/ROOTCA-1.crt.
datanode1_1  | 2022-10-20 02:09:27,895 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/CA-1003431474332.crt.
datanode1_1  | 2022-10-20 02:09:27,895 [main] INFO ozone.HddsDatanodeService: Successfully stored SCM signed certificate, case:GETCERT.
datanode1_1  | 2022-10-20 02:09:28,025 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
datanode1_1  | 2022-10-20 02:09:28,928 [main] INFO reflections.Reflections: Reflections took 716 ms to scan 2 urls, producing 92 keys and 204 values 
datanode1_1  | 2022-10-20 02:09:29,353 [main] INFO statemachine.DatanodeStateMachine: Datanode State Machine Task Thread Pool size 4
datanode1_1  | 2022-10-20 02:09:30,394 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode1_1  | 2022-10-20 02:09:30,466 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89297309696
datanode1_1  | 2022-10-20 02:09:30,492 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode1_1  | 2022-10-20 02:09:30,523 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode1_1  | 2022-10-20 02:09:30,674 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode1_1  | 2022-10-20 02:09:30,892 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode1_1  | 2022-10-20 02:09:30,894 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/metadata/ratis/scmUsed not found
datanode1_1  | 2022-10-20 02:09:30,894 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
datanode1_1  | 2022-10-20 02:09:30,894 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/metadata/ratis
datanode1_1  | 2022-10-20 02:09:30,894 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/metadata/ratis
datanode1_1  | 2022-10-20 02:09:30,999 [Thread-8] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode1_1  | 2022-10-20 02:09:31,030 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode1_1  | 2022-10-20 02:09:35,235 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for DNAudit to [].
datanode1_1  | 2022-10-20 02:09:36,121 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode1_1  | 2022-10-20 02:09:36,416 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
datanode1_1  | 2022-10-20 02:09:36,911 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
datanode1_1  | 2022-10-20 02:09:36,946 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
datanode1_1  | 2022-10-20 02:09:36,965 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.host = null (fallback to raft.grpc.server.host)
datanode1_1  | 2022-10-20 02:09:36,966 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
datanode1_1  | 2022-10-20 02:09:36,966 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.host = null (default)
datanode1_1  | 2022-10-20 02:09:36,966 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
datanode1_1  | 2022-10-20 02:09:36,967 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode1_1  | 2022-10-20 02:09:36,967 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode1_1  | 2022-10-20 02:09:36,968 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode1_1  | 2022-10-20 02:09:36,968 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode1_1  | 2022-10-20 02:09:37,072 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
datanode1_1  | 2022-10-20 02:09:37,135 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
datanode1_1  | 2022-10-20 02:09:37,146 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
datanode1_1  | 2022-10-20 02:09:42,464 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
datanode1_1  | 2022-10-20 02:09:42,491 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
datanode1_1  | 2022-10-20 02:09:42,491 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
datanode1_1  | 2022-10-20 02:09:42,491 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode1_1  | 2022-10-20 02:09:42,491 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode1_1  | 2022-10-20 02:09:42,514 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode1_1  | 2022-10-20 02:09:43,352 [main] INFO server.XceiverServerGrpc: GrpcServer channel type EpollServerSocketChannel
datanode1_1  | 2022-10-20 02:09:44,522 [main] INFO token.OzoneBlockTokenSecretManager: Updating the current master key for generating tokens
datanode1_1  | 2022-10-20 02:09:44,540 [main] INFO token.ContainerTokenSecretManager: Updating the current master key for generating tokens
datanode1_1  | 2022-10-20 02:09:44,954 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode1_1  | 2022-10-20 02:09:44,956 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
datanode1_1  | 2022-10-20 02:09:45,059 [main] INFO http.BaseHttpServer: HttpAuthType: hdds.datanode.http.auth.type = kerberos
datanode1_1  | 2022-10-20 02:09:45,169 [main] INFO util.log: Logging initialized @44441ms to org.eclipse.jetty.util.log.Slf4jLog
datanode1_1  | 2022-10-20 02:09:45,889 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode1_1  | 2022-10-20 02:09:45,958 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode1_1  | 2022-10-20 02:09:45,959 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
datanode1_1  | 2022-10-20 02:09:45,959 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode1_1  | 2022-10-20 02:09:45,959 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode1_1  | 2022-10-20 02:09:45,991 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.datanode.http.auth.kerberos.principal keytabKey: hdds.datanode.http.auth.kerberos.keytab
datanode1_1  | 2022-10-20 02:09:46,327 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode1_1  | 2022-10-20 02:09:46,328 [main] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
datanode1_1  | 2022-10-20 02:09:46,562 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode1_1  | 2022-10-20 02:09:46,562 [main] INFO server.session: No SessionScavenger set, using defaults
datanode1_1  | 2022-10-20 02:09:46,569 [main] INFO server.session: node0 Scavenging every 660000ms
datanode1_1  | 2022-10-20 02:09:46,630 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode1_1  | 2022-10-20 02:09:46,643 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6ed2aa8a{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode1_1  | 2022-10-20 02:09:46,648 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@8850865{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode1_1  | 2022-10-20 02:09:47,253 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode1_1  | 2022-10-20 02:09:47,268 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@55880c{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-1546879760997345859/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode1_1  | 2022-10-20 02:09:47,384 [main] INFO server.AbstractConnector: Started ServerConnector@504216ff{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
datanode1_1  | 2022-10-20 02:09:47,385 [main] INFO server.Server: Started @46658ms
datanode1_1  | 2022-10-20 02:09:47,405 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode1_1  | 2022-10-20 02:09:47,405 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode1_1  | 2022-10-20 02:09:47,407 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode1_1  | 2022-10-20 02:09:47,444 [Datanode State Machine Daemon Thread] INFO statemachine.DatanodeStateMachine: Ozone container server started.
datanode1_1  | 2022-10-20 02:09:47,635 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@192b20b5] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode1_1  | 2022-10-20 02:09:48,189 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.25.0.115:9891
datanode1_1  | 2022-10-20 02:09:48,252 [Datanode State Machine Task Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode1_1  | 2022-10-20 02:09:50,361 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO volume.HddsVolume: SchemaV3 db is created and loaded at /data/hdds/hdds/CID-959c5f9a-2485-4f2a-8075-3da9fe7c4057/DS-268b71d7-78a8-4da3-b62d-2c807f01391c/container.db for volume DS-268b71d7-78a8-4da3-b62d-2c807f01391c
datanode1_1  | 2022-10-20 02:09:50,377 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO volume.HddsVolume: SchemaV3 db is stopped at /data/hdds/hdds/CID-959c5f9a-2485-4f2a-8075-3da9fe7c4057/DS-268b71d7-78a8-4da3-b62d-2c807f01391c/container.db for volume DS-268b71d7-78a8-4da3-b62d-2c807f01391c
datanode1_1  | 2022-10-20 02:09:50,378 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode1_1  | 2022-10-20 02:09:50,380 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode1_1  | 2022-10-20 02:09:50,600 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 4026c186-2529-49de-a2d8-dcba1039e356
datanode1_1  | 2022-10-20 02:09:50,673 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO server.RaftServer: 4026c186-2529-49de-a2d8-dcba1039e356: start RPC server
datanode1_1  | 2022-10-20 02:09:50,675 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO server.GrpcService: 4026c186-2529-49de-a2d8-dcba1039e356: GrpcService started, listening on 9858
datanode1_1  | 2022-10-20 02:09:50,675 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO server.GrpcService: 4026c186-2529-49de-a2d8-dcba1039e356: GrpcService started, listening on 9856
datanode1_1  | 2022-10-20 02:09:50,684 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO server.GrpcService: 4026c186-2529-49de-a2d8-dcba1039e356: GrpcService started, listening on 9857
datanode1_1  | 2022-10-20 02:09:50,702 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 4026c186-2529-49de-a2d8-dcba1039e356 is started using port 9858 for RATIS
datanode1_1  | 2022-10-20 02:09:50,702 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 4026c186-2529-49de-a2d8-dcba1039e356 is started using port 9857 for RATIS_ADMIN
datanode1_1  | 2022-10-20 02:09:50,702 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 4026c186-2529-49de-a2d8-dcba1039e356 is started using port 9856 for RATIS_SERVER
datanode1_1  | 2022-10-20 02:09:50,705 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-4026c186-2529-49de-a2d8-dcba1039e356: Started
datanode1_1  | 2022-10-20 02:09:50,767 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode1_1  | 2022-10-20 02:09:50,770 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode1_1  | 2022-10-20 02:09:54,877 [Command processor thread] INFO server.RaftServer: 4026c186-2529-49de-a2d8-dcba1039e356: addNew group-44E7403E0592:[922d5e53-2e0d-4e01-adf2-129a3cebef39|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1|startupRole:FOLLOWER, 4026c186-2529-49de-a2d8-dcba1039e356|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0|startupRole:FOLLOWER, e4d9a0e3-266c-4558-944a-cafbea7b03e5|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0|startupRole:FOLLOWER] returns group-44E7403E0592:java.util.concurrent.CompletableFuture@32441ac3[Not completed]
datanode1_1  | 2022-10-20 02:09:55,235 [pool-23-thread-1] INFO server.RaftServer$Division: 4026c186-2529-49de-a2d8-dcba1039e356: new RaftServerImpl for group-44E7403E0592:[922d5e53-2e0d-4e01-adf2-129a3cebef39|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1|startupRole:FOLLOWER, 4026c186-2529-49de-a2d8-dcba1039e356|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0|startupRole:FOLLOWER, e4d9a0e3-266c-4558-944a-cafbea7b03e5|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
datanode1_1  | 2022-10-20 02:09:55,236 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode1_1  | 2022-10-20 02:09:55,253 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode1_1  | 2022-10-20 02:09:55,253 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode1_1  | 2022-10-20 02:09:55,253 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode1_1  | 2022-10-20 02:09:55,254 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode1_1  | 2022-10-20 02:09:55,254 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode1_1  | 2022-10-20 02:09:55,277 [pool-23-thread-1] INFO server.RaftServer$Division: 4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592: ConfigurationManager, init=-1: peers:[922d5e53-2e0d-4e01-adf2-129a3cebef39|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1|startupRole:FOLLOWER, 4026c186-2529-49de-a2d8-dcba1039e356|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0|startupRole:FOLLOWER, e4d9a0e3-266c-4558-944a-cafbea7b03e5|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
datanode1_1  | 2022-10-20 02:09:55,277 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode1_1  | 2022-10-20 02:09:55,315 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode1_1  | 2022-10-20 02:09:55,316 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode1_1  | 2022-10-20 02:09:55,344 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode1_1  | 2022-10-20 02:09:55,361 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode1_1  | 2022-10-20 02:09:55,361 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode1_1  | 2022-10-20 02:09:55,593 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode1_1  | 2022-10-20 02:09:55,593 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode1_1  | 2022-10-20 02:09:55,609 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode1_1  | 2022-10-20 02:09:55,609 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode1_1  | 2022-10-20 02:09:55,619 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode1_1  | 2022-10-20 02:09:55,620 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/904a7869-3351-4618-b9db-44e7403e0592 does not exist. Creating ...
datanode1_1  | 2022-10-20 02:09:55,653 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/904a7869-3351-4618-b9db-44e7403e0592/in_use.lock acquired by nodename 6@99666f78dec4
datanode1_1  | 2022-10-20 02:09:55,675 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/904a7869-3351-4618-b9db-44e7403e0592 has been successfully formatted.
datanode1_1  | 2022-10-20 02:09:55,774 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-44E7403E0592: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode1_1  | 2022-10-20 02:09:55,781 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode1_1  | 2022-10-20 02:09:55,838 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode1_1  | 2022-10-20 02:09:55,838 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode1_1  | 2022-10-20 02:09:55,851 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode1_1  | 2022-10-20 02:09:55,858 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
datanode1_1  | 2022-10-20 02:09:55,909 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2022-10-20 02:09:55,939 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode1_1  | 2022-10-20 02:09:55,939 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode1_1  | 2022-10-20 02:09:55,958 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/904a7869-3351-4618-b9db-44e7403e0592
datanode1_1  | 2022-10-20 02:09:55,958 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode1_1  | 2022-10-20 02:09:55,958 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode1_1  | 2022-10-20 02:09:55,966 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2022-10-20 02:09:55,966 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode2_1  | Sleeping for 5 seconds
datanode2_1  | Waiting for the service scm3.org:9894
datanode2_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
datanode2_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode2_1  | 2022-10-20 02:09:09,226 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode2_1  | /************************************************************
datanode2_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode2_1  | STARTUP_MSG:   host = c2c35b3075dc/172.25.0.103
datanode2_1  | STARTUP_MSG:   args = []
datanode2_1  | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
datanode1_1  | 2022-10-20 02:09:55,966 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode1_1  | 2022-10-20 02:09:55,967 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode1_1  | 2022-10-20 02:09:55,967 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode1_1  | 2022-10-20 02:09:55,968 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode1_1  | 2022-10-20 02:09:56,011 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode1_1  | 2022-10-20 02:09:56,011 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode1_1  | 2022-10-20 02:09:56,012 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
datanode1_1  | 2022-10-20 02:09:56,012 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode1_1  | 2022-10-20 02:09:56,032 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode1_1  | 2022-10-20 02:09:56,032 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode1_1  | 2022-10-20 02:09:56,042 [pool-23-thread-1] INFO server.RaftServer$Division: 4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592: start as a follower, conf=-1: peers:[922d5e53-2e0d-4e01-adf2-129a3cebef39|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1|startupRole:FOLLOWER, 4026c186-2529-49de-a2d8-dcba1039e356|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0|startupRole:FOLLOWER, e4d9a0e3-266c-4558-944a-cafbea7b03e5|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
datanode1_1  | 2022-10-20 02:09:56,042 [pool-23-thread-1] INFO server.RaftServer$Division: 4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode1_1  | 2022-10-20 02:09:56,049 [pool-23-thread-1] INFO impl.RoleInfo: 4026c186-2529-49de-a2d8-dcba1039e356: start 4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-FollowerState
datanode1_1  | 2022-10-20 02:09:56,071 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-44E7403E0592,id=4026c186-2529-49de-a2d8-dcba1039e356
datanode1_1  | 2022-10-20 02:09:56,076 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode1_1  | 2022-10-20 02:09:56,076 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode1_1  | 2022-10-20 02:09:56,076 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode1_1  | 2022-10-20 02:09:56,077 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode1_1  | 2022-10-20 02:09:56,081 [4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode1_1  | 2022-10-20 02:09:56,086 [4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode1_1  | 2022-10-20 02:09:56,145 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=904a7869-3351-4618-b9db-44e7403e0592
datanode1_1  | 2022-10-20 02:10:00,332 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=904a7869-3351-4618-b9db-44e7403e0592.
datanode1_1  | 2022-10-20 02:10:00,334 [pool-23-thread-1] INFO server.RaftServer$Division: 4026c186-2529-49de-a2d8-dcba1039e356: new RaftServerImpl for group-D27615E20C89:[922d5e53-2e0d-4e01-adf2-129a3cebef39|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0|startupRole:FOLLOWER, 4026c186-2529-49de-a2d8-dcba1039e356|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1|startupRole:FOLLOWER, e4d9a0e3-266c-4558-944a-cafbea7b03e5|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
datanode1_1  | 2022-10-20 02:10:00,340 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode1_1  | 2022-10-20 02:10:00,341 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode1_1  | 2022-10-20 02:10:00,341 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode1_1  | 2022-10-20 02:10:00,341 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode1_1  | 2022-10-20 02:10:00,341 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode1_1  | 2022-10-20 02:10:00,341 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode1_1  | 2022-10-20 02:10:00,341 [pool-23-thread-1] INFO server.RaftServer$Division: 4026c186-2529-49de-a2d8-dcba1039e356@group-D27615E20C89: ConfigurationManager, init=-1: peers:[922d5e53-2e0d-4e01-adf2-129a3cebef39|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0|startupRole:FOLLOWER, 4026c186-2529-49de-a2d8-dcba1039e356|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1|startupRole:FOLLOWER, e4d9a0e3-266c-4558-944a-cafbea7b03e5|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
datanode1_1  | 2022-10-20 02:10:00,341 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode1_1  | 2022-10-20 02:10:00,342 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode1_1  | 2022-10-20 02:10:00,342 [Command processor thread] INFO server.RaftServer: 4026c186-2529-49de-a2d8-dcba1039e356: addNew group-D27615E20C89:[922d5e53-2e0d-4e01-adf2-129a3cebef39|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0|startupRole:FOLLOWER, 4026c186-2529-49de-a2d8-dcba1039e356|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1|startupRole:FOLLOWER, e4d9a0e3-266c-4558-944a-cafbea7b03e5|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0|startupRole:FOLLOWER] returns group-D27615E20C89:java.util.concurrent.CompletableFuture@4ed4bd5c[Not completed]
datanode1_1  | 2022-10-20 02:10:00,359 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode1_1  | 2022-10-20 02:10:00,381 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode1_1  | 2022-10-20 02:10:00,381 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode1_1  | 2022-10-20 02:10:00,381 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode1_1  | 2022-10-20 02:10:00,382 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode2_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.2.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.4.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.4.0.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.4.0.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.4.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.4.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.32.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.4.5.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.4.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.4.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.4.0.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.4.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.4.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.3.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.4.0.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.3.0-SNAPSHOT.jar
datanode2_1  | STARTUP_MSG:   build = https://github.com/apache/ozone/ff6d15f5df822a5a3c776320b032fad3dd380f95 ; compiled by 'runner' on 2022-10-20T01:41Z
datanode2_1  | STARTUP_MSG:   java = 11.0.14.1
datanode2_1  | ************************************************************/
datanode2_1  | 2022-10-20 02:09:09,262 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode2_1  | 2022-10-20 02:09:09,644 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode2_1  | 2022-10-20 02:09:10,214 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode2_1  | 2022-10-20 02:09:11,145 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode2_1  | 2022-10-20 02:09:11,145 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode2_1  | 2022-10-20 02:09:11,631 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:c2c35b3075dc ip:172.25.0.103
datanode2_1  | 2022-10-20 02:09:14,612 [main] INFO ozone.HddsDatanodeService: Ozone security is enabled. Attempting login for Hdds Datanode user. Principal: dn/dn@EXAMPLE.COM,keytab: /etc/security/keytabs/dn.keytab
datanode2_1  | 2022-10-20 02:09:15,452 [main] INFO security.UserGroupInformation: Login successful for user dn/dn@EXAMPLE.COM using keytab file dn.keytab. Keytab auto renewal enabled : false
datanode2_1  | 2022-10-20 02:09:15,452 [main] INFO ozone.HddsDatanodeService: Hdds Datanode login successful.
datanode2_1  | 2022-10-20 02:09:17,600 [main] INFO ozone.HddsDatanodeService: Initializing secure Datanode.
datanode2_1  | 2022-10-20 02:09:17,600 [main] ERROR client.DNCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
datanode2_1  | 2022-10-20 02:09:17,600 [main] INFO client.DNCertificateClient: Certificate client init case: 0
datanode2_1  | 2022-10-20 02:09:17,615 [main] INFO client.DNCertificateClient: Creating keypair for client as keypair and certificate not found.
datanode2_1  | 2022-10-20 02:09:23,204 [main] INFO ozone.HddsDatanodeService: Init response: GETCERT
datanode2_1  | 2022-10-20 02:09:23,347 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.103,host:c2c35b3075dc
datanode2_1  | 2022-10-20 02:09:23,350 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
datanode2_1  | 2022-10-20 02:09:23,362 [main] ERROR client.DNCertificateClient: Invalid domain c2c35b3075dc
datanode2_1  | 2022-10-20 02:09:23,364 [main] INFO ozone.HddsDatanodeService: Creating csr for DN-> subject:dn@c2c35b3075dc
datanode2_1  | 2022-10-20 02:09:27,039 [main] INFO client.DNCertificateClient: Loading certificate from location:/data/metadata/dn/certs.
datanode2_1  | 2022-10-20 02:09:27,107 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/1082772173580.crt.
datanode2_1  | 2022-10-20 02:09:27,135 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/ROOTCA-1.crt.
datanode2_1  | 2022-10-20 02:09:27,163 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/CA-1003431474332.crt.
datanode2_1  | 2022-10-20 02:09:27,163 [main] INFO ozone.HddsDatanodeService: Successfully stored SCM signed certificate, case:GETCERT.
datanode2_1  | 2022-10-20 02:09:27,290 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
datanode2_1  | 2022-10-20 02:09:28,202 [main] INFO reflections.Reflections: Reflections took 745 ms to scan 2 urls, producing 92 keys and 204 values 
datanode2_1  | 2022-10-20 02:09:28,602 [main] INFO statemachine.DatanodeStateMachine: Datanode State Machine Task Thread Pool size 4
datanode2_1  | 2022-10-20 02:09:29,435 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode2_1  | 2022-10-20 02:09:29,517 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89297309696
datanode2_1  | 2022-10-20 02:09:29,560 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode2_1  | 2022-10-20 02:09:29,578 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode2_1  | 2022-10-20 02:09:29,717 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode2_1  | 2022-10-20 02:09:29,808 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode2_1  | 2022-10-20 02:09:29,827 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/metadata/ratis/scmUsed not found
datanode2_1  | 2022-10-20 02:09:29,831 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
datanode2_1  | 2022-10-20 02:09:29,834 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/metadata/ratis
datanode2_1  | 2022-10-20 02:09:29,834 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/metadata/ratis
datanode2_1  | 2022-10-20 02:09:30,065 [Thread-8] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode2_1  | 2022-10-20 02:09:30,070 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode2_1  | 2022-10-20 02:09:34,417 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for DNAudit to [].
datanode2_1  | 2022-10-20 02:09:35,781 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode2_1  | 2022-10-20 02:09:35,976 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
datanode2_1  | 2022-10-20 02:09:36,480 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
datanode2_1  | 2022-10-20 02:09:36,494 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
datanode2_1  | 2022-10-20 02:09:36,503 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.host = null (fallback to raft.grpc.server.host)
datanode2_1  | 2022-10-20 02:09:36,504 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
datanode2_1  | 2022-10-20 02:09:36,509 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.host = null (default)
datanode2_1  | 2022-10-20 02:09:36,509 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
datanode2_1  | 2022-10-20 02:09:36,513 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode2_1  | 2022-10-20 02:09:36,517 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2022-10-20 02:09:36,526 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode2_1  | 2022-10-20 02:09:36,533 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode2_1  | 2022-10-20 02:09:36,607 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
datanode2_1  | 2022-10-20 02:09:36,636 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
datanode1_1  | 2022-10-20 02:10:00,382 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode1_1  | 2022-10-20 02:10:00,382 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode1_1  | 2022-10-20 02:10:00,382 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode1_1  | 2022-10-20 02:10:00,385 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode1_1  | 2022-10-20 02:10:00,385 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/928115e6-57fc-4e60-abe7-d27615e20c89 does not exist. Creating ...
datanode1_1  | 2022-10-20 02:10:00,387 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/928115e6-57fc-4e60-abe7-d27615e20c89/in_use.lock acquired by nodename 6@99666f78dec4
datanode1_1  | 2022-10-20 02:10:00,391 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/928115e6-57fc-4e60-abe7-d27615e20c89 has been successfully formatted.
datanode1_1  | 2022-10-20 02:10:00,391 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-D27615E20C89: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode1_1  | 2022-10-20 02:10:00,391 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode1_1  | 2022-10-20 02:10:00,392 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode1_1  | 2022-10-20 02:10:00,392 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode1_1  | 2022-10-20 02:10:00,392 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode1_1  | 2022-10-20 02:10:00,431 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
datanode1_1  | 2022-10-20 02:10:00,433 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2022-10-20 02:10:00,434 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode1_1  | 2022-10-20 02:10:00,439 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode1_1  | 2022-10-20 02:10:00,450 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 4026c186-2529-49de-a2d8-dcba1039e356@group-D27615E20C89-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/928115e6-57fc-4e60-abe7-d27615e20c89
datanode1_1  | 2022-10-20 02:10:00,450 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode1_1  | 2022-10-20 02:10:00,457 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode1_1  | 2022-10-20 02:10:00,458 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2022-10-20 02:10:00,458 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode1_1  | 2022-10-20 02:10:00,459 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode1_1  | 2022-10-20 02:10:00,459 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode1_1  | 2022-10-20 02:10:00,460 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode1_1  | 2022-10-20 02:10:00,460 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode1_1  | 2022-10-20 02:10:00,461 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode1_1  | 2022-10-20 02:10:00,464 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode1_1  | 2022-10-20 02:10:00,465 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
datanode1_1  | 2022-10-20 02:10:00,465 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode1_1  | 2022-10-20 02:10:00,466 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 4026c186-2529-49de-a2d8-dcba1039e356@group-D27615E20C89-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode1_1  | 2022-10-20 02:10:00,467 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 4026c186-2529-49de-a2d8-dcba1039e356@group-D27615E20C89-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode1_1  | 2022-10-20 02:10:00,479 [pool-23-thread-1] INFO server.RaftServer$Division: 4026c186-2529-49de-a2d8-dcba1039e356@group-D27615E20C89: start as a follower, conf=-1: peers:[922d5e53-2e0d-4e01-adf2-129a3cebef39|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0|startupRole:FOLLOWER, 4026c186-2529-49de-a2d8-dcba1039e356|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1|startupRole:FOLLOWER, e4d9a0e3-266c-4558-944a-cafbea7b03e5|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
datanode1_1  | 2022-10-20 02:10:00,479 [pool-23-thread-1] INFO server.RaftServer$Division: 4026c186-2529-49de-a2d8-dcba1039e356@group-D27615E20C89: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode1_1  | 2022-10-20 02:10:00,480 [pool-23-thread-1] INFO impl.RoleInfo: 4026c186-2529-49de-a2d8-dcba1039e356: start 4026c186-2529-49de-a2d8-dcba1039e356@group-D27615E20C89-FollowerState
datanode1_1  | 2022-10-20 02:10:00,497 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-D27615E20C89,id=4026c186-2529-49de-a2d8-dcba1039e356
datanode1_1  | 2022-10-20 02:10:00,500 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode1_1  | 2022-10-20 02:10:00,500 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode1_1  | 2022-10-20 02:10:00,502 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode1_1  | 2022-10-20 02:10:00,505 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode1_1  | 2022-10-20 02:10:00,507 [4026c186-2529-49de-a2d8-dcba1039e356@group-D27615E20C89-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode1_1  | 2022-10-20 02:10:00,523 [4026c186-2529-49de-a2d8-dcba1039e356@group-D27615E20C89-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode1_1  | 2022-10-20 02:10:00,524 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=928115e6-57fc-4e60-abe7-d27615e20c89
datanode1_1  | 2022-10-20 02:10:01,206 [4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-FollowerState] INFO impl.FollowerState: 4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5162960303ns, electionTimeout:5119ms
datanode1_1  | 2022-10-20 02:10:01,206 [4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-FollowerState] INFO impl.RoleInfo: 4026c186-2529-49de-a2d8-dcba1039e356: shutdown 4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-FollowerState
datanode2_1  | 2022-10-20 02:09:36,649 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
datanode2_1  | 2022-10-20 02:09:42,044 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
datanode2_1  | 2022-10-20 02:09:42,055 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
datanode2_1  | 2022-10-20 02:09:42,071 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
datanode2_1  | 2022-10-20 02:09:42,071 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode2_1  | 2022-10-20 02:09:42,071 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode2_1  | 2022-10-20 02:09:42,082 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode2_1  | 2022-10-20 02:09:42,426 [main] INFO server.XceiverServerGrpc: GrpcServer channel type EpollServerSocketChannel
datanode2_1  | 2022-10-20 02:09:43,940 [main] INFO token.OzoneBlockTokenSecretManager: Updating the current master key for generating tokens
datanode2_1  | 2022-10-20 02:09:43,943 [main] INFO token.ContainerTokenSecretManager: Updating the current master key for generating tokens
datanode2_1  | 2022-10-20 02:09:44,349 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode2_1  | 2022-10-20 02:09:44,353 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
datanode2_1  | 2022-10-20 02:09:44,353 [main] INFO http.BaseHttpServer: HttpAuthType: hdds.datanode.http.auth.type = kerberos
datanode2_1  | 2022-10-20 02:09:44,610 [main] INFO util.log: Logging initialized @44737ms to org.eclipse.jetty.util.log.Slf4jLog
datanode2_1  | 2022-10-20 02:09:45,176 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode2_1  | 2022-10-20 02:09:45,212 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode2_1  | 2022-10-20 02:09:45,227 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
datanode2_1  | 2022-10-20 02:09:45,227 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode2_1  | 2022-10-20 02:09:45,227 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode2_1  | 2022-10-20 02:09:45,241 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.datanode.http.auth.kerberos.principal keytabKey: hdds.datanode.http.auth.kerberos.keytab
datanode2_1  | 2022-10-20 02:09:45,394 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode2_1  | 2022-10-20 02:09:45,403 [main] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
datanode2_1  | 2022-10-20 02:09:45,600 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode2_1  | 2022-10-20 02:09:45,600 [main] INFO server.session: No SessionScavenger set, using defaults
datanode2_1  | 2022-10-20 02:09:45,601 [main] INFO server.session: node0 Scavenging every 660000ms
datanode2_1  | 2022-10-20 02:09:45,706 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode2_1  | 2022-10-20 02:09:45,726 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@8850865{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode2_1  | 2022-10-20 02:09:45,727 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5f455d91{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode2_1  | 2022-10-20 02:09:46,422 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode2_1  | 2022-10-20 02:09:46,506 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@5b076d23{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-13426058281562443563/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode2_1  | 2022-10-20 02:09:46,574 [main] INFO server.AbstractConnector: Started ServerConnector@f4e235e{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
datanode2_1  | 2022-10-20 02:09:46,575 [main] INFO server.Server: Started @46702ms
datanode2_1  | 2022-10-20 02:09:46,615 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode2_1  | 2022-10-20 02:09:46,615 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode2_1  | 2022-10-20 02:09:46,620 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode2_1  | 2022-10-20 02:09:46,635 [Datanode State Machine Daemon Thread] INFO statemachine.DatanodeStateMachine: Ozone container server started.
datanode2_1  | 2022-10-20 02:09:46,753 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2bde81bb] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode2_1  | 2022-10-20 02:09:47,321 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.25.0.115:9891
datanode2_1  | 2022-10-20 02:09:47,355 [Datanode State Machine Task Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode2_1  | 2022-10-20 02:09:49,648 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO volume.HddsVolume: SchemaV3 db is created and loaded at /data/hdds/hdds/CID-959c5f9a-2485-4f2a-8075-3da9fe7c4057/DS-ba36cfd5-4a30-44d1-a7c3-42839d36a6cb/container.db for volume DS-ba36cfd5-4a30-44d1-a7c3-42839d36a6cb
datanode2_1  | 2022-10-20 02:09:49,678 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO volume.HddsVolume: SchemaV3 db is stopped at /data/hdds/hdds/CID-959c5f9a-2485-4f2a-8075-3da9fe7c4057/DS-ba36cfd5-4a30-44d1-a7c3-42839d36a6cb/container.db for volume DS-ba36cfd5-4a30-44d1-a7c3-42839d36a6cb
datanode2_1  | 2022-10-20 02:09:49,685 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode2_1  | 2022-10-20 02:09:49,687 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode2_1  | 2022-10-20 02:09:49,878 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 922d5e53-2e0d-4e01-adf2-129a3cebef39
datanode2_1  | 2022-10-20 02:09:50,030 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO server.RaftServer: 922d5e53-2e0d-4e01-adf2-129a3cebef39: start RPC server
datanode2_1  | 2022-10-20 02:09:50,041 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO server.GrpcService: 922d5e53-2e0d-4e01-adf2-129a3cebef39: GrpcService started, listening on 9858
datanode2_1  | 2022-10-20 02:09:50,047 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO server.GrpcService: 922d5e53-2e0d-4e01-adf2-129a3cebef39: GrpcService started, listening on 9856
datanode2_1  | 2022-10-20 02:09:50,053 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO server.GrpcService: 922d5e53-2e0d-4e01-adf2-129a3cebef39: GrpcService started, listening on 9857
datanode2_1  | 2022-10-20 02:09:50,064 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 922d5e53-2e0d-4e01-adf2-129a3cebef39 is started using port 9858 for RATIS
datanode2_1  | 2022-10-20 02:09:50,065 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 922d5e53-2e0d-4e01-adf2-129a3cebef39 is started using port 9857 for RATIS_ADMIN
datanode2_1  | 2022-10-20 02:09:50,065 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 922d5e53-2e0d-4e01-adf2-129a3cebef39 is started using port 9856 for RATIS_SERVER
datanode2_1  | 2022-10-20 02:09:50,067 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-922d5e53-2e0d-4e01-adf2-129a3cebef39: Started
datanode2_1  | 2022-10-20 02:09:50,138 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode2_1  | 2022-10-20 02:09:50,144 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode2_1  | 2022-10-20 02:09:59,079 [grpc-default-executor-1] INFO server.RaftServer: 922d5e53-2e0d-4e01-adf2-129a3cebef39: addNew group-44E7403E0592:[922d5e53-2e0d-4e01-adf2-129a3cebef39|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1|startupRole:FOLLOWER, 4026c186-2529-49de-a2d8-dcba1039e356|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0|startupRole:FOLLOWER, e4d9a0e3-266c-4558-944a-cafbea7b03e5|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0|startupRole:FOLLOWER] returns group-44E7403E0592:java.util.concurrent.CompletableFuture@b0485fc[Not completed]
datanode2_1  | 2022-10-20 02:09:59,274 [pool-23-thread-1] INFO server.RaftServer$Division: 922d5e53-2e0d-4e01-adf2-129a3cebef39: new RaftServerImpl for group-44E7403E0592:[922d5e53-2e0d-4e01-adf2-129a3cebef39|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1|startupRole:FOLLOWER, 4026c186-2529-49de-a2d8-dcba1039e356|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0|startupRole:FOLLOWER, e4d9a0e3-266c-4558-944a-cafbea7b03e5|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
datanode2_1  | 2022-10-20 02:09:59,282 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode2_1  | 2022-10-20 02:09:59,284 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode2_1  | 2022-10-20 02:09:59,286 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode2_1  | 2022-10-20 02:09:59,286 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode2_1  | 2022-10-20 02:09:59,288 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode2_1  | 2022-10-20 02:09:59,288 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode2_1  | 2022-10-20 02:09:59,327 [pool-23-thread-1] INFO server.RaftServer$Division: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592: ConfigurationManager, init=-1: peers:[922d5e53-2e0d-4e01-adf2-129a3cebef39|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1|startupRole:FOLLOWER, 4026c186-2529-49de-a2d8-dcba1039e356|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0|startupRole:FOLLOWER, e4d9a0e3-266c-4558-944a-cafbea7b03e5|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
datanode2_1  | 2022-10-20 02:09:59,333 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode2_1  | 2022-10-20 02:09:59,355 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode2_1  | 2022-10-20 02:09:59,369 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode2_1  | 2022-10-20 02:09:59,391 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode2_1  | 2022-10-20 02:09:59,416 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode2_1  | 2022-10-20 02:09:59,426 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode2_1  | 2022-10-20 02:09:59,570 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode2_1  | 2022-10-20 02:09:59,589 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode2_1  | 2022-10-20 02:09:59,589 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode2_1  | 2022-10-20 02:09:59,590 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode2_1  | 2022-10-20 02:09:59,591 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode2_1  | 2022-10-20 02:09:59,607 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/904a7869-3351-4618-b9db-44e7403e0592 does not exist. Creating ...
datanode2_1  | 2022-10-20 02:09:59,627 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/904a7869-3351-4618-b9db-44e7403e0592/in_use.lock acquired by nodename 7@c2c35b3075dc
datanode2_1  | 2022-10-20 02:09:59,658 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/904a7869-3351-4618-b9db-44e7403e0592 has been successfully formatted.
datanode2_1  | 2022-10-20 02:09:59,735 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-44E7403E0592: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode2_1  | 2022-10-20 02:09:59,758 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode2_1  | 2022-10-20 02:09:59,790 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode2_1  | 2022-10-20 02:09:59,791 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2022-10-20 02:09:59,792 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode2_1  | 2022-10-20 02:09:59,795 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
datanode2_1  | 2022-10-20 02:09:59,801 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2022-10-20 02:09:59,852 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode2_1  | 2022-10-20 02:09:59,880 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode2_1  | 2022-10-20 02:09:59,922 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/904a7869-3351-4618-b9db-44e7403e0592
datanode2_1  | 2022-10-20 02:09:59,945 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode2_1  | 2022-10-20 02:09:59,946 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode2_1  | 2022-10-20 02:09:59,958 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2022-10-20 02:10:01,207 [4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-FollowerState] INFO server.RaftServer$Division: 4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode1_1  | 2022-10-20 02:10:01,228 [4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode1_1  | 2022-10-20 02:10:01,228 [4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-FollowerState] INFO impl.RoleInfo: 4026c186-2529-49de-a2d8-dcba1039e356: start 4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-LeaderElection1
datanode1_1  | 2022-10-20 02:10:01,276 [4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-LeaderElection1] INFO impl.LeaderElection: 4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: peers:[922d5e53-2e0d-4e01-adf2-129a3cebef39|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1|startupRole:FOLLOWER, 4026c186-2529-49de-a2d8-dcba1039e356|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0|startupRole:FOLLOWER, e4d9a0e3-266c-4558-944a-cafbea7b03e5|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
datanode1_1  | 2022-10-20 02:10:01,427 [4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode1_1  | 2022-10-20 02:10:01,434 [4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode1_1  | 2022-10-20 02:10:01,427 [4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-LeaderElection1-1] INFO server.GrpcServerProtocolClient: Build channel for 922d5e53-2e0d-4e01-adf2-129a3cebef39
datanode1_1  | 2022-10-20 02:10:01,434 [4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-LeaderElection1-2] INFO server.GrpcServerProtocolClient: Build channel for e4d9a0e3-266c-4558-944a-cafbea7b03e5
datanode1_1  | 2022-10-20 02:10:02,908 [grpc-default-executor-2] INFO server.RaftServer$Division: 4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592: receive requestVote(ELECTION, e4d9a0e3-266c-4558-944a-cafbea7b03e5, group-44E7403E0592, 1, (t:0, i:0))
datanode1_1  | 2022-10-20 02:10:02,940 [grpc-default-executor-2] INFO impl.VoteContext: 4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-CANDIDATE: reject ELECTION from e4d9a0e3-266c-4558-944a-cafbea7b03e5: already has voted for 4026c186-2529-49de-a2d8-dcba1039e356 at current term 1
datanode1_1  | 2022-10-20 02:10:02,957 [grpc-default-executor-2] INFO server.RaftServer$Division: 4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592 replies to ELECTION vote request: e4d9a0e3-266c-4558-944a-cafbea7b03e5<-4026c186-2529-49de-a2d8-dcba1039e356#0:FAIL-t1. Peer's state: 4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592:t1, leader=null, voted=4026c186-2529-49de-a2d8-dcba1039e356, raftlog=Memoized:4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[922d5e53-2e0d-4e01-adf2-129a3cebef39|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1|startupRole:FOLLOWER, 4026c186-2529-49de-a2d8-dcba1039e356|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0|startupRole:FOLLOWER, e4d9a0e3-266c-4558-944a-cafbea7b03e5|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
datanode1_1  | 2022-10-20 02:10:03,141 [4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-LeaderElection1] INFO impl.LeaderElection: 4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-LeaderElection1: ELECTION REJECTED received 1 response(s) and 0 exception(s):
datanode1_1  | 2022-10-20 02:10:03,143 [4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-LeaderElection1] INFO impl.LeaderElection:   Response 0: 4026c186-2529-49de-a2d8-dcba1039e356<-922d5e53-2e0d-4e01-adf2-129a3cebef39#0:FAIL-t1
datanode1_1  | 2022-10-20 02:10:03,153 [4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-LeaderElection1] INFO impl.LeaderElection: 4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-LeaderElection1 ELECTION round 0: result REJECTED
datanode1_1  | 2022-10-20 02:10:03,154 [4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-LeaderElection1] INFO server.RaftServer$Division: 4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
datanode1_1  | 2022-10-20 02:10:03,154 [4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-LeaderElection1] INFO impl.RoleInfo: 4026c186-2529-49de-a2d8-dcba1039e356: shutdown 4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-LeaderElection1
datanode1_1  | 2022-10-20 02:10:03,154 [4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-LeaderElection1] INFO impl.RoleInfo: 4026c186-2529-49de-a2d8-dcba1039e356: start 4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-FollowerState
datanode1_1  | 2022-10-20 02:10:03,165 [4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode1_1  | 2022-10-20 02:10:03,182 [4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode1_1  | 2022-10-20 02:10:03,272 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=928115e6-57fc-4e60-abe7-d27615e20c89.
datanode1_1  | 2022-10-20 02:10:03,274 [pool-23-thread-1] INFO server.RaftServer$Division: 4026c186-2529-49de-a2d8-dcba1039e356: new RaftServerImpl for group-BC1BBCBC6578:[4026c186-2529-49de-a2d8-dcba1039e356|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
datanode1_1  | 2022-10-20 02:10:03,277 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode1_1  | 2022-10-20 02:10:03,277 [Command processor thread] INFO server.RaftServer: 4026c186-2529-49de-a2d8-dcba1039e356: addNew group-BC1BBCBC6578:[4026c186-2529-49de-a2d8-dcba1039e356|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1|startupRole:FOLLOWER] returns group-BC1BBCBC6578:java.util.concurrent.CompletableFuture@5cf35956[Not completed]
datanode1_1  | 2022-10-20 02:10:03,277 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode1_1  | 2022-10-20 02:10:03,278 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode1_1  | 2022-10-20 02:10:03,278 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode1_1  | 2022-10-20 02:10:03,278 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode1_1  | 2022-10-20 02:10:03,278 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode1_1  | 2022-10-20 02:10:03,278 [pool-23-thread-1] INFO server.RaftServer$Division: 4026c186-2529-49de-a2d8-dcba1039e356@group-BC1BBCBC6578: ConfigurationManager, init=-1: peers:[4026c186-2529-49de-a2d8-dcba1039e356|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
datanode1_1  | 2022-10-20 02:10:03,278 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode1_1  | 2022-10-20 02:10:03,278 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode1_1  | 2022-10-20 02:10:03,279 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode1_1  | 2022-10-20 02:10:03,279 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode1_1  | 2022-10-20 02:10:03,279 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode1_1  | 2022-10-20 02:10:03,279 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode1_1  | 2022-10-20 02:10:03,280 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode1_1  | 2022-10-20 02:10:03,285 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode1_1  | 2022-10-20 02:10:03,285 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode1_1  | 2022-10-20 02:10:03,285 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode1_1  | 2022-10-20 02:10:03,285 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode1_1  | 2022-10-20 02:10:03,285 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/d523f193-8112-4e25-a36e-bc1bbcbc6578 does not exist. Creating ...
datanode1_1  | 2022-10-20 02:10:03,301 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/d523f193-8112-4e25-a36e-bc1bbcbc6578/in_use.lock acquired by nodename 6@99666f78dec4
datanode1_1  | 2022-10-20 02:10:03,305 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/d523f193-8112-4e25-a36e-bc1bbcbc6578 has been successfully formatted.
datanode1_1  | 2022-10-20 02:10:03,318 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-BC1BBCBC6578: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode1_1  | 2022-10-20 02:10:03,318 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode1_1  | 2022-10-20 02:10:03,318 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode1_1  | 2022-10-20 02:10:03,318 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode1_1  | 2022-10-20 02:10:03,319 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode1_1  | 2022-10-20 02:10:03,319 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
datanode1_1  | 2022-10-20 02:10:03,320 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2022-10-20 02:10:03,320 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode1_1  | 2022-10-20 02:10:03,334 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode1_1  | 2022-10-20 02:10:03,335 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 4026c186-2529-49de-a2d8-dcba1039e356@group-BC1BBCBC6578-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/d523f193-8112-4e25-a36e-bc1bbcbc6578
datanode1_1  | 2022-10-20 02:10:03,354 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode1_1  | 2022-10-20 02:10:03,354 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode1_1  | 2022-10-20 02:10:03,354 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2022-10-20 02:10:03,354 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode1_1  | 2022-10-20 02:10:03,354 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode1_1  | 2022-10-20 02:10:03,354 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode1_1  | 2022-10-20 02:10:03,355 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode1_1  | 2022-10-20 02:10:03,355 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode1_1  | 2022-10-20 02:10:03,356 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode1_1  | 2022-10-20 02:10:03,357 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode1_1  | 2022-10-20 02:10:03,363 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
datanode1_1  | 2022-10-20 02:10:03,363 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode1_1  | 2022-10-20 02:10:03,377 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 4026c186-2529-49de-a2d8-dcba1039e356@group-BC1BBCBC6578-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode1_1  | 2022-10-20 02:10:03,378 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 4026c186-2529-49de-a2d8-dcba1039e356@group-BC1BBCBC6578-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode1_1  | 2022-10-20 02:10:03,379 [pool-23-thread-1] INFO server.RaftServer$Division: 4026c186-2529-49de-a2d8-dcba1039e356@group-BC1BBCBC6578: start as a follower, conf=-1: peers:[4026c186-2529-49de-a2d8-dcba1039e356|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode1_1  | 2022-10-20 02:10:03,379 [pool-23-thread-1] INFO server.RaftServer$Division: 4026c186-2529-49de-a2d8-dcba1039e356@group-BC1BBCBC6578: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode1_1  | 2022-10-20 02:10:03,380 [pool-23-thread-1] INFO impl.RoleInfo: 4026c186-2529-49de-a2d8-dcba1039e356: start 4026c186-2529-49de-a2d8-dcba1039e356@group-BC1BBCBC6578-FollowerState
datanode1_1  | 2022-10-20 02:10:03,380 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-BC1BBCBC6578,id=4026c186-2529-49de-a2d8-dcba1039e356
datanode1_1  | 2022-10-20 02:10:03,385 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode1_1  | 2022-10-20 02:10:03,385 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode1_1  | 2022-10-20 02:10:03,386 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode1_1  | 2022-10-20 02:10:03,386 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode1_1  | 2022-10-20 02:10:03,387 [4026c186-2529-49de-a2d8-dcba1039e356@group-BC1BBCBC6578-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode1_1  | 2022-10-20 02:10:03,389 [4026c186-2529-49de-a2d8-dcba1039e356@group-BC1BBCBC6578-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode1_1  | 2022-10-20 02:10:03,389 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=d523f193-8112-4e25-a36e-bc1bbcbc6578
datanode1_1  | 2022-10-20 02:10:03,389 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=d523f193-8112-4e25-a36e-bc1bbcbc6578.
datanode2_1  | 2022-10-20 02:09:59,962 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode2_1  | 2022-10-20 02:09:59,963 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode2_1  | 2022-10-20 02:09:59,968 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode2_1  | 2022-10-20 02:09:59,968 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode2_1  | 2022-10-20 02:09:59,969 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode2_1  | 2022-10-20 02:10:00,021 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode2_1  | 2022-10-20 02:10:00,022 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode2_1  | 2022-10-20 02:10:00,032 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
datanode2_1  | 2022-10-20 02:10:00,037 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode2_1  | 2022-10-20 02:10:00,079 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode2_1  | 2022-10-20 02:10:00,079 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode2_1  | 2022-10-20 02:10:00,091 [pool-23-thread-1] INFO server.RaftServer$Division: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592: start as a follower, conf=-1: peers:[922d5e53-2e0d-4e01-adf2-129a3cebef39|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1|startupRole:FOLLOWER, 4026c186-2529-49de-a2d8-dcba1039e356|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0|startupRole:FOLLOWER, e4d9a0e3-266c-4558-944a-cafbea7b03e5|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
datanode2_1  | 2022-10-20 02:10:00,091 [pool-23-thread-1] INFO server.RaftServer$Division: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode2_1  | 2022-10-20 02:10:00,092 [pool-23-thread-1] INFO impl.RoleInfo: 922d5e53-2e0d-4e01-adf2-129a3cebef39: start 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-FollowerState
datanode2_1  | 2022-10-20 02:10:00,116 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode2_1  | 2022-10-20 02:10:00,117 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-44E7403E0592,id=922d5e53-2e0d-4e01-adf2-129a3cebef39
datanode2_1  | 2022-10-20 02:10:00,133 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode2_1  | 2022-10-20 02:10:00,134 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode2_1  | 2022-10-20 02:10:00,203 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode2_1  | 2022-10-20 02:10:00,210 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode2_1  | 2022-10-20 02:10:00,220 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode2_1  | 2022-10-20 02:10:00,955 [grpc-default-executor-0] INFO server.RaftServer: 922d5e53-2e0d-4e01-adf2-129a3cebef39: addNew group-D27615E20C89:[922d5e53-2e0d-4e01-adf2-129a3cebef39|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0|startupRole:FOLLOWER, 4026c186-2529-49de-a2d8-dcba1039e356|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1|startupRole:FOLLOWER, e4d9a0e3-266c-4558-944a-cafbea7b03e5|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0|startupRole:FOLLOWER] returns group-D27615E20C89:java.util.concurrent.CompletableFuture@73998100[Not completed]
datanode2_1  | 2022-10-20 02:10:00,980 [pool-23-thread-1] INFO server.RaftServer$Division: 922d5e53-2e0d-4e01-adf2-129a3cebef39: new RaftServerImpl for group-D27615E20C89:[922d5e53-2e0d-4e01-adf2-129a3cebef39|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0|startupRole:FOLLOWER, 4026c186-2529-49de-a2d8-dcba1039e356|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1|startupRole:FOLLOWER, e4d9a0e3-266c-4558-944a-cafbea7b03e5|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
datanode2_1  | 2022-10-20 02:10:00,986 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode2_1  | 2022-10-20 02:10:00,986 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode2_1  | 2022-10-20 02:10:00,986 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode2_1  | 2022-10-20 02:10:00,988 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode2_1  | 2022-10-20 02:10:00,988 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode2_1  | 2022-10-20 02:10:00,988 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode2_1  | 2022-10-20 02:10:00,988 [pool-23-thread-1] INFO server.RaftServer$Division: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-D27615E20C89: ConfigurationManager, init=-1: peers:[922d5e53-2e0d-4e01-adf2-129a3cebef39|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0|startupRole:FOLLOWER, 4026c186-2529-49de-a2d8-dcba1039e356|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1|startupRole:FOLLOWER, e4d9a0e3-266c-4558-944a-cafbea7b03e5|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
datanode2_1  | 2022-10-20 02:10:00,989 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode2_1  | 2022-10-20 02:10:00,989 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode2_1  | 2022-10-20 02:10:00,989 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode2_1  | 2022-10-20 02:10:00,990 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode2_1  | 2022-10-20 02:10:00,993 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode2_1  | 2022-10-20 02:10:00,995 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode2_1  | 2022-10-20 02:10:00,999 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode2_1  | 2022-10-20 02:10:01,005 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
kdc_1        | Oct 20 02:07:45 kdc krb5kdc[7](info): Loaded
kdc_1        | Oct 20 02:07:45 kdc krb5kdc[7](Error): preauth spake failed to initialize: No SPAKE preauth groups configured
kdc_1        | Oct 20 02:07:45 kdc krb5kdc[7](info): setting up network...
kdc_1        | Oct 20 02:07:45 kdc krb5kdc[7](info): setsockopt(8,IPV6_V6ONLY,1) worked
kdc_1        | Oct 20 02:07:45 kdc krb5kdc[7](info): setsockopt(10,IPV6_V6ONLY,1) worked
kdc_1        | Oct 20 02:07:45 kdc krb5kdc[7](info): set up 4 sockets
kdc_1        | Oct 20 02:07:45 kdc krb5kdc[7](info): commencing operation
kdc_1        | krb5kdc: starting...
kdc_1        | Oct 20 02:07:48 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1666231668, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Oct 20 02:07:53 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1666231673, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Oct 20 02:07:57 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.114: ISSUE: authtime 1666231677, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, s3g/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Oct 20 02:07:58 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.115: ISSUE: authtime 1666231678, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, recon/recon@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Oct 20 02:08:09 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.117: ISSUE: authtime 1666231689, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Oct 20 02:08:16 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.116: ISSUE: authtime 1666231696, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Oct 20 02:08:20 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1666231673, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Oct 20 02:08:20 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: ISSUE: authtime 1666231678, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, recon/recon@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Oct 20 02:08:21 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1666231689, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Oct 20 02:08:31 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1666231711, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Oct 20 02:08:35 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.117: ISSUE: authtime 1666231715, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Oct 20 02:08:39 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1666231711, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Oct 20 02:08:43 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1666231715, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Oct 20 02:08:44 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1666231724, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Oct 20 02:08:47 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.118: ISSUE: authtime 1666231727, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Oct 20 02:08:48 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.118: ISSUE: authtime 1666231727, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Oct 20 02:08:51 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1666231724, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
datanode2_1  | 2022-10-20 02:10:01,006 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode2_1  | 2022-10-20 02:10:01,006 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode2_1  | 2022-10-20 02:10:01,006 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode2_1  | 2022-10-20 02:10:01,006 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/928115e6-57fc-4e60-abe7-d27615e20c89 does not exist. Creating ...
datanode2_1  | 2022-10-20 02:10:01,011 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/928115e6-57fc-4e60-abe7-d27615e20c89/in_use.lock acquired by nodename 7@c2c35b3075dc
datanode2_1  | 2022-10-20 02:10:01,017 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/928115e6-57fc-4e60-abe7-d27615e20c89 has been successfully formatted.
datanode2_1  | 2022-10-20 02:10:01,017 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-D27615E20C89: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode2_1  | 2022-10-20 02:10:01,048 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode2_1  | 2022-10-20 02:10:01,050 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode2_1  | 2022-10-20 02:10:01,050 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2022-10-20 02:10:01,056 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode2_1  | 2022-10-20 02:10:01,060 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
datanode2_1  | 2022-10-20 02:10:01,063 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2022-10-20 02:10:01,065 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode2_1  | 2022-10-20 02:10:01,081 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode2_1  | 2022-10-20 02:10:01,081 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-D27615E20C89-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/928115e6-57fc-4e60-abe7-d27615e20c89
datanode2_1  | 2022-10-20 02:10:01,082 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode2_1  | 2022-10-20 02:10:01,089 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode2_1  | 2022-10-20 02:10:01,089 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2022-10-20 02:10:01,089 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode2_1  | 2022-10-20 02:10:01,089 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode2_1  | 2022-10-20 02:10:01,089 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode2_1  | 2022-10-20 02:10:01,089 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode2_1  | 2022-10-20 02:10:01,089 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode2_1  | 2022-10-20 02:10:01,090 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode2_1  | 2022-10-20 02:10:01,090 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode2_1  | 2022-10-20 02:10:01,091 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
datanode2_1  | 2022-10-20 02:10:01,091 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode2_1  | 2022-10-20 02:10:01,091 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-D27615E20C89-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode2_1  | 2022-10-20 02:10:01,091 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-D27615E20C89-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode2_1  | 2022-10-20 02:10:01,110 [pool-23-thread-1] INFO server.RaftServer$Division: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-D27615E20C89: start as a follower, conf=-1: peers:[922d5e53-2e0d-4e01-adf2-129a3cebef39|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0|startupRole:FOLLOWER, 4026c186-2529-49de-a2d8-dcba1039e356|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1|startupRole:FOLLOWER, e4d9a0e3-266c-4558-944a-cafbea7b03e5|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
datanode2_1  | 2022-10-20 02:10:01,110 [pool-23-thread-1] INFO server.RaftServer$Division: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-D27615E20C89: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode2_1  | 2022-10-20 02:10:01,110 [pool-23-thread-1] INFO impl.RoleInfo: 922d5e53-2e0d-4e01-adf2-129a3cebef39: start 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-D27615E20C89-FollowerState
datanode2_1  | 2022-10-20 02:10:01,117 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-D27615E20C89,id=922d5e53-2e0d-4e01-adf2-129a3cebef39
datanode2_1  | 2022-10-20 02:10:01,117 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode2_1  | 2022-10-20 02:10:01,117 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode2_1  | 2022-10-20 02:10:01,117 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode2_1  | 2022-10-20 02:10:01,117 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode2_1  | 2022-10-20 02:10:01,119 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-D27615E20C89-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode2_1  | 2022-10-20 02:10:01,170 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-D27615E20C89-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode2_1  | 2022-10-20 02:10:02,771 [grpc-default-executor-0] INFO server.RaftServer$Division: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592: receive requestVote(ELECTION, e4d9a0e3-266c-4558-944a-cafbea7b03e5, group-44E7403E0592, 1, (t:0, i:0))
datanode2_1  | 2022-10-20 02:10:02,773 [grpc-default-executor-0] INFO impl.VoteContext: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-FOLLOWER: reject ELECTION from e4d9a0e3-266c-4558-944a-cafbea7b03e5: our priority 1 > candidate's priority 0
datanode2_1  | 2022-10-20 02:10:02,777 [grpc-default-executor-0] INFO server.RaftServer$Division: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:e4d9a0e3-266c-4558-944a-cafbea7b03e5
datanode2_1  | 2022-10-20 02:10:02,778 [grpc-default-executor-0] INFO impl.RoleInfo: 922d5e53-2e0d-4e01-adf2-129a3cebef39: shutdown 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-FollowerState
datanode1_1  | 2022-10-20 02:10:05,579 [4026c186-2529-49de-a2d8-dcba1039e356@group-D27615E20C89-FollowerState] INFO impl.FollowerState: 4026c186-2529-49de-a2d8-dcba1039e356@group-D27615E20C89-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5099043716ns, electionTimeout:5055ms
datanode1_1  | 2022-10-20 02:10:05,581 [4026c186-2529-49de-a2d8-dcba1039e356@group-D27615E20C89-FollowerState] INFO impl.RoleInfo: 4026c186-2529-49de-a2d8-dcba1039e356: shutdown 4026c186-2529-49de-a2d8-dcba1039e356@group-D27615E20C89-FollowerState
datanode1_1  | 2022-10-20 02:10:05,581 [4026c186-2529-49de-a2d8-dcba1039e356@group-D27615E20C89-FollowerState] INFO server.RaftServer$Division: 4026c186-2529-49de-a2d8-dcba1039e356@group-D27615E20C89: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode1_1  | 2022-10-20 02:10:05,582 [4026c186-2529-49de-a2d8-dcba1039e356@group-D27615E20C89-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode1_1  | 2022-10-20 02:10:05,582 [4026c186-2529-49de-a2d8-dcba1039e356@group-D27615E20C89-FollowerState] INFO impl.RoleInfo: 4026c186-2529-49de-a2d8-dcba1039e356: start 4026c186-2529-49de-a2d8-dcba1039e356@group-D27615E20C89-LeaderElection2
datanode1_1  | 2022-10-20 02:10:05,590 [4026c186-2529-49de-a2d8-dcba1039e356@group-D27615E20C89-LeaderElection2] INFO impl.LeaderElection: 4026c186-2529-49de-a2d8-dcba1039e356@group-D27615E20C89-LeaderElection2 ELECTION round 0: submit vote requests at term 1 for -1: peers:[922d5e53-2e0d-4e01-adf2-129a3cebef39|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0|startupRole:FOLLOWER, 4026c186-2529-49de-a2d8-dcba1039e356|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1|startupRole:FOLLOWER, e4d9a0e3-266c-4558-944a-cafbea7b03e5|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
datanode1_1  | 2022-10-20 02:10:05,593 [4026c186-2529-49de-a2d8-dcba1039e356@group-D27615E20C89-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode1_1  | 2022-10-20 02:10:05,593 [4026c186-2529-49de-a2d8-dcba1039e356@group-D27615E20C89-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode1_1  | 2022-10-20 02:10:05,637 [4026c186-2529-49de-a2d8-dcba1039e356@group-D27615E20C89-LeaderElection2] INFO impl.LeaderElection: 4026c186-2529-49de-a2d8-dcba1039e356@group-D27615E20C89-LeaderElection2: ELECTION PASSED received 1 response(s) and 0 exception(s):
datanode1_1  | 2022-10-20 02:10:05,637 [4026c186-2529-49de-a2d8-dcba1039e356@group-D27615E20C89-LeaderElection2] INFO impl.LeaderElection:   Response 0: 4026c186-2529-49de-a2d8-dcba1039e356<-922d5e53-2e0d-4e01-adf2-129a3cebef39#0:OK-t1
datanode1_1  | 2022-10-20 02:10:05,638 [4026c186-2529-49de-a2d8-dcba1039e356@group-D27615E20C89-LeaderElection2] INFO impl.LeaderElection: 4026c186-2529-49de-a2d8-dcba1039e356@group-D27615E20C89-LeaderElection2 ELECTION round 0: result PASSED
datanode1_1  | 2022-10-20 02:10:05,638 [4026c186-2529-49de-a2d8-dcba1039e356@group-D27615E20C89-LeaderElection2] INFO impl.RoleInfo: 4026c186-2529-49de-a2d8-dcba1039e356: shutdown 4026c186-2529-49de-a2d8-dcba1039e356@group-D27615E20C89-LeaderElection2
datanode1_1  | 2022-10-20 02:10:05,638 [4026c186-2529-49de-a2d8-dcba1039e356@group-D27615E20C89-LeaderElection2] INFO server.RaftServer$Division: 4026c186-2529-49de-a2d8-dcba1039e356@group-D27615E20C89: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode1_1  | 2022-10-20 02:10:05,638 [4026c186-2529-49de-a2d8-dcba1039e356@group-D27615E20C89-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-D27615E20C89 with new leaderId: 4026c186-2529-49de-a2d8-dcba1039e356
datanode1_1  | 2022-10-20 02:10:05,640 [4026c186-2529-49de-a2d8-dcba1039e356@group-D27615E20C89-LeaderElection2] INFO server.RaftServer$Division: 4026c186-2529-49de-a2d8-dcba1039e356@group-D27615E20C89: change Leader from null to 4026c186-2529-49de-a2d8-dcba1039e356 at term 1 for becomeLeader, leader elected after 5258ms
datanode1_1  | 2022-10-20 02:10:05,693 [4026c186-2529-49de-a2d8-dcba1039e356@group-D27615E20C89-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode1_1  | 2022-10-20 02:10:05,730 [4026c186-2529-49de-a2d8-dcba1039e356@group-D27615E20C89-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode1_1  | 2022-10-20 02:10:05,731 [4026c186-2529-49de-a2d8-dcba1039e356@group-D27615E20C89-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode1_1  | 2022-10-20 02:10:05,760 [4026c186-2529-49de-a2d8-dcba1039e356@group-D27615E20C89-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode1_1  | 2022-10-20 02:10:05,760 [4026c186-2529-49de-a2d8-dcba1039e356@group-D27615E20C89-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode1_1  | 2022-10-20 02:10:05,761 [4026c186-2529-49de-a2d8-dcba1039e356@group-D27615E20C89-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode1_1  | 2022-10-20 02:10:05,780 [4026c186-2529-49de-a2d8-dcba1039e356@group-D27615E20C89-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode1_1  | 2022-10-20 02:10:05,800 [4026c186-2529-49de-a2d8-dcba1039e356@group-D27615E20C89-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
datanode1_1  | 2022-10-20 02:10:05,848 [4026c186-2529-49de-a2d8-dcba1039e356@group-D27615E20C89-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode1_1  | 2022-10-20 02:10:05,849 [4026c186-2529-49de-a2d8-dcba1039e356@group-D27615E20C89-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode1_1  | 2022-10-20 02:10:05,849 [4026c186-2529-49de-a2d8-dcba1039e356@group-D27615E20C89-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode1_1  | 2022-10-20 02:10:05,852 [4026c186-2529-49de-a2d8-dcba1039e356@group-D27615E20C89-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode1_1  | 2022-10-20 02:10:05,857 [4026c186-2529-49de-a2d8-dcba1039e356@group-D27615E20C89-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode1_1  | 2022-10-20 02:10:05,857 [4026c186-2529-49de-a2d8-dcba1039e356@group-D27615E20C89-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode1_1  | 2022-10-20 02:10:05,861 [4026c186-2529-49de-a2d8-dcba1039e356@group-D27615E20C89-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
datanode1_1  | 2022-10-20 02:10:05,861 [4026c186-2529-49de-a2d8-dcba1039e356@group-D27615E20C89-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.wait-time.min = 10ms (default)
datanode1_1  | 2022-10-20 02:10:05,874 [4026c186-2529-49de-a2d8-dcba1039e356@group-D27615E20C89-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode1_1  | 2022-10-20 02:10:05,874 [4026c186-2529-49de-a2d8-dcba1039e356@group-D27615E20C89-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode1_1  | 2022-10-20 02:10:05,874 [4026c186-2529-49de-a2d8-dcba1039e356@group-D27615E20C89-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode1_1  | 2022-10-20 02:10:05,874 [4026c186-2529-49de-a2d8-dcba1039e356@group-D27615E20C89-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode1_1  | 2022-10-20 02:10:05,875 [4026c186-2529-49de-a2d8-dcba1039e356@group-D27615E20C89-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode1_1  | 2022-10-20 02:10:05,875 [4026c186-2529-49de-a2d8-dcba1039e356@group-D27615E20C89-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode1_1  | 2022-10-20 02:10:05,878 [4026c186-2529-49de-a2d8-dcba1039e356@group-D27615E20C89-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
datanode1_1  | 2022-10-20 02:10:05,878 [4026c186-2529-49de-a2d8-dcba1039e356@group-D27615E20C89-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.wait-time.min = 10ms (default)
datanode1_1  | 2022-10-20 02:10:05,883 [4026c186-2529-49de-a2d8-dcba1039e356@group-D27615E20C89-LeaderElection2] INFO impl.RoleInfo: 4026c186-2529-49de-a2d8-dcba1039e356: start 4026c186-2529-49de-a2d8-dcba1039e356@group-D27615E20C89-LeaderStateImpl
datanode1_1  | 2022-10-20 02:10:05,926 [4026c186-2529-49de-a2d8-dcba1039e356@group-D27615E20C89-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: 4026c186-2529-49de-a2d8-dcba1039e356@group-D27615E20C89-SegmentedRaftLogWorker: Starting segment from index:0
datanode1_1  | 2022-10-20 02:10:06,033 [4026c186-2529-49de-a2d8-dcba1039e356@group-D27615E20C89-LeaderElection2] INFO server.RaftServer$Division: 4026c186-2529-49de-a2d8-dcba1039e356@group-D27615E20C89: set configuration 0: peers:[922d5e53-2e0d-4e01-adf2-129a3cebef39|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0|startupRole:FOLLOWER, 4026c186-2529-49de-a2d8-dcba1039e356|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1|startupRole:FOLLOWER, e4d9a0e3-266c-4558-944a-cafbea7b03e5|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
datanode1_1  | 2022-10-20 02:10:06,612 [4026c186-2529-49de-a2d8-dcba1039e356@group-D27615E20C89-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 4026c186-2529-49de-a2d8-dcba1039e356@group-D27615E20C89-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/928115e6-57fc-4e60-abe7-d27615e20c89/current/log_inprogress_0
datanode1_1  | 2022-10-20 02:10:08,074 [grpc-default-executor-1] INFO server.RaftServer$Division: 4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592: receive requestVote(ELECTION, e4d9a0e3-266c-4558-944a-cafbea7b03e5, group-44E7403E0592, 2, (t:0, i:0))
datanode1_1  | 2022-10-20 02:10:08,075 [grpc-default-executor-1] INFO impl.VoteContext: 4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-FOLLOWER: accept ELECTION from e4d9a0e3-266c-4558-944a-cafbea7b03e5: our priority 0 <= candidate's priority 0
datanode1_1  | 2022-10-20 02:10:08,075 [grpc-default-executor-1] INFO server.RaftServer$Division: 4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:e4d9a0e3-266c-4558-944a-cafbea7b03e5
datanode1_1  | 2022-10-20 02:10:08,075 [grpc-default-executor-1] INFO impl.RoleInfo: 4026c186-2529-49de-a2d8-dcba1039e356: shutdown 4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-FollowerState
datanode1_1  | 2022-10-20 02:10:08,075 [4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-FollowerState] INFO impl.FollowerState: 4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-FollowerState was interrupted
datanode1_1  | 2022-10-20 02:10:08,076 [grpc-default-executor-1] INFO impl.RoleInfo: 4026c186-2529-49de-a2d8-dcba1039e356: start 4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-FollowerState
datanode1_1  | 2022-10-20 02:10:08,079 [4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode1_1  | 2022-10-20 02:10:08,079 [4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode1_1  | 2022-10-20 02:10:08,081 [grpc-default-executor-1] INFO server.RaftServer$Division: 4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592 replies to ELECTION vote request: e4d9a0e3-266c-4558-944a-cafbea7b03e5<-4026c186-2529-49de-a2d8-dcba1039e356#0:OK-t2. Peer's state: 4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592:t2, leader=null, voted=e4d9a0e3-266c-4558-944a-cafbea7b03e5, raftlog=Memoized:4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[922d5e53-2e0d-4e01-adf2-129a3cebef39|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1|startupRole:FOLLOWER, 4026c186-2529-49de-a2d8-dcba1039e356|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0|startupRole:FOLLOWER, e4d9a0e3-266c-4558-944a-cafbea7b03e5|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
datanode1_1  | 2022-10-20 02:10:08,434 [4026c186-2529-49de-a2d8-dcba1039e356@group-BC1BBCBC6578-FollowerState] INFO impl.FollowerState: 4026c186-2529-49de-a2d8-dcba1039e356@group-BC1BBCBC6578-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5053691728ns, electionTimeout:5039ms
datanode1_1  | 2022-10-20 02:10:08,434 [4026c186-2529-49de-a2d8-dcba1039e356@group-BC1BBCBC6578-FollowerState] INFO impl.RoleInfo: 4026c186-2529-49de-a2d8-dcba1039e356: shutdown 4026c186-2529-49de-a2d8-dcba1039e356@group-BC1BBCBC6578-FollowerState
datanode1_1  | 2022-10-20 02:10:08,434 [4026c186-2529-49de-a2d8-dcba1039e356@group-BC1BBCBC6578-FollowerState] INFO server.RaftServer$Division: 4026c186-2529-49de-a2d8-dcba1039e356@group-BC1BBCBC6578: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode1_1  | 2022-10-20 02:10:08,435 [4026c186-2529-49de-a2d8-dcba1039e356@group-BC1BBCBC6578-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode1_1  | 2022-10-20 02:10:08,435 [4026c186-2529-49de-a2d8-dcba1039e356@group-BC1BBCBC6578-FollowerState] INFO impl.RoleInfo: 4026c186-2529-49de-a2d8-dcba1039e356: start 4026c186-2529-49de-a2d8-dcba1039e356@group-BC1BBCBC6578-LeaderElection3
datanode1_1  | 2022-10-20 02:10:08,454 [4026c186-2529-49de-a2d8-dcba1039e356@group-BC1BBCBC6578-LeaderElection3] INFO impl.LeaderElection: 4026c186-2529-49de-a2d8-dcba1039e356@group-BC1BBCBC6578-LeaderElection3 ELECTION round 0: submit vote requests at term 1 for -1: peers:[4026c186-2529-49de-a2d8-dcba1039e356|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode1_1  | 2022-10-20 02:10:08,460 [4026c186-2529-49de-a2d8-dcba1039e356@group-BC1BBCBC6578-LeaderElection3] INFO impl.LeaderElection: 4026c186-2529-49de-a2d8-dcba1039e356@group-BC1BBCBC6578-LeaderElection3 ELECTION round 0: result PASSED (term=1)
datanode1_1  | 2022-10-20 02:10:08,460 [4026c186-2529-49de-a2d8-dcba1039e356@group-BC1BBCBC6578-LeaderElection3] INFO impl.RoleInfo: 4026c186-2529-49de-a2d8-dcba1039e356: shutdown 4026c186-2529-49de-a2d8-dcba1039e356@group-BC1BBCBC6578-LeaderElection3
datanode1_1  | 2022-10-20 02:10:08,460 [4026c186-2529-49de-a2d8-dcba1039e356@group-BC1BBCBC6578-LeaderElection3] INFO server.RaftServer$Division: 4026c186-2529-49de-a2d8-dcba1039e356@group-BC1BBCBC6578: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode1_1  | 2022-10-20 02:10:08,460 [4026c186-2529-49de-a2d8-dcba1039e356@group-BC1BBCBC6578-LeaderElection3] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-BC1BBCBC6578 with new leaderId: 4026c186-2529-49de-a2d8-dcba1039e356
datanode1_1  | 2022-10-20 02:10:08,461 [4026c186-2529-49de-a2d8-dcba1039e356@group-BC1BBCBC6578-LeaderElection3] INFO server.RaftServer$Division: 4026c186-2529-49de-a2d8-dcba1039e356@group-BC1BBCBC6578: change Leader from null to 4026c186-2529-49de-a2d8-dcba1039e356 at term 1 for becomeLeader, leader elected after 5181ms
datanode1_1  | 2022-10-20 02:10:08,461 [4026c186-2529-49de-a2d8-dcba1039e356@group-BC1BBCBC6578-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode1_1  | 2022-10-20 02:10:08,462 [4026c186-2529-49de-a2d8-dcba1039e356@group-BC1BBCBC6578-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode1_1  | 2022-10-20 02:10:08,462 [4026c186-2529-49de-a2d8-dcba1039e356@group-BC1BBCBC6578-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode1_1  | 2022-10-20 02:10:08,504 [4026c186-2529-49de-a2d8-dcba1039e356@group-BC1BBCBC6578-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode1_1  | 2022-10-20 02:10:08,517 [4026c186-2529-49de-a2d8-dcba1039e356@group-BC1BBCBC6578-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode1_1  | 2022-10-20 02:10:08,520 [4026c186-2529-49de-a2d8-dcba1039e356@group-BC1BBCBC6578-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode1_1  | 2022-10-20 02:10:08,521 [4026c186-2529-49de-a2d8-dcba1039e356@group-BC1BBCBC6578-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode1_1  | 2022-10-20 02:10:08,521 [4026c186-2529-49de-a2d8-dcba1039e356@group-BC1BBCBC6578-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
datanode1_1  | 2022-10-20 02:10:08,521 [4026c186-2529-49de-a2d8-dcba1039e356@group-BC1BBCBC6578-LeaderElection3] INFO impl.RoleInfo: 4026c186-2529-49de-a2d8-dcba1039e356: start 4026c186-2529-49de-a2d8-dcba1039e356@group-BC1BBCBC6578-LeaderStateImpl
datanode1_1  | 2022-10-20 02:10:08,522 [4026c186-2529-49de-a2d8-dcba1039e356@group-BC1BBCBC6578-LeaderElection3] INFO segmented.SegmentedRaftLogWorker: 4026c186-2529-49de-a2d8-dcba1039e356@group-BC1BBCBC6578-SegmentedRaftLogWorker: Starting segment from index:0
datanode1_1  | 2022-10-20 02:10:08,533 [4026c186-2529-49de-a2d8-dcba1039e356@group-BC1BBCBC6578-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 4026c186-2529-49de-a2d8-dcba1039e356@group-BC1BBCBC6578-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/d523f193-8112-4e25-a36e-bc1bbcbc6578/current/log_inprogress_0
datanode1_1  | 2022-10-20 02:10:08,555 [4026c186-2529-49de-a2d8-dcba1039e356@group-BC1BBCBC6578-LeaderElection3] INFO server.RaftServer$Division: 4026c186-2529-49de-a2d8-dcba1039e356@group-BC1BBCBC6578: set configuration 0: peers:[4026c186-2529-49de-a2d8-dcba1039e356|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode1_1  | 2022-10-20 02:10:13,090 [4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode1_1  | 2022-10-20 02:10:13,090 [4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode1_1  | 2022-10-20 02:10:13,173 [grpc-default-executor-1] INFO server.RaftServer$Division: 4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592: receive requestVote(ELECTION, e4d9a0e3-266c-4558-944a-cafbea7b03e5, group-44E7403E0592, 3, (t:0, i:0))
datanode1_1  | 2022-10-20 02:10:13,174 [grpc-default-executor-1] INFO impl.VoteContext: 4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-FOLLOWER: accept ELECTION from e4d9a0e3-266c-4558-944a-cafbea7b03e5: our priority 0 <= candidate's priority 0
datanode1_1  | 2022-10-20 02:10:13,174 [grpc-default-executor-1] INFO server.RaftServer$Division: 4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592: changes role from  FOLLOWER to FOLLOWER at term 3 for candidate:e4d9a0e3-266c-4558-944a-cafbea7b03e5
datanode1_1  | 2022-10-20 02:10:13,174 [grpc-default-executor-1] INFO impl.RoleInfo: 4026c186-2529-49de-a2d8-dcba1039e356: shutdown 4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-FollowerState
datanode1_1  | 2022-10-20 02:10:13,174 [4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-FollowerState] INFO impl.FollowerState: 4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-FollowerState was interrupted
datanode1_1  | 2022-10-20 02:10:13,174 [grpc-default-executor-1] INFO impl.RoleInfo: 4026c186-2529-49de-a2d8-dcba1039e356: start 4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-FollowerState
datanode1_1  | 2022-10-20 02:10:13,176 [grpc-default-executor-1] INFO server.RaftServer$Division: 4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592 replies to ELECTION vote request: e4d9a0e3-266c-4558-944a-cafbea7b03e5<-4026c186-2529-49de-a2d8-dcba1039e356#0:OK-t3. Peer's state: 4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592:t3, leader=null, voted=e4d9a0e3-266c-4558-944a-cafbea7b03e5, raftlog=Memoized:4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[922d5e53-2e0d-4e01-adf2-129a3cebef39|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1|startupRole:FOLLOWER, 4026c186-2529-49de-a2d8-dcba1039e356|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0|startupRole:FOLLOWER, e4d9a0e3-266c-4558-944a-cafbea7b03e5|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
datanode1_1  | 2022-10-20 02:10:13,185 [4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode1_1  | 2022-10-20 02:10:13,185 [4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode1_1  | 2022-10-20 02:10:14,180 [grpc-default-executor-1] INFO server.RaftServer$Division: 4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592: receive requestVote(ELECTION, 922d5e53-2e0d-4e01-adf2-129a3cebef39, group-44E7403E0592, 3, (t:0, i:0))
datanode1_1  | 2022-10-20 02:10:14,180 [grpc-default-executor-1] INFO impl.VoteContext: 4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-FOLLOWER: reject ELECTION from 922d5e53-2e0d-4e01-adf2-129a3cebef39: already has voted for e4d9a0e3-266c-4558-944a-cafbea7b03e5 at current term 3
datanode1_1  | 2022-10-20 02:10:14,180 [grpc-default-executor-1] INFO server.RaftServer$Division: 4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592 replies to ELECTION vote request: 922d5e53-2e0d-4e01-adf2-129a3cebef39<-4026c186-2529-49de-a2d8-dcba1039e356#0:FAIL-t3. Peer's state: 4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592:t3, leader=null, voted=e4d9a0e3-266c-4558-944a-cafbea7b03e5, raftlog=Memoized:4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[922d5e53-2e0d-4e01-adf2-129a3cebef39|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1|startupRole:FOLLOWER, 4026c186-2529-49de-a2d8-dcba1039e356|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0|startupRole:FOLLOWER, e4d9a0e3-266c-4558-944a-cafbea7b03e5|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
datanode1_1  | 2022-10-20 02:10:18,276 [4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-FollowerState] INFO impl.FollowerState: 4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5100809802ns, electionTimeout:5091ms
datanode1_1  | 2022-10-20 02:10:18,277 [4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-FollowerState] INFO impl.RoleInfo: 4026c186-2529-49de-a2d8-dcba1039e356: shutdown 4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-FollowerState
datanode1_1  | 2022-10-20 02:10:18,277 [4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-FollowerState] INFO server.RaftServer$Division: 4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592: changes role from  FOLLOWER to CANDIDATE at term 3 for changeToCandidate
datanode1_1  | 2022-10-20 02:10:18,277 [4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode1_1  | 2022-10-20 02:10:18,277 [4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-FollowerState] INFO impl.RoleInfo: 4026c186-2529-49de-a2d8-dcba1039e356: start 4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-LeaderElection4
datanode1_1  | 2022-10-20 02:10:18,283 [4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-LeaderElection4] INFO impl.LeaderElection: 4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-LeaderElection4 ELECTION round 0: submit vote requests at term 4 for -1: peers:[922d5e53-2e0d-4e01-adf2-129a3cebef39|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1|startupRole:FOLLOWER, 4026c186-2529-49de-a2d8-dcba1039e356|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0|startupRole:FOLLOWER, e4d9a0e3-266c-4558-944a-cafbea7b03e5|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
datanode1_1  | 2022-10-20 02:10:18,283 [4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode1_1  | 2022-10-20 02:10:18,284 [4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode1_1  | 2022-10-20 02:10:18,310 [4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-LeaderElection4] INFO impl.LeaderElection: 4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-LeaderElection4: ELECTION REJECTED received 1 response(s) and 0 exception(s):
datanode1_1  | 2022-10-20 02:10:18,310 [4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-LeaderElection4] INFO impl.LeaderElection:   Response 0: 4026c186-2529-49de-a2d8-dcba1039e356<-922d5e53-2e0d-4e01-adf2-129a3cebef39#0:FAIL-t4
datanode1_1  | 2022-10-20 02:10:18,310 [4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-LeaderElection4] INFO impl.LeaderElection: 4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-LeaderElection4 ELECTION round 0: result REJECTED
datanode1_1  | 2022-10-20 02:10:18,311 [4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-LeaderElection4] INFO server.RaftServer$Division: 4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592: changes role from CANDIDATE to FOLLOWER at term 4 for REJECTED
datanode1_1  | 2022-10-20 02:10:18,311 [4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-LeaderElection4] INFO impl.RoleInfo: 4026c186-2529-49de-a2d8-dcba1039e356: shutdown 4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-LeaderElection4
datanode1_1  | 2022-10-20 02:10:18,311 [4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-LeaderElection4] INFO impl.RoleInfo: 4026c186-2529-49de-a2d8-dcba1039e356: start 4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-FollowerState
datanode1_1  | 2022-10-20 02:10:18,322 [4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode1_1  | 2022-10-20 02:10:18,327 [4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode1_1  | 2022-10-20 02:10:18,327 [grpc-default-executor-1] INFO server.RaftServer$Division: 4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592: receive requestVote(ELECTION, e4d9a0e3-266c-4558-944a-cafbea7b03e5, group-44E7403E0592, 4, (t:0, i:0))
datanode1_1  | 2022-10-20 02:10:18,327 [grpc-default-executor-1] INFO impl.VoteContext: 4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-FOLLOWER: reject ELECTION from e4d9a0e3-266c-4558-944a-cafbea7b03e5: already has voted for 4026c186-2529-49de-a2d8-dcba1039e356 at current term 4
datanode1_1  | 2022-10-20 02:10:18,328 [grpc-default-executor-1] INFO server.RaftServer$Division: 4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592 replies to ELECTION vote request: e4d9a0e3-266c-4558-944a-cafbea7b03e5<-4026c186-2529-49de-a2d8-dcba1039e356#0:FAIL-t4. Peer's state: 4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592:t4, leader=null, voted=4026c186-2529-49de-a2d8-dcba1039e356, raftlog=Memoized:4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[922d5e53-2e0d-4e01-adf2-129a3cebef39|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1|startupRole:FOLLOWER, 4026c186-2529-49de-a2d8-dcba1039e356|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0|startupRole:FOLLOWER, e4d9a0e3-266c-4558-944a-cafbea7b03e5|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
datanode1_1  | 2022-10-20 02:10:23,419 [grpc-default-executor-1] INFO server.RaftServer$Division: 4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592: receive requestVote(ELECTION, e4d9a0e3-266c-4558-944a-cafbea7b03e5, group-44E7403E0592, 5, (t:0, i:0))
datanode1_1  | 2022-10-20 02:10:23,419 [grpc-default-executor-1] INFO impl.VoteContext: 4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-FOLLOWER: accept ELECTION from e4d9a0e3-266c-4558-944a-cafbea7b03e5: our priority 0 <= candidate's priority 0
datanode1_1  | 2022-10-20 02:10:23,419 [grpc-default-executor-1] INFO server.RaftServer$Division: 4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592: changes role from  FOLLOWER to FOLLOWER at term 5 for candidate:e4d9a0e3-266c-4558-944a-cafbea7b03e5
datanode1_1  | 2022-10-20 02:10:23,420 [grpc-default-executor-1] INFO impl.RoleInfo: 4026c186-2529-49de-a2d8-dcba1039e356: shutdown 4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-FollowerState
datanode1_1  | 2022-10-20 02:10:23,420 [grpc-default-executor-1] INFO impl.RoleInfo: 4026c186-2529-49de-a2d8-dcba1039e356: start 4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-FollowerState
datanode1_1  | 2022-10-20 02:10:23,420 [4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-FollowerState] INFO impl.FollowerState: 4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-FollowerState was interrupted
datanode1_1  | 2022-10-20 02:10:23,433 [4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode1_1  | 2022-10-20 02:10:23,433 [4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode1_1  | 2022-10-20 02:10:23,433 [grpc-default-executor-1] INFO server.RaftServer$Division: 4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592 replies to ELECTION vote request: e4d9a0e3-266c-4558-944a-cafbea7b03e5<-4026c186-2529-49de-a2d8-dcba1039e356#0:OK-t5. Peer's state: 4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592:t5, leader=null, voted=e4d9a0e3-266c-4558-944a-cafbea7b03e5, raftlog=Memoized:4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[922d5e53-2e0d-4e01-adf2-129a3cebef39|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1|startupRole:FOLLOWER, 4026c186-2529-49de-a2d8-dcba1039e356|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0|startupRole:FOLLOWER, e4d9a0e3-266c-4558-944a-cafbea7b03e5|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
datanode1_1  | 2022-10-20 02:10:28,594 [grpc-default-executor-1] INFO server.RaftServer$Division: 4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592: receive requestVote(ELECTION, 922d5e53-2e0d-4e01-adf2-129a3cebef39, group-44E7403E0592, 6, (t:0, i:0))
datanode1_1  | 2022-10-20 02:10:28,594 [grpc-default-executor-1] INFO impl.VoteContext: 4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-FOLLOWER: accept ELECTION from 922d5e53-2e0d-4e01-adf2-129a3cebef39: our priority 0 <= candidate's priority 1
datanode1_1  | 2022-10-20 02:10:28,594 [grpc-default-executor-1] INFO server.RaftServer$Division: 4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592: changes role from  FOLLOWER to FOLLOWER at term 6 for candidate:922d5e53-2e0d-4e01-adf2-129a3cebef39
datanode1_1  | 2022-10-20 02:10:28,594 [grpc-default-executor-1] INFO impl.RoleInfo: 4026c186-2529-49de-a2d8-dcba1039e356: shutdown 4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-FollowerState
datanode1_1  | 2022-10-20 02:10:28,594 [grpc-default-executor-1] INFO impl.RoleInfo: 4026c186-2529-49de-a2d8-dcba1039e356: start 4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-FollowerState
datanode1_1  | 2022-10-20 02:10:28,594 [4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-FollowerState] INFO impl.FollowerState: 4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-FollowerState was interrupted
datanode1_1  | 2022-10-20 02:10:28,604 [grpc-default-executor-1] INFO server.RaftServer$Division: 4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592 replies to ELECTION vote request: 922d5e53-2e0d-4e01-adf2-129a3cebef39<-4026c186-2529-49de-a2d8-dcba1039e356#0:OK-t6. Peer's state: 4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592:t6, leader=null, voted=922d5e53-2e0d-4e01-adf2-129a3cebef39, raftlog=Memoized:4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[922d5e53-2e0d-4e01-adf2-129a3cebef39|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1|startupRole:FOLLOWER, 4026c186-2529-49de-a2d8-dcba1039e356|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0|startupRole:FOLLOWER, e4d9a0e3-266c-4558-944a-cafbea7b03e5|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
datanode1_1  | 2022-10-20 02:10:28,607 [4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode1_1  | 2022-10-20 02:10:28,613 [4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode1_1  | 2022-10-20 02:10:28,638 [grpc-default-executor-1] INFO server.RaftServer$Division: 4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592: receive requestVote(ELECTION, e4d9a0e3-266c-4558-944a-cafbea7b03e5, group-44E7403E0592, 6, (t:0, i:0))
datanode1_1  | 2022-10-20 02:10:28,639 [grpc-default-executor-1] INFO impl.VoteContext: 4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-FOLLOWER: reject ELECTION from e4d9a0e3-266c-4558-944a-cafbea7b03e5: already has voted for 922d5e53-2e0d-4e01-adf2-129a3cebef39 at current term 6
datanode1_1  | 2022-10-20 02:10:28,639 [grpc-default-executor-1] INFO server.RaftServer$Division: 4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592 replies to ELECTION vote request: e4d9a0e3-266c-4558-944a-cafbea7b03e5<-4026c186-2529-49de-a2d8-dcba1039e356#0:FAIL-t6. Peer's state: 4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592:t6, leader=null, voted=922d5e53-2e0d-4e01-adf2-129a3cebef39, raftlog=Memoized:4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[922d5e53-2e0d-4e01-adf2-129a3cebef39|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1|startupRole:FOLLOWER, 4026c186-2529-49de-a2d8-dcba1039e356|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0|startupRole:FOLLOWER, e4d9a0e3-266c-4558-944a-cafbea7b03e5|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
datanode1_1  | 2022-10-20 02:10:28,946 [4026c186-2529-49de-a2d8-dcba1039e356-server-thread1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-44E7403E0592 with new leaderId: 922d5e53-2e0d-4e01-adf2-129a3cebef39
datanode1_1  | 2022-10-20 02:10:28,961 [4026c186-2529-49de-a2d8-dcba1039e356-server-thread1] INFO server.RaftServer$Division: 4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592: change Leader from null to 922d5e53-2e0d-4e01-adf2-129a3cebef39 at term 6 for appendEntries, leader elected after 33602ms
datanode1_1  | 2022-10-20 02:10:28,992 [4026c186-2529-49de-a2d8-dcba1039e356-server-thread1] INFO server.RaftServer$Division: 4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592: set configuration 0: peers:[922d5e53-2e0d-4e01-adf2-129a3cebef39|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1|startupRole:FOLLOWER, 4026c186-2529-49de-a2d8-dcba1039e356|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0|startupRole:FOLLOWER, e4d9a0e3-266c-4558-944a-cafbea7b03e5|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
datanode1_1  | 2022-10-20 02:10:28,993 [4026c186-2529-49de-a2d8-dcba1039e356-server-thread1] INFO segmented.SegmentedRaftLogWorker: 4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-SegmentedRaftLogWorker: Starting segment from index:0
datanode1_1  | 2022-10-20 02:10:29,003 [4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 4026c186-2529-49de-a2d8-dcba1039e356@group-44E7403E0592-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/904a7869-3351-4618-b9db-44e7403e0592/current/log_inprogress_0
datanode1_1  | 2022-10-20 02:10:58,158 [ChunkWriter-1-0] INFO client.DNCertificateClient: Getting certificate with certSerialId:1087378534705.
datanode2_1  | 2022-10-20 02:10:02,778 [grpc-default-executor-0] INFO impl.RoleInfo: 922d5e53-2e0d-4e01-adf2-129a3cebef39: start 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-FollowerState
datanode2_1  | 2022-10-20 02:10:02,778 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-FollowerState] INFO impl.FollowerState: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-FollowerState was interrupted
datanode2_1  | 2022-10-20 02:10:02,783 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode2_1  | 2022-10-20 02:10:02,783 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode2_1  | 2022-10-20 02:10:02,809 [grpc-default-executor-0] INFO server.RaftServer$Division: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592 replies to ELECTION vote request: e4d9a0e3-266c-4558-944a-cafbea7b03e5<-922d5e53-2e0d-4e01-adf2-129a3cebef39#0:FAIL-t1. Peer's state: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592:t1, leader=null, voted=null, raftlog=Memoized:922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[922d5e53-2e0d-4e01-adf2-129a3cebef39|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1|startupRole:FOLLOWER, 4026c186-2529-49de-a2d8-dcba1039e356|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0|startupRole:FOLLOWER, e4d9a0e3-266c-4558-944a-cafbea7b03e5|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
datanode2_1  | 2022-10-20 02:10:03,066 [grpc-default-executor-0] INFO server.RaftServer$Division: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592: receive requestVote(ELECTION, 4026c186-2529-49de-a2d8-dcba1039e356, group-44E7403E0592, 1, (t:0, i:0))
datanode2_1  | 2022-10-20 02:10:03,067 [grpc-default-executor-0] INFO impl.VoteContext: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-FOLLOWER: reject ELECTION from 4026c186-2529-49de-a2d8-dcba1039e356: our priority 1 > candidate's priority 0
datanode2_1  | 2022-10-20 02:10:03,067 [grpc-default-executor-0] INFO server.RaftServer$Division: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:4026c186-2529-49de-a2d8-dcba1039e356
datanode2_1  | 2022-10-20 02:10:03,067 [grpc-default-executor-0] INFO impl.RoleInfo: 922d5e53-2e0d-4e01-adf2-129a3cebef39: shutdown 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-FollowerState
datanode2_1  | 2022-10-20 02:10:03,067 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-FollowerState] INFO impl.FollowerState: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-FollowerState was interrupted
datanode2_1  | 2022-10-20 02:10:03,068 [grpc-default-executor-0] INFO impl.RoleInfo: 922d5e53-2e0d-4e01-adf2-129a3cebef39: start 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-FollowerState
datanode2_1  | 2022-10-20 02:10:03,077 [grpc-default-executor-0] INFO server.RaftServer$Division: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592 replies to ELECTION vote request: 4026c186-2529-49de-a2d8-dcba1039e356<-922d5e53-2e0d-4e01-adf2-129a3cebef39#0:FAIL-t1. Peer's state: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592:t1, leader=null, voted=null, raftlog=Memoized:922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[922d5e53-2e0d-4e01-adf2-129a3cebef39|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1|startupRole:FOLLOWER, 4026c186-2529-49de-a2d8-dcba1039e356|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0|startupRole:FOLLOWER, e4d9a0e3-266c-4558-944a-cafbea7b03e5|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
datanode2_1  | 2022-10-20 02:10:03,092 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode2_1  | 2022-10-20 02:10:03,092 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode2_1  | 2022-10-20 02:10:05,610 [grpc-default-executor-0] INFO server.RaftServer$Division: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-D27615E20C89: receive requestVote(ELECTION, 4026c186-2529-49de-a2d8-dcba1039e356, group-D27615E20C89, 1, (t:0, i:0))
datanode2_1  | 2022-10-20 02:10:05,611 [grpc-default-executor-0] INFO impl.VoteContext: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-D27615E20C89-FOLLOWER: accept ELECTION from 4026c186-2529-49de-a2d8-dcba1039e356: our priority 0 <= candidate's priority 1
datanode2_1  | 2022-10-20 02:10:05,611 [grpc-default-executor-0] INFO server.RaftServer$Division: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-D27615E20C89: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:4026c186-2529-49de-a2d8-dcba1039e356
datanode2_1  | 2022-10-20 02:10:05,611 [grpc-default-executor-0] INFO impl.RoleInfo: 922d5e53-2e0d-4e01-adf2-129a3cebef39: shutdown 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-D27615E20C89-FollowerState
datanode2_1  | 2022-10-20 02:10:05,611 [grpc-default-executor-0] INFO impl.RoleInfo: 922d5e53-2e0d-4e01-adf2-129a3cebef39: start 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-D27615E20C89-FollowerState
datanode2_1  | 2022-10-20 02:10:05,611 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-D27615E20C89-FollowerState] INFO impl.FollowerState: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-D27615E20C89-FollowerState was interrupted
datanode2_1  | 2022-10-20 02:10:05,626 [grpc-default-executor-0] INFO server.RaftServer$Division: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-D27615E20C89 replies to ELECTION vote request: 4026c186-2529-49de-a2d8-dcba1039e356<-922d5e53-2e0d-4e01-adf2-129a3cebef39#0:OK-t1. Peer's state: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-D27615E20C89:t1, leader=null, voted=4026c186-2529-49de-a2d8-dcba1039e356, raftlog=Memoized:922d5e53-2e0d-4e01-adf2-129a3cebef39@group-D27615E20C89-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[922d5e53-2e0d-4e01-adf2-129a3cebef39|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0|startupRole:FOLLOWER, 4026c186-2529-49de-a2d8-dcba1039e356|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1|startupRole:FOLLOWER, e4d9a0e3-266c-4558-944a-cafbea7b03e5|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
datanode2_1  | 2022-10-20 02:10:05,646 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-D27615E20C89-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode2_1  | 2022-10-20 02:10:05,650 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-D27615E20C89-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode2_1  | 2022-10-20 02:10:06,158 [922d5e53-2e0d-4e01-adf2-129a3cebef39-server-thread1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-D27615E20C89 with new leaderId: 4026c186-2529-49de-a2d8-dcba1039e356
datanode2_1  | 2022-10-20 02:10:06,182 [922d5e53-2e0d-4e01-adf2-129a3cebef39-server-thread1] INFO server.RaftServer$Division: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-D27615E20C89: change Leader from null to 4026c186-2529-49de-a2d8-dcba1039e356 at term 1 for appendEntries, leader elected after 5168ms
kdc_1        | Oct 20 02:08:53 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.118: ISSUE: authtime 1666231733, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Oct 20 02:08:55 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1666231735, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Oct 20 02:09:00 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.118: ISSUE: authtime 1666231733, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Oct 20 02:09:08 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1666231735, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Oct 20 02:09:13 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1666231753, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Oct 20 02:09:15 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.104: ISSUE: authtime 1666231755, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Oct 20 02:09:15 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.103: ISSUE: authtime 1666231755, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Oct 20 02:09:15 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.102: ISSUE: authtime 1666231755, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Oct 20 02:09:17 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.111: ISSUE: authtime 1666231757, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Oct 20 02:09:18 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.112: ISSUE: authtime 1666231758, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Oct 20 02:09:19 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.113: ISSUE: authtime 1666231759, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Oct 20 02:09:20 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.111: ISSUE: authtime 1666231757, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Oct 20 02:09:21 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.112: ISSUE: authtime 1666231758, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Oct 20 02:09:21 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.113: ISSUE: authtime 1666231759, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Oct 20 02:09:24 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.104: ISSUE: authtime 1666231755, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Oct 20 02:09:25 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.103: ISSUE: authtime 1666231755, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Oct 20 02:09:26 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.102: ISSUE: authtime 1666231755, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Oct 20 02:09:38 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1666231753, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Oct 20 02:09:43 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1666231783, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Oct 20 02:09:47 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.104: ISSUE: authtime 1666231755, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for recon/recon@EXAMPLE.COM
kdc_1        | Oct 20 02:09:49 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.103: ISSUE: authtime 1666231755, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for recon/recon@EXAMPLE.COM
kdc_1        | Oct 20 02:09:49 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.102: ISSUE: authtime 1666231755, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for recon/recon@EXAMPLE.COM
kdc_1        | Oct 20 02:09:50 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.112: ISSUE: authtime 1666231790, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Oct 20 02:09:51 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.111: ISSUE: authtime 1666231791, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Oct 20 02:09:53 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.113: ISSUE: authtime 1666231793, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Oct 20 02:09:54 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.112: ISSUE: authtime 1666231790, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Oct 20 02:09:54 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.111: ISSUE: authtime 1666231791, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Oct 20 02:09:57 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.113: ISSUE: authtime 1666231793, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Oct 20 02:10:08 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1666231783, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Oct 20 02:10:11 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1666231811, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Oct 20 02:10:16 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: ISSUE: authtime 1666231678, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, recon/recon@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Oct 20 02:10:22 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1666231811, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Oct 20 02:10:23 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Oct 20 02:10:23 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Oct 20 02:10:23 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Oct 20 02:10:23 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Oct 20 02:10:27 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1666231827, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Oct 20 02:10:37 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1666231827, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Oct 20 02:10:41 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1666231827, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode2_1  | 2022-10-20 02:10:06,310 [922d5e53-2e0d-4e01-adf2-129a3cebef39-server-thread2] INFO server.RaftServer$Division: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-D27615E20C89: set configuration 0: peers:[922d5e53-2e0d-4e01-adf2-129a3cebef39|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0|startupRole:FOLLOWER, 4026c186-2529-49de-a2d8-dcba1039e356|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1|startupRole:FOLLOWER, e4d9a0e3-266c-4558-944a-cafbea7b03e5|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
datanode2_1  | 2022-10-20 02:10:06,316 [922d5e53-2e0d-4e01-adf2-129a3cebef39-server-thread2] INFO segmented.SegmentedRaftLogWorker: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-D27615E20C89-SegmentedRaftLogWorker: Starting segment from index:0
datanode2_1  | 2022-10-20 02:10:06,721 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-D27615E20C89-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-D27615E20C89-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/928115e6-57fc-4e60-abe7-d27615e20c89/current/log_inprogress_0
datanode2_1  | 2022-10-20 02:10:08,024 [grpc-default-executor-0] INFO server.RaftServer$Division: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592: receive requestVote(ELECTION, e4d9a0e3-266c-4558-944a-cafbea7b03e5, group-44E7403E0592, 2, (t:0, i:0))
datanode2_1  | 2022-10-20 02:10:08,024 [grpc-default-executor-0] INFO impl.VoteContext: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-FOLLOWER: reject ELECTION from e4d9a0e3-266c-4558-944a-cafbea7b03e5: our priority 1 > candidate's priority 0
datanode2_1  | 2022-10-20 02:10:08,025 [grpc-default-executor-0] INFO server.RaftServer$Division: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:e4d9a0e3-266c-4558-944a-cafbea7b03e5
datanode2_1  | 2022-10-20 02:10:08,025 [grpc-default-executor-0] INFO impl.RoleInfo: 922d5e53-2e0d-4e01-adf2-129a3cebef39: shutdown 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-FollowerState
datanode2_1  | 2022-10-20 02:10:08,025 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-FollowerState] INFO impl.FollowerState: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-FollowerState was interrupted
datanode2_1  | 2022-10-20 02:10:08,026 [grpc-default-executor-0] INFO impl.RoleInfo: 922d5e53-2e0d-4e01-adf2-129a3cebef39: start 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-FollowerState
datanode2_1  | 2022-10-20 02:10:08,029 [grpc-default-executor-0] INFO server.RaftServer$Division: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592 replies to ELECTION vote request: e4d9a0e3-266c-4558-944a-cafbea7b03e5<-922d5e53-2e0d-4e01-adf2-129a3cebef39#0:FAIL-t2. Peer's state: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592:t2, leader=null, voted=null, raftlog=Memoized:922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[922d5e53-2e0d-4e01-adf2-129a3cebef39|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1|startupRole:FOLLOWER, 4026c186-2529-49de-a2d8-dcba1039e356|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0|startupRole:FOLLOWER, e4d9a0e3-266c-4558-944a-cafbea7b03e5|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
datanode2_1  | 2022-10-20 02:10:08,031 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode2_1  | 2022-10-20 02:10:08,031 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode2_1  | 2022-10-20 02:10:13,070 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-FollowerState] INFO impl.FollowerState: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5043914161ns, electionTimeout:5038ms
datanode2_1  | 2022-10-20 02:10:13,070 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-FollowerState] INFO impl.RoleInfo: 922d5e53-2e0d-4e01-adf2-129a3cebef39: shutdown 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-FollowerState
datanode2_1  | 2022-10-20 02:10:13,070 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-FollowerState] INFO server.RaftServer$Division: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592: changes role from  FOLLOWER to CANDIDATE at term 2 for changeToCandidate
datanode2_1  | 2022-10-20 02:10:13,072 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode2_1  | 2022-10-20 02:10:13,073 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-FollowerState] INFO impl.RoleInfo: 922d5e53-2e0d-4e01-adf2-129a3cebef39: start 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-LeaderElection1
datanode2_1  | 2022-10-20 02:10:13,076 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-LeaderElection1] INFO impl.LeaderElection: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-LeaderElection1 ELECTION round 0: submit vote requests at term 3 for -1: peers:[922d5e53-2e0d-4e01-adf2-129a3cebef39|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1|startupRole:FOLLOWER, 4026c186-2529-49de-a2d8-dcba1039e356|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0|startupRole:FOLLOWER, e4d9a0e3-266c-4558-944a-cafbea7b03e5|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
datanode2_1  | 2022-10-20 02:10:13,093 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode2_1  | 2022-10-20 02:10:13,093 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode2_1  | 2022-10-20 02:10:13,106 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-LeaderElection1-1] INFO server.GrpcServerProtocolClient: Build channel for 4026c186-2529-49de-a2d8-dcba1039e356
datanode2_1  | 2022-10-20 02:10:13,106 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-LeaderElection1-2] INFO server.GrpcServerProtocolClient: Build channel for e4d9a0e3-266c-4558-944a-cafbea7b03e5
datanode2_1  | 2022-10-20 02:10:13,138 [grpc-default-executor-0] INFO server.RaftServer$Division: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592: receive requestVote(ELECTION, e4d9a0e3-266c-4558-944a-cafbea7b03e5, group-44E7403E0592, 3, (t:0, i:0))
datanode2_1  | 2022-10-20 02:10:13,138 [grpc-default-executor-0] INFO impl.VoteContext: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-CANDIDATE: reject ELECTION from e4d9a0e3-266c-4558-944a-cafbea7b03e5: already has voted for 922d5e53-2e0d-4e01-adf2-129a3cebef39 at current term 3
kdc_1        | Oct 20 02:10:45 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1666231827, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Oct 20 02:10:49 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1666231827, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Oct 20 02:10:53 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1666231827, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Oct 20 02:11:03 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1666231827, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Oct 20 02:11:08 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1666231827, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Oct 20 02:11:13 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1666231827, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Oct 20 02:11:23 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Oct 20 02:11:23 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Oct 20 02:11:39 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1666231827, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Oct 20 02:11:46 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1666231827, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Oct 20 02:11:52 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1666231827, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Oct 20 02:11:59 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1666231827, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Oct 20 02:12:03 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1666231827, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Oct 20 02:12:11 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1666231827, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Oct 20 02:12:18 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1666231827, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Oct 20 02:12:23 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1666231827, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Oct 20 02:12:23 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Oct 20 02:12:23 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
datanode2_1  | 2022-10-20 02:10:13,145 [grpc-default-executor-0] INFO server.RaftServer$Division: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592 replies to ELECTION vote request: e4d9a0e3-266c-4558-944a-cafbea7b03e5<-922d5e53-2e0d-4e01-adf2-129a3cebef39#0:FAIL-t3. Peer's state: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592:t3, leader=null, voted=922d5e53-2e0d-4e01-adf2-129a3cebef39, raftlog=Memoized:922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[922d5e53-2e0d-4e01-adf2-129a3cebef39|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1|startupRole:FOLLOWER, 4026c186-2529-49de-a2d8-dcba1039e356|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0|startupRole:FOLLOWER, e4d9a0e3-266c-4558-944a-cafbea7b03e5|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
datanode2_1  | 2022-10-20 02:10:14,226 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-LeaderElection1] INFO impl.LeaderElection: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-LeaderElection1: ELECTION REJECTED received 2 response(s) and 0 exception(s):
datanode2_1  | 2022-10-20 02:10:14,227 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-LeaderElection1] INFO impl.LeaderElection:   Response 0: 922d5e53-2e0d-4e01-adf2-129a3cebef39<-4026c186-2529-49de-a2d8-dcba1039e356#0:FAIL-t3
datanode2_1  | 2022-10-20 02:10:14,227 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-LeaderElection1] INFO impl.LeaderElection:   Response 1: 922d5e53-2e0d-4e01-adf2-129a3cebef39<-e4d9a0e3-266c-4558-944a-cafbea7b03e5#0:FAIL-t3
datanode2_1  | 2022-10-20 02:10:14,227 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-LeaderElection1] INFO impl.LeaderElection: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-LeaderElection1 ELECTION round 0: result REJECTED
datanode2_1  | 2022-10-20 02:10:14,227 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-LeaderElection1] INFO server.RaftServer$Division: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592: changes role from CANDIDATE to FOLLOWER at term 3 for REJECTED
datanode2_1  | 2022-10-20 02:10:14,227 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-LeaderElection1] INFO impl.RoleInfo: 922d5e53-2e0d-4e01-adf2-129a3cebef39: shutdown 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-LeaderElection1
datanode2_1  | 2022-10-20 02:10:14,240 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-LeaderElection1] INFO impl.RoleInfo: 922d5e53-2e0d-4e01-adf2-129a3cebef39: start 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-FollowerState
datanode2_1  | 2022-10-20 02:10:14,248 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode2_1  | 2022-10-20 02:10:14,248 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode2_1  | 2022-10-20 02:10:18,286 [grpc-default-executor-2] INFO server.RaftServer$Division: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592: receive requestVote(ELECTION, 4026c186-2529-49de-a2d8-dcba1039e356, group-44E7403E0592, 4, (t:0, i:0))
datanode2_1  | 2022-10-20 02:10:18,286 [grpc-default-executor-2] INFO impl.VoteContext: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-FOLLOWER: reject ELECTION from 4026c186-2529-49de-a2d8-dcba1039e356: our priority 1 > candidate's priority 0
datanode2_1  | 2022-10-20 02:10:18,288 [grpc-default-executor-2] INFO server.RaftServer$Division: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592: changes role from  FOLLOWER to FOLLOWER at term 4 for candidate:4026c186-2529-49de-a2d8-dcba1039e356
datanode2_1  | 2022-10-20 02:10:18,288 [grpc-default-executor-2] INFO impl.RoleInfo: 922d5e53-2e0d-4e01-adf2-129a3cebef39: shutdown 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-FollowerState
datanode2_1  | 2022-10-20 02:10:18,291 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-FollowerState] INFO impl.FollowerState: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-FollowerState was interrupted
datanode2_1  | 2022-10-20 02:10:18,291 [grpc-default-executor-2] INFO impl.RoleInfo: 922d5e53-2e0d-4e01-adf2-129a3cebef39: start 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-FollowerState
datanode2_1  | 2022-10-20 02:10:18,293 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode2_1  | 2022-10-20 02:10:18,293 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode2_1  | 2022-10-20 02:10:18,293 [grpc-default-executor-2] INFO server.RaftServer$Division: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592 replies to ELECTION vote request: 4026c186-2529-49de-a2d8-dcba1039e356<-922d5e53-2e0d-4e01-adf2-129a3cebef39#0:FAIL-t4. Peer's state: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592:t4, leader=null, voted=null, raftlog=Memoized:922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[922d5e53-2e0d-4e01-adf2-129a3cebef39|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1|startupRole:FOLLOWER, 4026c186-2529-49de-a2d8-dcba1039e356|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0|startupRole:FOLLOWER, e4d9a0e3-266c-4558-944a-cafbea7b03e5|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
datanode2_1  | 2022-10-20 02:10:18,298 [grpc-default-executor-2] INFO server.RaftServer$Division: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592: receive requestVote(ELECTION, e4d9a0e3-266c-4558-944a-cafbea7b03e5, group-44E7403E0592, 4, (t:0, i:0))
datanode2_1  | 2022-10-20 02:10:18,298 [grpc-default-executor-2] INFO impl.VoteContext: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-FOLLOWER: reject ELECTION from e4d9a0e3-266c-4558-944a-cafbea7b03e5: our priority 1 > candidate's priority 0
datanode2_1  | 2022-10-20 02:10:18,298 [grpc-default-executor-2] INFO server.RaftServer$Division: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592: changes role from  FOLLOWER to FOLLOWER at term 4 for candidate:e4d9a0e3-266c-4558-944a-cafbea7b03e5
datanode2_1  | 2022-10-20 02:10:18,298 [grpc-default-executor-2] INFO impl.RoleInfo: 922d5e53-2e0d-4e01-adf2-129a3cebef39: shutdown 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-FollowerState
datanode2_1  | 2022-10-20 02:10:18,298 [grpc-default-executor-2] INFO impl.RoleInfo: 922d5e53-2e0d-4e01-adf2-129a3cebef39: start 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-FollowerState
datanode2_1  | 2022-10-20 02:10:18,298 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-FollowerState] INFO impl.FollowerState: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-FollowerState was interrupted
datanode2_1  | 2022-10-20 02:10:18,302 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode2_1  | 2022-10-20 02:10:18,302 [grpc-default-executor-2] INFO server.RaftServer$Division: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592 replies to ELECTION vote request: e4d9a0e3-266c-4558-944a-cafbea7b03e5<-922d5e53-2e0d-4e01-adf2-129a3cebef39#0:FAIL-t4. Peer's state: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592:t4, leader=null, voted=null, raftlog=Memoized:922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[922d5e53-2e0d-4e01-adf2-129a3cebef39|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1|startupRole:FOLLOWER, 4026c186-2529-49de-a2d8-dcba1039e356|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0|startupRole:FOLLOWER, e4d9a0e3-266c-4558-944a-cafbea7b03e5|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
datanode2_1  | 2022-10-20 02:10:18,306 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode3_1  | Sleeping for 5 seconds
datanode3_1  | Waiting for the service scm3.org:9894
datanode3_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
datanode3_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode3_1  | 2022-10-20 02:09:09,564 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode3_1  | /************************************************************
datanode3_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode3_1  | STARTUP_MSG:   host = 7b621abfba13/172.25.0.104
datanode3_1  | STARTUP_MSG:   args = []
datanode3_1  | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
datanode3_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.2.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.4.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.4.0.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.4.0.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.4.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.4.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.32.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.4.5.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.4.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.4.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.4.0.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.4.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.4.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.3.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.4.0.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.3.0-SNAPSHOT.jar
datanode3_1  | STARTUP_MSG:   build = https://github.com/apache/ozone/ff6d15f5df822a5a3c776320b032fad3dd380f95 ; compiled by 'runner' on 2022-10-20T01:41Z
datanode3_1  | STARTUP_MSG:   java = 11.0.14.1
datanode3_1  | ************************************************************/
datanode3_1  | 2022-10-20 02:09:09,656 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode3_1  | 2022-10-20 02:09:09,982 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode3_1  | 2022-10-20 02:09:10,583 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode3_1  | 2022-10-20 02:09:10,994 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode3_1  | 2022-10-20 02:09:11,001 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode3_1  | 2022-10-20 02:09:11,634 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:7b621abfba13 ip:172.25.0.104
datanode3_1  | 2022-10-20 02:09:14,556 [main] INFO ozone.HddsDatanodeService: Ozone security is enabled. Attempting login for Hdds Datanode user. Principal: dn/dn@EXAMPLE.COM,keytab: /etc/security/keytabs/dn.keytab
datanode3_1  | 2022-10-20 02:09:15,442 [main] INFO security.UserGroupInformation: Login successful for user dn/dn@EXAMPLE.COM using keytab file dn.keytab. Keytab auto renewal enabled : false
datanode3_1  | 2022-10-20 02:09:15,443 [main] INFO ozone.HddsDatanodeService: Hdds Datanode login successful.
datanode3_1  | 2022-10-20 02:09:17,318 [main] INFO ozone.HddsDatanodeService: Initializing secure Datanode.
datanode3_1  | 2022-10-20 02:09:17,319 [main] ERROR client.DNCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
datanode3_1  | 2022-10-20 02:09:17,319 [main] INFO client.DNCertificateClient: Certificate client init case: 0
datanode3_1  | 2022-10-20 02:09:17,324 [main] INFO client.DNCertificateClient: Creating keypair for client as keypair and certificate not found.
datanode3_1  | 2022-10-20 02:09:20,977 [main] INFO ozone.HddsDatanodeService: Init response: GETCERT
datanode3_1  | 2022-10-20 02:09:21,063 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.104,host:7b621abfba13
datanode3_1  | 2022-10-20 02:09:21,065 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
datanode3_1  | 2022-10-20 02:09:21,068 [main] ERROR client.DNCertificateClient: Invalid domain 7b621abfba13
datanode3_1  | 2022-10-20 02:09:21,086 [main] INFO ozone.HddsDatanodeService: Creating csr for DN-> subject:dn@7b621abfba13
datanode3_1  | 2022-10-20 02:09:25,569 [main] INFO client.DNCertificateClient: Loading certificate from location:/data/metadata/dn/certs.
datanode3_1  | 2022-10-20 02:09:25,626 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/1081094776367.crt.
datanode3_1  | 2022-10-20 02:09:25,642 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/ROOTCA-1.crt.
datanode3_1  | 2022-10-20 02:09:25,670 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/CA-1003431474332.crt.
datanode3_1  | 2022-10-20 02:09:25,670 [main] INFO ozone.HddsDatanodeService: Successfully stored SCM signed certificate, case:GETCERT.
datanode3_1  | 2022-10-20 02:09:25,800 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
datanode3_1  | 2022-10-20 02:09:26,673 [main] INFO reflections.Reflections: Reflections took 638 ms to scan 2 urls, producing 92 keys and 204 values 
datanode3_1  | 2022-10-20 02:09:27,232 [main] INFO statemachine.DatanodeStateMachine: Datanode State Machine Task Thread Pool size 4
datanode3_1  | 2022-10-20 02:09:28,210 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode3_1  | 2022-10-20 02:09:28,319 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89297309696
datanode3_1  | 2022-10-20 02:09:28,354 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode3_1  | 2022-10-20 02:09:28,360 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode3_1  | 2022-10-20 02:09:28,506 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode3_1  | 2022-10-20 02:09:28,619 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode3_1  | 2022-10-20 02:09:28,620 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/metadata/ratis/scmUsed not found
datanode3_1  | 2022-10-20 02:09:28,630 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
datanode3_1  | 2022-10-20 02:09:28,630 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/metadata/ratis
datanode3_1  | 2022-10-20 02:09:28,630 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/metadata/ratis
datanode3_1  | 2022-10-20 02:09:28,849 [Thread-8] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode3_1  | 2022-10-20 02:09:28,849 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode3_1  | 2022-10-20 02:09:33,014 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for DNAudit to [].
datanode3_1  | 2022-10-20 02:09:33,723 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode3_1  | 2022-10-20 02:09:33,993 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
datanode3_1  | 2022-10-20 02:09:34,531 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
datanode3_1  | 2022-10-20 02:09:34,546 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
datanode3_1  | 2022-10-20 02:09:34,557 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.host = null (fallback to raft.grpc.server.host)
datanode3_1  | 2022-10-20 02:09:34,559 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
datanode3_1  | 2022-10-20 02:09:34,565 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.host = null (default)
datanode3_1  | 2022-10-20 02:09:34,565 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
datanode3_1  | 2022-10-20 02:09:34,566 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode3_1  | 2022-10-20 02:09:34,576 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2022-10-20 02:09:34,580 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode3_1  | 2022-10-20 02:09:34,590 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode3_1  | 2022-10-20 02:09:34,660 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
datanode3_1  | 2022-10-20 02:09:34,681 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
datanode3_1  | 2022-10-20 02:09:34,684 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
datanode3_1  | 2022-10-20 02:09:40,433 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
datanode3_1  | 2022-10-20 02:09:40,466 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
datanode3_1  | 2022-10-20 02:09:40,470 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
datanode3_1  | 2022-10-20 02:09:40,470 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode3_1  | 2022-10-20 02:09:40,473 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode3_1  | 2022-10-20 02:09:40,490 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode3_1  | 2022-10-20 02:09:40,910 [main] INFO server.XceiverServerGrpc: GrpcServer channel type EpollServerSocketChannel
datanode3_1  | 2022-10-20 02:09:41,706 [main] INFO token.OzoneBlockTokenSecretManager: Updating the current master key for generating tokens
datanode3_1  | 2022-10-20 02:09:41,727 [main] INFO token.ContainerTokenSecretManager: Updating the current master key for generating tokens
datanode3_1  | 2022-10-20 02:09:41,968 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode3_1  | 2022-10-20 02:09:41,968 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
datanode3_1  | 2022-10-20 02:09:41,968 [main] INFO http.BaseHttpServer: HttpAuthType: hdds.datanode.http.auth.type = kerberos
datanode3_1  | 2022-10-20 02:09:42,081 [main] INFO util.log: Logging initialized @42091ms to org.eclipse.jetty.util.log.Slf4jLog
datanode3_1  | 2022-10-20 02:09:42,560 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode3_1  | 2022-10-20 02:09:42,617 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode3_1  | 2022-10-20 02:09:42,640 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
datanode3_1  | 2022-10-20 02:09:42,645 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode3_1  | 2022-10-20 02:09:42,645 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode3_1  | 2022-10-20 02:09:42,660 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.datanode.http.auth.kerberos.principal keytabKey: hdds.datanode.http.auth.kerberos.keytab
datanode3_1  | 2022-10-20 02:09:43,078 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode3_1  | 2022-10-20 02:09:43,081 [main] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
datanode3_1  | 2022-10-20 02:09:43,347 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode3_1  | 2022-10-20 02:09:43,347 [main] INFO server.session: No SessionScavenger set, using defaults
datanode3_1  | 2022-10-20 02:09:43,360 [main] INFO server.session: node0 Scavenging every 600000ms
datanode3_1  | 2022-10-20 02:09:43,659 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode3_1  | 2022-10-20 02:09:43,691 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@2ca3a203{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode3_1  | 2022-10-20 02:09:43,713 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@44eda25b{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode3_1  | 2022-10-20 02:09:44,371 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode3_1  | 2022-10-20 02:09:44,484 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@43ab4e83{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-2083914725146357677/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode3_1  | 2022-10-20 02:09:44,561 [main] INFO server.AbstractConnector: Started ServerConnector@29fa465a{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
datanode3_1  | 2022-10-20 02:09:44,561 [main] INFO server.Server: Started @44571ms
datanode3_1  | 2022-10-20 02:09:44,577 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode3_1  | 2022-10-20 02:09:44,577 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode3_1  | 2022-10-20 02:09:44,579 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode3_1  | 2022-10-20 02:09:44,613 [Datanode State Machine Daemon Thread] INFO statemachine.DatanodeStateMachine: Ozone container server started.
datanode3_1  | 2022-10-20 02:09:44,798 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1c9b20c6] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode3_1  | 2022-10-20 02:09:45,197 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.25.0.115:9891
datanode3_1  | 2022-10-20 02:09:45,238 [Datanode State Machine Task Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode3_1  | 2022-10-20 02:09:48,863 [Datanode State Machine Daemon Thread] ERROR datanode.RunningDatanodeState: Error in executing end point task.
datanode3_1  | java.util.concurrent.ExecutionException: java.util.concurrent.TimeoutException
datanode3_1  | 	at java.base/java.util.concurrent.FutureTask.report(FutureTask.java:122)
datanode3_1  | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:191)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.computeNextContainerState(RunningDatanodeState.java:199)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:239)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:50)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.StateContext.execute(StateContext.java:660)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:298)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:493)
datanode3_1  | 	at java.base/java.lang.Thread.run(Thread.java:829)
datanode3_1  | Caused by: java.util.concurrent.TimeoutException
datanode3_1  | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:204)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.lambda$execute$0(RunningDatanodeState.java:157)
datanode3_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode3_1  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode3_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode3_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode3_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode3_1  | 	... 1 more
datanode3_1  | 2022-10-20 02:09:49,028 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO volume.HddsVolume: SchemaV3 db is created and loaded at /data/hdds/hdds/CID-959c5f9a-2485-4f2a-8075-3da9fe7c4057/DS-2f6a1bc9-a3b4-4708-a3ab-c33814c35e79/container.db for volume DS-2f6a1bc9-a3b4-4708-a3ab-c33814c35e79
datanode3_1  | 2022-10-20 02:09:49,091 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO volume.HddsVolume: SchemaV3 db is stopped at /data/hdds/hdds/CID-959c5f9a-2485-4f2a-8075-3da9fe7c4057/DS-2f6a1bc9-a3b4-4708-a3ab-c33814c35e79/container.db for volume DS-2f6a1bc9-a3b4-4708-a3ab-c33814c35e79
datanode3_1  | 2022-10-20 02:09:49,093 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode3_1  | 2022-10-20 02:09:49,095 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode3_1  | 2022-10-20 02:09:49,420 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis e4d9a0e3-266c-4558-944a-cafbea7b03e5
datanode3_1  | 2022-10-20 02:09:49,537 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO server.RaftServer: e4d9a0e3-266c-4558-944a-cafbea7b03e5: start RPC server
datanode3_1  | 2022-10-20 02:09:49,541 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO server.GrpcService: e4d9a0e3-266c-4558-944a-cafbea7b03e5: GrpcService started, listening on 9858
datanode3_1  | 2022-10-20 02:09:49,550 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO server.GrpcService: e4d9a0e3-266c-4558-944a-cafbea7b03e5: GrpcService started, listening on 9856
datanode3_1  | 2022-10-20 02:09:49,558 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO server.GrpcService: e4d9a0e3-266c-4558-944a-cafbea7b03e5: GrpcService started, listening on 9857
datanode3_1  | 2022-10-20 02:09:49,570 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis e4d9a0e3-266c-4558-944a-cafbea7b03e5 is started using port 9858 for RATIS
datanode3_1  | 2022-10-20 02:09:49,572 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis e4d9a0e3-266c-4558-944a-cafbea7b03e5 is started using port 9857 for RATIS_ADMIN
datanode3_1  | 2022-10-20 02:09:49,572 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis e4d9a0e3-266c-4558-944a-cafbea7b03e5 is started using port 9856 for RATIS_SERVER
datanode3_1  | 2022-10-20 02:09:49,573 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-e4d9a0e3-266c-4558-944a-cafbea7b03e5: Started
datanode3_1  | 2022-10-20 02:09:49,629 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode3_1  | 2022-10-20 02:09:49,633 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode3_1  | 2022-10-20 02:09:54,051 [Command processor thread] INFO server.RaftServer: e4d9a0e3-266c-4558-944a-cafbea7b03e5: addNew group-FFBE57651D3A:[e4d9a0e3-266c-4558-944a-cafbea7b03e5|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1|startupRole:FOLLOWER] returns group-FFBE57651D3A:java.util.concurrent.CompletableFuture@2eacecd1[Not completed]
datanode3_1  | 2022-10-20 02:09:54,240 [pool-23-thread-1] INFO server.RaftServer$Division: e4d9a0e3-266c-4558-944a-cafbea7b03e5: new RaftServerImpl for group-FFBE57651D3A:[e4d9a0e3-266c-4558-944a-cafbea7b03e5|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
datanode3_1  | 2022-10-20 02:09:54,255 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode3_1  | 2022-10-20 02:09:54,265 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode3_1  | 2022-10-20 02:09:54,265 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode3_1  | 2022-10-20 02:09:54,266 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode3_1  | 2022-10-20 02:09:54,266 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode3_1  | 2022-10-20 02:09:54,266 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode3_1  | 2022-10-20 02:09:54,279 [pool-23-thread-1] INFO server.RaftServer$Division: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-FFBE57651D3A: ConfigurationManager, init=-1: peers:[e4d9a0e3-266c-4558-944a-cafbea7b03e5|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
datanode3_1  | 2022-10-20 02:09:54,305 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode3_1  | 2022-10-20 02:09:54,322 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode3_1  | 2022-10-20 02:09:54,323 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode3_1  | 2022-10-20 02:09:54,348 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode3_1  | 2022-10-20 02:09:54,360 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode3_1  | 2022-10-20 02:09:54,375 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode3_1  | 2022-10-20 02:09:54,600 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode3_1  | 2022-10-20 02:09:54,600 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode3_1  | 2022-10-20 02:09:54,623 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode3_1  | 2022-10-20 02:09:54,624 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode3_1  | 2022-10-20 02:09:54,634 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode3_1  | 2022-10-20 02:09:54,635 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/461fda09-4c27-4112-8f11-ffbe57651d3a does not exist. Creating ...
datanode3_1  | 2022-10-20 02:09:54,671 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/461fda09-4c27-4112-8f11-ffbe57651d3a/in_use.lock acquired by nodename 7@7b621abfba13
datanode3_1  | 2022-10-20 02:09:54,707 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/461fda09-4c27-4112-8f11-ffbe57651d3a has been successfully formatted.
datanode3_1  | 2022-10-20 02:09:54,799 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-FFBE57651D3A: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode3_1  | 2022-10-20 02:09:54,820 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode3_1  | 2022-10-20 02:09:54,928 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode3_1  | 2022-10-20 02:09:54,928 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2022-10-20 02:09:54,930 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode3_1  | 2022-10-20 02:09:54,930 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
kdc_1        | Oct 20 02:12:28 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1666231827, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Oct 20 02:12:33 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1666231827, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode2_1  | 2022-10-20 02:10:23,420 [grpc-default-executor-2] INFO server.RaftServer$Division: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592: receive requestVote(ELECTION, e4d9a0e3-266c-4558-944a-cafbea7b03e5, group-44E7403E0592, 5, (t:0, i:0))
datanode2_1  | 2022-10-20 02:10:23,420 [grpc-default-executor-2] INFO impl.VoteContext: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-FOLLOWER: reject ELECTION from e4d9a0e3-266c-4558-944a-cafbea7b03e5: our priority 1 > candidate's priority 0
datanode2_1  | 2022-10-20 02:10:23,420 [grpc-default-executor-2] INFO server.RaftServer$Division: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592: changes role from  FOLLOWER to FOLLOWER at term 5 for candidate:e4d9a0e3-266c-4558-944a-cafbea7b03e5
datanode2_1  | 2022-10-20 02:10:23,420 [grpc-default-executor-2] INFO impl.RoleInfo: 922d5e53-2e0d-4e01-adf2-129a3cebef39: shutdown 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-FollowerState
datanode2_1  | 2022-10-20 02:10:23,421 [grpc-default-executor-2] INFO impl.RoleInfo: 922d5e53-2e0d-4e01-adf2-129a3cebef39: start 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-FollowerState
datanode2_1  | 2022-10-20 02:10:23,421 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-FollowerState] INFO impl.FollowerState: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-FollowerState was interrupted
datanode2_1  | 2022-10-20 02:10:23,429 [grpc-default-executor-2] INFO server.RaftServer$Division: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592 replies to ELECTION vote request: e4d9a0e3-266c-4558-944a-cafbea7b03e5<-922d5e53-2e0d-4e01-adf2-129a3cebef39#0:FAIL-t5. Peer's state: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592:t5, leader=null, voted=null, raftlog=Memoized:922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[922d5e53-2e0d-4e01-adf2-129a3cebef39|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1|startupRole:FOLLOWER, 4026c186-2529-49de-a2d8-dcba1039e356|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0|startupRole:FOLLOWER, e4d9a0e3-266c-4558-944a-cafbea7b03e5|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
datanode2_1  | 2022-10-20 02:10:23,440 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode2_1  | 2022-10-20 02:10:23,454 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode2_1  | 2022-10-20 02:10:23,775 [Command processor thread] INFO server.RaftServer: 922d5e53-2e0d-4e01-adf2-129a3cebef39: addNew group-2749F1317DC3:[922d5e53-2e0d-4e01-adf2-129a3cebef39|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1|startupRole:FOLLOWER] returns group-2749F1317DC3:java.util.concurrent.CompletableFuture@573f2dcb[Not completed]
datanode2_1  | 2022-10-20 02:10:23,779 [pool-23-thread-1] INFO server.RaftServer$Division: 922d5e53-2e0d-4e01-adf2-129a3cebef39: new RaftServerImpl for group-2749F1317DC3:[922d5e53-2e0d-4e01-adf2-129a3cebef39|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
datanode2_1  | 2022-10-20 02:10:23,779 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode2_1  | 2022-10-20 02:10:23,779 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode2_1  | 2022-10-20 02:10:23,779 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode2_1  | 2022-10-20 02:10:23,779 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode2_1  | 2022-10-20 02:10:23,781 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode2_1  | 2022-10-20 02:10:23,781 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode2_1  | 2022-10-20 02:10:23,781 [pool-23-thread-1] INFO server.RaftServer$Division: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-2749F1317DC3: ConfigurationManager, init=-1: peers:[922d5e53-2e0d-4e01-adf2-129a3cebef39|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
datanode2_1  | 2022-10-20 02:10:23,781 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode2_1  | 2022-10-20 02:10:23,781 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode2_1  | 2022-10-20 02:10:23,781 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode2_1  | 2022-10-20 02:10:23,782 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode2_1  | 2022-10-20 02:10:23,782 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode2_1  | 2022-10-20 02:10:23,782 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode2_1  | 2022-10-20 02:10:23,782 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode2_1  | 2022-10-20 02:10:23,782 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode2_1  | 2022-10-20 02:10:23,783 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode2_1  | 2022-10-20 02:10:23,783 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode2_1  | 2022-10-20 02:10:23,783 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode2_1  | 2022-10-20 02:10:23,783 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/b2bba008-413d-43a9-8499-2749f1317dc3 does not exist. Creating ...
datanode2_1  | 2022-10-20 02:10:23,785 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/b2bba008-413d-43a9-8499-2749f1317dc3/in_use.lock acquired by nodename 7@c2c35b3075dc
datanode2_1  | 2022-10-20 02:10:23,787 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/b2bba008-413d-43a9-8499-2749f1317dc3 has been successfully formatted.
datanode2_1  | 2022-10-20 02:10:23,789 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-2749F1317DC3: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode2_1  | 2022-10-20 02:10:23,789 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode2_1  | 2022-10-20 02:10:23,790 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode2_1  | 2022-10-20 02:10:23,790 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2022-10-20 02:10:23,790 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode2_1  | 2022-10-20 02:10:23,790 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
datanode2_1  | 2022-10-20 02:10:23,790 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2022-10-20 02:10:23,790 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode3_1  | 2022-10-20 02:09:55,011 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2022-10-20 02:09:55,069 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode3_1  | 2022-10-20 02:09:55,070 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode3_1  | 2022-10-20 02:09:55,128 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-FFBE57651D3A-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/461fda09-4c27-4112-8f11-ffbe57651d3a
datanode3_1  | 2022-10-20 02:09:55,129 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode3_1  | 2022-10-20 02:09:55,151 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode3_1  | 2022-10-20 02:09:55,152 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2022-10-20 02:09:55,152 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode3_1  | 2022-10-20 02:09:55,153 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode3_1  | 2022-10-20 02:09:55,169 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode3_1  | 2022-10-20 02:09:55,169 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode3_1  | 2022-10-20 02:09:55,170 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode3_1  | 2022-10-20 02:09:55,196 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode3_1  | 2022-10-20 02:09:55,197 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode3_1  | 2022-10-20 02:09:55,217 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
datanode3_1  | 2022-10-20 02:09:55,217 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode3_1  | 2022-10-20 02:09:55,239 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-FFBE57651D3A-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode3_1  | 2022-10-20 02:09:55,239 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-FFBE57651D3A-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode3_1  | 2022-10-20 02:09:55,315 [pool-23-thread-1] INFO server.RaftServer$Division: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-FFBE57651D3A: start as a follower, conf=-1: peers:[e4d9a0e3-266c-4558-944a-cafbea7b03e5|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode3_1  | 2022-10-20 02:09:55,317 [pool-23-thread-1] INFO server.RaftServer$Division: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-FFBE57651D3A: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode3_1  | 2022-10-20 02:09:55,318 [pool-23-thread-1] INFO impl.RoleInfo: e4d9a0e3-266c-4558-944a-cafbea7b03e5: start e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-FFBE57651D3A-FollowerState
datanode3_1  | 2022-10-20 02:09:55,322 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-FFBE57651D3A-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode3_1  | 2022-10-20 02:09:55,324 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-FFBE57651D3A-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode3_1  | 2022-10-20 02:09:55,374 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-FFBE57651D3A,id=e4d9a0e3-266c-4558-944a-cafbea7b03e5
datanode3_1  | 2022-10-20 02:09:55,375 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode3_1  | 2022-10-20 02:09:55,391 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode3_1  | 2022-10-20 02:09:55,397 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode3_1  | 2022-10-20 02:09:55,398 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode3_1  | 2022-10-20 02:09:55,473 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=461fda09-4c27-4112-8f11-ffbe57651d3a
datanode3_1  | 2022-10-20 02:09:55,489 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=461fda09-4c27-4112-8f11-ffbe57651d3a.
datanode3_1  | 2022-10-20 02:09:55,489 [Command processor thread] INFO server.RaftServer: e4d9a0e3-266c-4558-944a-cafbea7b03e5: addNew group-44E7403E0592:[922d5e53-2e0d-4e01-adf2-129a3cebef39|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1|startupRole:FOLLOWER, 4026c186-2529-49de-a2d8-dcba1039e356|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0|startupRole:FOLLOWER, e4d9a0e3-266c-4558-944a-cafbea7b03e5|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0|startupRole:FOLLOWER] returns group-44E7403E0592:java.util.concurrent.CompletableFuture@6e1f9f97[Not completed]
datanode3_1  | 2022-10-20 02:09:55,517 [pool-23-thread-1] INFO server.RaftServer$Division: e4d9a0e3-266c-4558-944a-cafbea7b03e5: new RaftServerImpl for group-44E7403E0592:[922d5e53-2e0d-4e01-adf2-129a3cebef39|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1|startupRole:FOLLOWER, 4026c186-2529-49de-a2d8-dcba1039e356|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0|startupRole:FOLLOWER, e4d9a0e3-266c-4558-944a-cafbea7b03e5|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
datanode3_1  | 2022-10-20 02:09:55,517 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode3_1  | 2022-10-20 02:09:55,517 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode3_1  | 2022-10-20 02:09:55,518 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode3_1  | 2022-10-20 02:09:55,518 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode3_1  | 2022-10-20 02:09:55,518 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode3_1  | 2022-10-20 02:09:55,518 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode3_1  | 2022-10-20 02:09:55,518 [pool-23-thread-1] INFO server.RaftServer$Division: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592: ConfigurationManager, init=-1: peers:[922d5e53-2e0d-4e01-adf2-129a3cebef39|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1|startupRole:FOLLOWER, 4026c186-2529-49de-a2d8-dcba1039e356|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0|startupRole:FOLLOWER, e4d9a0e3-266c-4558-944a-cafbea7b03e5|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
datanode3_1  | 2022-10-20 02:09:55,518 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode3_1  | 2022-10-20 02:09:55,519 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode3_1  | 2022-10-20 02:09:55,521 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode3_1  | 2022-10-20 02:09:55,521 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode3_1  | 2022-10-20 02:09:55,521 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode3_1  | 2022-10-20 02:09:55,522 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode3_1  | 2022-10-20 02:09:55,522 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode3_1  | 2022-10-20 02:09:55,533 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode3_1  | 2022-10-20 02:09:55,533 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode3_1  | 2022-10-20 02:09:55,533 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode3_1  | 2022-10-20 02:09:55,533 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode3_1  | 2022-10-20 02:09:55,534 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/904a7869-3351-4618-b9db-44e7403e0592 does not exist. Creating ...
datanode3_1  | 2022-10-20 02:09:55,538 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/904a7869-3351-4618-b9db-44e7403e0592/in_use.lock acquired by nodename 7@7b621abfba13
datanode3_1  | 2022-10-20 02:09:55,545 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/904a7869-3351-4618-b9db-44e7403e0592 has been successfully formatted.
datanode3_1  | 2022-10-20 02:09:55,546 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-44E7403E0592: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode3_1  | 2022-10-20 02:09:55,546 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode3_1  | 2022-10-20 02:09:55,549 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode3_1  | 2022-10-20 02:09:55,550 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2022-10-20 02:09:55,554 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode3_1  | 2022-10-20 02:09:55,559 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
datanode3_1  | 2022-10-20 02:09:55,560 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2022-10-20 02:09:55,561 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode3_1  | 2022-10-20 02:09:55,577 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode3_1  | 2022-10-20 02:09:55,577 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/904a7869-3351-4618-b9db-44e7403e0592
datanode3_1  | 2022-10-20 02:09:55,577 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode3_1  | 2022-10-20 02:09:55,578 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode3_1  | 2022-10-20 02:09:55,578 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2022-10-20 02:09:55,578 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode3_1  | 2022-10-20 02:09:55,585 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode3_1  | 2022-10-20 02:09:55,585 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode3_1  | 2022-10-20 02:09:55,585 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode3_1  | 2022-10-20 02:09:55,586 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode3_1  | 2022-10-20 02:09:55,586 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode3_1  | 2022-10-20 02:09:55,625 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode3_1  | 2022-10-20 02:09:55,626 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
datanode3_1  | 2022-10-20 02:09:55,627 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode3_1  | 2022-10-20 02:09:55,627 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode3_1  | 2022-10-20 02:09:55,627 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode3_1  | 2022-10-20 02:09:55,635 [pool-23-thread-1] INFO server.RaftServer$Division: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592: start as a follower, conf=-1: peers:[922d5e53-2e0d-4e01-adf2-129a3cebef39|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1|startupRole:FOLLOWER, 4026c186-2529-49de-a2d8-dcba1039e356|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0|startupRole:FOLLOWER, e4d9a0e3-266c-4558-944a-cafbea7b03e5|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
datanode3_1  | 2022-10-20 02:09:55,635 [pool-23-thread-1] INFO server.RaftServer$Division: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode3_1  | 2022-10-20 02:09:55,636 [pool-23-thread-1] INFO impl.RoleInfo: e4d9a0e3-266c-4558-944a-cafbea7b03e5: start e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-FollowerState
datanode2_1  | 2022-10-20 02:10:23,790 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode2_1  | 2022-10-20 02:10:23,790 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-2749F1317DC3-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/b2bba008-413d-43a9-8499-2749f1317dc3
datanode2_1  | 2022-10-20 02:10:23,790 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode2_1  | 2022-10-20 02:10:23,790 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode2_1  | 2022-10-20 02:10:23,790 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2022-10-20 02:10:23,790 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode2_1  | 2022-10-20 02:10:23,791 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode2_1  | 2022-10-20 02:10:23,791 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode2_1  | 2022-10-20 02:10:23,791 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode2_1  | 2022-10-20 02:10:23,791 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode2_1  | 2022-10-20 02:10:23,797 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode2_1  | 2022-10-20 02:10:23,797 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode2_1  | 2022-10-20 02:10:23,798 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
datanode2_1  | 2022-10-20 02:10:23,798 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode2_1  | 2022-10-20 02:10:23,798 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-2749F1317DC3-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode2_1  | 2022-10-20 02:10:23,798 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-2749F1317DC3-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode2_1  | 2022-10-20 02:10:23,798 [pool-23-thread-1] INFO server.RaftServer$Division: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-2749F1317DC3: start as a follower, conf=-1: peers:[922d5e53-2e0d-4e01-adf2-129a3cebef39|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode2_1  | 2022-10-20 02:10:23,798 [pool-23-thread-1] INFO server.RaftServer$Division: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-2749F1317DC3: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode2_1  | 2022-10-20 02:10:23,798 [pool-23-thread-1] INFO impl.RoleInfo: 922d5e53-2e0d-4e01-adf2-129a3cebef39: start 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-2749F1317DC3-FollowerState
datanode2_1  | 2022-10-20 02:10:23,825 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-2749F1317DC3,id=922d5e53-2e0d-4e01-adf2-129a3cebef39
datanode2_1  | 2022-10-20 02:10:23,826 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode2_1  | 2022-10-20 02:10:23,826 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode2_1  | 2022-10-20 02:10:23,826 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode2_1  | 2022-10-20 02:10:23,826 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode2_1  | 2022-10-20 02:10:23,828 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=b2bba008-413d-43a9-8499-2749f1317dc3
datanode2_1  | 2022-10-20 02:10:23,835 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-2749F1317DC3-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode2_1  | 2022-10-20 02:10:23,835 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-2749F1317DC3-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode2_1  | 2022-10-20 02:10:23,843 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=b2bba008-413d-43a9-8499-2749f1317dc3.
datanode2_1  | 2022-10-20 02:10:28,576 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-FollowerState] INFO impl.FollowerState: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5155484975ns, electionTimeout:5122ms
datanode2_1  | 2022-10-20 02:10:28,576 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-FollowerState] INFO impl.RoleInfo: 922d5e53-2e0d-4e01-adf2-129a3cebef39: shutdown 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-FollowerState
datanode2_1  | 2022-10-20 02:10:28,576 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-FollowerState] INFO server.RaftServer$Division: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592: changes role from  FOLLOWER to CANDIDATE at term 5 for changeToCandidate
datanode2_1  | 2022-10-20 02:10:28,577 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode2_1  | 2022-10-20 02:10:28,577 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-FollowerState] INFO impl.RoleInfo: 922d5e53-2e0d-4e01-adf2-129a3cebef39: start 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-LeaderElection2
datanode2_1  | 2022-10-20 02:10:28,585 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-LeaderElection2] INFO impl.LeaderElection: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-LeaderElection2 ELECTION round 0: submit vote requests at term 6 for -1: peers:[922d5e53-2e0d-4e01-adf2-129a3cebef39|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1|startupRole:FOLLOWER, 4026c186-2529-49de-a2d8-dcba1039e356|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0|startupRole:FOLLOWER, e4d9a0e3-266c-4558-944a-cafbea7b03e5|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
datanode2_1  | 2022-10-20 02:10:28,595 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode2_1  | 2022-10-20 02:10:28,603 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode2_1  | 2022-10-20 02:10:28,610 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-LeaderElection2] INFO impl.LeaderElection: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-LeaderElection2: ELECTION PASSED received 1 response(s) and 0 exception(s):
datanode2_1  | 2022-10-20 02:10:28,611 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-LeaderElection2] INFO impl.LeaderElection:   Response 0: 922d5e53-2e0d-4e01-adf2-129a3cebef39<-4026c186-2529-49de-a2d8-dcba1039e356#0:OK-t6
datanode2_1  | 2022-10-20 02:10:28,611 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-LeaderElection2] INFO impl.LeaderElection: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-LeaderElection2 ELECTION round 0: result PASSED
datanode2_1  | 2022-10-20 02:10:28,612 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-LeaderElection2] INFO impl.RoleInfo: 922d5e53-2e0d-4e01-adf2-129a3cebef39: shutdown 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-LeaderElection2
datanode2_1  | 2022-10-20 02:10:28,612 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-LeaderElection2] INFO server.RaftServer$Division: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592: changes role from CANDIDATE to LEADER at term 6 for changeToLeader
datanode2_1  | 2022-10-20 02:10:28,612 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-44E7403E0592 with new leaderId: 922d5e53-2e0d-4e01-adf2-129a3cebef39
datanode2_1  | 2022-10-20 02:10:28,612 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-LeaderElection2] INFO server.RaftServer$Division: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592: change Leader from null to 922d5e53-2e0d-4e01-adf2-129a3cebef39 at term 6 for becomeLeader, leader elected after 29221ms
datanode2_1  | 2022-10-20 02:10:28,633 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode2_1  | 2022-10-20 02:10:28,665 [grpc-default-executor-2] INFO server.RaftServer$Division: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592: receive requestVote(ELECTION, e4d9a0e3-266c-4558-944a-cafbea7b03e5, group-44E7403E0592, 6, (t:0, i:0))
datanode2_1  | 2022-10-20 02:10:28,679 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode2_1  | 2022-10-20 02:10:28,679 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode2_1  | 2022-10-20 02:10:28,714 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode2_1  | 2022-10-20 02:10:28,714 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode2_1  | 2022-10-20 02:10:28,715 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode2_1  | 2022-10-20 02:10:28,730 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode2_1  | 2022-10-20 02:10:28,738 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
datanode2_1  | 2022-10-20 02:10:28,754 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode2_1  | 2022-10-20 02:10:28,754 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2022-10-20 02:10:28,754 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode2_1  | 2022-10-20 02:10:28,763 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode2_1  | 2022-10-20 02:10:28,764 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode2_1  | 2022-10-20 02:10:28,764 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode2_1  | 2022-10-20 02:10:28,764 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
datanode2_1  | 2022-10-20 02:10:28,764 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.wait-time.min = 10ms (default)
datanode2_1  | 2022-10-20 02:10:28,779 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode2_1  | 2022-10-20 02:10:28,779 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2022-10-20 02:10:28,785 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode2_1  | 2022-10-20 02:10:28,785 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode2_1  | 2022-10-20 02:10:28,785 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode2_1  | 2022-10-20 02:10:28,786 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode2_1  | 2022-10-20 02:10:28,786 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
datanode2_1  | 2022-10-20 02:10:28,787 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.wait-time.min = 10ms (default)
datanode2_1  | 2022-10-20 02:10:28,789 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-LeaderElection2] INFO impl.RoleInfo: 922d5e53-2e0d-4e01-adf2-129a3cebef39: start 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-LeaderStateImpl
datanode2_1  | 2022-10-20 02:10:28,812 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-SegmentedRaftLogWorker: Starting segment from index:0
datanode2_1  | 2022-10-20 02:10:28,815 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/904a7869-3351-4618-b9db-44e7403e0592/current/log_inprogress_0
datanode2_1  | 2022-10-20 02:10:28,829 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-LeaderElection2] INFO server.RaftServer$Division: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592: set configuration 0: peers:[922d5e53-2e0d-4e01-adf2-129a3cebef39|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1|startupRole:FOLLOWER, 4026c186-2529-49de-a2d8-dcba1039e356|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0|startupRole:FOLLOWER, e4d9a0e3-266c-4558-944a-cafbea7b03e5|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
datanode2_1  | 2022-10-20 02:10:28,830 [grpc-default-executor-2] INFO impl.VoteContext: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-LEADER: reject ELECTION from e4d9a0e3-266c-4558-944a-cafbea7b03e5: already has voted for 922d5e53-2e0d-4e01-adf2-129a3cebef39 at current term 6
datanode2_1  | 2022-10-20 02:10:28,830 [grpc-default-executor-2] INFO server.RaftServer$Division: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592 replies to ELECTION vote request: e4d9a0e3-266c-4558-944a-cafbea7b03e5<-922d5e53-2e0d-4e01-adf2-129a3cebef39#0:FAIL-t6. Peer's state: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592:t6, leader=922d5e53-2e0d-4e01-adf2-129a3cebef39, voted=922d5e53-2e0d-4e01-adf2-129a3cebef39, raftlog=Memoized:922d5e53-2e0d-4e01-adf2-129a3cebef39@group-44E7403E0592-SegmentedRaftLog:OPENED:c-1, conf=0: peers:[922d5e53-2e0d-4e01-adf2-129a3cebef39|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1|startupRole:FOLLOWER, 4026c186-2529-49de-a2d8-dcba1039e356|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0|startupRole:FOLLOWER, e4d9a0e3-266c-4558-944a-cafbea7b03e5|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
datanode2_1  | 2022-10-20 02:10:28,861 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-2749F1317DC3-FollowerState] INFO impl.FollowerState: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-2749F1317DC3-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5062834817ns, electionTimeout:5023ms
datanode2_1  | 2022-10-20 02:10:28,866 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-2749F1317DC3-FollowerState] INFO impl.RoleInfo: 922d5e53-2e0d-4e01-adf2-129a3cebef39: shutdown 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-2749F1317DC3-FollowerState
datanode2_1  | 2022-10-20 02:10:28,867 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-2749F1317DC3-FollowerState] INFO server.RaftServer$Division: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-2749F1317DC3: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode2_1  | 2022-10-20 02:10:28,867 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-2749F1317DC3-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode2_1  | 2022-10-20 02:10:28,868 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-2749F1317DC3-FollowerState] INFO impl.RoleInfo: 922d5e53-2e0d-4e01-adf2-129a3cebef39: start 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-2749F1317DC3-LeaderElection3
datanode2_1  | 2022-10-20 02:10:28,918 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-2749F1317DC3-LeaderElection3] INFO impl.LeaderElection: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-2749F1317DC3-LeaderElection3 ELECTION round 0: submit vote requests at term 1 for -1: peers:[922d5e53-2e0d-4e01-adf2-129a3cebef39|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode2_1  | 2022-10-20 02:10:28,925 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-2749F1317DC3-LeaderElection3] INFO impl.LeaderElection: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-2749F1317DC3-LeaderElection3 ELECTION round 0: result PASSED (term=1)
datanode2_1  | 2022-10-20 02:10:28,926 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-2749F1317DC3-LeaderElection3] INFO impl.RoleInfo: 922d5e53-2e0d-4e01-adf2-129a3cebef39: shutdown 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-2749F1317DC3-LeaderElection3
datanode2_1  | 2022-10-20 02:10:28,931 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-2749F1317DC3-LeaderElection3] INFO server.RaftServer$Division: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-2749F1317DC3: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode2_1  | 2022-10-20 02:10:28,931 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-2749F1317DC3-LeaderElection3] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-2749F1317DC3 with new leaderId: 922d5e53-2e0d-4e01-adf2-129a3cebef39
datanode2_1  | 2022-10-20 02:10:28,931 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-2749F1317DC3-LeaderElection3] INFO server.RaftServer$Division: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-2749F1317DC3: change Leader from null to 922d5e53-2e0d-4e01-adf2-129a3cebef39 at term 1 for becomeLeader, leader elected after 5149ms
datanode2_1  | 2022-10-20 02:10:28,931 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-2749F1317DC3-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode2_1  | 2022-10-20 02:10:28,932 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-2749F1317DC3-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode2_1  | 2022-10-20 02:10:28,932 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-2749F1317DC3-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode2_1  | 2022-10-20 02:10:28,963 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-2749F1317DC3-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode2_1  | 2022-10-20 02:10:28,968 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-2749F1317DC3-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode2_1  | 2022-10-20 02:10:28,968 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-2749F1317DC3-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode2_1  | 2022-10-20 02:10:28,968 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-2749F1317DC3-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode2_1  | 2022-10-20 02:10:28,968 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-2749F1317DC3-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
datanode2_1  | 2022-10-20 02:10:28,979 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-2749F1317DC3-LeaderElection3] INFO impl.RoleInfo: 922d5e53-2e0d-4e01-adf2-129a3cebef39: start 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-2749F1317DC3-LeaderStateImpl
datanode2_1  | 2022-10-20 02:10:28,980 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-2749F1317DC3-LeaderElection3] INFO segmented.SegmentedRaftLogWorker: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-2749F1317DC3-SegmentedRaftLogWorker: Starting segment from index:0
datanode2_1  | 2022-10-20 02:10:29,010 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-2749F1317DC3-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-2749F1317DC3-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/b2bba008-413d-43a9-8499-2749f1317dc3/current/log_inprogress_0
datanode2_1  | 2022-10-20 02:10:29,058 [922d5e53-2e0d-4e01-adf2-129a3cebef39@group-2749F1317DC3-LeaderElection3] INFO server.RaftServer$Division: 922d5e53-2e0d-4e01-adf2-129a3cebef39@group-2749F1317DC3: set configuration 0: peers:[922d5e53-2e0d-4e01-adf2-129a3cebef39|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode2_1  | 2022-10-20 02:10:57,907 [ChunkWriter-1-0] INFO client.DNCertificateClient: Getting certificate with certSerialId:1087378534705.
om3_1        | Sleeping for 5 seconds
om3_1        | Waiting for the service scm3.org:9894
om3_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om3_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om3_1        | 2022-10-20 02:09:09,926 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om3_1        | /************************************************************
om3_1        | STARTUP_MSG: Starting OzoneManager
om3_1        | STARTUP_MSG:   host = om3/172.25.0.113
om3_1        | STARTUP_MSG:   args = [--init]
om3_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
om3_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/jna-platform-5.2.0.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/orc-core-1.5.8.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.2.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-linux-x86_64.jar:/opt/hadoop/share/ozone/lib/httpmime-4.5.6.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.9.0.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/httpasyncclient-4.1.3.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.4.0.jar:/opt/hadoop/share/ozone/lib/jetty-client-9.4.31.v20200723.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/ranger-plugin-classloader-2.3.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.4.0.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.48.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.4.0.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.48.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-osx-aarch_64.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.4.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.48.1.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.10.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/commons-lang-2.6.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jna-5.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.4.0.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.32.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.48.1.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.48.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.4.5.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.4.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-cred-2.3.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/hppc-0.8.0.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-osx-x86_64.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-audit-2.3.0.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/jersey-client-1.19.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-windows-x86_64.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.4.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.4.0.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-linux-aarch_64.jar:/opt/hadoop/share/ozone/lib/gethostname4j-0.0.2.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.21.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.48.1.jar:/opt/hadoop/share/ozone/lib/ranger-intg-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.53.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.4.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.4.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.48.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.4.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.25.0.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.3.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.4.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/httpcore-nio-4.4.6.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar
om3_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/ff6d15f5df822a5a3c776320b032fad3dd380f95 ; compiled by 'runner' on 2022-10-20T01:42Z
om3_1        | STARTUP_MSG:   java = 11.0.14.1
om3_1        | ************************************************************/
om3_1        | 2022-10-20 02:09:09,979 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om3_1        | 2022-10-20 02:09:15,720 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for OMAudit to [].
om3_1        | 2022-10-20 02:09:17,818 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om3_1        | 2022-10-20 02:09:18,240 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om3, RPC Address: om3:9862 and Ratis port: 9872
om3_1        | 2022-10-20 02:09:18,244 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om3: om3
om3_1        | 2022-10-20 02:09:18,244 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om3: om3
om3_1        | 2022-10-20 02:09:19,719 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om3_1        | 2022-10-20 02:09:19,719 [main] INFO om.OzoneManager: Ozone Manager login successful.
om3_1        | 2022-10-20 02:09:19,776 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1        | 2022-10-20 02:09:20,341 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 3 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
om3_1        | 2022-10-20 02:09:22,176 [main] INFO om.OzoneManager: Initializing secure OzoneManager.
om3_1        | 2022-10-20 02:09:25,165 [main] ERROR client.OMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
om3_1        | 2022-10-20 02:09:25,165 [main] INFO client.OMCertificateClient: Certificate client init case: 0
om3_1        | 2022-10-20 02:09:25,166 [main] INFO client.OMCertificateClient: Creating keypair for client as keypair and certificate not found.
om3_1        | 2022-10-20 02:09:31,227 [main] INFO om.OzoneManager: Init response: GETCERT
om3_1        | 2022-10-20 02:09:31,455 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.113,host:om3
om3_1        | 2022-10-20 02:09:31,455 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
om3_1        | 2022-10-20 02:09:31,491 [main] ERROR client.OMCertificateClient: Invalid domain om3
om3_1        | 2022-10-20 02:09:31,498 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om3_1        | 2022-10-20 02:09:31,507 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om3, RPC Address: om3:9862 and Ratis port: 9872
om3_1        | 2022-10-20 02:09:31,507 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om3: om3
om3_1        | 2022-10-20 02:09:31,511 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om3: om3
om3_1        | 2022-10-20 02:09:31,533 [main] INFO om.OzoneManager: Creating csr for OM->dns:om3,ip:172.25.0.113,scmId:193991a4-d526-4123-97ec-0cf0bd3049b7,clusterId:CID-959c5f9a-2485-4f2a-8075-3da9fe7c4057,subject:om3
om3_1        | 2022-10-20 02:09:32,341 [main] INFO om.OzoneManager: OzoneManager ports added:[name: "RPC"
om3_1        | value: 9862
om3_1        | ]
om3_1        | 2022-10-20 02:09:33,683 [main] INFO om.OzoneManager: Successfully stored SCM signed certificate.
om3_1        | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-959c5f9a-2485-4f2a-8075-3da9fe7c4057;layoutVersion=3
om3_1        | 2022-10-20 02:09:33,839 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
om3_1        | /************************************************************
om3_1        | SHUTDOWN_MSG: Shutting down OzoneManager at om3/172.25.0.113
om3_1        | ************************************************************/
om3_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om3_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om3_1        | 2022-10-20 02:09:42,173 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om3_1        | /************************************************************
kms_1        | Sleeping for 5 seconds
kms_1        | WARNING: /opt/hadoop/temp does not exist. Creating.
om1_1        | Sleeping for 5 seconds
om1_1        | Waiting for the service scm3.org:9894
om1_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om1_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om1_1        | 2022-10-20 02:09:08,436 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om1_1        | /************************************************************
om1_1        | STARTUP_MSG: Starting OzoneManager
om1_1        | STARTUP_MSG:   host = om1/172.25.0.111
om1_1        | STARTUP_MSG:   args = [--init]
om1_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
datanode3_1  | 2022-10-20 02:09:55,676 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-44E7403E0592,id=e4d9a0e3-266c-4558-944a-cafbea7b03e5
datanode3_1  | 2022-10-20 02:09:55,676 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode3_1  | 2022-10-20 02:09:55,676 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode3_1  | 2022-10-20 02:09:55,676 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode3_1  | 2022-10-20 02:09:55,694 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode3_1  | 2022-10-20 02:09:55,676 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode3_1  | 2022-10-20 02:09:55,695 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode3_1  | 2022-10-20 02:09:55,719 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=904a7869-3351-4618-b9db-44e7403e0592
datanode3_1  | 2022-10-20 02:10:00,445 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-FFBE57651D3A-FollowerState] INFO impl.FollowerState: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-FFBE57651D3A-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5127019364ns, electionTimeout:5091ms
datanode3_1  | 2022-10-20 02:10:00,446 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-FFBE57651D3A-FollowerState] INFO impl.RoleInfo: e4d9a0e3-266c-4558-944a-cafbea7b03e5: shutdown e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-FFBE57651D3A-FollowerState
datanode3_1  | 2022-10-20 02:10:00,456 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-FFBE57651D3A-FollowerState] INFO server.RaftServer$Division: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-FFBE57651D3A: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode3_1  | 2022-10-20 02:10:00,491 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-FFBE57651D3A-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode3_1  | 2022-10-20 02:10:00,492 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-FFBE57651D3A-FollowerState] INFO impl.RoleInfo: e4d9a0e3-266c-4558-944a-cafbea7b03e5: start e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-FFBE57651D3A-LeaderElection1
datanode3_1  | 2022-10-20 02:10:00,559 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-FFBE57651D3A-LeaderElection1] INFO impl.LeaderElection: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-FFBE57651D3A-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: peers:[e4d9a0e3-266c-4558-944a-cafbea7b03e5|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode3_1  | 2022-10-20 02:10:00,560 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-FFBE57651D3A-LeaderElection1] INFO impl.LeaderElection: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-FFBE57651D3A-LeaderElection1 ELECTION round 0: result PASSED (term=1)
datanode3_1  | 2022-10-20 02:10:00,570 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-FFBE57651D3A-LeaderElection1] INFO impl.RoleInfo: e4d9a0e3-266c-4558-944a-cafbea7b03e5: shutdown e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-FFBE57651D3A-LeaderElection1
datanode3_1  | 2022-10-20 02:10:00,573 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-FFBE57651D3A-LeaderElection1] INFO server.RaftServer$Division: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-FFBE57651D3A: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode3_1  | 2022-10-20 02:10:00,575 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-FFBE57651D3A-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-FFBE57651D3A with new leaderId: e4d9a0e3-266c-4558-944a-cafbea7b03e5
datanode3_1  | 2022-10-20 02:10:00,576 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-FFBE57651D3A-LeaderElection1] INFO server.RaftServer$Division: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-FFBE57651D3A: change Leader from null to e4d9a0e3-266c-4558-944a-cafbea7b03e5 at term 1 for becomeLeader, leader elected after 6227ms
datanode3_1  | 2022-10-20 02:10:00,620 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-FFBE57651D3A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode3_1  | 2022-10-20 02:10:00,639 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-FFBE57651D3A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode3_1  | 2022-10-20 02:10:00,645 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-FFBE57651D3A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode3_1  | 2022-10-20 02:10:00,659 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-FFBE57651D3A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode3_1  | 2022-10-20 02:10:00,669 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-FFBE57651D3A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode3_1  | 2022-10-20 02:10:00,675 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-FFBE57651D3A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode3_1  | 2022-10-20 02:10:00,720 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-FFBE57651D3A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode3_1  | 2022-10-20 02:10:00,726 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-FFBE57651D3A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
datanode3_1  | 2022-10-20 02:10:00,749 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-FFBE57651D3A-LeaderElection1] INFO impl.RoleInfo: e4d9a0e3-266c-4558-944a-cafbea7b03e5: start e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-FFBE57651D3A-LeaderStateImpl
datanode3_1  | 2022-10-20 02:10:00,847 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-FollowerState] INFO impl.FollowerState: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5211440993ns, electionTimeout:5133ms
datanode3_1  | 2022-10-20 02:10:00,857 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-FollowerState] INFO impl.RoleInfo: e4d9a0e3-266c-4558-944a-cafbea7b03e5: shutdown e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-FollowerState
datanode3_1  | 2022-10-20 02:10:00,858 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-FollowerState] INFO server.RaftServer$Division: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode3_1  | 2022-10-20 02:10:00,875 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode3_1  | 2022-10-20 02:10:00,876 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-FollowerState] INFO impl.RoleInfo: e4d9a0e3-266c-4558-944a-cafbea7b03e5: start e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection2
datanode3_1  | 2022-10-20 02:10:00,904 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-FFBE57651D3A-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-FFBE57651D3A-SegmentedRaftLogWorker: Starting segment from index:0
datanode3_1  | 2022-10-20 02:10:01,317 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection2] INFO impl.LeaderElection: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection2 ELECTION round 0: submit vote requests at term 1 for -1: peers:[922d5e53-2e0d-4e01-adf2-129a3cebef39|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1|startupRole:FOLLOWER, 4026c186-2529-49de-a2d8-dcba1039e356|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0|startupRole:FOLLOWER, e4d9a0e3-266c-4558-944a-cafbea7b03e5|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
datanode3_1  | 2022-10-20 02:10:01,393 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection2-1] INFO server.GrpcServerProtocolClient: Build channel for 922d5e53-2e0d-4e01-adf2-129a3cebef39
datanode3_1  | 2022-10-20 02:10:01,413 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode3_1  | 2022-10-20 02:10:01,434 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
om2_1        | Sleeping for 5 seconds
om2_1        | Waiting for the service scm3.org:9894
om2_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om2_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om2_1        | 2022-10-20 02:09:08,933 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om2_1        | /************************************************************
om2_1        | STARTUP_MSG: Starting OzoneManager
om2_1        | STARTUP_MSG:   host = om2/172.25.0.112
om2_1        | STARTUP_MSG:   args = [--init]
om2_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
om1_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/jna-platform-5.2.0.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/orc-core-1.5.8.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.2.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-linux-x86_64.jar:/opt/hadoop/share/ozone/lib/httpmime-4.5.6.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.9.0.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/httpasyncclient-4.1.3.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.4.0.jar:/opt/hadoop/share/ozone/lib/jetty-client-9.4.31.v20200723.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/ranger-plugin-classloader-2.3.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.4.0.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.48.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.4.0.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.48.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-osx-aarch_64.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.4.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.48.1.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.10.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/commons-lang-2.6.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jna-5.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.4.0.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.32.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.48.1.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.48.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.4.5.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.4.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-cred-2.3.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/hppc-0.8.0.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-osx-x86_64.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-audit-2.3.0.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/jersey-client-1.19.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-windows-x86_64.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.4.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.4.0.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-linux-aarch_64.jar:/opt/hadoop/share/ozone/lib/gethostname4j-0.0.2.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.21.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.48.1.jar:/opt/hadoop/share/ozone/lib/ranger-intg-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.53.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.4.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.4.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.48.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.4.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.25.0.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.3.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.4.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/httpcore-nio-4.4.6.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar
om1_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/ff6d15f5df822a5a3c776320b032fad3dd380f95 ; compiled by 'runner' on 2022-10-20T01:42Z
om1_1        | STARTUP_MSG:   java = 11.0.14.1
om1_1        | ************************************************************/
om1_1        | 2022-10-20 02:09:08,490 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om1_1        | 2022-10-20 02:09:14,314 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for OMAudit to [].
om1_1        | 2022-10-20 02:09:17,000 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om1_1        | 2022-10-20 02:09:17,222 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om1, RPC Address: om1:9862 and Ratis port: 9872
om1_1        | 2022-10-20 02:09:17,225 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om1: om1
om1_1        | 2022-10-20 02:09:17,225 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om1: om1
om1_1        | 2022-10-20 02:09:17,974 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om1_1        | 2022-10-20 02:09:17,988 [main] INFO om.OzoneManager: Ozone Manager login successful.
om1_1        | 2022-10-20 02:09:18,009 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1        | 2022-10-20 02:09:18,671 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 3 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
om1_1        | 2022-10-20 02:09:20,601 [main] INFO om.OzoneManager: Initializing secure OzoneManager.
om1_1        | 2022-10-20 02:09:23,449 [main] ERROR client.OMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
om1_1        | 2022-10-20 02:09:23,450 [main] INFO client.OMCertificateClient: Certificate client init case: 0
om1_1        | 2022-10-20 02:09:23,457 [main] INFO client.OMCertificateClient: Creating keypair for client as keypair and certificate not found.
om1_1        | 2022-10-20 02:09:28,745 [main] INFO om.OzoneManager: Init response: GETCERT
om1_1        | 2022-10-20 02:09:29,022 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.111,host:om1
om1_1        | 2022-10-20 02:09:29,024 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
om1_1        | 2022-10-20 02:09:29,044 [main] ERROR client.OMCertificateClient: Invalid domain om1
om1_1        | 2022-10-20 02:09:29,048 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om1_1        | 2022-10-20 02:09:29,052 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om1, RPC Address: om1:9862 and Ratis port: 9872
om1_1        | 2022-10-20 02:09:29,056 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om1: om1
om1_1        | 2022-10-20 02:09:29,056 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om1: om1
om1_1        | 2022-10-20 02:09:29,073 [main] INFO om.OzoneManager: Creating csr for OM->dns:om1,ip:172.25.0.111,scmId:193991a4-d526-4123-97ec-0cf0bd3049b7,clusterId:CID-959c5f9a-2485-4f2a-8075-3da9fe7c4057,subject:om1
om1_1        | 2022-10-20 02:09:29,903 [main] INFO om.OzoneManager: OzoneManager ports added:[name: "RPC"
om1_1        | value: 9862
om1_1        | ]
om1_1        | 2022-10-20 02:09:31,413 [main] INFO om.OzoneManager: Successfully stored SCM signed certificate.
om1_1        | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-959c5f9a-2485-4f2a-8075-3da9fe7c4057;layoutVersion=3
om1_1        | 2022-10-20 02:09:31,632 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
om1_1        | /************************************************************
om1_1        | SHUTDOWN_MSG: Shutting down OzoneManager at om1/172.25.0.111
om1_1        | ************************************************************/
om1_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om1_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om1_1        | 2022-10-20 02:09:40,143 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om1_1        | /************************************************************
datanode3_1  | 2022-10-20 02:10:01,502 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-FFBE57651D3A-LeaderElection1] INFO server.RaftServer$Division: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-FFBE57651D3A: set configuration 0: peers:[e4d9a0e3-266c-4558-944a-cafbea7b03e5|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode3_1  | 2022-10-20 02:10:01,502 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection2-2] INFO server.GrpcServerProtocolClient: Build channel for 4026c186-2529-49de-a2d8-dcba1039e356
datanode3_1  | 2022-10-20 02:10:02,118 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-FFBE57651D3A-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-FFBE57651D3A-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/461fda09-4c27-4112-8f11-ffbe57651d3a/current/log_inprogress_0
datanode3_1  | 2022-10-20 02:10:02,821 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection2] INFO impl.LeaderElection: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection2: ELECTION REJECTED received 1 response(s) and 0 exception(s):
datanode3_1  | 2022-10-20 02:10:02,822 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection2] INFO impl.LeaderElection:   Response 0: e4d9a0e3-266c-4558-944a-cafbea7b03e5<-922d5e53-2e0d-4e01-adf2-129a3cebef39#0:FAIL-t1
datanode3_1  | 2022-10-20 02:10:02,822 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection2] INFO impl.LeaderElection: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection2 ELECTION round 0: result REJECTED
datanode3_1  | 2022-10-20 02:10:02,822 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection2] INFO server.RaftServer$Division: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
datanode3_1  | 2022-10-20 02:10:02,822 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection2] INFO impl.RoleInfo: e4d9a0e3-266c-4558-944a-cafbea7b03e5: shutdown e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection2
datanode3_1  | 2022-10-20 02:10:02,822 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection2] INFO impl.RoleInfo: e4d9a0e3-266c-4558-944a-cafbea7b03e5: start e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-FollowerState
datanode3_1  | 2022-10-20 02:10:02,826 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode3_1  | 2022-10-20 02:10:02,826 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode3_1  | 2022-10-20 02:10:02,944 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=904a7869-3351-4618-b9db-44e7403e0592.
datanode3_1  | 2022-10-20 02:10:02,944 [Command processor thread] INFO server.RaftServer: e4d9a0e3-266c-4558-944a-cafbea7b03e5: addNew group-D27615E20C89:[922d5e53-2e0d-4e01-adf2-129a3cebef39|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0|startupRole:FOLLOWER, 4026c186-2529-49de-a2d8-dcba1039e356|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1|startupRole:FOLLOWER, e4d9a0e3-266c-4558-944a-cafbea7b03e5|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0|startupRole:FOLLOWER] returns group-D27615E20C89:java.util.concurrent.CompletableFuture@49957988[Not completed]
datanode3_1  | 2022-10-20 02:10:02,946 [pool-23-thread-1] INFO server.RaftServer$Division: e4d9a0e3-266c-4558-944a-cafbea7b03e5: new RaftServerImpl for group-D27615E20C89:[922d5e53-2e0d-4e01-adf2-129a3cebef39|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0|startupRole:FOLLOWER, 4026c186-2529-49de-a2d8-dcba1039e356|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1|startupRole:FOLLOWER, e4d9a0e3-266c-4558-944a-cafbea7b03e5|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
datanode3_1  | 2022-10-20 02:10:02,964 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode3_1  | 2022-10-20 02:10:02,964 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode3_1  | 2022-10-20 02:10:02,964 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode3_1  | 2022-10-20 02:10:02,964 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode3_1  | 2022-10-20 02:10:02,964 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode3_1  | 2022-10-20 02:10:02,964 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode3_1  | 2022-10-20 02:10:02,964 [pool-23-thread-1] INFO server.RaftServer$Division: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-D27615E20C89: ConfigurationManager, init=-1: peers:[922d5e53-2e0d-4e01-adf2-129a3cebef39|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0|startupRole:FOLLOWER, 4026c186-2529-49de-a2d8-dcba1039e356|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1|startupRole:FOLLOWER, e4d9a0e3-266c-4558-944a-cafbea7b03e5|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
datanode3_1  | 2022-10-20 02:10:02,964 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode3_1  | 2022-10-20 02:10:02,965 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode3_1  | 2022-10-20 02:10:02,965 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode3_1  | 2022-10-20 02:10:02,965 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode3_1  | 2022-10-20 02:10:02,965 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode3_1  | 2022-10-20 02:10:02,969 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode3_1  | 2022-10-20 02:10:02,970 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode3_1  | 2022-10-20 02:10:02,977 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode3_1  | 2022-10-20 02:10:02,977 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode3_1  | 2022-10-20 02:10:02,979 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode3_1  | 2022-10-20 02:10:02,979 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode3_1  | 2022-10-20 02:10:02,984 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/928115e6-57fc-4e60-abe7-d27615e20c89 does not exist. Creating ...
datanode3_1  | 2022-10-20 02:10:02,994 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/928115e6-57fc-4e60-abe7-d27615e20c89/in_use.lock acquired by nodename 7@7b621abfba13
datanode3_1  | 2022-10-20 02:10:03,008 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/928115e6-57fc-4e60-abe7-d27615e20c89 has been successfully formatted.
datanode3_1  | 2022-10-20 02:10:03,018 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-D27615E20C89: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
om1_1        | STARTUP_MSG: Starting OzoneManager
om1_1        | STARTUP_MSG:   host = om1/172.25.0.111
om1_1        | STARTUP_MSG:   args = []
om1_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
om2_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/jna-platform-5.2.0.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/orc-core-1.5.8.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.2.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-linux-x86_64.jar:/opt/hadoop/share/ozone/lib/httpmime-4.5.6.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.9.0.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/httpasyncclient-4.1.3.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.4.0.jar:/opt/hadoop/share/ozone/lib/jetty-client-9.4.31.v20200723.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/ranger-plugin-classloader-2.3.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.4.0.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.48.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.4.0.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.48.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-osx-aarch_64.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.4.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.48.1.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.10.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/commons-lang-2.6.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jna-5.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.4.0.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.32.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.48.1.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.48.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.4.5.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.4.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-cred-2.3.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/hppc-0.8.0.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-osx-x86_64.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-audit-2.3.0.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/jersey-client-1.19.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-windows-x86_64.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.4.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.4.0.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-linux-aarch_64.jar:/opt/hadoop/share/ozone/lib/gethostname4j-0.0.2.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.21.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.48.1.jar:/opt/hadoop/share/ozone/lib/ranger-intg-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.53.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.4.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.4.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.48.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.4.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.25.0.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.3.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.4.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/httpcore-nio-4.4.6.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar
om2_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/ff6d15f5df822a5a3c776320b032fad3dd380f95 ; compiled by 'runner' on 2022-10-20T01:42Z
om2_1        | STARTUP_MSG:   java = 11.0.14.1
om2_1        | ************************************************************/
om2_1        | 2022-10-20 02:09:09,001 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om2_1        | 2022-10-20 02:09:15,013 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for OMAudit to [].
om2_1        | 2022-10-20 02:09:17,445 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om2_1        | 2022-10-20 02:09:17,917 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om2, RPC Address: om2:9862 and Ratis port: 9872
om2_1        | 2022-10-20 02:09:17,917 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om2: om2
om2_1        | 2022-10-20 02:09:17,917 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om2: om2
om2_1        | 2022-10-20 02:09:18,916 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om2_1        | 2022-10-20 02:09:18,917 [main] INFO om.OzoneManager: Ozone Manager login successful.
om2_1        | 2022-10-20 02:09:19,010 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1        | 2022-10-20 02:09:19,945 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 3 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
om2_1        | 2022-10-20 02:09:21,963 [main] INFO om.OzoneManager: Initializing secure OzoneManager.
om2_1        | 2022-10-20 02:09:24,451 [main] ERROR client.OMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
om2_1        | 2022-10-20 02:09:24,452 [main] INFO client.OMCertificateClient: Certificate client init case: 0
om2_1        | 2022-10-20 02:09:24,462 [main] INFO client.OMCertificateClient: Creating keypair for client as keypair and certificate not found.
om2_1        | 2022-10-20 02:09:30,070 [main] INFO om.OzoneManager: Init response: GETCERT
om2_1        | 2022-10-20 02:09:30,277 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.112,host:om2
om2_1        | 2022-10-20 02:09:30,280 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
om2_1        | 2022-10-20 02:09:30,282 [main] ERROR client.OMCertificateClient: Invalid domain om2
om2_1        | 2022-10-20 02:09:30,287 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om2_1        | 2022-10-20 02:09:30,291 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om2, RPC Address: om2:9862 and Ratis port: 9872
om2_1        | 2022-10-20 02:09:30,291 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om2: om2
om2_1        | 2022-10-20 02:09:30,291 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om2: om2
om2_1        | 2022-10-20 02:09:30,301 [main] INFO om.OzoneManager: Creating csr for OM->dns:om2,ip:172.25.0.112,scmId:193991a4-d526-4123-97ec-0cf0bd3049b7,clusterId:CID-959c5f9a-2485-4f2a-8075-3da9fe7c4057,subject:om2
om2_1        | 2022-10-20 02:09:31,020 [main] INFO om.OzoneManager: OzoneManager ports added:[name: "RPC"
om2_1        | value: 9862
om2_1        | ]
om2_1        | 2022-10-20 02:09:32,310 [main] INFO om.OzoneManager: Successfully stored SCM signed certificate.
om2_1        | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-959c5f9a-2485-4f2a-8075-3da9fe7c4057;layoutVersion=3
om2_1        | 2022-10-20 02:09:32,486 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
om2_1        | /************************************************************
om2_1        | SHUTDOWN_MSG: Shutting down OzoneManager at om2/172.25.0.112
om2_1        | ************************************************************/
om2_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om2_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om2_1        | 2022-10-20 02:09:40,802 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om2_1        | /************************************************************
datanode3_1  | 2022-10-20 02:10:03,024 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode3_1  | 2022-10-20 02:10:03,028 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode3_1  | 2022-10-20 02:10:03,028 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2022-10-20 02:10:03,028 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode3_1  | 2022-10-20 02:10:03,029 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
datanode3_1  | 2022-10-20 02:10:03,029 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2022-10-20 02:10:03,029 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode3_1  | 2022-10-20 02:10:03,029 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode3_1  | 2022-10-20 02:10:03,029 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-D27615E20C89-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/928115e6-57fc-4e60-abe7-d27615e20c89
datanode3_1  | 2022-10-20 02:10:03,029 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode3_1  | 2022-10-20 02:10:03,030 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode3_1  | 2022-10-20 02:10:03,030 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2022-10-20 02:10:03,030 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode3_1  | 2022-10-20 02:10:03,030 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode3_1  | 2022-10-20 02:10:03,030 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode3_1  | 2022-10-20 02:10:03,030 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode3_1  | 2022-10-20 02:10:03,030 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode3_1  | 2022-10-20 02:10:03,031 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode3_1  | 2022-10-20 02:10:03,043 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode3_1  | 2022-10-20 02:10:03,043 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
datanode3_1  | 2022-10-20 02:10:03,049 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode3_1  | 2022-10-20 02:10:03,049 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-D27615E20C89-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode3_1  | 2022-10-20 02:10:03,055 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-D27615E20C89-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode3_1  | 2022-10-20 02:10:03,055 [pool-23-thread-1] INFO server.RaftServer$Division: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-D27615E20C89: start as a follower, conf=-1: peers:[922d5e53-2e0d-4e01-adf2-129a3cebef39|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0|startupRole:FOLLOWER, 4026c186-2529-49de-a2d8-dcba1039e356|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1|startupRole:FOLLOWER, e4d9a0e3-266c-4558-944a-cafbea7b03e5|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
datanode3_1  | 2022-10-20 02:10:03,056 [pool-23-thread-1] INFO server.RaftServer$Division: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-D27615E20C89: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode3_1  | 2022-10-20 02:10:03,056 [pool-23-thread-1] INFO impl.RoleInfo: e4d9a0e3-266c-4558-944a-cafbea7b03e5: start e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-D27615E20C89-FollowerState
datanode3_1  | 2022-10-20 02:10:03,056 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-D27615E20C89,id=e4d9a0e3-266c-4558-944a-cafbea7b03e5
datanode3_1  | 2022-10-20 02:10:03,056 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode3_1  | 2022-10-20 02:10:03,056 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode3_1  | 2022-10-20 02:10:03,056 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode3_1  | 2022-10-20 02:10:03,057 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode3_1  | 2022-10-20 02:10:03,057 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-D27615E20C89-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode3_1  | 2022-10-20 02:10:03,063 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=928115e6-57fc-4e60-abe7-d27615e20c89
datanode3_1  | 2022-10-20 02:10:03,085 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-D27615E20C89-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode3_1  | 2022-10-20 02:10:03,214 [grpc-default-executor-0] INFO server.RaftServer$Division: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592: receive requestVote(ELECTION, 4026c186-2529-49de-a2d8-dcba1039e356, group-44E7403E0592, 1, (t:0, i:0))
datanode3_1  | 2022-10-20 02:10:03,235 [grpc-default-executor-0] INFO impl.VoteContext: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-FOLLOWER: reject ELECTION from 4026c186-2529-49de-a2d8-dcba1039e356: already has voted for e4d9a0e3-266c-4558-944a-cafbea7b03e5 at current term 1
datanode3_1  | 2022-10-20 02:10:03,239 [grpc-default-executor-0] INFO server.RaftServer$Division: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592 replies to ELECTION vote request: 4026c186-2529-49de-a2d8-dcba1039e356<-e4d9a0e3-266c-4558-944a-cafbea7b03e5#0:FAIL-t1. Peer's state: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592:t1, leader=null, voted=e4d9a0e3-266c-4558-944a-cafbea7b03e5, raftlog=Memoized:e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[922d5e53-2e0d-4e01-adf2-129a3cebef39|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1|startupRole:FOLLOWER, 4026c186-2529-49de-a2d8-dcba1039e356|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0|startupRole:FOLLOWER, e4d9a0e3-266c-4558-944a-cafbea7b03e5|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
datanode3_1  | 2022-10-20 02:10:03,865 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=928115e6-57fc-4e60-abe7-d27615e20c89.
datanode3_1  | 2022-10-20 02:10:05,597 [grpc-default-executor-0] INFO server.RaftServer$Division: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-D27615E20C89: receive requestVote(ELECTION, 4026c186-2529-49de-a2d8-dcba1039e356, group-D27615E20C89, 1, (t:0, i:0))
om2_1        | STARTUP_MSG: Starting OzoneManager
om2_1        | STARTUP_MSG:   host = om2/172.25.0.112
om2_1        | STARTUP_MSG:   args = []
om2_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
om1_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/jna-platform-5.2.0.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/orc-core-1.5.8.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.2.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-linux-x86_64.jar:/opt/hadoop/share/ozone/lib/httpmime-4.5.6.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.9.0.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/httpasyncclient-4.1.3.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.4.0.jar:/opt/hadoop/share/ozone/lib/jetty-client-9.4.31.v20200723.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/ranger-plugin-classloader-2.3.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.4.0.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.48.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.4.0.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.48.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-osx-aarch_64.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.4.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.48.1.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.10.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/commons-lang-2.6.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jna-5.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.4.0.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.32.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.48.1.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.48.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.4.5.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.4.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-cred-2.3.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/hppc-0.8.0.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-osx-x86_64.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-audit-2.3.0.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/jersey-client-1.19.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-windows-x86_64.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.4.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.4.0.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-linux-aarch_64.jar:/opt/hadoop/share/ozone/lib/gethostname4j-0.0.2.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.21.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.48.1.jar:/opt/hadoop/share/ozone/lib/ranger-intg-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.53.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.4.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.4.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.48.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.4.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.25.0.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.3.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.4.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/httpcore-nio-4.4.6.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar
om1_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/ff6d15f5df822a5a3c776320b032fad3dd380f95 ; compiled by 'runner' on 2022-10-20T01:42Z
om1_1        | STARTUP_MSG:   java = 11.0.14.1
om1_1        | ************************************************************/
om1_1        | 2022-10-20 02:09:40,209 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om1_1        | 2022-10-20 02:09:45,529 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for OMAudit to [].
om1_1        | 2022-10-20 02:09:47,815 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om1_1        | 2022-10-20 02:09:48,596 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om1, RPC Address: om1:9862 and Ratis port: 9872
om1_1        | 2022-10-20 02:09:48,596 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om1: om1
om1_1        | 2022-10-20 02:09:48,601 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om1: om1
om1_1        | 2022-10-20 02:09:48,810 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1        | 2022-10-20 02:09:49,272 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = MULTITENANCY_SCHEMA (version = 3), software layout = MULTITENANCY_SCHEMA (version = 3)
om1_1        | 2022-10-20 02:09:50,610 [main] INFO reflections.Reflections: Reflections took 751 ms to scan 1 urls, producing 114 keys and 335 values [using 2 cores]
om1_1        | 2022-10-20 02:09:51,762 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om1_1        | 2022-10-20 02:09:51,768 [main] INFO om.OzoneManager: Ozone Manager login successful.
om1_1        | 2022-10-20 02:09:51,768 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1        | 2022-10-20 02:09:53,608 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 3 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
om1_1        | 2022-10-20 02:09:53,953 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 3 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
om1_1        | 2022-10-20 02:09:58,390 [main] INFO client.OMCertificateClient: Loading certificate from location:/data/metadata/om/certs.
om1_1        | 2022-10-20 02:09:59,040 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/1087378534705.crt.
om1_1        | 2022-10-20 02:09:59,078 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/ROOTCA-1.crt.
om1_1        | 2022-10-20 02:09:59,104 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/CA-1003431474332.crt.
om1_1        | 2022-10-20 02:09:59,330 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1        | 2022-10-20 02:10:00,455 [main] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
om1_1        | 2022-10-20 02:10:00,476 [main] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
om1_1        | 2022-10-20 02:10:01,840 [main] INFO om.OzoneManager: S3 Multi-Tenancy is disabled
om1_1        | 2022-10-20 02:10:01,898 [main] INFO security.OzoneSecretStore: Loaded 0 tokens
om1_1        | 2022-10-20 02:10:01,898 [main] INFO security.OzoneDelegationTokenSecretManager: Loading token state into token manager.
om1_1        | 2022-10-20 02:10:02,456 [main] INFO om.OzoneManager: Created Volume s3v With Owner om required for S3Gateway operations.
om1_1        | 2022-10-20 02:10:02,869 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om1_1        | 2022-10-20 02:10:02,869 [main] WARN utils.OzoneManagerRatisUtils: ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
om1_1        | 2022-10-20 02:10:02,899 [main] INFO snapshot.OzoneManagerSnapshotProvider: Initializing OM Snapshot Provider
om1_1        | 2022-10-20 02:10:03,416 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
om1_1        | 2022-10-20 02:10:03,499 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om1_1        | 2022-10-20 02:10:03,698 [main] INFO ratis.OzoneManagerRatisServer: Instantiating OM Ratis server with groupID: id1 and peers: om1:9872, om3:9872, om2:9872
om1_1        | 2022-10-20 02:10:03,751 [main] INFO ratis.OzoneManagerStateMachine: LastAppliedIndex is set from TransactionInfo from OM DB as (t:0, i:~)
om1_1        | 2022-10-20 02:10:05,036 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
om1_1        | 2022-10-20 02:10:05,441 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
datanode3_1  | 2022-10-20 02:10:05,598 [grpc-default-executor-0] INFO impl.VoteContext: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-D27615E20C89-FOLLOWER: accept ELECTION from 4026c186-2529-49de-a2d8-dcba1039e356: our priority 0 <= candidate's priority 1
datanode3_1  | 2022-10-20 02:10:05,598 [grpc-default-executor-0] INFO server.RaftServer$Division: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-D27615E20C89: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:4026c186-2529-49de-a2d8-dcba1039e356
datanode3_1  | 2022-10-20 02:10:05,598 [grpc-default-executor-0] INFO impl.RoleInfo: e4d9a0e3-266c-4558-944a-cafbea7b03e5: shutdown e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-D27615E20C89-FollowerState
datanode3_1  | 2022-10-20 02:10:05,598 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-D27615E20C89-FollowerState] INFO impl.FollowerState: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-D27615E20C89-FollowerState was interrupted
datanode3_1  | 2022-10-20 02:10:05,598 [grpc-default-executor-0] INFO impl.RoleInfo: e4d9a0e3-266c-4558-944a-cafbea7b03e5: start e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-D27615E20C89-FollowerState
datanode3_1  | 2022-10-20 02:10:05,600 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-D27615E20C89-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode3_1  | 2022-10-20 02:10:05,600 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-D27615E20C89-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode3_1  | 2022-10-20 02:10:05,602 [grpc-default-executor-0] INFO server.RaftServer$Division: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-D27615E20C89 replies to ELECTION vote request: 4026c186-2529-49de-a2d8-dcba1039e356<-e4d9a0e3-266c-4558-944a-cafbea7b03e5#0:OK-t1. Peer's state: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-D27615E20C89:t1, leader=null, voted=4026c186-2529-49de-a2d8-dcba1039e356, raftlog=Memoized:e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-D27615E20C89-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[922d5e53-2e0d-4e01-adf2-129a3cebef39|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0|startupRole:FOLLOWER, 4026c186-2529-49de-a2d8-dcba1039e356|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1|startupRole:FOLLOWER, e4d9a0e3-266c-4558-944a-cafbea7b03e5|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
datanode3_1  | 2022-10-20 02:10:06,331 [e4d9a0e3-266c-4558-944a-cafbea7b03e5-server-thread1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-D27615E20C89 with new leaderId: 4026c186-2529-49de-a2d8-dcba1039e356
datanode3_1  | 2022-10-20 02:10:06,331 [e4d9a0e3-266c-4558-944a-cafbea7b03e5-server-thread1] INFO server.RaftServer$Division: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-D27615E20C89: change Leader from null to 4026c186-2529-49de-a2d8-dcba1039e356 at term 1 for appendEntries, leader elected after 3366ms
datanode3_1  | 2022-10-20 02:10:06,358 [e4d9a0e3-266c-4558-944a-cafbea7b03e5-server-thread1] INFO server.RaftServer$Division: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-D27615E20C89: set configuration 0: peers:[922d5e53-2e0d-4e01-adf2-129a3cebef39|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0|startupRole:FOLLOWER, 4026c186-2529-49de-a2d8-dcba1039e356|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1|startupRole:FOLLOWER, e4d9a0e3-266c-4558-944a-cafbea7b03e5|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
datanode3_1  | 2022-10-20 02:10:06,362 [e4d9a0e3-266c-4558-944a-cafbea7b03e5-server-thread1] INFO segmented.SegmentedRaftLogWorker: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-D27615E20C89-SegmentedRaftLogWorker: Starting segment from index:0
datanode3_1  | 2022-10-20 02:10:06,364 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-D27615E20C89-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-D27615E20C89-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/928115e6-57fc-4e60-abe7-d27615e20c89/current/log_inprogress_0
datanode3_1  | 2022-10-20 02:10:08,011 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-FollowerState] INFO impl.FollowerState: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5188638996ns, electionTimeout:5185ms
datanode3_1  | 2022-10-20 02:10:08,011 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-FollowerState] INFO impl.RoleInfo: e4d9a0e3-266c-4558-944a-cafbea7b03e5: shutdown e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-FollowerState
datanode3_1  | 2022-10-20 02:10:08,012 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-FollowerState] INFO server.RaftServer$Division: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
datanode3_1  | 2022-10-20 02:10:08,012 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode3_1  | 2022-10-20 02:10:08,012 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-FollowerState] INFO impl.RoleInfo: e4d9a0e3-266c-4558-944a-cafbea7b03e5: start e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection3
datanode3_1  | 2022-10-20 02:10:08,019 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection3] INFO impl.LeaderElection: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection3 ELECTION round 0: submit vote requests at term 2 for -1: peers:[922d5e53-2e0d-4e01-adf2-129a3cebef39|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1|startupRole:FOLLOWER, 4026c186-2529-49de-a2d8-dcba1039e356|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0|startupRole:FOLLOWER, e4d9a0e3-266c-4558-944a-cafbea7b03e5|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
datanode3_1  | 2022-10-20 02:10:08,028 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode3_1  | 2022-10-20 02:10:08,046 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode3_1  | 2022-10-20 02:10:08,049 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection3] INFO impl.LeaderElection: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection3: ELECTION REJECTED received 1 response(s) and 0 exception(s):
datanode3_1  | 2022-10-20 02:10:08,050 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection3] INFO impl.LeaderElection:   Response 0: e4d9a0e3-266c-4558-944a-cafbea7b03e5<-922d5e53-2e0d-4e01-adf2-129a3cebef39#0:FAIL-t2
datanode3_1  | 2022-10-20 02:10:08,050 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection3] INFO impl.LeaderElection: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection3 ELECTION round 0: result REJECTED
datanode3_1  | 2022-10-20 02:10:08,052 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection3] INFO server.RaftServer$Division: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592: changes role from CANDIDATE to FOLLOWER at term 2 for REJECTED
datanode3_1  | 2022-10-20 02:10:08,052 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection3] INFO impl.RoleInfo: e4d9a0e3-266c-4558-944a-cafbea7b03e5: shutdown e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection3
om1_1        | 2022-10-20 02:10:05,454 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9872 (fallback to raft.grpc.server.port)
om1_1        | 2022-10-20 02:10:05,456 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.host = null (fallback to raft.grpc.server.host)
om1_1        | 2022-10-20 02:10:05,458 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9872 (fallback to raft.grpc.server.port)
om1_1        | 2022-10-20 02:10:05,461 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.host = null (default)
om1_1        | 2022-10-20 02:10:05,462 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om1_1        | 2022-10-20 02:10:05,467 [main] INFO server.GrpcService: raft.grpc.message.size.max = 33554432 (custom)
om1_1        | 2022-10-20 02:10:05,471 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om1_1        | 2022-10-20 02:10:05,475 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
om1_1        | 2022-10-20 02:10:05,478 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om1_1        | 2022-10-20 02:10:05,518 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
om1_1        | 2022-10-20 02:10:05,528 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
om1_1        | 2022-10-20 02:10:05,529 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
om1_1        | 2022-10-20 02:10:07,865 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
om1_1        | 2022-10-20 02:10:07,869 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
om1_1        | 2022-10-20 02:10:07,885 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
om1_1        | 2022-10-20 02:10:07,887 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om1_1        | 2022-10-20 02:10:07,887 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om1_1        | 2022-10-20 02:10:07,910 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om1_1        | 2022-10-20 02:10:07,954 [main] INFO server.RaftServer: om1: addNew group-562213E44849:[om1|rpc:om1:9872|priority:0|startupRole:FOLLOWER, om3|rpc:om3:9872|priority:0|startupRole:FOLLOWER, om2|rpc:om2:9872|priority:0|startupRole:FOLLOWER] returns group-562213E44849:java.util.concurrent.CompletableFuture@4fc41cba[Not completed]
om1_1        | 2022-10-20 02:10:07,956 [main] INFO om.OzoneManager: OzoneManager Ratis server initialized at port 9872
om1_1        | 2022-10-20 02:10:08,014 [pool-27-thread-1] INFO server.RaftServer$Division: om1: new RaftServerImpl for group-562213E44849:[om1|rpc:om1:9872|priority:0|startupRole:FOLLOWER, om3|rpc:om3:9872|priority:0|startupRole:FOLLOWER, om2|rpc:om2:9872|priority:0|startupRole:FOLLOWER] with OzoneManagerStateMachine:uninitialized
om1_1        | 2022-10-20 02:10:08,044 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
om1_1        | 2022-10-20 02:10:08,044 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
om1_1        | 2022-10-20 02:10:08,044 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
om1_1        | 2022-10-20 02:10:08,045 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om1_1        | 2022-10-20 02:10:08,047 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om1_1        | 2022-10-20 02:10:08,047 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
om1_1        | 2022-10-20 02:10:08,069 [main] INFO om.OzoneManager: Creating RPC Server
om1_1        | 2022-10-20 02:10:08,086 [pool-27-thread-1] INFO server.RaftServer$Division: om1@group-562213E44849: ConfigurationManager, init=-1: peers:[om1|rpc:om1:9872|priority:0|startupRole:FOLLOWER, om3|rpc:om3:9872|priority:0|startupRole:FOLLOWER, om2|rpc:om2:9872|priority:0|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
om1_1        | 2022-10-20 02:10:08,087 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om1_1        | 2022-10-20 02:10:08,105 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om1_1        | 2022-10-20 02:10:08,106 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
om1_1        | 2022-10-20 02:10:08,200 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
om1_1        | 2022-10-20 02:10:08,232 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 300s (custom)
om1_1        | 2022-10-20 02:10:08,239 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
om1_1        | 2022-10-20 02:10:08,690 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om1_1        | 2022-10-20 02:10:08,716 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
om1_1        | 2022-10-20 02:10:08,719 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
om1_1        | 2022-10-20 02:10:08,721 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
om1_1        | 2022-10-20 02:10:08,722 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
om1_1        | 2022-10-20 02:10:10,102 [main] INFO reflections.Reflections: Reflections took 1653 ms to scan 8 urls, producing 23 keys and 519 values [using 2 cores]
om1_1        | 2022-10-20 02:10:11,218 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om1_1        | 2022-10-20 02:10:11,227 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om1_1        | 2022-10-20 02:10:14,371 [Listener at om1/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om1_1        | 2022-10-20 02:10:14,426 [Listener at om1/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om1_1        | 2022-10-20 02:10:14,426 [Listener at om1/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om1_1        | 2022-10-20 02:10:14,623 [Listener at om1/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om1/172.25.0.111:9862
om1_1        | 2022-10-20 02:10:14,625 [Listener at om1/9862] INFO ratis.OzoneManagerRatisServer: Starting OzoneManagerRatisServer om1 at port 9872
om1_1        | 2022-10-20 02:10:14,640 [om1-impl-thread1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 does not exist. Creating ...
om1_1        | 2022-10-20 02:10:14,651 [om1-impl-thread1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/in_use.lock acquired by nodename 6@om1
om1_1        | 2022-10-20 02:10:14,702 [om1-impl-thread1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 has been successfully formatted.
om1_1        | 2022-10-20 02:10:14,705 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
om1_1        | 2022-10-20 02:10:14,749 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om1_1        | 2022-10-20 02:10:14,749 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om2_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/jna-platform-5.2.0.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/orc-core-1.5.8.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.2.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-linux-x86_64.jar:/opt/hadoop/share/ozone/lib/httpmime-4.5.6.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.9.0.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/httpasyncclient-4.1.3.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.4.0.jar:/opt/hadoop/share/ozone/lib/jetty-client-9.4.31.v20200723.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/ranger-plugin-classloader-2.3.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.4.0.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.48.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.4.0.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.48.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-osx-aarch_64.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.4.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.48.1.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.10.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/commons-lang-2.6.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jna-5.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.4.0.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.32.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.48.1.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.48.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.4.5.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.4.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-cred-2.3.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/hppc-0.8.0.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-osx-x86_64.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-audit-2.3.0.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/jersey-client-1.19.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-windows-x86_64.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.4.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.4.0.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-linux-aarch_64.jar:/opt/hadoop/share/ozone/lib/gethostname4j-0.0.2.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.21.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.48.1.jar:/opt/hadoop/share/ozone/lib/ranger-intg-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.53.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.4.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.4.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.48.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.4.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.25.0.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.3.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.4.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/httpcore-nio-4.4.6.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar
om2_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/ff6d15f5df822a5a3c776320b032fad3dd380f95 ; compiled by 'runner' on 2022-10-20T01:42Z
om2_1        | STARTUP_MSG:   java = 11.0.14.1
om2_1        | ************************************************************/
om2_1        | 2022-10-20 02:09:40,855 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om2_1        | 2022-10-20 02:09:45,968 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for OMAudit to [].
om2_1        | 2022-10-20 02:09:48,187 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om2_1        | 2022-10-20 02:09:48,577 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om2, RPC Address: om2:9862 and Ratis port: 9872
om2_1        | 2022-10-20 02:09:48,577 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om2: om2
om2_1        | 2022-10-20 02:09:48,578 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om2: om2
om2_1        | 2022-10-20 02:09:48,714 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1        | 2022-10-20 02:09:49,036 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = MULTITENANCY_SCHEMA (version = 3), software layout = MULTITENANCY_SCHEMA (version = 3)
om2_1        | 2022-10-20 02:09:50,233 [main] INFO reflections.Reflections: Reflections took 710 ms to scan 1 urls, producing 114 keys and 335 values [using 2 cores]
om2_1        | 2022-10-20 02:09:50,653 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om2_1        | 2022-10-20 02:09:50,655 [main] INFO om.OzoneManager: Ozone Manager login successful.
om2_1        | 2022-10-20 02:09:50,656 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1        | 2022-10-20 02:09:53,096 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 3 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
om2_1        | 2022-10-20 02:09:53,447 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 3 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
om2_1        | 2022-10-20 02:09:57,720 [main] INFO client.OMCertificateClient: Loading certificate from location:/data/metadata/om/certs.
om2_1        | 2022-10-20 02:09:58,330 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/1088397168328.crt.
om2_1        | 2022-10-20 02:09:58,581 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/ROOTCA-1.crt.
om2_1        | 2022-10-20 02:09:58,586 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/CA-1003431474332.crt.
om2_1        | 2022-10-20 02:09:58,845 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1        | 2022-10-20 02:09:59,923 [main] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
om2_1        | 2022-10-20 02:09:59,934 [main] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
om2_1        | 2022-10-20 02:10:01,196 [main] INFO om.OzoneManager: S3 Multi-Tenancy is disabled
om2_1        | 2022-10-20 02:10:01,262 [main] INFO security.OzoneSecretStore: Loaded 0 tokens
om2_1        | 2022-10-20 02:10:01,263 [main] INFO security.OzoneDelegationTokenSecretManager: Loading token state into token manager.
om2_1        | 2022-10-20 02:10:01,952 [main] INFO om.OzoneManager: Created Volume s3v With Owner om required for S3Gateway operations.
om2_1        | 2022-10-20 02:10:02,493 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om2_1        | 2022-10-20 02:10:02,494 [main] WARN utils.OzoneManagerRatisUtils: ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
om2_1        | 2022-10-20 02:10:02,532 [main] INFO snapshot.OzoneManagerSnapshotProvider: Initializing OM Snapshot Provider
om2_1        | 2022-10-20 02:10:03,078 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
om2_1        | 2022-10-20 02:10:03,119 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om2_1        | 2022-10-20 02:10:03,339 [main] INFO ratis.OzoneManagerRatisServer: Instantiating OM Ratis server with groupID: id1 and peers: om2:9872, om1:9872, om3:9872
om2_1        | 2022-10-20 02:10:03,448 [main] INFO ratis.OzoneManagerStateMachine: LastAppliedIndex is set from TransactionInfo from OM DB as (t:0, i:~)
om2_1        | 2022-10-20 02:10:04,663 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
om2_1        | 2022-10-20 02:10:05,046 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
recon_1      | Sleeping for 5 seconds
recon_1      | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
recon_1      | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
recon_1      | 2022-10-20 02:07:52,645 [main] INFO recon.ReconServer: STARTUP_MSG: 
recon_1      | /************************************************************
recon_1      | STARTUP_MSG: Starting ReconServer
recon_1      | STARTUP_MSG:   host = recon/172.25.0.115
recon_1      | STARTUP_MSG:   args = []
recon_1      | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
om1_1        | 2022-10-20 02:10:14,757 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
om1_1        | 2022-10-20 02:10:14,759 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
om1_1        | 2022-10-20 02:10:14,774 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om1_1        | 2022-10-20 02:10:14,793 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
om1_1        | 2022-10-20 02:10:14,793 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
om1_1        | 2022-10-20 02:10:14,809 [om1-impl-thread1] INFO segmented.SegmentedRaftLogWorker: new om1@group-562213E44849-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849
om1_1        | 2022-10-20 02:10:14,810 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
om1_1        | 2022-10-20 02:10:14,817 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
om1_1        | 2022-10-20 02:10:14,821 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om1_1        | 2022-10-20 02:10:14,822 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
om1_1        | 2022-10-20 02:10:14,825 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
om1_1        | 2022-10-20 02:10:14,827 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
om1_1        | 2022-10-20 02:10:14,828 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om1_1        | 2022-10-20 02:10:14,828 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
om1_1        | 2022-10-20 02:10:14,857 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
om1_1        | 2022-10-20 02:10:14,859 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
om1_1        | 2022-10-20 02:10:14,860 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
om1_1        | 2022-10-20 02:10:14,865 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
om1_1        | 2022-10-20 02:10:14,887 [om1-impl-thread1] INFO segmented.SegmentedRaftLogWorker: om1@group-562213E44849-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
om1_1        | 2022-10-20 02:10:14,888 [om1-impl-thread1] INFO segmented.SegmentedRaftLogWorker: om1@group-562213E44849-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
om1_1        | 2022-10-20 02:10:14,896 [om1-impl-thread1] INFO server.RaftServer$Division: om1@group-562213E44849: start as a follower, conf=-1: peers:[om1|rpc:om1:9872|priority:0|startupRole:FOLLOWER, om3|rpc:om3:9872|priority:0|startupRole:FOLLOWER, om2|rpc:om2:9872|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
om1_1        | 2022-10-20 02:10:14,899 [om1-impl-thread1] INFO server.RaftServer$Division: om1@group-562213E44849: changes role from      null to FOLLOWER at term 0 for startAsFollower
om1_1        | 2022-10-20 02:10:14,901 [om1-impl-thread1] INFO impl.RoleInfo: om1: start om1@group-562213E44849-FollowerState
om1_1        | 2022-10-20 02:10:14,914 [om1@group-562213E44849-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
om1_1        | 2022-10-20 02:10:14,915 [om1@group-562213E44849-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
om1_1        | 2022-10-20 02:10:14,917 [om1-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-562213E44849,id=om1
om1_1        | 2022-10-20 02:10:14,921 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
om1_1        | 2022-10-20 02:10:14,923 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 400000 (default)
om1_1        | 2022-10-20 02:10:14,923 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
om1_1        | 2022-10-20 02:10:14,925 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = true (custom)
om1_1        | 2022-10-20 02:10:14,931 [Listener at om1/9862] INFO server.RaftServer: om1: start RPC server
om1_1        | 2022-10-20 02:10:15,040 [Listener at om1/9862] INFO server.GrpcService: om1: GrpcService started, listening on 9872
om1_1        | 2022-10-20 02:10:15,042 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-om1: Started
om1_1        | 2022-10-20 02:10:15,042 [Listener at om1/9862] INFO om.OzoneManager: Starting OM block token secret manager
om1_1        | 2022-10-20 02:10:15,042 [Listener at om1/9862] INFO token.OzoneBlockTokenSecretManager: Updating the current master key for generating tokens
om1_1        | 2022-10-20 02:10:15,046 [Listener at om1/9862] INFO om.OzoneManager: Starting OM delegation token secret manager
om1_1        | 2022-10-20 02:10:15,046 [Listener at om1/9862] INFO security.OzoneDelegationTokenSecretManager: Updating the current master key for generating tokens
om1_1        | 2022-10-20 02:10:15,049 [Listener at om1/9862] INFO om.OzoneManager: Version File has different layout version (3) than OM DB (null). That is expected if this OM has never been finalized to a newer layout version.
om1_1        | 2022-10-20 02:10:15,066 [Thread[Thread-18,5,main]] INFO security.OzoneDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
om1_1        | 2022-10-20 02:10:15,172 [Listener at om1/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om1_1        | 2022-10-20 02:10:15,172 [Listener at om1/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
om1_1        | 2022-10-20 02:10:15,177 [Listener at om1/9862] INFO http.BaseHttpServer: HttpAuthType: ozone.om.http.auth.type = kerberos
om1_1        | 2022-10-20 02:10:15,276 [Listener at om1/9862] INFO util.log: Logging initialized @42779ms to org.eclipse.jetty.util.log.Slf4jLog
om1_1        | 2022-10-20 02:10:15,655 [Listener at om1/9862] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
om1_1        | 2022-10-20 02:10:15,680 [Listener at om1/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om1_1        | 2022-10-20 02:10:15,682 [Listener at om1/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context ozoneManager
om1_1        | 2022-10-20 02:10:15,682 [Listener at om1/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
om1_1        | 2022-10-20 02:10:15,682 [Listener at om1/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
om1_1        | 2022-10-20 02:10:15,692 [Listener at om1/9862] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.om.http.auth.kerberos.principal keytabKey: ozone.om.http.auth.kerberos.keytab
om1_1        | 2022-10-20 02:10:15,860 [Listener at om1/9862] INFO http.HttpServer2: Jetty bound to port 9874
datanode3_1  | 2022-10-20 02:10:08,052 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection3] INFO impl.RoleInfo: e4d9a0e3-266c-4558-944a-cafbea7b03e5: start e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-FollowerState
datanode3_1  | 2022-10-20 02:10:08,053 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode3_1  | 2022-10-20 02:10:08,071 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode3_1  | 2022-10-20 02:10:13,112 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-FollowerState] INFO impl.FollowerState: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5059855835ns, electionTimeout:5041ms
datanode3_1  | 2022-10-20 02:10:13,112 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-FollowerState] INFO impl.RoleInfo: e4d9a0e3-266c-4558-944a-cafbea7b03e5: shutdown e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-FollowerState
datanode3_1  | 2022-10-20 02:10:13,113 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-FollowerState] INFO server.RaftServer$Division: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592: changes role from  FOLLOWER to CANDIDATE at term 2 for changeToCandidate
datanode3_1  | 2022-10-20 02:10:13,113 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode3_1  | 2022-10-20 02:10:13,113 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-FollowerState] INFO impl.RoleInfo: e4d9a0e3-266c-4558-944a-cafbea7b03e5: start e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection4
datanode3_1  | 2022-10-20 02:10:13,122 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection4] INFO impl.LeaderElection: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection4 ELECTION round 0: submit vote requests at term 3 for -1: peers:[922d5e53-2e0d-4e01-adf2-129a3cebef39|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1|startupRole:FOLLOWER, 4026c186-2529-49de-a2d8-dcba1039e356|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0|startupRole:FOLLOWER, e4d9a0e3-266c-4558-944a-cafbea7b03e5|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
datanode3_1  | 2022-10-20 02:10:13,124 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode3_1  | 2022-10-20 02:10:13,161 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode3_1  | 2022-10-20 02:10:13,162 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection4] INFO impl.LeaderElection: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection4: ELECTION REJECTED received 1 response(s) and 0 exception(s):
datanode3_1  | 2022-10-20 02:10:13,163 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection4] INFO impl.LeaderElection:   Response 0: e4d9a0e3-266c-4558-944a-cafbea7b03e5<-922d5e53-2e0d-4e01-adf2-129a3cebef39#0:FAIL-t3
datanode3_1  | 2022-10-20 02:10:13,164 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection4] INFO impl.LeaderElection: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection4 ELECTION round 0: result REJECTED
datanode3_1  | 2022-10-20 02:10:13,164 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection4] INFO server.RaftServer$Division: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592: changes role from CANDIDATE to FOLLOWER at term 3 for REJECTED
datanode3_1  | 2022-10-20 02:10:13,164 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection4] INFO impl.RoleInfo: e4d9a0e3-266c-4558-944a-cafbea7b03e5: shutdown e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection4
datanode3_1  | 2022-10-20 02:10:13,164 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection4] INFO impl.RoleInfo: e4d9a0e3-266c-4558-944a-cafbea7b03e5: start e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-FollowerState
datanode3_1  | 2022-10-20 02:10:13,181 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode3_1  | 2022-10-20 02:10:13,189 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode3_1  | 2022-10-20 02:10:14,218 [grpc-default-executor-0] INFO server.RaftServer$Division: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592: receive requestVote(ELECTION, 922d5e53-2e0d-4e01-adf2-129a3cebef39, group-44E7403E0592, 3, (t:0, i:0))
datanode3_1  | 2022-10-20 02:10:14,218 [grpc-default-executor-0] INFO impl.VoteContext: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-FOLLOWER: reject ELECTION from 922d5e53-2e0d-4e01-adf2-129a3cebef39: already has voted for e4d9a0e3-266c-4558-944a-cafbea7b03e5 at current term 3
datanode3_1  | 2022-10-20 02:10:14,218 [grpc-default-executor-0] INFO server.RaftServer$Division: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592 replies to ELECTION vote request: 922d5e53-2e0d-4e01-adf2-129a3cebef39<-e4d9a0e3-266c-4558-944a-cafbea7b03e5#0:FAIL-t3. Peer's state: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592:t3, leader=null, voted=e4d9a0e3-266c-4558-944a-cafbea7b03e5, raftlog=Memoized:e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[922d5e53-2e0d-4e01-adf2-129a3cebef39|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1|startupRole:FOLLOWER, 4026c186-2529-49de-a2d8-dcba1039e356|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0|startupRole:FOLLOWER, e4d9a0e3-266c-4558-944a-cafbea7b03e5|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
datanode3_1  | 2022-10-20 02:10:18,290 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-FollowerState] INFO impl.FollowerState: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5126088740ns, electionTimeout:5101ms
datanode3_1  | 2022-10-20 02:10:18,290 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-FollowerState] INFO impl.RoleInfo: e4d9a0e3-266c-4558-944a-cafbea7b03e5: shutdown e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-FollowerState
datanode3_1  | 2022-10-20 02:10:18,290 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-FollowerState] INFO server.RaftServer$Division: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592: changes role from  FOLLOWER to CANDIDATE at term 3 for changeToCandidate
datanode3_1  | 2022-10-20 02:10:18,291 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode3_1  | 2022-10-20 02:10:18,291 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-FollowerState] INFO impl.RoleInfo: e4d9a0e3-266c-4558-944a-cafbea7b03e5: start e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection5
datanode3_1  | 2022-10-20 02:10:18,292 [grpc-default-executor-0] INFO server.RaftServer$Division: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592: receive requestVote(ELECTION, 4026c186-2529-49de-a2d8-dcba1039e356, group-44E7403E0592, 4, (t:0, i:0))
recon_1      | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/hk2-utils-2.5.0.jar:/opt/hadoop/share/ozone/lib/jakarta.inject-2.6.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/sqlite-jdbc-3.25.2.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/aopalliance-repackaged-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/guice-4.0.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/orc-core-1.5.8.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-linux-x86_64.jar:/opt/hadoop/share/ozone/lib/httpmime-4.5.6.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/httpasyncclient-4.1.3.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.4.0.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/ranger-plugin-classloader-2.3.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jakarta.xml.bind-api-2.3.3.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.4.0.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-osx-aarch_64.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.4.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.48.1.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/commons-lang-2.6.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jna-5.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.4.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.48.1.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.4.5.jar:/opt/hadoop/share/ozone/lib/jakarta.validation-api-2.0.2.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-cred-2.3.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/hppc-0.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-tools-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jooq-3.11.10.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jersey-client-2.34.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jersey-entity-filtering-2.34.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/osgi-resource-locator-1.0.3.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/spring-beans-5.2.20.RELEASE.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-windows-x86_64.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.4.0.jar:/opt/hadoop/share/ozone/lib/derby-10.14.2.0.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/spring-core-5.2.20.RELEASE.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/jooq-codegen-3.11.10.jar:/opt/hadoop/share/ozone/lib/gethostname4j-0.0.2.jar:/opt/hadoop/share/ozone/lib/spring-tx-5.2.20.RELEASE.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.48.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.4.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/guice-servlet-4.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.4.jar:/opt/hadoop/share/ozone/lib/guice-bridge-2.5.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.4.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.25.0.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.4.0.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/jna-platform-5.2.0.jar:/opt/hadoop/share/ozone/lib/hk2-locator-2.6.1.jar:/opt/hadoop/share/ozone/lib/aopalliance-1.0.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.2.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jakarta.ws.rs-api-2.1.6.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.9.0.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-media-json-jackson-2.34.jar:/opt/hadoop/share/ozone/lib/jetty-client-9.4.31.v20200723.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.4.0.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.48.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.48.1.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/guice-multibindings-4.0.jar:/opt/hadoop/share/ozone/lib/jersey-server-2.34.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.10.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-core-2.34.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/bonecp-0.8.0.RELEASE.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.32.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hk2-api-2.5.0.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.48.1.jar:/opt/hadoop/share/ozone/lib/javax.inject-1.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/jackson-module-jaxb-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.4.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-osx-x86_64.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-audit-2.3.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/jakarta.annotation-api-1.3.5.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.4.0.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-linux-aarch_64.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.21.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/guice-assistedinject-4.0.jar:/opt/hadoop/share/ozone/lib/ranger-intg-2.3.0.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.53.Final.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jersey-common-2.34.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.48.1.jar:/opt/hadoop/share/ozone/lib/jooq-meta-3.11.10.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/ozone-reconcodegen-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-2.34.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-hk2-2.34.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.3.jar:/opt/hadoop/share/ozone/lib/jersey-media-jaxb-2.34.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/spring-jdbc-5.2.20.RELEASE.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-nio-4.4.6.jar:/opt/hadoop/share/ozone/lib/spring-jcl-5.2.20.RELEASE.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-recon-1.3.0-SNAPSHOT.jar
recon_1      | STARTUP_MSG:   build = https://github.com/apache/ozone/ff6d15f5df822a5a3c776320b032fad3dd380f95 ; compiled by 'runner' on 2022-10-20T01:42Z
recon_1      | STARTUP_MSG:   java = 11.0.14.1
recon_1      | ************************************************************/
recon_1      | 2022-10-20 02:07:52,716 [main] INFO recon.ReconServer: registered UNIX signal handlers for [TERM, HUP, INT]
recon_1      | 2022-10-20 02:07:55,260 [main] INFO reflections.Reflections: Reflections took 257 ms to scan 1 urls, producing 16 keys and 48 values 
recon_1      | 2022-10-20 02:07:57,637 [main] INFO recon.ReconServer: Initializing Recon server...
recon_1      | 2022-10-20 02:07:57,756 [main] INFO recon.ReconServer: Ozone security is enabled. Attempting login for Recon service. Principal: recon/recon@EXAMPLE.COM, keytab: /etc/security/keytabs/recon.keytab
recon_1      | 2022-10-20 02:07:58,508 [main] INFO security.UserGroupInformation: Login successful for user recon/recon@EXAMPLE.COM using keytab file recon.keytab. Keytab auto renewal enabled : false
recon_1      | 2022-10-20 02:07:58,525 [main] INFO recon.ReconServer: Recon login successful.
recon_1      | 2022-10-20 02:07:58,525 [main] INFO recon.ReconServer: Initializing secure Recon.
recon_1      | 2022-10-20 02:07:59,865 [main] ERROR client.ReconCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
recon_1      | 2022-10-20 02:07:59,866 [main] INFO client.ReconCertificateClient: Certificate client init case: 0
recon_1      | 2022-10-20 02:07:59,873 [main] INFO client.ReconCertificateClient: Creating keypair for client as keypair and certificate not found.
recon_1      | 2022-10-20 02:08:01,368 [main] INFO recon.ReconServer: Init response: GETCERT
recon_1      | 2022-10-20 02:08:01,390 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.115,host:recon
recon_1      | 2022-10-20 02:08:01,390 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
recon_1      | 2022-10-20 02:08:01,403 [main] ERROR client.ReconCertificateClient: Invalid domain recon
recon_1      | 2022-10-20 02:08:01,640 [main] INFO recon.ReconServer: Creating CSR for Recon.
recon_1      | 2022-10-20 02:08:04,339 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm2.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9961 after 1 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-10-20 02:08:06,341 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm3.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9961 after 2 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-10-20 02:08:08,343 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm1.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9961 after 3 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-10-20 02:08:10,344 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm2.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9961 after 4 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-10-20 02:08:12,345 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm3.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9961 after 5 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-10-20 02:08:14,347 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm1.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9961 after 6 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-10-20 02:08:16,348 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm2.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9961 after 7 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-10-20 02:08:18,349 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm3.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9961 after 8 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-10-20 02:08:20,750 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:193991a4-d526-4123-97ec-0cf0bd3049b7 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
recon_1      | 	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
recon_1      | 	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:93)
recon_1      | 	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:16080)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
recon_1      | , while invoking $Proxy39.submitRequest over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9961 after 9 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-10-20 02:08:22,758 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm2.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9961 after 10 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-10-20 02:08:24,759 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm3.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9961 after 11 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-10-20 02:08:27,419 [main] INFO recon.ReconServer: Successfully stored SCM signed certificate, case:GETCERT.
recon_1      | 2022-10-20 02:08:28,165 [main] INFO persistence.DefaultDataSourceProvider: JDBC Url for Recon : jdbc:derby:/data/metadata/recon/ozone_recon_derby.db 
recon_1      | 2022-10-20 02:08:29,446 [main] INFO codegen.SqlDbUtils: Created derby database at jdbc:derby:/data/metadata/recon/ozone_recon_derby.db.
recon_1      | WARNING: An illegal reflective access operation has occurred
recon_1      | WARNING: Illegal reflective access by org.jooq.tools.reflect.Reflect (file:/opt/hadoop/share/ozone/lib/jooq-3.11.10.jar) to constructor java.lang.invoke.MethodHandles$Lookup(java.lang.Class)
recon_1      | WARNING: Please consider reporting this to the maintainers of org.jooq.tools.reflect.Reflect
recon_1      | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
recon_1      | WARNING: All illegal access operations will be denied in a future release
recon_1      | 2022-10-20 02:08:29,988 [main] INFO impl.ReconContainerMetadataManagerImpl: KEY_CONTAINER Table is empty, initializing from CONTAINER_KEY Table ...
recon_1      | 2022-10-20 02:08:29,989 [main] INFO impl.ReconContainerMetadataManagerImpl: It took 0.0 seconds to initialized 0 records to KEY_CONTAINER table
om1_1        | 2022-10-20 02:10:15,863 [Listener at om1/9862] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
om1_1        | 2022-10-20 02:10:16,019 [Listener at om1/9862] INFO server.session: DefaultSessionIdManager workerName=node0
om1_1        | 2022-10-20 02:10:16,026 [Listener at om1/9862] INFO server.session: No SessionScavenger set, using defaults
om1_1        | 2022-10-20 02:10:16,028 [Listener at om1/9862] INFO server.session: node0 Scavenging every 600000ms
om1_1        | 2022-10-20 02:10:16,083 [Listener at om1/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om1_1        | 2022-10-20 02:10:16,097 [Listener at om1/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@4dec9271{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om1_1        | 2022-10-20 02:10:16,098 [Listener at om1/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@18432787{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om1_1        | 2022-10-20 02:10:16,517 [Listener at om1/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om1_1        | 2022-10-20 02:10:16,576 [Listener at om1/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@5cb20350{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-ozone-manager-1_3_0-SNAPSHOT_jar-_-any-13700074197757851924/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/ozoneManager}
om1_1        | 2022-10-20 02:10:16,639 [Listener at om1/9862] INFO server.AbstractConnector: Started ServerConnector@792ae10d{HTTP/1.1, (http/1.1)}{0.0.0.0:9874}
om1_1        | 2022-10-20 02:10:16,639 [Listener at om1/9862] INFO server.Server: Started @44142ms
om1_1        | 2022-10-20 02:10:16,675 [Listener at om1/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
om1_1        | 2022-10-20 02:10:16,675 [Listener at om1/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
om1_1        | 2022-10-20 02:10:16,677 [Listener at om1/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
om1_1        | 2022-10-20 02:10:16,677 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om1_1        | 2022-10-20 02:10:16,678 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om1_1        | 2022-10-20 02:10:16,952 [Listener at om1/9862] INFO om.OzoneManager: Trash Interval set to 0. Files deleted won't move to trash
om1_1        | 2022-10-20 02:10:17,004 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:33177
om1_1        | 2022-10-20 02:10:17,009 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-10-20 02:10:17,434 [Listener at om1/9862] INFO om.GrpcOzoneManagerServer: GrpcOzoneManagerServer is started using port 8981
om1_1        | 2022-10-20 02:10:17,459 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@21b44898] INFO util.JvmPauseMonitor: Starting JVM pause monitor
om1_1        | 2022-10-20 02:10:20,043 [om1@group-562213E44849-FollowerState] INFO impl.FollowerState: om1@group-562213E44849-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5142085714ns, electionTimeout:5127ms
om1_1        | 2022-10-20 02:10:20,044 [om1@group-562213E44849-FollowerState] INFO impl.RoleInfo: om1: shutdown om1@group-562213E44849-FollowerState
om1_1        | 2022-10-20 02:10:20,045 [om1@group-562213E44849-FollowerState] INFO server.RaftServer$Division: om1@group-562213E44849: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
om1_1        | 2022-10-20 02:10:20,048 [om1@group-562213E44849-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
om1_1        | 2022-10-20 02:10:20,048 [om1@group-562213E44849-FollowerState] INFO impl.RoleInfo: om1: start om1@group-562213E44849-LeaderElection1
om1_1        | 2022-10-20 02:10:20,052 [om1@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om1@group-562213E44849-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: peers:[om1|rpc:om1:9872|priority:0|startupRole:FOLLOWER, om3|rpc:om3:9872|priority:0|startupRole:FOLLOWER, om2|rpc:om2:9872|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
om1_1        | 2022-10-20 02:10:20,117 [om1@group-562213E44849-LeaderElection1-1] INFO server.GrpcServerProtocolClient: Build channel for om3
om1_1        | 2022-10-20 02:10:20,120 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
om1_1        | 2022-10-20 02:10:20,120 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
om1_1        | 2022-10-20 02:10:20,122 [om1@group-562213E44849-LeaderElection1-2] INFO server.GrpcServerProtocolClient: Build channel for om2
om1_1        | 2022-10-20 02:10:21,690 [grpc-default-executor-0] INFO server.RaftServer$Division: om1@group-562213E44849: receive requestVote(ELECTION, om2, group-562213E44849, 1, (t:0, i:~))
om1_1        | 2022-10-20 02:10:21,695 [grpc-default-executor-0] INFO impl.VoteContext: om1@group-562213E44849-CANDIDATE: reject ELECTION from om2: already has voted for om1 at current term 1
om1_1        | 2022-10-20 02:10:21,808 [om1@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om1@group-562213E44849-LeaderElection1: ELECTION PASSED received 1 response(s) and 0 exception(s):
om1_1        | 2022-10-20 02:10:21,809 [om1@group-562213E44849-LeaderElection1] INFO impl.LeaderElection:   Response 0: om1<-om3#0:OK-t1
om1_1        | 2022-10-20 02:10:21,809 [om1@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om1@group-562213E44849-LeaderElection1 ELECTION round 0: result PASSED
om1_1        | 2022-10-20 02:10:21,828 [grpc-default-executor-0] INFO server.RaftServer$Division: om1@group-562213E44849 replies to ELECTION vote request: om2<-om1#0:FAIL-t1. Peer's state: om1@group-562213E44849:t1, leader=null, voted=om1, raftlog=Memoized:om1@group-562213E44849-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[om1|rpc:om1:9872|priority:0|startupRole:FOLLOWER, om3|rpc:om3:9872|priority:0|startupRole:FOLLOWER, om2|rpc:om2:9872|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
om1_1        | 2022-10-20 02:10:21,847 [om1@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om1: shutdown om1@group-562213E44849-LeaderElection1
om1_1        | 2022-10-20 02:10:21,849 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServer$Division: om1@group-562213E44849: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
om1_1        | 2022-10-20 02:10:21,849 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServer$Division: om1@group-562213E44849: change Leader from null to om1 at term 1 for becomeLeader, leader elected after 13649ms
om1_1        | 2022-10-20 02:10:21,869 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
om1_1        | 2022-10-20 02:10:21,904 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
om1_1        | 2022-10-20 02:10:21,910 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
om1_1        | 2022-10-20 02:10:21,935 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
om1_1        | 2022-10-20 02:10:21,944 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
recon_1      | 2022-10-20 02:08:29,996 [main] INFO persistence.DefaultDataSourceProvider: JDBC Url for Recon : jdbc:derby:/data/metadata/recon/ozone_recon_derby.db 
recon_1      | 2022-10-20 02:08:30,031 [main] INFO codegen.SqlDbUtils: Created derby database at jdbc:derby:/data/metadata/recon/ozone_recon_derby.db.
recon_1      | 2022-10-20 02:08:30,032 [main] INFO recon.ReconServer: Creating Recon Schema.
recon_1      | 2022-10-20 02:08:30,265 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
recon_1      | 2022-10-20 02:08:32,355 [main] INFO http.BaseHttpServer: Starting Web-server for recon at: http://0.0.0.0:9888
recon_1      | 2022-10-20 02:08:32,355 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
recon_1      | 2022-10-20 02:08:32,356 [main] INFO http.BaseHttpServer: HttpAuthType: ozone.recon.http.auth.type = kerberos
recon_1      | 2022-10-20 02:08:32,396 [main] INFO util.log: Logging initialized @41301ms to org.eclipse.jetty.util.log.Slf4jLog
recon_1      | 2022-10-20 02:08:32,672 [main] WARN http.HttpRequestLog: Jetty request log can only be enabled using Log4j
recon_1      | 2022-10-20 02:08:32,694 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
recon_1      | 2022-10-20 02:08:32,698 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context recon
recon_1      | 2022-10-20 02:08:32,701 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
recon_1      | 2022-10-20 02:08:32,701 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
recon_1      | 2022-10-20 02:08:32,708 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.recon.http.auth.kerberos.principal keytabKey: ozone.recon.http.auth.kerberos.keytab
recon_1      | 2022-10-20 02:08:32,914 [main] INFO tasks.ReconTaskControllerImpl: Registered task ContainerKeyMapperTask with controller.
recon_1      | 2022-10-20 02:08:33,459 [main] INFO tasks.ReconTaskControllerImpl: Registered task FileSizeCountTask with controller.
recon_1      | 2022-10-20 02:08:33,489 [main] INFO tasks.ReconTaskControllerImpl: Registered task TableCountTask with controller.
recon_1      | 2022-10-20 02:08:33,509 [main] INFO tasks.ReconTaskControllerImpl: Registered task NSSummaryTaskWithFSO with controller.
recon_1      | 2022-10-20 02:08:33,544 [main] INFO ozone.OmUtils: Using OzoneManager ServiceID 'id1'.
recon_1      | 2022-10-20 02:08:34,943 [main] WARN recon.ReconUtils: ozone.recon.om.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1      | 2022-10-20 02:08:35,265 [main] WARN recon.ReconUtils: ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1      | 2022-10-20 02:08:35,466 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar!/network-topology-default.xml]
recon_1      | 2022-10-20 02:08:35,486 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
recon_1      | 2022-10-20 02:08:35,676 [main] WARN db.DBStoreBuilder: ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1      | 2022-10-20 02:08:35,996 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
recon_1      | 2022-10-20 02:08:36,184 [main] INFO reflections.Reflections: Reflections took 174 ms to scan 3 urls, producing 112 keys and 252 values 
recon_1      | 2022-10-20 02:08:36,420 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
recon_1      | 2022-10-20 02:08:36,514 [main] INFO node.SCMNodeManager: Entering startup safe mode.
recon_1      | 2022-10-20 02:08:36,525 [main] INFO scm.ReconNodeManager: Loaded 0 nodes from node DB.
recon_1      | 2022-10-20 02:08:36,540 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
recon_1      | 2022-10-20 02:08:36,605 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
recon_1      | 2022-10-20 02:08:36,669 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
recon_1      | 2022-10-20 02:08:36,698 [Socket Reader #1 for port 9891] INFO ipc.Server: Starting Socket Reader #1 for port 9891
recon_1      | 2022-10-20 02:08:36,813 [Listener at 0.0.0.0/9891] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
recon_1      | 2022-10-20 02:08:37,222 [Listener at 0.0.0.0/9891] INFO recon.ReconServer: Recon server initialized successfully!
recon_1      | 2022-10-20 02:08:37,222 [Listener at 0.0.0.0/9891] INFO recon.ReconServer: Starting Recon server
recon_1      | 2022-10-20 02:08:37,351 [Listener at 0.0.0.0/9891] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
recon_1      | 2022-10-20 02:08:37,385 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
recon_1      | 2022-10-20 02:08:37,385 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Recon metrics system started
recon_1      | 2022-10-20 02:08:38,027 [Listener at 0.0.0.0/9891] INFO http.HttpServer2: Jetty bound to port 9888
recon_1      | 2022-10-20 02:08:38,034 [Listener at 0.0.0.0/9891] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
recon_1      | 2022-10-20 02:08:38,150 [Listener at 0.0.0.0/9891] INFO server.session: DefaultSessionIdManager workerName=node0
recon_1      | 2022-10-20 02:08:38,150 [Listener at 0.0.0.0/9891] INFO server.session: No SessionScavenger set, using defaults
recon_1      | 2022-10-20 02:08:38,152 [Listener at 0.0.0.0/9891] INFO server.session: node0 Scavenging every 600000ms
recon_1      | 2022-10-20 02:08:38,196 [Listener at 0.0.0.0/9891] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/recon.keytab, for principal HTTP/recon@EXAMPLE.COM
recon_1      | 2022-10-20 02:08:38,198 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@8318808{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
recon_1      | 2022-10-20 02:08:38,199 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@bbf361a{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-recon-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
recon_1      | 2022-10-20 02:08:39,234 [Listener at 0.0.0.0/9891] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/recon.keytab, for principal HTTP/recon@EXAMPLE.COM
recon_1      | 2022-10-20 02:08:39,248 [Listener at 0.0.0.0/9891] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/recon.keytab, for principal HTTP/recon@EXAMPLE.COM
recon_1      | 2022-10-20 02:08:41,901 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@197115d6{recon,/,file:///tmp/jetty-0_0_0_0-9888-ozone-recon-1_3_0-SNAPSHOT_jar-_-any-15306642257212916097/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-recon-1.3.0-SNAPSHOT.jar!/webapps/recon}
recon_1      | 2022-10-20 02:08:41,939 [Listener at 0.0.0.0/9891] INFO server.AbstractConnector: Started ServerConnector@4807b2b7{HTTP/1.1, (http/1.1)}{0.0.0.0:9888}
recon_1      | 2022-10-20 02:08:41,939 [Listener at 0.0.0.0/9891] INFO server.Server: Started @50851ms
om2_1        | 2022-10-20 02:10:05,060 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9872 (fallback to raft.grpc.server.port)
om2_1        | 2022-10-20 02:10:05,064 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.host = null (fallback to raft.grpc.server.host)
om2_1        | 2022-10-20 02:10:05,067 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9872 (fallback to raft.grpc.server.port)
om2_1        | 2022-10-20 02:10:05,072 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.host = null (default)
om2_1        | 2022-10-20 02:10:05,072 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om2_1        | 2022-10-20 02:10:05,077 [main] INFO server.GrpcService: raft.grpc.message.size.max = 33554432 (custom)
om2_1        | 2022-10-20 02:10:05,082 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om2_1        | 2022-10-20 02:10:05,089 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
om2_1        | 2022-10-20 02:10:05,090 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om2_1        | 2022-10-20 02:10:05,119 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
om2_1        | 2022-10-20 02:10:05,124 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
om2_1        | 2022-10-20 02:10:05,125 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
om2_1        | 2022-10-20 02:10:07,567 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
om2_1        | 2022-10-20 02:10:07,573 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
om2_1        | 2022-10-20 02:10:07,576 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
om2_1        | 2022-10-20 02:10:07,576 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om2_1        | 2022-10-20 02:10:07,576 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om2_1        | 2022-10-20 02:10:07,587 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om2_1        | 2022-10-20 02:10:07,607 [main] INFO server.RaftServer: om2: addNew group-562213E44849:[om1|rpc:om1:9872|priority:0|startupRole:FOLLOWER, om3|rpc:om3:9872|priority:0|startupRole:FOLLOWER, om2|rpc:om2:9872|priority:0|startupRole:FOLLOWER] returns group-562213E44849:java.util.concurrent.CompletableFuture@120bb5b5[Not completed]
om2_1        | 2022-10-20 02:10:07,607 [main] INFO om.OzoneManager: OzoneManager Ratis server initialized at port 9872
om2_1        | 2022-10-20 02:10:07,688 [main] INFO om.OzoneManager: Creating RPC Server
om2_1        | 2022-10-20 02:10:07,688 [pool-27-thread-1] INFO server.RaftServer$Division: om2: new RaftServerImpl for group-562213E44849:[om1|rpc:om1:9872|priority:0|startupRole:FOLLOWER, om3|rpc:om3:9872|priority:0|startupRole:FOLLOWER, om2|rpc:om2:9872|priority:0|startupRole:FOLLOWER] with OzoneManagerStateMachine:uninitialized
om2_1        | 2022-10-20 02:10:07,726 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
om2_1        | 2022-10-20 02:10:07,733 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
om2_1        | 2022-10-20 02:10:07,733 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
om2_1        | 2022-10-20 02:10:07,738 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om2_1        | 2022-10-20 02:10:07,738 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om2_1        | 2022-10-20 02:10:07,738 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
om2_1        | 2022-10-20 02:10:07,759 [pool-27-thread-1] INFO server.RaftServer$Division: om2@group-562213E44849: ConfigurationManager, init=-1: peers:[om1|rpc:om1:9872|priority:0|startupRole:FOLLOWER, om3|rpc:om3:9872|priority:0|startupRole:FOLLOWER, om2|rpc:om2:9872|priority:0|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
om2_1        | 2022-10-20 02:10:07,766 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om2_1        | 2022-10-20 02:10:07,949 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om2_1        | 2022-10-20 02:10:07,953 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
om2_1        | 2022-10-20 02:10:08,029 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
om2_1        | 2022-10-20 02:10:08,070 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 300s (custom)
om2_1        | 2022-10-20 02:10:08,085 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
om2_1        | 2022-10-20 02:10:08,618 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om2_1        | 2022-10-20 02:10:08,622 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
om2_1        | 2022-10-20 02:10:08,626 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
om2_1        | 2022-10-20 02:10:08,635 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
om2_1        | 2022-10-20 02:10:08,640 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
om2_1        | 2022-10-20 02:10:09,763 [main] INFO reflections.Reflections: Reflections took 1581 ms to scan 8 urls, producing 23 keys and 519 values [using 2 cores]
om2_1        | 2022-10-20 02:10:11,016 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om2_1        | 2022-10-20 02:10:11,043 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om2_1        | 2022-10-20 02:10:14,393 [Listener at om2/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om2_1        | 2022-10-20 02:10:14,446 [Listener at om2/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om2_1        | 2022-10-20 02:10:14,446 [Listener at om2/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om2_1        | 2022-10-20 02:10:14,578 [Listener at om2/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om2/172.25.0.112:9862
om2_1        | 2022-10-20 02:10:14,579 [Listener at om2/9862] INFO ratis.OzoneManagerRatisServer: Starting OzoneManagerRatisServer om2 at port 9872
om2_1        | 2022-10-20 02:10:14,580 [om2-impl-thread1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 does not exist. Creating ...
om2_1        | 2022-10-20 02:10:14,605 [om2-impl-thread1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/in_use.lock acquired by nodename 6@om2
om2_1        | 2022-10-20 02:10:14,669 [om2-impl-thread1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 has been successfully formatted.
om2_1        | 2022-10-20 02:10:14,673 [om2-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
om2_1        | 2022-10-20 02:10:14,726 [om2-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om2_1        | 2022-10-20 02:10:14,726 [om2-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om1_1        | 2022-10-20 02:10:21,955 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
om1_1        | 2022-10-20 02:10:21,982 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
om1_1        | 2022-10-20 02:10:21,987 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
om1_1        | 2022-10-20 02:10:22,013 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
om1_1        | 2022-10-20 02:10:22,014 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om1_1        | 2022-10-20 02:10:22,016 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1024 (custom)
om1_1        | 2022-10-20 02:10:22,023 [om1@group-562213E44849-LeaderElection1] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
om1_1        | 2022-10-20 02:10:22,023 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om1_1        | 2022-10-20 02:10:22,023 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om1_1        | 2022-10-20 02:10:22,023 [om1@group-562213E44849-LeaderElection1] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
om1_1        | 2022-10-20 02:10:22,023 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.wait-time.min = 10ms (default)
om1_1        | 2022-10-20 02:10:22,029 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
om1_1        | 2022-10-20 02:10:22,029 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om1_1        | 2022-10-20 02:10:22,035 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1024 (custom)
om1_1        | 2022-10-20 02:10:22,036 [om1@group-562213E44849-LeaderElection1] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
om1_1        | 2022-10-20 02:10:22,036 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om1_1        | 2022-10-20 02:10:22,036 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om1_1        | 2022-10-20 02:10:22,036 [om1@group-562213E44849-LeaderElection1] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
om1_1        | 2022-10-20 02:10:22,036 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.wait-time.min = 10ms (default)
om1_1        | 2022-10-20 02:10:22,037 [om1@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om1: start om1@group-562213E44849-LeaderStateImpl
om1_1        | 2022-10-20 02:10:22,086 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34164
om1_1        | 2022-10-20 02:10:22,098 [om1@group-562213E44849-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: om1@group-562213E44849-SegmentedRaftLogWorker: Starting segment from index:0
om1_1        | 2022-10-20 02:10:22,117 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-10-20 02:10:22,181 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServer$Division: om1@group-562213E44849: set configuration 0: peers:[om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
om1_1        | 2022-10-20 02:10:22,472 [om1@group-562213E44849-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: om1@group-562213E44849-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/current/log_inprogress_0
om1_1        | 2022-10-20 02:10:22,681 [om1@group-562213E44849-StateMachineUpdater] INFO ratis.OzoneManagerStateMachine: Received Configuration change notification from Ratis. New Peer list:
om1_1        | [id: "om1"
om1_1        | address: "om1:9872"
om1_1        | startupRole: FOLLOWER
om1_1        | , id: "om3"
om1_1        | address: "om3:9872"
om1_1        | startupRole: FOLLOWER
om1_1        | , id: "om2"
om1_1        | address: "om2:9872"
om1_1        | startupRole: FOLLOWER
om1_1        | ]
om1_1        | 2022-10-20 02:10:37,592 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35202
om1_1        | 2022-10-20 02:10:37,609 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-10-20 02:10:41,658 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35210
om1_1        | 2022-10-20 02:10:41,676 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-10-20 02:10:45,803 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:59380
om1_1        | 2022-10-20 02:10:45,818 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-10-20 02:10:49,776 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:59392
om1_1        | 2022-10-20 02:10:49,792 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-10-20 02:10:53,811 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:59404
om1_1        | 2022-10-20 02:10:53,829 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-10-20 02:10:54,584 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:vol1 for user:testuser
om1_1        | 2022-10-20 02:10:54,862 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket1 of layout LEGACY in volume: vol1
om1_1        | 2022-10-20 02:11:03,667 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:46900
om1_1        | 2022-10-20 02:11:03,686 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
recon_1      | 2022-10-20 02:08:41,949 [Listener at 0.0.0.0/9891] INFO impl.MetricsSinkAdapter: Sink prometheus started
recon_1      | 2022-10-20 02:08:41,949 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Registered sink prometheus
recon_1      | 2022-10-20 02:08:41,951 [Listener at 0.0.0.0/9891] INFO http.BaseHttpServer: HTTP server of recon listening at http://0.0.0.0:9888
recon_1      | 2022-10-20 02:08:41,951 [Listener at 0.0.0.0/9891] INFO impl.OzoneManagerServiceProviderImpl: Starting Ozone Manager Service Provider.
recon_1      | 2022-10-20 02:08:41,966 [Listener at 0.0.0.0/9891] INFO impl.OzoneManagerServiceProviderImpl: Registered OmDeltaRequest task 
recon_1      | 2022-10-20 02:08:41,978 [Listener at 0.0.0.0/9891] INFO impl.OzoneManagerServiceProviderImpl: Registered OmSnapshotRequest task 
recon_1      | 2022-10-20 02:08:41,978 [Listener at 0.0.0.0/9891] INFO recovery.ReconOmMetadataManagerImpl: Starting ReconOMMetadataManagerImpl
recon_1      | 2022-10-20 02:08:41,978 [Listener at 0.0.0.0/9891] WARN recon.ReconUtils: ozone.recon.om.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1      | 2022-10-20 02:08:41,979 [Listener at 0.0.0.0/9891] INFO tasks.ReconTaskControllerImpl: Starting Recon Task Controller.
recon_1      | 2022-10-20 02:08:41,983 [Listener at 0.0.0.0/9891] INFO scm.ReconStorageContainerManagerFacade: Recon ScmDatanodeProtocol RPC server is listening at /0.0.0.0:9891
recon_1      | 2022-10-20 02:08:42,385 [Listener at 0.0.0.0/9891] INFO scm.ReconStorageContainerManagerFacade: Obtained 0 pipelines from SCM.
recon_1      | 2022-10-20 02:08:42,386 [Listener at 0.0.0.0/9891] INFO scm.ReconPipelineManager: Recon has 0 pipelines in house.
recon_1      | 2022-10-20 02:08:42,386 [Listener at 0.0.0.0/9891] INFO scm.ReconStorageContainerManagerFacade: SCM DB initialized
recon_1      | 2022-10-20 02:08:42,386 [Listener at 0.0.0.0/9891] INFO server.SCMDatanodeProtocolServer: ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:9891
recon_1      | 2022-10-20 02:08:42,388 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
recon_1      | 2022-10-20 02:08:42,463 [IPC Server listener on 9891] INFO ipc.Server: IPC Server listener on 9891: starting
recon_1      | 2022-10-20 02:08:42,563 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Registered PipelineSyncTask task 
recon_1      | 2022-10-20 02:08:42,563 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Starting PipelineSyncTask Thread.
recon_1      | 2022-10-20 02:08:42,578 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Registered ContainerHealthTask task 
recon_1      | 2022-10-20 02:08:42,578 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Starting ContainerHealthTask Thread.
recon_1      | 2022-10-20 02:08:42,609 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 0 pipelines in house.
recon_1      | 2022-10-20 02:08:42,610 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 29 milliseconds.
recon_1      | 2022-10-20 02:09:01,979 [pool-29-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-10-20 02:09:01,980 [pool-29-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-10-20 02:09:02,290 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
recon_1      | 2022-10-20 02:09:02,328 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 2 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-10-20 02:09:04,329 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 3 failover attempts. Trying to failover immediately.
recon_1      | 2022-10-20 02:09:04,331 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 4 failover attempts. Trying to failover immediately.
recon_1      | 2022-10-20 02:09:04,331 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 5 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-10-20 02:09:06,333 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 6 failover attempts. Trying to failover immediately.
recon_1      | 2022-10-20 02:09:06,334 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 7 failover attempts. Trying to failover immediately.
recon_1      | 2022-10-20 02:09:06,335 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 8 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-10-20 02:09:08,336 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 9 failover attempts. Trying to failover immediately.
recon_1      | 2022-10-20 02:09:08,337 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 10 failover attempts. Trying to failover immediately.
om2_1        | 2022-10-20 02:10:14,727 [om2-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
om2_1        | 2022-10-20 02:10:14,730 [om2-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
om2_1        | 2022-10-20 02:10:14,742 [om2-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om2_1        | 2022-10-20 02:10:14,755 [om2-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
om2_1        | 2022-10-20 02:10:14,763 [om2-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
om2_1        | 2022-10-20 02:10:14,804 [om2-impl-thread1] INFO segmented.SegmentedRaftLogWorker: new om2@group-562213E44849-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849
om2_1        | 2022-10-20 02:10:14,804 [om2-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
om2_1        | 2022-10-20 02:10:14,804 [om2-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
om2_1        | 2022-10-20 02:10:14,813 [om2-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om2_1        | 2022-10-20 02:10:14,816 [om2-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
om2_1        | 2022-10-20 02:10:14,816 [om2-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
om2_1        | 2022-10-20 02:10:14,819 [om2-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
om2_1        | 2022-10-20 02:10:14,821 [om2-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om2_1        | 2022-10-20 02:10:14,825 [om2-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
om2_1        | 2022-10-20 02:10:14,856 [om2-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
om2_1        | 2022-10-20 02:10:14,869 [om2-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
om2_1        | 2022-10-20 02:10:14,869 [om2-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
om2_1        | 2022-10-20 02:10:14,876 [om2-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
om2_1        | 2022-10-20 02:10:14,894 [om2-impl-thread1] INFO segmented.SegmentedRaftLogWorker: om2@group-562213E44849-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
om2_1        | 2022-10-20 02:10:14,894 [om2-impl-thread1] INFO segmented.SegmentedRaftLogWorker: om2@group-562213E44849-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
om2_1        | 2022-10-20 02:10:14,905 [om2-impl-thread1] INFO server.RaftServer$Division: om2@group-562213E44849: start as a follower, conf=-1: peers:[om1|rpc:om1:9872|priority:0|startupRole:FOLLOWER, om3|rpc:om3:9872|priority:0|startupRole:FOLLOWER, om2|rpc:om2:9872|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
om2_1        | 2022-10-20 02:10:14,918 [om2-impl-thread1] INFO server.RaftServer$Division: om2@group-562213E44849: changes role from      null to FOLLOWER at term 0 for startAsFollower
om2_1        | 2022-10-20 02:10:14,919 [om2-impl-thread1] INFO impl.RoleInfo: om2: start om2@group-562213E44849-FollowerState
om2_1        | 2022-10-20 02:10:14,922 [om2@group-562213E44849-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
om2_1        | 2022-10-20 02:10:14,929 [om2@group-562213E44849-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
om2_1        | 2022-10-20 02:10:14,939 [om2-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-562213E44849,id=om2
om2_1        | 2022-10-20 02:10:14,941 [om2-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
om2_1        | 2022-10-20 02:10:14,941 [om2-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 400000 (default)
om2_1        | 2022-10-20 02:10:14,941 [om2-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
om2_1        | 2022-10-20 02:10:14,945 [om2-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = true (custom)
om2_1        | 2022-10-20 02:10:14,956 [Listener at om2/9862] INFO server.RaftServer: om2: start RPC server
om2_1        | 2022-10-20 02:10:15,069 [Listener at om2/9862] INFO server.GrpcService: om2: GrpcService started, listening on 9872
om2_1        | 2022-10-20 02:10:15,084 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-om2: Started
om2_1        | 2022-10-20 02:10:15,084 [Listener at om2/9862] INFO om.OzoneManager: Starting OM block token secret manager
om2_1        | 2022-10-20 02:10:15,084 [Listener at om2/9862] INFO token.OzoneBlockTokenSecretManager: Updating the current master key for generating tokens
om2_1        | 2022-10-20 02:10:15,085 [Listener at om2/9862] INFO om.OzoneManager: Starting OM delegation token secret manager
om2_1        | 2022-10-20 02:10:15,086 [Listener at om2/9862] INFO security.OzoneDelegationTokenSecretManager: Updating the current master key for generating tokens
om2_1        | 2022-10-20 02:10:15,090 [Listener at om2/9862] INFO om.OzoneManager: Version File has different layout version (3) than OM DB (null). That is expected if this OM has never been finalized to a newer layout version.
om2_1        | 2022-10-20 02:10:15,118 [Thread[Thread-18,5,main]] INFO security.OzoneDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
om2_1        | 2022-10-20 02:10:15,249 [Listener at om2/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om2_1        | 2022-10-20 02:10:15,249 [Listener at om2/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
om2_1        | 2022-10-20 02:10:15,249 [Listener at om2/9862] INFO http.BaseHttpServer: HttpAuthType: ozone.om.http.auth.type = kerberos
om2_1        | 2022-10-20 02:10:15,326 [Listener at om2/9862] INFO util.log: Logging initialized @42123ms to org.eclipse.jetty.util.log.Slf4jLog
om2_1        | 2022-10-20 02:10:15,699 [Listener at om2/9862] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
om2_1        | 2022-10-20 02:10:15,741 [Listener at om2/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om2_1        | 2022-10-20 02:10:15,745 [Listener at om2/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context ozoneManager
om2_1        | 2022-10-20 02:10:15,746 [Listener at om2/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
om2_1        | 2022-10-20 02:10:15,748 [Listener at om2/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
om2_1        | 2022-10-20 02:10:15,750 [Listener at om2/9862] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.om.http.auth.kerberos.principal keytabKey: ozone.om.http.auth.kerberos.keytab
om2_1        | 2022-10-20 02:10:15,917 [Listener at om2/9862] INFO http.HttpServer2: Jetty bound to port 9874
om2_1        | 2022-10-20 02:10:15,919 [Listener at om2/9862] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
om2_1        | 2022-10-20 02:10:16,158 [Listener at om2/9862] INFO server.session: DefaultSessionIdManager workerName=node0
om2_1        | 2022-10-20 02:10:16,158 [Listener at om2/9862] INFO server.session: No SessionScavenger set, using defaults
om2_1        | 2022-10-20 02:10:16,165 [Listener at om2/9862] INFO server.session: node0 Scavenging every 600000ms
om2_1        | 2022-10-20 02:10:16,231 [Listener at om2/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om2_1        | 2022-10-20 02:10:16,239 [Listener at om2/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@42b0183{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om2_1        | 2022-10-20 02:10:16,248 [Listener at om2/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1d17fbda{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om2_1        | 2022-10-20 02:10:16,664 [Listener at om2/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om2_1        | 2022-10-20 02:10:16,701 [Listener at om2/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@30b6eca3{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-ozone-manager-1_3_0-SNAPSHOT_jar-_-any-13866648745288903730/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/ozoneManager}
om2_1        | 2022-10-20 02:10:16,753 [Listener at om2/9862] INFO server.AbstractConnector: Started ServerConnector@62d6caf9{HTTP/1.1, (http/1.1)}{0.0.0.0:9874}
om2_1        | 2022-10-20 02:10:16,753 [Listener at om2/9862] INFO server.Server: Started @43551ms
om2_1        | 2022-10-20 02:10:16,775 [Listener at om2/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
om2_1        | 2022-10-20 02:10:16,775 [Listener at om2/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
om2_1        | 2022-10-20 02:10:16,779 [Listener at om2/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
om2_1        | 2022-10-20 02:10:16,785 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om2_1        | 2022-10-20 02:10:16,791 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om2_1        | 2022-10-20 02:10:16,937 [Listener at om2/9862] INFO om.OzoneManager: Trash Interval set to 0. Files deleted won't move to trash
om2_1        | 2022-10-20 02:10:17,040 [Listener at om2/9862] INFO om.GrpcOzoneManagerServer: GrpcOzoneManagerServer is started using port 8981
om2_1        | 2022-10-20 02:10:17,085 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2c13db34] INFO util.JvmPauseMonitor: Starting JVM pause monitor
om2_1        | 2022-10-20 02:10:17,810 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:36525
om2_1        | 2022-10-20 02:10:17,830 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-10-20 02:10:20,033 [om2@group-562213E44849-FollowerState] INFO impl.FollowerState: om2@group-562213E44849-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5113596827ns, electionTimeout:5103ms
om2_1        | 2022-10-20 02:10:20,034 [om2@group-562213E44849-FollowerState] INFO impl.RoleInfo: om2: shutdown om2@group-562213E44849-FollowerState
om2_1        | 2022-10-20 02:10:20,034 [om2@group-562213E44849-FollowerState] INFO server.RaftServer$Division: om2@group-562213E44849: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
om2_1        | 2022-10-20 02:10:20,037 [om2@group-562213E44849-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
om2_1        | 2022-10-20 02:10:20,037 [om2@group-562213E44849-FollowerState] INFO impl.RoleInfo: om2: start om2@group-562213E44849-LeaderElection1
om2_1        | 2022-10-20 02:10:20,047 [om2@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om2@group-562213E44849-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: peers:[om1|rpc:om1:9872|priority:0|startupRole:FOLLOWER, om3|rpc:om3:9872|priority:0|startupRole:FOLLOWER, om2|rpc:om2:9872|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
om2_1        | 2022-10-20 02:10:20,120 [om2@group-562213E44849-LeaderElection1-1] INFO server.GrpcServerProtocolClient: Build channel for om1
om2_1        | 2022-10-20 02:10:20,120 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
om2_1        | 2022-10-20 02:10:20,121 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
om2_1        | 2022-10-20 02:10:20,124 [om2@group-562213E44849-LeaderElection1-2] INFO server.GrpcServerProtocolClient: Build channel for om3
om2_1        | 2022-10-20 02:10:21,671 [grpc-default-executor-2] INFO server.RaftServer$Division: om2@group-562213E44849: receive requestVote(ELECTION, om1, group-562213E44849, 1, (t:0, i:~))
datanode3_1  | 2022-10-20 02:10:18,294 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection5] INFO impl.LeaderElection: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection5 ELECTION round 0: submit vote requests at term 4 for -1: peers:[922d5e53-2e0d-4e01-adf2-129a3cebef39|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1|startupRole:FOLLOWER, 4026c186-2529-49de-a2d8-dcba1039e356|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0|startupRole:FOLLOWER, e4d9a0e3-266c-4558-944a-cafbea7b03e5|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
datanode3_1  | 2022-10-20 02:10:18,295 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection5] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode3_1  | 2022-10-20 02:10:18,295 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection5] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode3_1  | 2022-10-20 02:10:18,297 [grpc-default-executor-0] INFO impl.VoteContext: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-CANDIDATE: reject ELECTION from 4026c186-2529-49de-a2d8-dcba1039e356: already has voted for e4d9a0e3-266c-4558-944a-cafbea7b03e5 at current term 4
datanode3_1  | 2022-10-20 02:10:18,305 [grpc-default-executor-0] INFO server.RaftServer$Division: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592 replies to ELECTION vote request: 4026c186-2529-49de-a2d8-dcba1039e356<-e4d9a0e3-266c-4558-944a-cafbea7b03e5#0:FAIL-t4. Peer's state: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592:t4, leader=null, voted=e4d9a0e3-266c-4558-944a-cafbea7b03e5, raftlog=Memoized:e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[922d5e53-2e0d-4e01-adf2-129a3cebef39|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1|startupRole:FOLLOWER, 4026c186-2529-49de-a2d8-dcba1039e356|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0|startupRole:FOLLOWER, e4d9a0e3-266c-4558-944a-cafbea7b03e5|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
datanode3_1  | 2022-10-20 02:10:18,309 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection5] INFO impl.LeaderElection: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection5: ELECTION REJECTED received 1 response(s) and 0 exception(s):
datanode3_1  | 2022-10-20 02:10:18,309 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection5] INFO impl.LeaderElection:   Response 0: e4d9a0e3-266c-4558-944a-cafbea7b03e5<-922d5e53-2e0d-4e01-adf2-129a3cebef39#0:FAIL-t4
datanode3_1  | 2022-10-20 02:10:18,309 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection5] INFO impl.LeaderElection: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection5 ELECTION round 0: result REJECTED
datanode3_1  | 2022-10-20 02:10:18,309 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection5] INFO server.RaftServer$Division: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592: changes role from CANDIDATE to FOLLOWER at term 4 for REJECTED
datanode3_1  | 2022-10-20 02:10:18,309 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection5] INFO impl.RoleInfo: e4d9a0e3-266c-4558-944a-cafbea7b03e5: shutdown e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection5
datanode3_1  | 2022-10-20 02:10:18,310 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection5] INFO impl.RoleInfo: e4d9a0e3-266c-4558-944a-cafbea7b03e5: start e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-FollowerState
datanode3_1  | 2022-10-20 02:10:18,310 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode3_1  | 2022-10-20 02:10:18,316 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode3_1  | 2022-10-20 02:10:23,413 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-FollowerState] INFO impl.FollowerState: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5102990348ns, electionTimeout:5096ms
datanode3_1  | 2022-10-20 02:10:23,413 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-FollowerState] INFO impl.RoleInfo: e4d9a0e3-266c-4558-944a-cafbea7b03e5: shutdown e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-FollowerState
datanode3_1  | 2022-10-20 02:10:23,413 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-FollowerState] INFO server.RaftServer$Division: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592: changes role from  FOLLOWER to CANDIDATE at term 4 for changeToCandidate
datanode3_1  | 2022-10-20 02:10:23,413 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode3_1  | 2022-10-20 02:10:23,413 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-FollowerState] INFO impl.RoleInfo: e4d9a0e3-266c-4558-944a-cafbea7b03e5: start e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection6
datanode3_1  | 2022-10-20 02:10:23,415 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection6] INFO impl.LeaderElection: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection6 ELECTION round 0: submit vote requests at term 5 for -1: peers:[922d5e53-2e0d-4e01-adf2-129a3cebef39|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1|startupRole:FOLLOWER, 4026c186-2529-49de-a2d8-dcba1039e356|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0|startupRole:FOLLOWER, e4d9a0e3-266c-4558-944a-cafbea7b03e5|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
datanode3_1  | 2022-10-20 02:10:23,415 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode3_1  | 2022-10-20 02:10:23,415 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode3_1  | 2022-10-20 02:10:23,434 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection6] INFO impl.LeaderElection: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection6: ELECTION REJECTED received 1 response(s) and 0 exception(s):
datanode3_1  | 2022-10-20 02:10:23,435 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection6] INFO impl.LeaderElection:   Response 0: e4d9a0e3-266c-4558-944a-cafbea7b03e5<-922d5e53-2e0d-4e01-adf2-129a3cebef39#0:FAIL-t5
datanode3_1  | 2022-10-20 02:10:23,435 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection6] INFO impl.LeaderElection: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection6 ELECTION round 0: result REJECTED
datanode3_1  | 2022-10-20 02:10:23,435 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection6] INFO server.RaftServer$Division: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592: changes role from CANDIDATE to FOLLOWER at term 5 for REJECTED
datanode3_1  | 2022-10-20 02:10:23,435 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection6] INFO impl.RoleInfo: e4d9a0e3-266c-4558-944a-cafbea7b03e5: shutdown e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection6
datanode3_1  | 2022-10-20 02:10:23,435 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection6] INFO impl.RoleInfo: e4d9a0e3-266c-4558-944a-cafbea7b03e5: start e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-FollowerState
om1_1        | 2022-10-20 02:11:04,197 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:46910
om1_1        | 2022-10-20 02:11:04,204 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-10-20 02:11:08,706 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42864
om1_1        | 2022-10-20 02:11:08,722 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-10-20 02:11:09,296 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42878
om1_1        | 2022-10-20 02:11:09,300 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-10-20 02:11:09,310 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ombg0 of layout LEGACY in volume: vol1
om1_1        | 2022-10-20 02:11:13,599 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42882
om1_1        | 2022-10-20 02:11:13,616 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-10-20 02:11:14,050 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42888
om1_1        | 2022-10-20 02:11:14,054 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-10-20 02:11:14,076 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42904
om1_1        | 2022-10-20 02:11:14,080 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-10-20 02:11:14,097 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42910
om1_1        | 2022-10-20 02:11:14,101 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-10-20 02:11:14,119 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42918
om1_1        | 2022-10-20 02:11:14,123 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-10-20 02:11:14,139 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42928
om1_1        | 2022-10-20 02:11:14,143 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-10-20 02:11:14,172 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42940
om1_1        | 2022-10-20 02:11:14,177 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-10-20 02:11:14,192 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42948
om1_1        | 2022-10-20 02:11:14,196 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-10-20 02:11:14,219 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42950
om1_1        | 2022-10-20 02:11:14,225 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-10-20 02:11:14,254 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42962
om1_1        | 2022-10-20 02:11:14,256 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-10-20 02:11:14,335 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:voltest for user:testuser
om1_1        | 2022-10-20 02:11:14,402 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: buckettest of layout LEGACY in volume: voltest
om1_1        | 2022-10-20 02:11:23,803 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:34563
om1_1        | 2022-10-20 02:11:23,811 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-10-20 02:11:39,285 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50448
om1_1        | 2022-10-20 02:11:39,309 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-10-20 02:11:39,680 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50450
om1_1        | 2022-10-20 02:11:39,684 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-10-20 02:11:39,707 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50460
om1_1        | 2022-10-20 02:11:39,708 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-10-20 02:11:39,721 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50462
datanode3_1  | 2022-10-20 02:10:23,458 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode3_1  | 2022-10-20 02:10:23,462 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode3_1  | 2022-10-20 02:10:28,611 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-FollowerState] INFO impl.FollowerState: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5176067499ns, electionTimeout:5149ms
datanode3_1  | 2022-10-20 02:10:28,611 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-FollowerState] INFO impl.RoleInfo: e4d9a0e3-266c-4558-944a-cafbea7b03e5: shutdown e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-FollowerState
datanode3_1  | 2022-10-20 02:10:28,611 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-FollowerState] INFO server.RaftServer$Division: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592: changes role from  FOLLOWER to CANDIDATE at term 5 for changeToCandidate
datanode3_1  | 2022-10-20 02:10:28,611 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode3_1  | 2022-10-20 02:10:28,611 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-FollowerState] INFO impl.RoleInfo: e4d9a0e3-266c-4558-944a-cafbea7b03e5: start e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection7
datanode3_1  | 2022-10-20 02:10:28,620 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection7] INFO impl.LeaderElection: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection7 ELECTION round 0: submit vote requests at term 6 for -1: peers:[922d5e53-2e0d-4e01-adf2-129a3cebef39|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1|startupRole:FOLLOWER, 4026c186-2529-49de-a2d8-dcba1039e356|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0|startupRole:FOLLOWER, e4d9a0e3-266c-4558-944a-cafbea7b03e5|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
datanode3_1  | 2022-10-20 02:10:28,622 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection7] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode3_1  | 2022-10-20 02:10:28,622 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection7] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode3_1  | 2022-10-20 02:10:28,688 [grpc-default-executor-0] INFO server.RaftServer$Division: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592: receive requestVote(ELECTION, 922d5e53-2e0d-4e01-adf2-129a3cebef39, group-44E7403E0592, 6, (t:0, i:0))
datanode3_1  | 2022-10-20 02:10:28,688 [grpc-default-executor-0] INFO impl.VoteContext: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-CANDIDATE: reject ELECTION from 922d5e53-2e0d-4e01-adf2-129a3cebef39: already has voted for e4d9a0e3-266c-4558-944a-cafbea7b03e5 at current term 6
datanode3_1  | 2022-10-20 02:10:28,689 [grpc-default-executor-0] INFO server.RaftServer$Division: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592 replies to ELECTION vote request: 922d5e53-2e0d-4e01-adf2-129a3cebef39<-e4d9a0e3-266c-4558-944a-cafbea7b03e5#0:FAIL-t6. Peer's state: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592:t6, leader=null, voted=e4d9a0e3-266c-4558-944a-cafbea7b03e5, raftlog=Memoized:e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[922d5e53-2e0d-4e01-adf2-129a3cebef39|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1|startupRole:FOLLOWER, 4026c186-2529-49de-a2d8-dcba1039e356|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0|startupRole:FOLLOWER, e4d9a0e3-266c-4558-944a-cafbea7b03e5|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
datanode3_1  | 2022-10-20 02:10:28,833 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection7] INFO impl.LeaderElection: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection7: ELECTION REJECTED received 2 response(s) and 0 exception(s):
datanode3_1  | 2022-10-20 02:10:28,833 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection7] INFO impl.LeaderElection:   Response 0: e4d9a0e3-266c-4558-944a-cafbea7b03e5<-4026c186-2529-49de-a2d8-dcba1039e356#0:FAIL-t6
datanode3_1  | 2022-10-20 02:10:28,833 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection7] INFO impl.LeaderElection:   Response 1: e4d9a0e3-266c-4558-944a-cafbea7b03e5<-922d5e53-2e0d-4e01-adf2-129a3cebef39#0:FAIL-t6
datanode3_1  | 2022-10-20 02:10:28,833 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection7] INFO impl.LeaderElection: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection7 ELECTION round 0: result REJECTED
datanode3_1  | 2022-10-20 02:10:28,834 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection7] INFO server.RaftServer$Division: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592: changes role from CANDIDATE to FOLLOWER at term 6 for REJECTED
datanode3_1  | 2022-10-20 02:10:28,834 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection7] INFO impl.RoleInfo: e4d9a0e3-266c-4558-944a-cafbea7b03e5: shutdown e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection7
datanode3_1  | 2022-10-20 02:10:28,834 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-LeaderElection7] INFO impl.RoleInfo: e4d9a0e3-266c-4558-944a-cafbea7b03e5: start e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-FollowerState
datanode3_1  | 2022-10-20 02:10:28,840 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode3_1  | 2022-10-20 02:10:28,840 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode3_1  | 2022-10-20 02:10:28,950 [e4d9a0e3-266c-4558-944a-cafbea7b03e5-server-thread1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-44E7403E0592 with new leaderId: 922d5e53-2e0d-4e01-adf2-129a3cebef39
datanode3_1  | 2022-10-20 02:10:28,950 [e4d9a0e3-266c-4558-944a-cafbea7b03e5-server-thread1] INFO server.RaftServer$Division: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592: change Leader from null to 922d5e53-2e0d-4e01-adf2-129a3cebef39 at term 6 for appendEntries, leader elected after 33428ms
datanode3_1  | 2022-10-20 02:10:28,952 [e4d9a0e3-266c-4558-944a-cafbea7b03e5-server-thread1] INFO server.RaftServer$Division: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592: set configuration 0: peers:[922d5e53-2e0d-4e01-adf2-129a3cebef39|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1|startupRole:FOLLOWER, 4026c186-2529-49de-a2d8-dcba1039e356|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0|startupRole:FOLLOWER, e4d9a0e3-266c-4558-944a-cafbea7b03e5|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
datanode3_1  | 2022-10-20 02:10:28,952 [e4d9a0e3-266c-4558-944a-cafbea7b03e5-server-thread1] INFO segmented.SegmentedRaftLogWorker: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-SegmentedRaftLogWorker: Starting segment from index:0
datanode3_1  | 2022-10-20 02:10:28,955 [e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: e4d9a0e3-266c-4558-944a-cafbea7b03e5@group-44E7403E0592-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/904a7869-3351-4618-b9db-44e7403e0592/current/log_inprogress_0
datanode3_1  | 2022-10-20 02:10:58,170 [ChunkWriter-1-0] INFO client.DNCertificateClient: Getting certificate with certSerialId:1087378534705.
recon_1      | 2022-10-20 02:09:08,338 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 11 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-10-20 02:09:10,339 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 12 failover attempts. Trying to failover immediately.
recon_1      | 2022-10-20 02:09:10,341 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 13 failover attempts. Trying to failover immediately.
recon_1      | 2022-10-20 02:09:10,342 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 14 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-10-20 02:09:12,344 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 15 failover attempts. Trying to failover immediately.
recon_1      | 2022-10-20 02:09:12,345 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 16 failover attempts. Trying to failover immediately.
recon_1      | 2022-10-20 02:09:12,346 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 17 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-10-20 02:09:14,349 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 18 failover attempts. Trying to failover immediately.
recon_1      | 2022-10-20 02:09:14,350 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 19 failover attempts. Trying to failover immediately.
recon_1      | 2022-10-20 02:09:14,350 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 20 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-10-20 02:09:16,354 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 21 failover attempts. Trying to failover immediately.
recon_1      | 2022-10-20 02:09:16,356 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 22 failover attempts. Trying to failover immediately.
recon_1      | 2022-10-20 02:09:16,388 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 23 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-10-20 02:09:18,390 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 24 failover attempts. Trying to failover immediately.
recon_1      | 2022-10-20 02:09:18,391 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 25 failover attempts. Trying to failover immediately.
recon_1      | 2022-10-20 02:09:18,393 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 26 failover attempts. Trying to failover after sleeping for 2000ms.
om2_1        | 2022-10-20 02:10:21,676 [grpc-default-executor-2] INFO impl.VoteContext: om2@group-562213E44849-CANDIDATE: reject ELECTION from om1: already has voted for om2 at current term 1
om2_1        | 2022-10-20 02:10:21,696 [grpc-default-executor-2] INFO server.RaftServer$Division: om2@group-562213E44849 replies to ELECTION vote request: om1<-om2#0:FAIL-t1. Peer's state: om2@group-562213E44849:t1, leader=null, voted=om2, raftlog=Memoized:om2@group-562213E44849-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[om1|rpc:om1:9872|priority:0|startupRole:FOLLOWER, om3|rpc:om3:9872|priority:0|startupRole:FOLLOWER, om2|rpc:om2:9872|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
om2_1        | 2022-10-20 02:10:21,922 [om2@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om2@group-562213E44849-LeaderElection1: ELECTION REJECTED received 2 response(s) and 0 exception(s):
om2_1        | 2022-10-20 02:10:21,924 [om2@group-562213E44849-LeaderElection1] INFO impl.LeaderElection:   Response 0: om2<-om1#0:FAIL-t1
om2_1        | 2022-10-20 02:10:21,924 [om2@group-562213E44849-LeaderElection1] INFO impl.LeaderElection:   Response 1: om2<-om3#0:FAIL-t1
om2_1        | 2022-10-20 02:10:21,925 [om2@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om2@group-562213E44849-LeaderElection1 ELECTION round 0: result REJECTED
om2_1        | 2022-10-20 02:10:21,927 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServer$Division: om2@group-562213E44849: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
om2_1        | 2022-10-20 02:10:21,927 [om2@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om2: shutdown om2@group-562213E44849-LeaderElection1
om2_1        | 2022-10-20 02:10:21,928 [om2@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om2: start om2@group-562213E44849-FollowerState
om2_1        | 2022-10-20 02:10:21,953 [om2@group-562213E44849-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
om2_1        | 2022-10-20 02:10:21,953 [om2@group-562213E44849-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
om2_1        | 2022-10-20 02:10:22,327 [om2-server-thread1] INFO server.RaftServer$Division: om2@group-562213E44849: change Leader from null to om1 at term 1 for appendEntries, leader elected after 14298ms
om1_1        | 2022-10-20 02:11:39,726 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-10-20 02:11:39,745 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50476
om1_1        | 2022-10-20 02:11:39,750 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-10-20 02:11:39,769 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50482
om1_1        | 2022-10-20 02:11:39,781 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-10-20 02:11:39,802 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50488
om1_1        | 2022-10-20 02:11:39,811 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-10-20 02:11:39,829 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50504
om1_1        | 2022-10-20 02:11:39,841 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-10-20 02:11:39,854 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50514
om1_1        | 2022-10-20 02:11:39,864 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-10-20 02:11:39,876 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50516
om1_1        | 2022-10-20 02:11:39,882 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-10-20 02:11:46,734 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33020
om1_1        | 2022-10-20 02:11:46,749 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-10-20 02:11:47,561 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33022
om1_1        | 2022-10-20 02:11:47,569 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-10-20 02:11:47,593 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33036
om1_1        | 2022-10-20 02:11:47,603 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-10-20 02:11:47,631 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33044
om1_1        | 2022-10-20 02:11:47,637 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-10-20 02:11:47,652 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33056
om1_1        | 2022-10-20 02:11:47,661 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-10-20 02:11:47,675 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33062
om1_1        | 2022-10-20 02:11:47,679 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-10-20 02:11:47,693 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33066
om1_1        | 2022-10-20 02:11:47,703 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-10-20 02:11:47,732 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33070
om1_1        | 2022-10-20 02:11:47,738 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-10-20 02:11:47,754 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33082
om1_1        | 2022-10-20 02:11:47,757 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-10-20 02:11:47,773 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33084
om1_1        | 2022-10-20 02:11:47,779 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-10-20 02:11:52,322 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33098
om1_1        | 2022-10-20 02:11:52,350 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-10-20 02:11:52,818 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33100
om1_1        | 2022-10-20 02:11:52,824 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
recon_1      | 2022-10-20 02:09:20,394 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 27 failover attempts. Trying to failover immediately.
recon_1      | 2022-10-20 02:09:20,395 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 28 failover attempts. Trying to failover immediately.
recon_1      | 2022-10-20 02:09:20,396 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 29 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-10-20 02:09:22,397 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 30 failover attempts. Trying to failover immediately.
recon_1      | 2022-10-20 02:09:22,398 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 31 failover attempts. Trying to failover immediately.
recon_1      | 2022-10-20 02:09:22,399 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 32 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-10-20 02:09:24,400 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 33 failover attempts. Trying to failover immediately.
recon_1      | 2022-10-20 02:09:24,401 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 34 failover attempts. Trying to failover immediately.
recon_1      | 2022-10-20 02:09:24,404 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 35 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-10-20 02:09:26,406 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 36 failover attempts. Trying to failover immediately.
recon_1      | 2022-10-20 02:09:26,412 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 37 failover attempts. Trying to failover immediately.
recon_1      | 2022-10-20 02:09:26,421 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 38 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-10-20 02:09:28,422 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 39 failover attempts. Trying to failover immediately.
recon_1      | 2022-10-20 02:09:28,424 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 40 failover attempts. Trying to failover immediately.
recon_1      | 2022-10-20 02:09:28,425 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 41 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-10-20 02:09:30,426 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 42 failover attempts. Trying to failover immediately.
recon_1      | 2022-10-20 02:09:30,426 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 43 failover attempts. Trying to failover immediately.
om1_1        | 2022-10-20 02:11:52,854 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33110
om1_1        | 2022-10-20 02:11:52,862 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-10-20 02:11:52,887 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33124
om1_1        | 2022-10-20 02:11:52,888 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-10-20 02:11:52,901 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33134
om1_1        | 2022-10-20 02:11:52,905 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-10-20 02:11:52,926 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33144
om1_1        | 2022-10-20 02:11:52,930 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-10-20 02:11:52,949 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33154
om1_1        | 2022-10-20 02:11:52,960 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-10-20 02:11:52,982 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33162
om1_1        | 2022-10-20 02:11:52,987 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-10-20 02:11:53,005 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33170
om1_1        | 2022-10-20 02:11:53,009 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-10-20 02:11:53,027 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33180
om1_1        | 2022-10-20 02:11:53,037 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-10-20 02:11:59,999 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50634
om1_1        | 2022-10-20 02:12:00,022 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-10-20 02:12:03,818 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50646
om1_1        | 2022-10-20 02:12:03,837 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-10-20 02:12:04,304 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50650
om1_1        | 2022-10-20 02:12:04,309 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-10-20 02:12:04,324 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50660
om1_1        | 2022-10-20 02:12:04,325 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-10-20 02:12:04,338 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50676
om1_1        | 2022-10-20 02:12:04,342 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-10-20 02:12:04,356 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50684
om1_1        | 2022-10-20 02:12:04,361 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-10-20 02:12:04,378 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50692
om1_1        | 2022-10-20 02:12:04,380 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-10-20 02:12:04,399 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50702
om1_1        | 2022-10-20 02:12:04,406 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-10-20 02:12:04,440 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50704
om1_1        | 2022-10-20 02:12:04,446 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-10-20 02:12:04,470 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50708
om1_1        | 2022-10-20 02:12:04,476 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-10-20 02:12:04,494 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50722
om2_1        | 2022-10-20 02:10:22,337 [om2-server-thread1] INFO server.RaftServer$Division: om2@group-562213E44849: set configuration 0: peers:[om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
om2_1        | 2022-10-20 02:10:22,345 [om2-server-thread1] INFO segmented.SegmentedRaftLogWorker: om2@group-562213E44849-SegmentedRaftLogWorker: Starting segment from index:0
om2_1        | 2022-10-20 02:10:22,627 [om2@group-562213E44849-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: om2@group-562213E44849-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/current/log_inprogress_0
om2_1        | 2022-10-20 02:10:25,353 [om2@group-562213E44849-StateMachineUpdater] INFO ratis.OzoneManagerStateMachine: Received Configuration change notification from Ratis. New Peer list:
om2_1        | [id: "om1"
om2_1        | address: "om1:9872"
om2_1        | startupRole: FOLLOWER
om2_1        | , id: "om3"
om2_1        | address: "om3:9872"
om2_1        | startupRole: FOLLOWER
om2_1        | , id: "om2"
om2_1        | address: "om2:9872"
om2_1        | startupRole: FOLLOWER
om2_1        | ]
om2_1        | 2022-10-20 02:10:54,666 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:vol1 for user:testuser
om2_1        | 2022-10-20 02:10:54,811 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket1 of layout LEGACY in volume: vol1
om2_1        | 2022-10-20 02:11:09,326 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ombg0 of layout LEGACY in volume: vol1
om2_1        | 2022-10-20 02:11:14,330 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:voltest for user:testuser
om2_1        | 2022-10-20 02:11:14,395 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: buckettest of layout LEGACY in volume: voltest
om2_1        | 2022-10-20 02:12:24,351 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ombr0 of layout LEGACY in volume: vol1
recon_1      | 2022-10-20 02:09:30,427 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 44 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-10-20 02:09:32,428 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 45 failover attempts. Trying to failover immediately.
recon_1      | 2022-10-20 02:09:32,429 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 46 failover attempts. Trying to failover immediately.
recon_1      | 2022-10-20 02:09:32,430 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 47 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-10-20 02:09:34,431 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 48 failover attempts. Trying to failover immediately.
recon_1      | 2022-10-20 02:09:34,432 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 49 failover attempts. Trying to failover immediately.
recon_1      | 2022-10-20 02:09:34,433 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 50 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-10-20 02:09:36,434 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 51 failover attempts. Trying to failover immediately.
recon_1      | 2022-10-20 02:09:36,436 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 52 failover attempts. Trying to failover immediately.
recon_1      | 2022-10-20 02:09:36,436 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 53 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-10-20 02:09:38,437 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 54 failover attempts. Trying to failover immediately.
recon_1      | 2022-10-20 02:09:38,438 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 55 failover attempts. Trying to failover immediately.
recon_1      | 2022-10-20 02:09:38,440 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 56 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-10-20 02:09:40,441 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 57 failover attempts. Trying to failover immediately.
recon_1      | 2022-10-20 02:09:40,441 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 58 failover attempts. Trying to failover immediately.
recon_1      | 2022-10-20 02:09:40,442 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 59 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-10-20 02:09:42,443 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 60 failover attempts. Trying to failover immediately.
om3_1        | STARTUP_MSG: Starting OzoneManager
om3_1        | STARTUP_MSG:   host = om3/172.25.0.113
om3_1        | STARTUP_MSG:   args = []
om3_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
om1_1        | 2022-10-20 02:12:04,500 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-10-20 02:12:11,421 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:46532
om1_1        | 2022-10-20 02:12:11,434 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-10-20 02:12:18,994 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39114
om1_1        | 2022-10-20 02:12:19,013 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-10-20 02:12:23,804 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39120
om1_1        | 2022-10-20 02:12:23,822 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-10-20 02:12:23,876 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:40585
om1_1        | 2022-10-20 02:12:23,893 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-10-20 02:12:24,338 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39124
om1_1        | 2022-10-20 02:12:24,343 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-10-20 02:12:24,348 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ombr0 of layout LEGACY in volume: vol1
om1_1        | 2022-10-20 02:12:28,750 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41962
om1_1        | 2022-10-20 02:12:28,769 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-10-20 02:12:33,118 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41964
om1_1        | 2022-10-20 02:12:33,134 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/jna-platform-5.2.0.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/orc-core-1.5.8.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.2.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-linux-x86_64.jar:/opt/hadoop/share/ozone/lib/httpmime-4.5.6.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.9.0.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/httpasyncclient-4.1.3.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.4.0.jar:/opt/hadoop/share/ozone/lib/jetty-client-9.4.31.v20200723.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/ranger-plugin-classloader-2.3.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.4.0.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.48.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.4.0.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.48.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-osx-aarch_64.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.4.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.48.1.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.10.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/commons-lang-2.6.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jna-5.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.4.0.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.32.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.48.1.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.48.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.4.5.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.4.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-cred-2.3.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/hppc-0.8.0.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-osx-x86_64.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-audit-2.3.0.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/jersey-client-1.19.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-windows-x86_64.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.4.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.4.0.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-linux-aarch_64.jar:/opt/hadoop/share/ozone/lib/gethostname4j-0.0.2.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.21.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.48.1.jar:/opt/hadoop/share/ozone/lib/ranger-intg-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.53.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.4.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.4.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.48.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.4.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.25.0.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.3.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.4.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/httpcore-nio-4.4.6.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar
om3_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/ff6d15f5df822a5a3c776320b032fad3dd380f95 ; compiled by 'runner' on 2022-10-20T01:42Z
om3_1        | STARTUP_MSG:   java = 11.0.14.1
om3_1        | ************************************************************/
om3_1        | 2022-10-20 02:09:42,245 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om3_1        | 2022-10-20 02:09:48,135 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for OMAudit to [].
om3_1        | 2022-10-20 02:09:50,752 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om3_1        | 2022-10-20 02:09:51,159 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om3, RPC Address: om3:9862 and Ratis port: 9872
om3_1        | 2022-10-20 02:09:51,159 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om3: om3
om3_1        | 2022-10-20 02:09:51,159 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om3: om3
om3_1        | 2022-10-20 02:09:51,237 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1        | 2022-10-20 02:09:51,486 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = MULTITENANCY_SCHEMA (version = 3), software layout = MULTITENANCY_SCHEMA (version = 3)
om3_1        | 2022-10-20 02:09:53,083 [main] INFO reflections.Reflections: Reflections took 1083 ms to scan 1 urls, producing 114 keys and 335 values [using 2 cores]
om3_1        | 2022-10-20 02:09:53,956 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om3_1        | 2022-10-20 02:09:53,977 [main] INFO om.OzoneManager: Ozone Manager login successful.
om3_1        | 2022-10-20 02:09:53,977 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1        | 2022-10-20 02:09:56,058 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 3 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
om3_1        | 2022-10-20 02:09:56,452 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 3 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
om3_1        | 2022-10-20 02:10:00,896 [main] INFO client.OMCertificateClient: Loading certificate from location:/data/metadata/om/certs.
om3_1        | 2022-10-20 02:10:01,426 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/1089806136571.crt.
om3_1        | 2022-10-20 02:10:01,458 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/ROOTCA-1.crt.
om3_1        | 2022-10-20 02:10:01,473 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/CA-1003431474332.crt.
om3_1        | 2022-10-20 02:10:01,911 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1        | 2022-10-20 02:10:02,818 [main] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
om3_1        | 2022-10-20 02:10:02,864 [main] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
om3_1        | 2022-10-20 02:10:04,215 [main] INFO om.OzoneManager: S3 Multi-Tenancy is disabled
om3_1        | 2022-10-20 02:10:04,244 [main] INFO security.OzoneSecretStore: Loaded 0 tokens
om3_1        | 2022-10-20 02:10:04,244 [main] INFO security.OzoneDelegationTokenSecretManager: Loading token state into token manager.
om3_1        | 2022-10-20 02:10:04,670 [main] INFO om.OzoneManager: Created Volume s3v With Owner om required for S3Gateway operations.
om3_1        | 2022-10-20 02:10:04,909 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om3_1        | 2022-10-20 02:10:04,910 [main] WARN utils.OzoneManagerRatisUtils: ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
om3_1        | 2022-10-20 02:10:04,992 [main] INFO snapshot.OzoneManagerSnapshotProvider: Initializing OM Snapshot Provider
om3_1        | 2022-10-20 02:10:05,432 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
om3_1        | 2022-10-20 02:10:05,475 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om3_1        | 2022-10-20 02:10:05,590 [main] INFO ratis.OzoneManagerRatisServer: Instantiating OM Ratis server with groupID: id1 and peers: om3:9872, om1:9872, om2:9872
om3_1        | 2022-10-20 02:10:05,651 [main] INFO ratis.OzoneManagerStateMachine: LastAppliedIndex is set from TransactionInfo from OM DB as (t:0, i:~)
om3_1        | 2022-10-20 02:10:07,139 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
om3_1        | 2022-10-20 02:10:07,588 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
om3_1        | 2022-10-20 02:10:07,609 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9872 (fallback to raft.grpc.server.port)
om3_1        | 2022-10-20 02:10:07,610 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.host = null (fallback to raft.grpc.server.host)
om3_1        | 2022-10-20 02:10:07,611 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9872 (fallback to raft.grpc.server.port)
om3_1        | 2022-10-20 02:10:07,612 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.host = null (default)
om3_1        | 2022-10-20 02:10:07,612 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om3_1        | 2022-10-20 02:10:07,613 [main] INFO server.GrpcService: raft.grpc.message.size.max = 33554432 (custom)
om3_1        | 2022-10-20 02:10:07,630 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om3_1        | 2022-10-20 02:10:07,633 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
om3_1        | 2022-10-20 02:10:07,636 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om3_1        | 2022-10-20 02:10:07,685 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
om3_1        | 2022-10-20 02:10:07,687 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
om3_1        | 2022-10-20 02:10:07,693 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
om3_1        | 2022-10-20 02:10:10,107 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
om3_1        | 2022-10-20 02:10:10,138 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
om3_1        | 2022-10-20 02:10:10,166 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
om3_1        | 2022-10-20 02:10:10,167 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om3_1        | 2022-10-20 02:10:10,167 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om3_1        | 2022-10-20 02:10:10,197 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om3_1        | 2022-10-20 02:10:10,264 [main] INFO server.RaftServer: om3: addNew group-562213E44849:[om1|rpc:om1:9872|priority:0|startupRole:FOLLOWER, om3|rpc:om3:9872|priority:0|startupRole:FOLLOWER, om2|rpc:om2:9872|priority:0|startupRole:FOLLOWER] returns group-562213E44849:java.util.concurrent.CompletableFuture@39d5376c[Not completed]
om3_1        | 2022-10-20 02:10:10,264 [main] INFO om.OzoneManager: OzoneManager Ratis server initialized at port 9872
om3_1        | 2022-10-20 02:10:10,421 [pool-27-thread-1] INFO server.RaftServer$Division: om3: new RaftServerImpl for group-562213E44849:[om1|rpc:om1:9872|priority:0|startupRole:FOLLOWER, om3|rpc:om3:9872|priority:0|startupRole:FOLLOWER, om2|rpc:om2:9872|priority:0|startupRole:FOLLOWER] with OzoneManagerStateMachine:uninitialized
om3_1        | 2022-10-20 02:10:10,423 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
om3_1        | 2022-10-20 02:10:10,423 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
om3_1        | 2022-10-20 02:10:10,431 [main] INFO om.OzoneManager: Creating RPC Server
om3_1        | 2022-10-20 02:10:10,437 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
om3_1        | 2022-10-20 02:10:10,437 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om3_1        | 2022-10-20 02:10:10,437 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om3_1        | 2022-10-20 02:10:10,437 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
om3_1        | 2022-10-20 02:10:10,524 [pool-27-thread-1] INFO server.RaftServer$Division: om3@group-562213E44849: ConfigurationManager, init=-1: peers:[om1|rpc:om1:9872|priority:0|startupRole:FOLLOWER, om3|rpc:om3:9872|priority:0|startupRole:FOLLOWER, om2|rpc:om2:9872|priority:0|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
om3_1        | 2022-10-20 02:10:10,532 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om3_1        | 2022-10-20 02:10:10,591 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om3_1        | 2022-10-20 02:10:10,611 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
om3_1        | 2022-10-20 02:10:10,816 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
om3_1        | 2022-10-20 02:10:10,866 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 300s (custom)
om3_1        | 2022-10-20 02:10:10,866 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
om3_1        | 2022-10-20 02:10:11,326 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om3_1        | 2022-10-20 02:10:11,336 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
om3_1        | 2022-10-20 02:10:11,338 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
om3_1        | 2022-10-20 02:10:11,339 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
om3_1        | 2022-10-20 02:10:11,345 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
om3_1        | 2022-10-20 02:10:12,396 [main] INFO reflections.Reflections: Reflections took 1434 ms to scan 8 urls, producing 23 keys and 519 values [using 2 cores]
om3_1        | 2022-10-20 02:10:13,210 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om3_1        | 2022-10-20 02:10:13,240 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om3_1        | 2022-10-20 02:10:16,456 [Listener at om3/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om3_1        | 2022-10-20 02:10:16,510 [Listener at om3/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om3_1        | 2022-10-20 02:10:16,510 [Listener at om3/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om3_1        | 2022-10-20 02:10:16,704 [Listener at om3/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om3/172.25.0.113:9862
om3_1        | 2022-10-20 02:10:16,704 [Listener at om3/9862] INFO ratis.OzoneManagerRatisServer: Starting OzoneManagerRatisServer om3 at port 9872
om3_1        | 2022-10-20 02:10:16,717 [om3-impl-thread1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 does not exist. Creating ...
om3_1        | 2022-10-20 02:10:16,724 [om3-impl-thread1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/in_use.lock acquired by nodename 7@om3
om3_1        | 2022-10-20 02:10:16,767 [om3-impl-thread1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 has been successfully formatted.
om3_1        | 2022-10-20 02:10:16,779 [om3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
om3_1        | 2022-10-20 02:10:16,808 [om3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om3_1        | 2022-10-20 02:10:16,813 [om3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
recon_1      | 2022-10-20 02:09:42,444 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 61 failover attempts. Trying to failover immediately.
recon_1      | 2022-10-20 02:09:42,444 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 62 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-10-20 02:09:44,446 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 63 failover attempts. Trying to failover immediately.
recon_1      | 2022-10-20 02:09:44,448 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 64 failover attempts. Trying to failover immediately.
recon_1      | 2022-10-20 02:09:44,450 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 65 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-10-20 02:09:46,452 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 66 failover attempts. Trying to failover immediately.
recon_1      | 2022-10-20 02:09:46,454 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 67 failover attempts. Trying to failover immediately.
recon_1      | 2022-10-20 02:09:46,454 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 68 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-10-20 02:09:47,447 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:40242
recon_1      | 2022-10-20 02:09:47,515 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-10-20 02:09:48,455 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 69 failover attempts. Trying to failover immediately.
recon_1      | 2022-10-20 02:09:48,456 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 70 failover attempts. Trying to failover immediately.
recon_1      | 2022-10-20 02:09:48,456 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 71 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-10-20 02:09:49,147 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54800
recon_1      | 2022-10-20 02:09:49,263 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-10-20 02:09:49,954 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:55284
recon_1      | 2022-10-20 02:09:50,078 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-10-20 02:09:50,458 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 72 failover attempts. Trying to failover immediately.
recon_1      | 2022-10-20 02:09:50,458 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 73 failover attempts. Trying to failover immediately.
recon_1      | 2022-10-20 02:09:50,459 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 74 failover attempts. Trying to failover after sleeping for 2000ms.
om3_1        | 2022-10-20 02:10:16,822 [om3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
om3_1        | 2022-10-20 02:10:16,823 [om3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
om3_1        | 2022-10-20 02:10:16,838 [om3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om3_1        | 2022-10-20 02:10:16,852 [om3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
om3_1        | 2022-10-20 02:10:16,856 [om3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
om3_1        | 2022-10-20 02:10:16,900 [om3-impl-thread1] INFO segmented.SegmentedRaftLogWorker: new om3@group-562213E44849-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849
om3_1        | 2022-10-20 02:10:16,903 [om3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
om3_1        | 2022-10-20 02:10:16,909 [om3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
om3_1        | 2022-10-20 02:10:16,911 [om3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om3_1        | 2022-10-20 02:10:16,913 [om3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
om3_1        | 2022-10-20 02:10:16,919 [om3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
om3_1        | 2022-10-20 02:10:16,923 [om3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
om3_1        | 2022-10-20 02:10:16,926 [om3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om3_1        | 2022-10-20 02:10:16,926 [om3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
om3_1        | 2022-10-20 02:10:16,964 [om3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
om3_1        | 2022-10-20 02:10:16,970 [om3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
om3_1        | 2022-10-20 02:10:16,970 [om3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
om3_1        | 2022-10-20 02:10:16,971 [om3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
om3_1        | 2022-10-20 02:10:16,990 [om3-impl-thread1] INFO segmented.SegmentedRaftLogWorker: om3@group-562213E44849-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
om3_1        | 2022-10-20 02:10:16,990 [om3-impl-thread1] INFO segmented.SegmentedRaftLogWorker: om3@group-562213E44849-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
om3_1        | 2022-10-20 02:10:16,994 [om3-impl-thread1] INFO server.RaftServer$Division: om3@group-562213E44849: start as a follower, conf=-1: peers:[om1|rpc:om1:9872|priority:0|startupRole:FOLLOWER, om3|rpc:om3:9872|priority:0|startupRole:FOLLOWER, om2|rpc:om2:9872|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
om3_1        | 2022-10-20 02:10:16,997 [om3-impl-thread1] INFO server.RaftServer$Division: om3@group-562213E44849: changes role from      null to FOLLOWER at term 0 for startAsFollower
om3_1        | 2022-10-20 02:10:17,004 [om3-impl-thread1] INFO impl.RoleInfo: om3: start om3@group-562213E44849-FollowerState
om3_1        | 2022-10-20 02:10:17,021 [om3@group-562213E44849-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
om3_1        | 2022-10-20 02:10:17,021 [om3@group-562213E44849-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
om3_1        | 2022-10-20 02:10:17,026 [om3-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-562213E44849,id=om3
om3_1        | 2022-10-20 02:10:17,028 [om3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
om3_1        | 2022-10-20 02:10:17,029 [om3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 400000 (default)
om3_1        | 2022-10-20 02:10:17,032 [om3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
om3_1        | 2022-10-20 02:10:17,047 [om3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = true (custom)
om3_1        | 2022-10-20 02:10:17,057 [Listener at om3/9862] INFO server.RaftServer: om3: start RPC server
om3_1        | 2022-10-20 02:10:17,271 [Listener at om3/9862] INFO server.GrpcService: om3: GrpcService started, listening on 9872
om3_1        | 2022-10-20 02:10:17,281 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-om3: Started
om3_1        | 2022-10-20 02:10:17,281 [Listener at om3/9862] INFO om.OzoneManager: Starting OM block token secret manager
om3_1        | 2022-10-20 02:10:17,282 [Listener at om3/9862] INFO token.OzoneBlockTokenSecretManager: Updating the current master key for generating tokens
om3_1        | 2022-10-20 02:10:17,283 [Listener at om3/9862] INFO om.OzoneManager: Starting OM delegation token secret manager
om3_1        | 2022-10-20 02:10:17,286 [Listener at om3/9862] INFO security.OzoneDelegationTokenSecretManager: Updating the current master key for generating tokens
om3_1        | 2022-10-20 02:10:17,298 [Listener at om3/9862] INFO om.OzoneManager: Version File has different layout version (3) than OM DB (null). That is expected if this OM has never been finalized to a newer layout version.
om3_1        | 2022-10-20 02:10:17,323 [Thread[Thread-18,5,main]] INFO security.OzoneDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
om3_1        | 2022-10-20 02:10:17,415 [Listener at om3/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om3_1        | 2022-10-20 02:10:17,416 [Listener at om3/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
om3_1        | 2022-10-20 02:10:17,416 [Listener at om3/9862] INFO http.BaseHttpServer: HttpAuthType: ozone.om.http.auth.type = kerberos
om3_1        | 2022-10-20 02:10:17,499 [Listener at om3/9862] INFO util.log: Logging initialized @42725ms to org.eclipse.jetty.util.log.Slf4jLog
om3_1        | 2022-10-20 02:10:17,750 [Listener at om3/9862] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
om3_1        | 2022-10-20 02:10:17,771 [Listener at om3/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om3_1        | 2022-10-20 02:10:17,780 [Listener at om3/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context ozoneManager
om3_1        | 2022-10-20 02:10:17,782 [Listener at om3/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
om3_1        | 2022-10-20 02:10:17,783 [Listener at om3/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
om3_1        | 2022-10-20 02:10:17,786 [Listener at om3/9862] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.om.http.auth.kerberos.principal keytabKey: ozone.om.http.auth.kerberos.keytab
om3_1        | 2022-10-20 02:10:17,900 [Listener at om3/9862] INFO http.HttpServer2: Jetty bound to port 9874
recon_1      | 2022-10-20 02:09:51,080 [IPC Server handler 22 on default port 9891] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/922d5e53-2e0d-4e01-adf2-129a3cebef39
recon_1      | 2022-10-20 02:09:51,120 [IPC Server handler 22 on default port 9891] INFO node.SCMNodeManager: Registered Data node : 922d5e53-2e0d-4e01-adf2-129a3cebef39{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1082772173580, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-10-20 02:09:51,432 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node 922d5e53-2e0d-4e01-adf2-129a3cebef39 to Node DB.
recon_1      | 2022-10-20 02:09:51,478 [IPC Server handler 30 on default port 9891] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/e4d9a0e3-266c-4558-944a-cafbea7b03e5
recon_1      | 2022-10-20 02:09:51,483 [IPC Server handler 30 on default port 9891] INFO node.SCMNodeManager: Registered Data node : e4d9a0e3-266c-4558-944a-cafbea7b03e5{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1081094776367, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-10-20 02:09:51,511 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node e4d9a0e3-266c-4558-944a-cafbea7b03e5 to Node DB.
recon_1      | 2022-10-20 02:09:52,079 [IPC Server handler 22 on default port 9891] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/4026c186-2529-49de-a2d8-dcba1039e356
recon_1      | 2022-10-20 02:09:52,080 [IPC Server handler 22 on default port 9891] INFO node.SCMNodeManager: Registered Data node : 4026c186-2529-49de-a2d8-dcba1039e356{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1083227860558, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-10-20 02:09:52,085 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node 4026c186-2529-49de-a2d8-dcba1039e356 to Node DB.
recon_1      | 2022-10-20 02:09:52,460 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 75 failover attempts. Trying to failover immediately.
recon_1      | 2022-10-20 02:09:52,464 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 76 failover attempts. Trying to failover immediately.
recon_1      | 2022-10-20 02:09:52,466 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 77 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-10-20 02:09:52,819 [IPC Server handler 35 on default port 9891] INFO scm.ReconNodeManager: Sending ReregisterCommand() for ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net
recon_1      | 2022-10-20 02:09:52,950 [IPC Server handler 22 on default port 9891] INFO scm.ReconNodeManager: Sending ReregisterCommand() for ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net
recon_1      | 2022-10-20 02:09:53,680 [IPC Server handler 35 on default port 9891] INFO scm.ReconNodeManager: Sending ReregisterCommand() for ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net
recon_1      | 2022-10-20 02:09:54,467 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 78 failover attempts. Trying to failover immediately.
recon_1      | 2022-10-20 02:09:54,468 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 79 failover attempts. Trying to failover immediately.
recon_1      | 2022-10-20 02:09:54,468 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 80 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-10-20 02:09:54,806 [IPC Server handler 22 on default port 9891] INFO scm.ReconNodeManager: Updating nodeDB for ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net
recon_1      | 2022-10-20 02:09:54,808 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=461fda09-4c27-4112-8f11-ffbe57651d3a. Trying to get from SCM.
recon_1      | 2022-10-20 02:09:54,963 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: 461fda09-4c27-4112-8f11-ffbe57651d3a, Nodes: e4d9a0e3-266c-4558-944a-cafbea7b03e5{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-10-20T02:09:51.773Z[UTC]] to Recon pipeline metadata.
recon_1      | 2022-10-20 02:09:55,112 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 461fda09-4c27-4112-8f11-ffbe57651d3a, Nodes: e4d9a0e3-266c-4558-944a-cafbea7b03e5{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-10-20T02:09:51.773Z[UTC]].
recon_1      | 2022-10-20 02:09:55,124 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/ONE PipelineID=461fda09-4c27-4112-8f11-ffbe57651d3a reported by e4d9a0e3-266c-4558-944a-cafbea7b03e5{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1081094776367, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
om3_1        | 2022-10-20 02:10:17,906 [Listener at om3/9862] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
om3_1        | 2022-10-20 02:10:18,020 [Listener at om3/9862] INFO server.session: DefaultSessionIdManager workerName=node0
om3_1        | 2022-10-20 02:10:18,045 [Listener at om3/9862] INFO server.session: No SessionScavenger set, using defaults
om3_1        | 2022-10-20 02:10:18,046 [Listener at om3/9862] INFO server.session: node0 Scavenging every 660000ms
om3_1        | 2022-10-20 02:10:18,111 [Listener at om3/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om3_1        | 2022-10-20 02:10:18,113 [Listener at om3/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7b161b91{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om3_1        | 2022-10-20 02:10:18,116 [Listener at om3/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@58b2df95{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om3_1        | 2022-10-20 02:10:18,485 [Listener at om3/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om3_1        | 2022-10-20 02:10:18,494 [Listener at om3/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@16cb470a{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-ozone-manager-1_3_0-SNAPSHOT_jar-_-any-928038335763242003/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/ozoneManager}
om3_1        | 2022-10-20 02:10:18,502 [Listener at om3/9862] INFO server.AbstractConnector: Started ServerConnector@30845b6d{HTTP/1.1, (http/1.1)}{0.0.0.0:9874}
om3_1        | 2022-10-20 02:10:18,502 [Listener at om3/9862] INFO server.Server: Started @43727ms
om3_1        | 2022-10-20 02:10:18,504 [Listener at om3/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
om3_1        | 2022-10-20 02:10:18,504 [Listener at om3/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
om3_1        | 2022-10-20 02:10:18,511 [Listener at om3/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
om3_1        | 2022-10-20 02:10:18,519 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om3_1        | 2022-10-20 02:10:18,525 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om3_1        | 2022-10-20 02:10:18,612 [Listener at om3/9862] INFO om.OzoneManager: Trash Interval set to 0. Files deleted won't move to trash
om3_1        | 2022-10-20 02:10:18,722 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:37841
om3_1        | 2022-10-20 02:10:18,735 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-10-20 02:10:18,848 [Listener at om3/9862] INFO om.GrpcOzoneManagerServer: GrpcOzoneManagerServer is started using port 8981
om3_1        | 2022-10-20 02:10:18,874 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4fc1edc3] INFO util.JvmPauseMonitor: Starting JVM pause monitor
om3_1        | 2022-10-20 02:10:21,672 [grpc-default-executor-0] INFO server.RaftServer$Division: om3@group-562213E44849: receive requestVote(ELECTION, om1, group-562213E44849, 1, (t:0, i:~))
om3_1        | 2022-10-20 02:10:21,673 [grpc-default-executor-1] INFO server.RaftServer$Division: om3@group-562213E44849: receive requestVote(ELECTION, om2, group-562213E44849, 1, (t:0, i:~))
om3_1        | 2022-10-20 02:10:21,685 [grpc-default-executor-0] INFO impl.VoteContext: om3@group-562213E44849-FOLLOWER: accept ELECTION from om1: our priority 0 <= candidate's priority 0
om3_1        | 2022-10-20 02:10:21,693 [grpc-default-executor-0] INFO server.RaftServer$Division: om3@group-562213E44849: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:om1
om3_1        | 2022-10-20 02:10:21,693 [grpc-default-executor-0] INFO impl.RoleInfo: om3: shutdown om3@group-562213E44849-FollowerState
om3_1        | 2022-10-20 02:10:21,693 [grpc-default-executor-0] INFO impl.RoleInfo: om3: start om3@group-562213E44849-FollowerState
om3_1        | 2022-10-20 02:10:21,693 [om3@group-562213E44849-FollowerState] INFO impl.FollowerState: om3@group-562213E44849-FollowerState was interrupted
om3_1        | 2022-10-20 02:10:21,707 [om3@group-562213E44849-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
om3_1        | 2022-10-20 02:10:21,707 [om3@group-562213E44849-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
om3_1        | 2022-10-20 02:10:21,723 [grpc-default-executor-0] INFO server.RaftServer$Division: om3@group-562213E44849 replies to ELECTION vote request: om1<-om3#0:OK-t1. Peer's state: om3@group-562213E44849:t1, leader=null, voted=om1, raftlog=Memoized:om3@group-562213E44849-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[om1|rpc:om1:9872|priority:0|startupRole:FOLLOWER, om3|rpc:om3:9872|priority:0|startupRole:FOLLOWER, om2|rpc:om2:9872|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
om3_1        | 2022-10-20 02:10:21,723 [grpc-default-executor-1] INFO impl.VoteContext: om3@group-562213E44849-FOLLOWER: reject ELECTION from om2: already has voted for om1 at current term 1
om3_1        | 2022-10-20 02:10:21,723 [grpc-default-executor-1] INFO server.RaftServer$Division: om3@group-562213E44849 replies to ELECTION vote request: om2<-om3#0:FAIL-t1. Peer's state: om3@group-562213E44849:t1, leader=null, voted=om1, raftlog=Memoized:om3@group-562213E44849-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[om1|rpc:om1:9872|priority:0|startupRole:FOLLOWER, om3|rpc:om3:9872|priority:0|startupRole:FOLLOWER, om2|rpc:om2:9872|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
om3_1        | 2022-10-20 02:10:22,347 [om3-server-thread1] INFO server.RaftServer$Division: om3@group-562213E44849: change Leader from null to om1 at term 1 for appendEntries, leader elected after 11531ms
om3_1        | 2022-10-20 02:10:22,379 [om3-server-thread1] INFO server.RaftServer$Division: om3@group-562213E44849: set configuration 0: peers:[om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
om3_1        | 2022-10-20 02:10:22,402 [om3-server-thread1] INFO segmented.SegmentedRaftLogWorker: om3@group-562213E44849-SegmentedRaftLogWorker: Starting segment from index:0
om3_1        | 2022-10-20 02:10:22,637 [om3@group-562213E44849-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: om3@group-562213E44849-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/current/log_inprogress_0
om3_1        | 2022-10-20 02:10:25,350 [om3@group-562213E44849-StateMachineUpdater] INFO ratis.OzoneManagerStateMachine: Received Configuration change notification from Ratis. New Peer list:
om3_1        | [id: "om1"
om3_1        | address: "om1:9872"
om3_1        | startupRole: FOLLOWER
om3_1        | , id: "om3"
om3_1        | address: "om3:9872"
om3_1        | startupRole: FOLLOWER
om3_1        | , id: "om2"
om3_1        | address: "om2:9872"
om3_1        | startupRole: FOLLOWER
om3_1        | ]
om3_1        | 2022-10-20 02:10:54,627 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:vol1 for user:testuser
om3_1        | 2022-10-20 02:10:54,853 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket1 of layout LEGACY in volume: vol1
om3_1        | 2022-10-20 02:11:09,323 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ombg0 of layout LEGACY in volume: vol1
om3_1        | 2022-10-20 02:11:14,332 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:voltest for user:testuser
om3_1        | 2022-10-20 02:11:14,389 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: buckettest of layout LEGACY in volume: voltest
om3_1        | 2022-10-20 02:12:24,356 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ombr0 of layout LEGACY in volume: vol1
s3g_1        | Sleeping for 5 seconds
s3g_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
s3g_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
s3g_1        | 2022-10-20 02:07:57,391 [main] INFO security.UserGroupInformation: Login successful for user s3g/s3g@EXAMPLE.COM using keytab file s3g.keytab. Keytab auto renewal enabled : false
s3g_1        | 2022-10-20 02:07:57,392 [main] INFO s3.Gateway: S3Gateway login successful.
s3g_1        | 2022-10-20 02:07:57,690 [main] INFO http.BaseHttpServer: Starting Web-server for s3gateway at: http://0.0.0.0:9878
s3g_1        | 2022-10-20 02:07:57,690 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
s3g_1        | 2022-10-20 02:07:57,691 [main] INFO http.BaseHttpServer: HttpAuthType: ozone.s3g.http.auth.type = kerberos
s3g_1        | 2022-10-20 02:07:57,847 [main] INFO util.log: Logging initialized @5712ms to org.eclipse.jetty.util.log.Slf4jLog
s3g_1        | 2022-10-20 02:07:58,314 [main] INFO http.HttpRequestLog: Http request log for http.requests.s3gateway is not defined
s3g_1        | 2022-10-20 02:07:58,348 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
s3g_1        | 2022-10-20 02:07:58,352 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context s3gateway
s3g_1        | 2022-10-20 02:07:58,357 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
s3g_1        | 2022-10-20 02:07:58,358 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
s3g_1        | 2022-10-20 02:07:58,361 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.s3g.http.auth.kerberos.principal keytabKey: ozone.s3g.http.auth.kerberos.keytab
s3g_1        | 2022-10-20 02:07:58,605 [main] INFO s3.Gateway: STARTUP_MSG: 
s3g_1        | /************************************************************
s3g_1        | STARTUP_MSG: Starting Gateway
s3g_1        | STARTUP_MSG:   host = s3g/172.25.0.114
s3g_1        | STARTUP_MSG:   args = []
s3g_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
s3g_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/hk2-utils-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/jakarta.inject-2.6.1.jar:/opt/hadoop/share/ozone/lib/hk2-locator-2.6.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/aopalliance-repackaged-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.interceptor-api-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.2.jar:/opt/hadoop/share/ozone/lib/javax.el-api-3.0.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-linux-x86_64.jar:/opt/hadoop/share/ozone/lib/jakarta.ws.rs-api-2.1.6.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.9.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.4.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.4.0.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.4.0.jar:/opt/hadoop/share/ozone/lib/jakarta.xml.bind-api-2.3.3.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.48.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.48.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-osx-aarch_64.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.4.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-2.34.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.48.1.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.10.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-core-2.34.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/cdi-api-1.2.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.4.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.32.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-cdi1x-2.34.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hk2-api-2.5.0.jar:/opt/hadoop/share/ozone/lib/javax.inject-1.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.48.1.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.48.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/jackson-module-jaxb-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.4.5.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/jakarta.validation-api-2.0.2.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.4.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-osx-x86_64.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/jersey-client-2.34.jar:/opt/hadoop/share/ozone/lib/jakarta.annotation-api-1.3.5.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/osgi-resource-locator-1.0.3.jar:/opt/hadoop/share/ozone/lib/jackson-dataformat-xml-2.13.4.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-windows-x86_64.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.4.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.4.0.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-linux-aarch_64.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.21.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.48.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.53.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.4.jar:/opt/hadoop/share/ozone/lib/jersey-common-2.34.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.4.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.48.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.4.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jersey-hk2-2.34.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.25.0.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.3.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final.jar:/opt/hadoop/share/ozone/lib/jersey-media-jaxb-2.34.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/weld-servlet-2.4.7.Final.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.4.0.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-s3gateway-1.3.0-SNAPSHOT.jar
s3g_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/ff6d15f5df822a5a3c776320b032fad3dd380f95 ; compiled by 'runner' on 2022-10-20T01:42Z
s3g_1        | STARTUP_MSG:   java = 11.0.14.1
s3g_1        | ************************************************************/
s3g_1        | 2022-10-20 02:07:58,639 [main] INFO s3.Gateway: registered UNIX signal handlers for [TERM, HUP, INT]
s3g_1        | 2022-10-20 02:07:58,685 [main] INFO s3.Gateway: Starting Ozone S3 gateway
s3g_1        | 2022-10-20 02:07:58,944 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
s3g_1        | 2022-10-20 02:07:59,413 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
s3g_1        | 2022-10-20 02:07:59,418 [main] INFO impl.MetricsSystemImpl: S3Gateway metrics system started
s3g_1        | 2022-10-20 02:07:59,598 [main] INFO http.HttpServer2: Jetty bound to port 9878
s3g_1        | 2022-10-20 02:07:59,599 [main] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
s3g_1        | 2022-10-20 02:07:59,776 [main] INFO server.session: DefaultSessionIdManager workerName=node0
s3g_1        | 2022-10-20 02:07:59,776 [main] INFO server.session: No SessionScavenger set, using defaults
s3g_1        | 2022-10-20 02:07:59,777 [main] INFO server.session: node0 Scavenging every 660000ms
s3g_1        | 2022-10-20 02:07:59,815 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/s3g@EXAMPLE.COM
s3g_1        | 2022-10-20 02:07:59,854 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@54361a9{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
s3g_1        | 2022-10-20 02:07:59,854 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7bf9b098{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-s3gateway-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
s3g_1        | WARNING: An illegal reflective access operation has occurred
s3g_1        | WARNING: Illegal reflective access by org.jboss.weld.util.reflection.Formats (file:/opt/hadoop/share/ozone/lib/weld-servlet-2.4.7.Final.jar) to constructor com.sun.org.apache.bcel.internal.classfile.ClassParser(java.io.InputStream,java.lang.String)
s3g_1        | WARNING: Please consider reporting this to the maintainers of org.jboss.weld.util.reflection.Formats
s3g_1        | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
s3g_1        | WARNING: All illegal access operations will be denied in a future release
s3g_1        | 2022-10-20 02:08:04,225 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/s3g@EXAMPLE.COM
s3g_1        | Oct 20, 2022 2:08:06 AM org.glassfish.jersey.internal.Errors logErrors
s3g_1        | WARNING: The following warnings have been detected: WARNING: A HTTP GET method, public javax.ws.rs.core.Response org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.get(java.lang.String,java.lang.String,java.lang.String,int,java.lang.String,java.io.InputStream) throws java.io.IOException,org.apache.hadoop.ozone.s3.exception.OS3Exception, should not consume any entity.
s3g_1        | 
s3g_1        | 2022-10-20 02:08:06,095 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@2b4829aa{s3gateway,/,file:///tmp/jetty-0_0_0_0-9878-ozone-s3gateway-1_3_0-SNAPSHOT_jar-_-any-20574187486842313/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-s3gateway-1.3.0-SNAPSHOT.jar!/webapps/s3gateway}
s3g_1        | 2022-10-20 02:08:06,114 [main] INFO server.AbstractConnector: Started ServerConnector@4de025bf{HTTP/1.1, (http/1.1)}{0.0.0.0:9878}
s3g_1        | 2022-10-20 02:08:06,114 [main] INFO server.Server: Started @13979ms
s3g_1        | 2022-10-20 02:08:06,116 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
s3g_1        | 2022-10-20 02:08:06,116 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
s3g_1        | 2022-10-20 02:08:06,121 [main] INFO http.BaseHttpServer: HTTP server of s3gateway listening at http://0.0.0.0:9878
recon_1      | 2022-10-20 02:09:55,151 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 461fda09-4c27-4112-8f11-ffbe57651d3a, Nodes: e4d9a0e3-266c-4558-944a-cafbea7b03e5{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:e4d9a0e3-266c-4558-944a-cafbea7b03e5, CreationTimestamp2022-10-20T02:09:51.773Z[UTC]] moved to OPEN state
recon_1      | 2022-10-20 02:09:55,691 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=904a7869-3351-4618-b9db-44e7403e0592. Trying to get from SCM.
recon_1      | 2022-10-20 02:09:55,703 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: 904a7869-3351-4618-b9db-44e7403e0592, Nodes: 922d5e53-2e0d-4e01-adf2-129a3cebef39{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}e4d9a0e3-266c-4558-944a-cafbea7b03e5{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}4026c186-2529-49de-a2d8-dcba1039e356{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-10-20T02:09:52.276Z[UTC]] to Recon pipeline metadata.
recon_1      | 2022-10-20 02:09:55,704 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 904a7869-3351-4618-b9db-44e7403e0592, Nodes: 922d5e53-2e0d-4e01-adf2-129a3cebef39{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}e4d9a0e3-266c-4558-944a-cafbea7b03e5{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}4026c186-2529-49de-a2d8-dcba1039e356{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-10-20T02:09:52.276Z[UTC]].
recon_1      | 2022-10-20 02:09:55,710 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=904a7869-3351-4618-b9db-44e7403e0592 reported by e4d9a0e3-266c-4558-944a-cafbea7b03e5{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1081094776367, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-10-20 02:09:55,725 [IPC Server handler 19 on default port 9891] INFO scm.ReconNodeManager: Updating nodeDB for ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net
recon_1      | 2022-10-20 02:09:55,727 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=904a7869-3351-4618-b9db-44e7403e0592 reported by 4026c186-2529-49de-a2d8-dcba1039e356{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1083227860558, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-10-20 02:09:56,469 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 81 failover attempts. Trying to failover immediately.
recon_1      | 2022-10-20 02:09:56,470 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 82 failover attempts. Trying to failover immediately.
recon_1      | 2022-10-20 02:09:56,470 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 83 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-10-20 02:09:58,471 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 84 failover attempts. Trying to failover immediately.
recon_1      | 2022-10-20 02:09:58,473 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 85 failover attempts. Trying to failover immediately.
recon_1      | 2022-10-20 02:09:58,474 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 86 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-10-20 02:09:59,722 [IPC Server handler 19 on default port 9891] INFO scm.ReconNodeManager: Updating nodeDB for ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net
scm1.org_1   | Sleeping for 5 seconds
scm1.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm1.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm1.org_1   | 2022-10-20 02:07:59,198 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm1.org_1   | /************************************************************
scm1.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm1.org_1   | STARTUP_MSG:   host = scm1.org/172.25.0.116
scm1.org_1   | STARTUP_MSG:   args = [--init]
scm1.org_1   | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
scm1.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.2.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.4.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.4.0.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.4.0.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.4.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.10.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.4.0.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.32.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.4.5.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.4.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.4.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.4.0.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.4.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.4.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.3.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.4.0.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar
scm1.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/ff6d15f5df822a5a3c776320b032fad3dd380f95 ; compiled by 'runner' on 2022-10-20T01:41Z
scm1.org_1   | STARTUP_MSG:   java = 11.0.14.1
scm1.org_1   | ************************************************************/
scm1.org_1   | 2022-10-20 02:07:59,296 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm1.org_1   | 2022-10-20 02:07:59,767 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm1.org_1   | 2022-10-20 02:08:00,046 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm1.org_1   | 2022-10-20 02:08:00,122 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm1.org_1   | 2022-10-20 02:08:00,296 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm1, RPC Address: scm1.org:9894 and Ratis port: 9894
scm1.org_1   | 2022-10-20 02:08:00,314 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm1: scm1.org
scm1.org_1   | 2022-10-20 02:08:00,393 [main] INFO ha.HASecurityUtils: Initializing secure StorageContainerManager.
scm1.org_1   | 2022-10-20 02:08:02,974 [main] ERROR client.SCMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
scm1.org_1   | 2022-10-20 02:08:02,975 [main] INFO client.SCMCertificateClient: Certificate client init case: 0
scm1.org_1   | 2022-10-20 02:08:02,976 [main] INFO client.SCMCertificateClient: Creating keypair for client as keypair and certificate not found.
scm1.org_1   | 2022-10-20 02:08:05,362 [main] INFO ha.HASecurityUtils: Init response: GETCERT
scm1.org_1   | 2022-10-20 02:08:06,681 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.116,host:scm1.org
scm1.org_1   | 2022-10-20 02:08:06,681 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
scm1.org_1   | 2022-10-20 02:08:06,811 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.116,host:scm1.org
scm1.org_1   | 2022-10-20 02:08:06,811 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
scm1.org_1   | 2022-10-20 02:08:06,812 [main] INFO ha.HASecurityUtils: Creating csr for SCM->hostName:scm1.org,scmId:193991a4-d526-4123-97ec-0cf0bd3049b7,clusterId:CID-959c5f9a-2485-4f2a-8075-3da9fe7c4057,subject:scm-sub@scm1.org
scm1.org_1   | 2022-10-20 02:08:06,929 [main] INFO ha.HASecurityUtils: Successfully stored SCM signed certificate.
scm1.org_1   | 2022-10-20 02:08:07,055 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
scm1.org_1   | 2022-10-20 02:08:07,156 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
scm1.org_1   | 2022-10-20 02:08:07,162 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9894 (fallback to raft.grpc.server.port)
scm1.org_1   | 2022-10-20 02:08:07,164 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.host = null (fallback to raft.grpc.server.host)
scm1.org_1   | 2022-10-20 02:08:07,165 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9894 (fallback to raft.grpc.server.port)
scm1.org_1   | 2022-10-20 02:08:07,165 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.host = null (default)
scm1.org_1   | 2022-10-20 02:08:07,165 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2022-10-20 02:08:07,166 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
scm1.org_1   | 2022-10-20 02:08:07,168 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2022-10-20 02:08:07,170 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
scm1.org_1   | 2022-10-20 02:08:07,170 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm1.org_1   | 2022-10-20 02:08:07,188 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
scm1.org_1   | 2022-10-20 02:08:07,194 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
scm1.org_1   | 2022-10-20 02:08:07,194 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
scm1.org_1   | 2022-10-20 02:08:07,474 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
scm1.org_1   | 2022-10-20 02:08:07,475 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
scm1.org_1   | 2022-10-20 02:08:07,476 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
scm1.org_1   | 2022-10-20 02:08:07,481 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm1.org_1   | 2022-10-20 02:08:07,481 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm1.org_1   | 2022-10-20 02:08:07,486 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm1.org_1   | 2022-10-20 02:08:07,506 [main] INFO server.RaftServer: 193991a4-d526-4123-97ec-0cf0bd3049b7: addNew group-3DA9FE7C4057:[193991a4-d526-4123-97ec-0cf0bd3049b7|rpc:scm1.org:9894|priority:0|startupRole:FOLLOWER] returns group-3DA9FE7C4057:java.util.concurrent.CompletableFuture@61ab89b0[Not completed]
scm1.org_1   | 2022-10-20 02:08:07,537 [pool-2-thread-1] INFO server.RaftServer$Division: 193991a4-d526-4123-97ec-0cf0bd3049b7: new RaftServerImpl for group-3DA9FE7C4057:[193991a4-d526-4123-97ec-0cf0bd3049b7|rpc:scm1.org:9894|priority:0|startupRole:FOLLOWER] with SCMStateMachine:uninitialized
scm1.org_1   | 2022-10-20 02:08:07,545 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
scm1.org_1   | 2022-10-20 02:08:07,546 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
scm1.org_1   | 2022-10-20 02:08:07,546 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
scm1.org_1   | 2022-10-20 02:08:07,546 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm1.org_1   | 2022-10-20 02:08:07,546 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm1.org_1   | 2022-10-20 02:08:07,546 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
scm1.org_1   | 2022-10-20 02:08:07,554 [pool-2-thread-1] INFO server.RaftServer$Division: 193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057: ConfigurationManager, init=-1: peers:[193991a4-d526-4123-97ec-0cf0bd3049b7|rpc:scm1.org:9894|priority:0|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
scm1.org_1   | 2022-10-20 02:08:07,555 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm3.org_1   | Sleeping for 5 seconds
scm3.org_1   | Waiting for the service scm2.org:9894
scm3.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm3.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm3.org_1   | 2022-10-20 02:08:46,481 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm3.org_1   | /************************************************************
scm3.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm3.org_1   | STARTUP_MSG:   host = scm3.org/172.25.0.118
scm3.org_1   | STARTUP_MSG:   args = [--bootstrap]
scm3.org_1   | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
recon_1      | 2022-10-20 02:09:59,723 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=904a7869-3351-4618-b9db-44e7403e0592 reported by 922d5e53-2e0d-4e01-adf2-129a3cebef39{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1082772173580, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-10-20 02:10:00,422 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=928115e6-57fc-4e60-abe7-d27615e20c89. Trying to get from SCM.
recon_1      | 2022-10-20 02:10:00,436 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: 928115e6-57fc-4e60-abe7-d27615e20c89, Nodes: 922d5e53-2e0d-4e01-adf2-129a3cebef39{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}4026c186-2529-49de-a2d8-dcba1039e356{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}e4d9a0e3-266c-4558-944a-cafbea7b03e5{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-10-20T02:09:52.497Z[UTC]] to Recon pipeline metadata.
recon_1      | 2022-10-20 02:10:00,437 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 928115e6-57fc-4e60-abe7-d27615e20c89, Nodes: 922d5e53-2e0d-4e01-adf2-129a3cebef39{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}4026c186-2529-49de-a2d8-dcba1039e356{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}e4d9a0e3-266c-4558-944a-cafbea7b03e5{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-10-20T02:09:52.497Z[UTC]].
recon_1      | 2022-10-20 02:10:00,437 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=928115e6-57fc-4e60-abe7-d27615e20c89 reported by 4026c186-2529-49de-a2d8-dcba1039e356{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1083227860558, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-10-20 02:10:00,437 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=904a7869-3351-4618-b9db-44e7403e0592 reported by 4026c186-2529-49de-a2d8-dcba1039e356{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1083227860558, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-10-20 02:10:00,479 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 87 failover attempts. Trying to failover immediately.
recon_1      | 2022-10-20 02:10:00,491 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 88 failover attempts. Trying to failover immediately.
recon_1      | 2022-10-20 02:10:00,497 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 89 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-10-20 02:10:00,599 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=904a7869-3351-4618-b9db-44e7403e0592 reported by e4d9a0e3-266c-4558-944a-cafbea7b03e5{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1081094776367, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-10-20 02:10:01,059 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=928115e6-57fc-4e60-abe7-d27615e20c89 reported by 922d5e53-2e0d-4e01-adf2-129a3cebef39{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1082772173580, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-10-20 02:10:01,059 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=904a7869-3351-4618-b9db-44e7403e0592 reported by 922d5e53-2e0d-4e01-adf2-129a3cebef39{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1082772173580, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-10-20 02:10:02,498 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 90 failover attempts. Trying to failover immediately.
recon_1      | 2022-10-20 02:10:02,499 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 91 failover attempts. Trying to failover immediately.
scm3.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.2.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.4.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.4.0.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.4.0.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.4.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.10.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.4.0.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.32.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.4.5.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.4.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.4.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.4.0.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.4.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.4.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.3.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.4.0.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar
scm3.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/ff6d15f5df822a5a3c776320b032fad3dd380f95 ; compiled by 'runner' on 2022-10-20T01:41Z
scm3.org_1   | STARTUP_MSG:   java = 11.0.14.1
scm3.org_1   | ************************************************************/
scm3.org_1   | 2022-10-20 02:08:46,503 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm3.org_1   | 2022-10-20 02:08:46,688 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm3.org_1   | 2022-10-20 02:08:46,772 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm3.org_1   | 2022-10-20 02:08:46,772 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm3.org_1   | 2022-10-20 02:08:46,895 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm3, RPC Address: scm3.org:9894 and Ratis port: 9894
scm3.org_1   | 2022-10-20 02:08:46,895 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm3: scm3.org
scm3.org_1   | 2022-10-20 02:08:47,296 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
scm3.org_1   | 2022-10-20 02:08:47,296 [main] INFO server.StorageContainerManager: SCM login successful.
scm3.org_1   | 2022-10-20 02:08:47,490 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 2 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863]
scm3.org_1   | 2022-10-20 02:08:48,283 [main] INFO ha.HASecurityUtils: Initializing secure StorageContainerManager.
scm3.org_1   | 2022-10-20 02:08:49,199 [main] ERROR client.SCMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
scm3.org_1   | 2022-10-20 02:08:49,199 [main] INFO client.SCMCertificateClient: Certificate client init case: 0
scm3.org_1   | 2022-10-20 02:08:49,253 [main] INFO client.SCMCertificateClient: Creating keypair for client as keypair and certificate not found.
scm3.org_1   | 2022-10-20 02:08:49,952 [main] INFO ha.HASecurityUtils: Init response: GETCERT
scm3.org_1   | 2022-10-20 02:08:49,995 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.118,host:scm3.org
scm3.org_1   | 2022-10-20 02:08:49,995 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
scm3.org_1   | 2022-10-20 02:08:50,004 [main] INFO ha.HASecurityUtils: Creating csr for SCM->hostName:scm3.org,scmId:ff795c6b-74b4-4669-bf8f-984925e59fb3,clusterId:CID-959c5f9a-2485-4f2a-8075-3da9fe7c4057,subject:scm-sub@scm3.org
scm3.org_1   | 2022-10-20 02:08:50,906 [main] INFO ha.HASecurityUtils: Successfully stored SCM signed certificate.
scm3.org_1   | 2022-10-20 02:08:50,923 [main] INFO server.StorageContainerManager: SCM BootStrap  is successful for ClusterID CID-959c5f9a-2485-4f2a-8075-3da9fe7c4057, SCMID ff795c6b-74b4-4669-bf8f-984925e59fb3
scm3.org_1   | 2022-10-20 02:08:50,923 [main] INFO server.StorageContainerManager: Primary SCM Node ID 193991a4-d526-4123-97ec-0cf0bd3049b7
scm3.org_1   | 2022-10-20 02:08:50,962 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
scm3.org_1   | /************************************************************
scm3.org_1   | SHUTDOWN_MSG: Shutting down StorageContainerManager at scm3.org/172.25.0.118
scm3.org_1   | ************************************************************/
scm3.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm3.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm3.org_1   | 2022-10-20 02:08:52,919 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm3.org_1   | /************************************************************
scm3.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm3.org_1   | STARTUP_MSG:   host = scm3.org/172.25.0.118
scm3.org_1   | STARTUP_MSG:   args = []
scm3.org_1   | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
recon_1      | 2022-10-20 02:10:02,500 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 92 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-10-20 02:10:03,024 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=928115e6-57fc-4e60-abe7-d27615e20c89 reported by e4d9a0e3-266c-4558-944a-cafbea7b03e5{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1081094776367, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-10-20 02:10:03,028 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=904a7869-3351-4618-b9db-44e7403e0592 reported by e4d9a0e3-266c-4558-944a-cafbea7b03e5{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1081094776367, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-10-20 02:10:03,352 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=928115e6-57fc-4e60-abe7-d27615e20c89 reported by 4026c186-2529-49de-a2d8-dcba1039e356{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1083227860558, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-10-20 02:10:03,353 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=d523f193-8112-4e25-a36e-bc1bbcbc6578. Trying to get from SCM.
recon_1      | 2022-10-20 02:10:03,359 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: d523f193-8112-4e25-a36e-bc1bbcbc6578, Nodes: 4026c186-2529-49de-a2d8-dcba1039e356{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-10-20T02:09:52.579Z[UTC]] to Recon pipeline metadata.
recon_1      | 2022-10-20 02:10:03,360 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: d523f193-8112-4e25-a36e-bc1bbcbc6578, Nodes: 4026c186-2529-49de-a2d8-dcba1039e356{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-10-20T02:09:52.579Z[UTC]].
recon_1      | 2022-10-20 02:10:03,360 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/ONE PipelineID=d523f193-8112-4e25-a36e-bc1bbcbc6578 reported by 4026c186-2529-49de-a2d8-dcba1039e356{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1083227860558, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-10-20 02:10:03,360 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: d523f193-8112-4e25-a36e-bc1bbcbc6578, Nodes: 4026c186-2529-49de-a2d8-dcba1039e356{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:4026c186-2529-49de-a2d8-dcba1039e356, CreationTimestamp2022-10-20T02:09:52.579Z[UTC]] moved to OPEN state
recon_1      | 2022-10-20 02:10:03,360 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=904a7869-3351-4618-b9db-44e7403e0592 reported by 4026c186-2529-49de-a2d8-dcba1039e356{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1083227860558, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-10-20 02:10:04,501 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 93 failover attempts. Trying to failover immediately.
recon_1      | 2022-10-20 02:10:04,502 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 94 failover attempts. Trying to failover immediately.
recon_1      | 2022-10-20 02:10:04,503 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 95 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-10-20 02:10:05,666 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=928115e6-57fc-4e60-abe7-d27615e20c89 reported by 4026c186-2529-49de-a2d8-dcba1039e356{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1083227860558, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm2.org_1   | Sleeping for 5 seconds
scm2.org_1   | Waiting for the service scm1.org:9894
scm2.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm2.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm2.org_1   | 2022-10-20 02:08:09,249 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm2.org_1   | /************************************************************
scm2.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm2.org_1   | STARTUP_MSG:   host = scm2.org/172.25.0.117
scm2.org_1   | STARTUP_MSG:   args = [--bootstrap]
scm2.org_1   | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
scm1.org_1   | 2022-10-20 02:08:07,566 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
scm1.org_1   | 2022-10-20 02:08:07,566 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
scm1.org_1   | 2022-10-20 02:08:07,582 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
scm1.org_1   | 2022-10-20 02:08:07,589 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
scm1.org_1   | 2022-10-20 02:08:07,591 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
scm1.org_1   | 2022-10-20 02:08:07,655 [pool-2-thread-1] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
scm1.org_1   | 2022-10-20 02:08:07,828 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm1.org_1   | 2022-10-20 02:08:07,829 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
scm1.org_1   | 2022-10-20 02:08:07,829 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
scm1.org_1   | 2022-10-20 02:08:07,829 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
scm1.org_1   | 2022-10-20 02:08:07,830 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
scm1.org_1   | 2022-10-20 02:08:07,830 [193991a4-d526-4123-97ec-0cf0bd3049b7-impl-thread1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/scm-ha/959c5f9a-2485-4f2a-8075-3da9fe7c4057 does not exist. Creating ...
scm1.org_1   | 2022-10-20 02:08:07,834 [193991a4-d526-4123-97ec-0cf0bd3049b7-impl-thread1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/959c5f9a-2485-4f2a-8075-3da9fe7c4057/in_use.lock acquired by nodename 92@scm1.org
scm1.org_1   | 2022-10-20 02:08:07,838 [193991a4-d526-4123-97ec-0cf0bd3049b7-impl-thread1] INFO storage.RaftStorage: Storage directory /data/metadata/scm-ha/959c5f9a-2485-4f2a-8075-3da9fe7c4057 has been successfully formatted.
scm1.org_1   | 2022-10-20 02:08:07,843 [193991a4-d526-4123-97ec-0cf0bd3049b7-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
scm1.org_1   | 2022-10-20 02:08:07,849 [193991a4-d526-4123-97ec-0cf0bd3049b7-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
scm1.org_1   | 2022-10-20 02:08:07,850 [193991a4-d526-4123-97ec-0cf0bd3049b7-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2022-10-20 02:08:07,851 [193991a4-d526-4123-97ec-0cf0bd3049b7-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
scm1.org_1   | 2022-10-20 02:08:07,856 [193991a4-d526-4123-97ec-0cf0bd3049b7-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
scm1.org_1   | 2022-10-20 02:08:07,858 [193991a4-d526-4123-97ec-0cf0bd3049b7-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm1.org_1   | 2022-10-20 02:08:07,862 [193991a4-d526-4123-97ec-0cf0bd3049b7-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
scm1.org_1   | 2022-10-20 02:08:07,862 [193991a4-d526-4123-97ec-0cf0bd3049b7-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
scm1.org_1   | 2022-10-20 02:08:07,867 [193991a4-d526-4123-97ec-0cf0bd3049b7-impl-thread1] INFO segmented.SegmentedRaftLogWorker: new 193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/959c5f9a-2485-4f2a-8075-3da9fe7c4057
scm1.org_1   | 2022-10-20 02:08:07,867 [193991a4-d526-4123-97ec-0cf0bd3049b7-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
scm1.org_1   | 2022-10-20 02:08:07,868 [193991a4-d526-4123-97ec-0cf0bd3049b7-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
scm1.org_1   | 2022-10-20 02:08:07,869 [193991a4-d526-4123-97ec-0cf0bd3049b7-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm1.org_1   | 2022-10-20 02:08:07,869 [193991a4-d526-4123-97ec-0cf0bd3049b7-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
scm1.org_1   | 2022-10-20 02:08:07,870 [193991a4-d526-4123-97ec-0cf0bd3049b7-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
scm1.org_1   | 2022-10-20 02:08:07,871 [193991a4-d526-4123-97ec-0cf0bd3049b7-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
scm1.org_1   | 2022-10-20 02:08:07,871 [193991a4-d526-4123-97ec-0cf0bd3049b7-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
scm1.org_1   | 2022-10-20 02:08:07,872 [193991a4-d526-4123-97ec-0cf0bd3049b7-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
scm1.org_1   | 2022-10-20 02:08:07,880 [193991a4-d526-4123-97ec-0cf0bd3049b7-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
scm1.org_1   | 2022-10-20 02:08:07,880 [193991a4-d526-4123-97ec-0cf0bd3049b7-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
scm1.org_1   | 2022-10-20 02:08:07,881 [193991a4-d526-4123-97ec-0cf0bd3049b7-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
scm1.org_1   | 2022-10-20 02:08:07,881 [193991a4-d526-4123-97ec-0cf0bd3049b7-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
scm1.org_1   | 2022-10-20 02:08:07,887 [193991a4-d526-4123-97ec-0cf0bd3049b7-impl-thread1] INFO segmented.SegmentedRaftLogWorker: 193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
scm1.org_1   | 2022-10-20 02:08:07,887 [193991a4-d526-4123-97ec-0cf0bd3049b7-impl-thread1] INFO segmented.SegmentedRaftLogWorker: 193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
scm1.org_1   | 2022-10-20 02:08:07,892 [193991a4-d526-4123-97ec-0cf0bd3049b7-impl-thread1] INFO server.RaftServer$Division: 193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057: start as a follower, conf=-1: peers:[193991a4-d526-4123-97ec-0cf0bd3049b7|rpc:scm1.org:9894|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
scm1.org_1   | 2022-10-20 02:08:07,892 [193991a4-d526-4123-97ec-0cf0bd3049b7-impl-thread1] INFO server.RaftServer$Division: 193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057: changes role from      null to FOLLOWER at term 0 for startAsFollower
scm1.org_1   | 2022-10-20 02:08:07,893 [193991a4-d526-4123-97ec-0cf0bd3049b7-impl-thread1] INFO impl.RoleInfo: 193991a4-d526-4123-97ec-0cf0bd3049b7: start 193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-FollowerState
scm1.org_1   | 2022-10-20 02:08:07,895 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
scm1.org_1   | 2022-10-20 02:08:07,896 [193991a4-d526-4123-97ec-0cf0bd3049b7-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-3DA9FE7C4057,id=193991a4-d526-4123-97ec-0cf0bd3049b7
scm3.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.2.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.4.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.4.0.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.4.0.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.4.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.10.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.4.0.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.32.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.4.5.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.4.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.4.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.4.0.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.4.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.4.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.3.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.4.0.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar
scm3.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/ff6d15f5df822a5a3c776320b032fad3dd380f95 ; compiled by 'runner' on 2022-10-20T01:41Z
scm3.org_1   | STARTUP_MSG:   java = 11.0.14.1
scm3.org_1   | ************************************************************/
scm3.org_1   | 2022-10-20 02:08:52,926 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm3.org_1   | 2022-10-20 02:08:52,995 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm3.org_1   | 2022-10-20 02:08:53,044 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm3.org_1   | 2022-10-20 02:08:53,058 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm3.org_1   | 2022-10-20 02:08:53,101 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm3, RPC Address: scm3.org:9894 and Ratis port: 9894
scm3.org_1   | 2022-10-20 02:08:53,101 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm3: scm3.org
scm3.org_1   | 2022-10-20 02:08:53,540 [main] INFO client.SCMCertificateClient: Loading certificate from location:/data/metadata/scm/sub-ca/certs.
scm3.org_1   | 2022-10-20 02:08:53,629 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/CA-1.crt.
scm3.org_1   | 2022-10-20 02:08:53,632 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/certificate.crt.
scm3.org_1   | 2022-10-20 02:08:53,634 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/1047064298409.crt.
scm3.org_1   | 2022-10-20 02:08:53,716 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
scm3.org_1   | 2022-10-20 02:08:53,716 [main] INFO server.StorageContainerManager: SCM login successful.
scm3.org_1   | 2022-10-20 02:08:53,739 [main] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm3.org_1   | 2022-10-20 02:08:53,881 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm3.org_1   | 2022-10-20 02:08:54,110 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar!/network-topology-default.xml]
scm3.org_1   | 2022-10-20 02:08:54,110 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
scm3.org_1   | 2022-10-20 02:08:54,203 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
scm3.org_1   | 2022-10-20 02:08:54,277 [main] INFO ha.SCMRatisServerImpl: starting Raft server for scm:ff795c6b-74b4-4669-bf8f-984925e59fb3
scm3.org_1   | 2022-10-20 02:08:54,419 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
scm3.org_1   | 2022-10-20 02:08:54,527 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
scm3.org_1   | 2022-10-20 02:08:54,529 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9894 (fallback to raft.grpc.server.port)
scm3.org_1   | 2022-10-20 02:08:54,529 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.host = null (fallback to raft.grpc.server.host)
scm3.org_1   | 2022-10-20 02:08:54,530 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9894 (fallback to raft.grpc.server.port)
scm3.org_1   | 2022-10-20 02:08:54,531 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.host = null (default)
scm3.org_1   | 2022-10-20 02:08:54,531 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm3.org_1   | 2022-10-20 02:08:54,532 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
scm3.org_1   | 2022-10-20 02:08:54,534 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm3.org_1   | 2022-10-20 02:08:54,541 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
scm3.org_1   | 2022-10-20 02:08:54,541 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm3.org_1   | 2022-10-20 02:08:54,560 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
scm3.org_1   | 2022-10-20 02:08:54,563 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
scm3.org_1   | 2022-10-20 02:08:54,564 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
scm3.org_1   | 2022-10-20 02:08:55,424 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
scm3.org_1   | 2022-10-20 02:08:55,426 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
scm3.org_1   | 2022-10-20 02:08:55,426 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
scm3.org_1   | 2022-10-20 02:08:55,427 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm3.org_1   | 2022-10-20 02:08:55,427 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm3.org_1   | 2022-10-20 02:08:55,430 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm3.org_1   | 2022-10-20 02:08:55,447 [main] INFO server.RaftServer: ff795c6b-74b4-4669-bf8f-984925e59fb3: addNew group-3DA9FE7C4057:[] returns group-3DA9FE7C4057:java.util.concurrent.CompletableFuture@6544899b[Not completed]
scm3.org_1   | 2022-10-20 02:08:55,477 [pool-16-thread-1] INFO server.RaftServer$Division: ff795c6b-74b4-4669-bf8f-984925e59fb3: new RaftServerImpl for group-3DA9FE7C4057:[] with SCMStateMachine:uninitialized
scm3.org_1   | 2022-10-20 02:08:55,480 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
scm3.org_1   | 2022-10-20 02:08:55,481 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
scm3.org_1   | 2022-10-20 02:08:55,481 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
scm3.org_1   | 2022-10-20 02:08:55,481 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm3.org_1   | 2022-10-20 02:08:55,482 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm3.org_1   | 2022-10-20 02:08:55,482 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
scm3.org_1   | 2022-10-20 02:08:55,500 [pool-16-thread-1] INFO server.RaftServer$Division: ff795c6b-74b4-4669-bf8f-984925e59fb3@group-3DA9FE7C4057: ConfigurationManager, init=-1: peers:[]|listeners:[], old=null, confs=<EMPTY_MAP>
scm3.org_1   | 2022-10-20 02:08:55,500 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm3.org_1   | 2022-10-20 02:08:55,510 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
scm3.org_1   | 2022-10-20 02:08:55,511 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
scm3.org_1   | 2022-10-20 02:08:55,530 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
scm3.org_1   | 2022-10-20 02:08:55,534 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
scm3.org_1   | 2022-10-20 02:08:55,534 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
scm3.org_1   | 2022-10-20 02:08:55,683 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm3.org_1   | 2022-10-20 02:08:55,683 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
scm3.org_1   | 2022-10-20 02:08:55,684 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
scm3.org_1   | 2022-10-20 02:08:55,684 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
scm3.org_1   | 2022-10-20 02:08:55,685 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
scm3.org_1   | 2022-10-20 02:08:55,686 [main] INFO ha.SCMSnapshotProvider: Initializing SCM Snapshot Provider
scm3.org_1   | 2022-10-20 02:08:55,689 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
scm3.org_1   | 2022-10-20 02:08:55,689 [main] WARN ha.SCMHAUtils: SCM snapshot dir is not configured. Falling back to ozone.metadata.dirs config
scm3.org_1   | 2022-10-20 02:08:56,010 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
scm3.org_1   | 2022-10-20 02:08:56,152 [main] INFO reflections.Reflections: Reflections took 95 ms to scan 3 urls, producing 112 keys and 252 values 
scm3.org_1   | 2022-10-20 02:08:56,351 [main] INFO ha.SequenceIdGenerator: upgrade localId to 109611004723200000
scm3.org_1   | 2022-10-20 02:08:56,351 [main] INFO ha.SequenceIdGenerator: upgrade delTxnId to 0
scm3.org_1   | 2022-10-20 02:08:56,355 [main] INFO ha.SequenceIdGenerator: upgrade containerId to 0
scm3.org_1   | 2022-10-20 02:08:56,357 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
scm3.org_1   | 2022-10-20 02:08:56,503 [main] INFO node.SCMNodeManager: Entering startup safe mode.
scm3.org_1   | 2022-10-20 02:08:56,539 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
scm3.org_1   | 2022-10-20 02:08:56,540 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
scm3.org_1   | 2022-10-20 02:08:56,556 [main] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
scm1.org_1   | 2022-10-20 02:08:07,901 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
scm1.org_1   | 2022-10-20 02:08:07,903 [193991a4-d526-4123-97ec-0cf0bd3049b7-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
scm1.org_1   | 2022-10-20 02:08:07,903 [193991a4-d526-4123-97ec-0cf0bd3049b7-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
scm1.org_1   | 2022-10-20 02:08:07,903 [193991a4-d526-4123-97ec-0cf0bd3049b7-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
scm1.org_1   | 2022-10-20 02:08:07,904 [193991a4-d526-4123-97ec-0cf0bd3049b7-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
scm1.org_1   | 2022-10-20 02:08:07,905 [main] INFO server.RaftServer: 193991a4-d526-4123-97ec-0cf0bd3049b7: start RPC server
scm1.org_1   | 2022-10-20 02:08:07,936 [main] INFO server.GrpcService: 193991a4-d526-4123-97ec-0cf0bd3049b7: GrpcService started, listening on 9894
scm1.org_1   | 2022-10-20 02:08:07,938 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-193991a4-d526-4123-97ec-0cf0bd3049b7: Started
scm1.org_1   | 2022-10-20 02:08:13,042 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-FollowerState] INFO impl.FollowerState: 193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5149056759ns, electionTimeout:5140ms
scm1.org_1   | 2022-10-20 02:08:13,043 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-FollowerState] INFO impl.RoleInfo: 193991a4-d526-4123-97ec-0cf0bd3049b7: shutdown 193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-FollowerState
scm1.org_1   | 2022-10-20 02:08:13,043 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-FollowerState] INFO server.RaftServer$Division: 193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
scm1.org_1   | 2022-10-20 02:08:13,046 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
scm1.org_1   | 2022-10-20 02:08:13,046 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-FollowerState] INFO impl.RoleInfo: 193991a4-d526-4123-97ec-0cf0bd3049b7: start 193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-LeaderElection1
scm1.org_1   | 2022-10-20 02:08:13,049 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-LeaderElection1] INFO impl.LeaderElection: 193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: peers:[193991a4-d526-4123-97ec-0cf0bd3049b7|rpc:scm1.org:9894|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
scm1.org_1   | 2022-10-20 02:08:13,050 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-LeaderElection1] INFO impl.LeaderElection: 193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-LeaderElection1 ELECTION round 0: result PASSED (term=1)
scm1.org_1   | 2022-10-20 02:08:13,050 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-LeaderElection1] INFO impl.RoleInfo: 193991a4-d526-4123-97ec-0cf0bd3049b7: shutdown 193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-LeaderElection1
scm1.org_1   | 2022-10-20 02:08:13,053 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-LeaderElection1] INFO server.RaftServer$Division: 193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
scm1.org_1   | 2022-10-20 02:08:13,054 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-LeaderElection1] INFO server.RaftServer$Division: 193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057: change Leader from null to 193991a4-d526-4123-97ec-0cf0bd3049b7 at term 1 for becomeLeader, leader elected after 5471ms
scm1.org_1   | 2022-10-20 02:08:13,058 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
scm1.org_1   | 2022-10-20 02:08:13,061 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
scm1.org_1   | 2022-10-20 02:08:13,062 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
scm1.org_1   | 2022-10-20 02:08:13,066 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
scm1.org_1   | 2022-10-20 02:08:13,066 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
scm1.org_1   | 2022-10-20 02:08:13,067 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
scm1.org_1   | 2022-10-20 02:08:13,072 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
scm1.org_1   | 2022-10-20 02:08:13,073 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
scm1.org_1   | 2022-10-20 02:08:13,074 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-LeaderElection1] INFO impl.RoleInfo: 193991a4-d526-4123-97ec-0cf0bd3049b7: start 193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-LeaderStateImpl
scm1.org_1   | 2022-10-20 02:08:13,095 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-SegmentedRaftLogWorker: Starting segment from index:0
scm1.org_1   | 2022-10-20 02:08:13,126 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-LeaderElection1] INFO server.RaftServer$Division: 193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057: set configuration 0: peers:[193991a4-d526-4123-97ec-0cf0bd3049b7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
scm1.org_1   | 2022-10-20 02:08:13,159 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/959c5f9a-2485-4f2a-8075-3da9fe7c4057/current/log_inprogress_0
scm1.org_1   | 2022-10-20 02:08:13,939 [main] INFO server.RaftServer: 193991a4-d526-4123-97ec-0cf0bd3049b7: close
scm1.org_1   | 2022-10-20 02:08:13,941 [main] INFO server.GrpcService: 193991a4-d526-4123-97ec-0cf0bd3049b7: shutdown server GrpcServerProtocolService now
scm1.org_1   | 2022-10-20 02:08:13,941 [193991a4-d526-4123-97ec-0cf0bd3049b7-impl-thread1] INFO server.RaftServer$Division: 193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057: shutdown
scm1.org_1   | 2022-10-20 02:08:13,942 [193991a4-d526-4123-97ec-0cf0bd3049b7-impl-thread1] INFO util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-3DA9FE7C4057,id=193991a4-d526-4123-97ec-0cf0bd3049b7
scm1.org_1   | 2022-10-20 02:08:13,942 [193991a4-d526-4123-97ec-0cf0bd3049b7-impl-thread1] INFO impl.RoleInfo: 193991a4-d526-4123-97ec-0cf0bd3049b7: shutdown 193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-LeaderStateImpl
scm1.org_1   | 2022-10-20 02:08:13,946 [193991a4-d526-4123-97ec-0cf0bd3049b7-impl-thread1] INFO impl.PendingRequests: 193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-PendingRequests: sendNotLeaderResponses
scm1.org_1   | 2022-10-20 02:08:13,954 [main] INFO server.GrpcService: 193991a4-d526-4123-97ec-0cf0bd3049b7: shutdown server GrpcServerProtocolService successfully
scm2.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.2.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.4.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.4.0.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.4.0.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.4.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.10.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.4.0.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.32.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.4.5.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.4.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.4.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.4.0.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.4.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.4.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.3.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.4.0.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar
scm2.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/ff6d15f5df822a5a3c776320b032fad3dd380f95 ; compiled by 'runner' on 2022-10-20T01:41Z
scm2.org_1   | STARTUP_MSG:   java = 11.0.14.1
scm2.org_1   | ************************************************************/
scm2.org_1   | 2022-10-20 02:08:09,255 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm2.org_1   | 2022-10-20 02:08:09,306 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm2.org_1   | 2022-10-20 02:08:09,327 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm2.org_1   | 2022-10-20 02:08:09,327 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm2.org_1   | 2022-10-20 02:08:09,379 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm2, RPC Address: scm2.org:9894 and Ratis port: 9894
scm2.org_1   | 2022-10-20 02:08:09,380 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm2: scm2.org
scm2.org_1   | 2022-10-20 02:08:09,520 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
scm2.org_1   | 2022-10-20 02:08:09,520 [main] INFO server.StorageContainerManager: SCM login successful.
scm2.org_1   | 2022-10-20 02:08:09,573 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 2 nodes: [nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
scm2.org_1   | 2022-10-20 02:08:11,809 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm3.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863 after 1 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2022-10-20 02:08:13,810 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm1.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863 after 2 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2022-10-20 02:08:15,812 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm3.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863 after 3 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2022-10-20 02:08:17,813 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm1.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863 after 4 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2022-10-20 02:08:19,821 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm3.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863 after 5 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2022-10-20 02:08:21,997 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:193991a4-d526-4123-97ec-0cf0bd3049b7 is not the leader. Could not determine the leader node.
scm2.org_1   | 	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
scm2.org_1   | 	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
scm2.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:109)
scm2.org_1   | 	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:14202)
scm2.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465)
scm2.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578)
scm2.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)
scm2.org_1   | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
scm2.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)
scm2.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
scm2.org_1   | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm2.org_1   | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm2.org_1   | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
scm2.org_1   | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
scm2.org_1   | , while invoking $Proxy15.send over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863 after 6 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2022-10-20 02:08:23,999 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm3.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863 after 7 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2022-10-20 02:08:26,123 [main] INFO ha.HASecurityUtils: Initializing secure StorageContainerManager.
scm2.org_1   | 2022-10-20 02:08:26,599 [main] ERROR client.SCMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
scm2.org_1   | 2022-10-20 02:08:26,599 [main] INFO client.SCMCertificateClient: Certificate client init case: 0
scm2.org_1   | 2022-10-20 02:08:26,600 [main] INFO client.SCMCertificateClient: Creating keypair for client as keypair and certificate not found.
scm2.org_1   | 2022-10-20 02:08:27,553 [main] INFO ha.HASecurityUtils: Init response: GETCERT
scm2.org_1   | 2022-10-20 02:08:27,719 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.117,host:scm2.org
scm2.org_1   | 2022-10-20 02:08:27,730 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
scm2.org_1   | 2022-10-20 02:08:27,743 [main] INFO ha.HASecurityUtils: Creating csr for SCM->hostName:scm2.org,scmId:473d8c0f-fcdd-4210-80f8-a6eef5407d4b,clusterId:CID-959c5f9a-2485-4f2a-8075-3da9fe7c4057,subject:scm-sub@scm2.org
scm2.org_1   | 2022-10-20 02:08:29,483 [main] INFO ha.HASecurityUtils: Successfully stored SCM signed certificate.
scm2.org_1   | 2022-10-20 02:08:29,503 [main] INFO server.StorageContainerManager: SCM BootStrap  is successful for ClusterID CID-959c5f9a-2485-4f2a-8075-3da9fe7c4057, SCMID 473d8c0f-fcdd-4210-80f8-a6eef5407d4b
scm2.org_1   | 2022-10-20 02:08:29,503 [main] INFO server.StorageContainerManager: Primary SCM Node ID 193991a4-d526-4123-97ec-0cf0bd3049b7
scm2.org_1   | 2022-10-20 02:08:29,540 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
scm2.org_1   | /************************************************************
scm2.org_1   | SHUTDOWN_MSG: Shutting down StorageContainerManager at scm2.org/172.25.0.117
scm2.org_1   | ************************************************************/
scm2.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm2.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm2.org_1   | 2022-10-20 02:08:33,066 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm2.org_1   | /************************************************************
scm2.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm2.org_1   | STARTUP_MSG:   host = scm2.org/172.25.0.117
scm2.org_1   | STARTUP_MSG:   args = []
scm2.org_1   | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
recon_1      | 2022-10-20 02:10:05,667 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 928115e6-57fc-4e60-abe7-d27615e20c89, Nodes: 922d5e53-2e0d-4e01-adf2-129a3cebef39{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}4026c186-2529-49de-a2d8-dcba1039e356{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}e4d9a0e3-266c-4558-944a-cafbea7b03e5{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:4026c186-2529-49de-a2d8-dcba1039e356, CreationTimestamp2022-10-20T02:09:52.497Z[UTC]] moved to OPEN state
recon_1      | 2022-10-20 02:10:05,668 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=904a7869-3351-4618-b9db-44e7403e0592 reported by 4026c186-2529-49de-a2d8-dcba1039e356{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1083227860558, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-10-20 02:10:06,504 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 96 failover attempts. Trying to failover immediately.
recon_1      | 2022-10-20 02:10:06,505 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 97 failover attempts. Trying to failover immediately.
recon_1      | 2022-10-20 02:10:06,506 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 98 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-10-20 02:10:08,491 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=904a7869-3351-4618-b9db-44e7403e0592 reported by 4026c186-2529-49de-a2d8-dcba1039e356{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1083227860558, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-10-20 02:10:08,507 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 99 failover attempts. Trying to failover immediately.
recon_1      | 2022-10-20 02:10:08,508 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 100 failover attempts. Trying to failover immediately.
recon_1      | 2022-10-20 02:10:08,508 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 101 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-10-20 02:10:10,509 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 102 failover attempts. Trying to failover immediately.
recon_1      | 2022-10-20 02:10:10,510 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 103 failover attempts. Trying to failover immediately.
recon_1      | 2022-10-20 02:10:10,510 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 104 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-10-20 02:10:17,707 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om1 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:248)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:235)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:228)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:175)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:147)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 105 failover attempts. Trying to failover immediately.
recon_1      | 2022-10-20 02:10:18,401 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:248)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:235)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:228)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:175)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:147)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 106 failover attempts. Trying to failover immediately.
recon_1      | 2022-10-20 02:10:19,165 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om3 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:248)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:235)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:228)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:175)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:147)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 107 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-10-20 02:10:21,168 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om1 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:248)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:235)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:228)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:175)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:147)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 108 failover attempts. Trying to failover immediately.
recon_1      | 2022-10-20 02:10:21,171 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
scm1.org_1   | 2022-10-20 02:08:13,954 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-StateMachineUpdater] INFO impl.StateMachineUpdater: 193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-StateMachineUpdater: Took a snapshot at index 0
scm1.org_1   | 2022-10-20 02:08:13,954 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-StateMachineUpdater] INFO impl.StateMachineUpdater: 193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
scm1.org_1   | 2022-10-20 02:08:13,957 [193991a4-d526-4123-97ec-0cf0bd3049b7-impl-thread1] INFO impl.StateMachineUpdater: 193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-StateMachineUpdater: set stopIndex = 0
scm1.org_1   | 2022-10-20 02:08:13,960 [193991a4-d526-4123-97ec-0cf0bd3049b7-impl-thread1] INFO server.RaftServer$Division: 193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057: closes. applyIndex: 0
scm1.org_1   | 2022-10-20 02:08:13,961 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
scm1.org_1   | 2022-10-20 02:08:13,962 [193991a4-d526-4123-97ec-0cf0bd3049b7-impl-thread1] INFO segmented.SegmentedRaftLogWorker: 193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-SegmentedRaftLogWorker close()
scm1.org_1   | 2022-10-20 02:08:13,963 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-193991a4-d526-4123-97ec-0cf0bd3049b7: Stopped
scm1.org_1   | 2022-10-20 02:08:13,963 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm1.org_1   | 2022-10-20 02:08:13,965 [main] INFO server.StorageContainerManager: SCM initialization succeeded. Current cluster id for sd=/data/metadata/scm; cid=CID-959c5f9a-2485-4f2a-8075-3da9fe7c4057; layoutVersion=4; scmId=193991a4-d526-4123-97ec-0cf0bd3049b7
scm1.org_1   | 2022-10-20 02:08:13,970 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
scm1.org_1   | /************************************************************
scm1.org_1   | SHUTDOWN_MSG: Shutting down StorageContainerManager at scm1.org/172.25.0.116
scm1.org_1   | ************************************************************/
scm1.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm1.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm1.org_1   | 2022-10-20 02:08:15,552 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm1.org_1   | /************************************************************
scm1.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm1.org_1   | STARTUP_MSG:   host = scm1.org/172.25.0.116
scm1.org_1   | STARTUP_MSG:   args = []
scm1.org_1   | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
scm3.org_1   | 2022-10-20 02:08:56,618 [main] INFO algorithms.LeaderChoosePolicyFactory: Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
scm3.org_1   | 2022-10-20 02:08:56,618 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
scm3.org_1   | 2022-10-20 02:08:56,634 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineCreator.
scm3.org_1   | 2022-10-20 02:08:56,635 [main] INFO pipeline.BackgroundPipelineCreator: Starting RatisPipelineUtilsThread.
scm3.org_1   | 2022-10-20 02:08:56,637 [main] INFO BackgroundPipelineScrubber: Starting BackgroundPipelineScrubber Service.
scm3.org_1   | 2022-10-20 02:08:56,655 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineScrubber.
scm3.org_1   | 2022-10-20 02:08:56,667 [main] INFO ExpiredContainerReplicaOpScrubber: Starting ExpiredContainerReplicaOpScrubber Service.
scm3.org_1   | 2022-10-20 02:08:56,672 [main] INFO ha.SCMServiceManager: Registering service ExpiredContainerReplicaOpScrubber.
scm3.org_1   | 2022-10-20 02:08:56,777 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
scm3.org_1   | 2022-10-20 02:08:56,805 [main] INFO ha.SCMServiceManager: Registering service SCMBlockDeletingService.
scm3.org_1   | 2022-10-20 02:08:56,914 [main] INFO replication.ReplicationManager: Starting Replication Monitor Thread.
scm3.org_1   | 2022-10-20 02:08:56,949 [main] INFO ha.SCMServiceManager: Registering service ReplicationManager.
scm3.org_1   | 2022-10-20 02:08:56,960 [main] INFO safemode.ContainerSafeModeRule: containers with one replica threshold count 0
scm3.org_1   | 2022-10-20 02:08:56,964 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-10-20 02:08:56,960 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm3.org_1   | 2022-10-20 02:08:56,971 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm3.org_1   | 2022-10-20 02:08:57,018 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
scm3.org_1   | 2022-10-20 02:08:57,094 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 200, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm3.org_1   | 2022-10-20 02:08:57,164 [Socket Reader #1 for port 9961] INFO ipc.Server: Starting Socket Reader #1 for port 9961
scm3.org_1   | 2022-10-20 02:08:58,472 [Listener at 0.0.0.0/9961] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm3.org_1   | 2022-10-20 02:08:58,488 [Listener at 0.0.0.0/9961] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm3.org_1   | 2022-10-20 02:08:58,498 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
scm3.org_1   | 2022-10-20 02:08:58,561 [Listener at 0.0.0.0/9861] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm3.org_1   | 2022-10-20 02:08:58,572 [Listener at 0.0.0.0/9861] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm3.org_1   | 2022-10-20 02:08:58,576 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
scm3.org_1   | 2022-10-20 02:08:58,642 [Listener at 0.0.0.0/9863] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm3.org_1   | 2022-10-20 02:08:58,662 [Listener at 0.0.0.0/9863] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm3.org_1   | 2022-10-20 02:08:58,673 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
scm3.org_1   | 2022-10-20 02:08:58,781 [Listener at 0.0.0.0/9860] INFO ha.SCMServiceManager: Registering service ContainerBalancer.
scm3.org_1   | 2022-10-20 02:08:58,782 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: 
scm3.org_1   | Container Balancer status:
scm3.org_1   | Key                            Value
scm3.org_1   | Running                        true
scm3.org_1   | Container Balancer Configuration values:
scm3.org_1   | Key                                                Value
scm3.org_1   | Threshold                                          10
scm3.org_1   | Max Datanodes to Involve per Iteration(percent)    20
scm3.org_1   | Max Size to Move per Iteration                     500GB
scm3.org_1   | Max Size Entering Target per Iteration             26GB
scm3.org_1   | Max Size Leaving Source per Iteration              26GB
scm3.org_1   | 
scm3.org_1   | 2022-10-20 02:08:58,782 [Listener at 0.0.0.0/9860] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm3.org_1   | 2022-10-20 02:08:58,783 [Listener at 0.0.0.0/9860] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
scm3.org_1   | 2022-10-20 02:08:58,795 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
scm3.org_1   | 2022-10-20 02:08:58,798 [Listener at 0.0.0.0/9860] INFO ha.SCMRatisServerImpl: starting ratis server 0.0.0.0:9894
scm3.org_1   | 2022-10-20 02:08:58,799 [ff795c6b-74b4-4669-bf8f-984925e59fb3-impl-thread1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/scm-ha/959c5f9a-2485-4f2a-8075-3da9fe7c4057 does not exist. Creating ...
scm3.org_1   | 2022-10-20 02:08:58,805 [ff795c6b-74b4-4669-bf8f-984925e59fb3-impl-thread1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/959c5f9a-2485-4f2a-8075-3da9fe7c4057/in_use.lock acquired by nodename 7@scm3.org
scm3.org_1   | 2022-10-20 02:08:58,828 [ff795c6b-74b4-4669-bf8f-984925e59fb3-impl-thread1] INFO storage.RaftStorage: Storage directory /data/metadata/scm-ha/959c5f9a-2485-4f2a-8075-3da9fe7c4057 has been successfully formatted.
scm3.org_1   | 2022-10-20 02:08:58,830 [ff795c6b-74b4-4669-bf8f-984925e59fb3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
scm3.org_1   | 2022-10-20 02:08:58,910 [ff795c6b-74b4-4669-bf8f-984925e59fb3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
scm3.org_1   | 2022-10-20 02:08:58,910 [ff795c6b-74b4-4669-bf8f-984925e59fb3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm3.org_1   | 2022-10-20 02:08:58,937 [ff795c6b-74b4-4669-bf8f-984925e59fb3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
scm3.org_1   | 2022-10-20 02:08:58,938 [ff795c6b-74b4-4669-bf8f-984925e59fb3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
scm3.org_1   | 2022-10-20 02:08:58,948 [ff795c6b-74b4-4669-bf8f-984925e59fb3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm3.org_1   | 2022-10-20 02:08:58,967 [ff795c6b-74b4-4669-bf8f-984925e59fb3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
scm3.org_1   | 2022-10-20 02:08:58,967 [ff795c6b-74b4-4669-bf8f-984925e59fb3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
scm2.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.2.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.4.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.4.0.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.4.0.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.4.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.10.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.4.0.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.32.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.4.5.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.4.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.4.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.4.0.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.4.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.4.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.3.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.4.0.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar
scm2.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/ff6d15f5df822a5a3c776320b032fad3dd380f95 ; compiled by 'runner' on 2022-10-20T01:41Z
scm2.org_1   | STARTUP_MSG:   java = 11.0.14.1
scm2.org_1   | ************************************************************/
scm2.org_1   | 2022-10-20 02:08:33,087 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm2.org_1   | 2022-10-20 02:08:33,215 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm2.org_1   | 2022-10-20 02:08:33,286 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm2.org_1   | 2022-10-20 02:08:33,317 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm2.org_1   | 2022-10-20 02:08:33,427 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm2, RPC Address: scm2.org:9894 and Ratis port: 9894
scm2.org_1   | 2022-10-20 02:08:33,429 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm2: scm2.org
scm2.org_1   | 2022-10-20 02:08:34,652 [main] INFO client.SCMCertificateClient: Loading certificate from location:/data/metadata/scm/sub-ca/certs.
scm2.org_1   | 2022-10-20 02:08:35,092 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/CA-1.crt.
scm2.org_1   | 2022-10-20 02:08:35,095 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/1024933079495.crt.
scm2.org_1   | 2022-10-20 02:08:35,107 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/certificate.crt.
scm2.org_1   | 2022-10-20 02:08:35,379 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
scm2.org_1   | 2022-10-20 02:08:35,379 [main] INFO server.StorageContainerManager: SCM login successful.
scm2.org_1   | 2022-10-20 02:08:35,470 [main] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm2.org_1   | 2022-10-20 02:08:35,962 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm2.org_1   | 2022-10-20 02:08:36,380 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar!/network-topology-default.xml]
scm2.org_1   | 2022-10-20 02:08:36,385 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
scm2.org_1   | 2022-10-20 02:08:36,621 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
scm2.org_1   | 2022-10-20 02:08:36,687 [main] INFO ha.SCMRatisServerImpl: starting Raft server for scm:473d8c0f-fcdd-4210-80f8-a6eef5407d4b
scm2.org_1   | 2022-10-20 02:08:36,905 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
scm2.org_1   | 2022-10-20 02:08:37,076 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
scm2.org_1   | 2022-10-20 02:08:37,089 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9894 (fallback to raft.grpc.server.port)
scm2.org_1   | 2022-10-20 02:08:37,090 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.host = null (fallback to raft.grpc.server.host)
scm2.org_1   | 2022-10-20 02:08:37,090 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9894 (fallback to raft.grpc.server.port)
scm2.org_1   | 2022-10-20 02:08:37,090 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.host = null (default)
scm2.org_1   | 2022-10-20 02:08:37,090 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm2.org_1   | 2022-10-20 02:08:37,090 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
scm2.org_1   | 2022-10-20 02:08:37,092 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm2.org_1   | 2022-10-20 02:08:37,092 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
scm2.org_1   | 2022-10-20 02:08:37,092 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm2.org_1   | 2022-10-20 02:08:37,109 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
scm2.org_1   | 2022-10-20 02:08:37,120 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
scm2.org_1   | 2022-10-20 02:08:37,121 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
scm2.org_1   | 2022-10-20 02:08:38,381 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
scm2.org_1   | 2022-10-20 02:08:38,384 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
scm2.org_1   | 2022-10-20 02:08:38,385 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
scm2.org_1   | 2022-10-20 02:08:38,386 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm2.org_1   | 2022-10-20 02:08:38,386 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm2.org_1   | 2022-10-20 02:08:38,393 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm3.org_1   | 2022-10-20 02:08:58,971 [ff795c6b-74b4-4669-bf8f-984925e59fb3-impl-thread1] INFO segmented.SegmentedRaftLogWorker: new ff795c6b-74b4-4669-bf8f-984925e59fb3@group-3DA9FE7C4057-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/959c5f9a-2485-4f2a-8075-3da9fe7c4057
scm3.org_1   | 2022-10-20 02:08:58,971 [ff795c6b-74b4-4669-bf8f-984925e59fb3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
scm3.org_1   | 2022-10-20 02:08:58,971 [ff795c6b-74b4-4669-bf8f-984925e59fb3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
scm3.org_1   | 2022-10-20 02:08:58,972 [ff795c6b-74b4-4669-bf8f-984925e59fb3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm3.org_1   | 2022-10-20 02:08:58,972 [ff795c6b-74b4-4669-bf8f-984925e59fb3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
scm3.org_1   | 2022-10-20 02:08:58,973 [ff795c6b-74b4-4669-bf8f-984925e59fb3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
scm3.org_1   | 2022-10-20 02:08:58,973 [ff795c6b-74b4-4669-bf8f-984925e59fb3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
scm3.org_1   | 2022-10-20 02:08:58,973 [ff795c6b-74b4-4669-bf8f-984925e59fb3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
scm3.org_1   | 2022-10-20 02:08:58,973 [ff795c6b-74b4-4669-bf8f-984925e59fb3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
scm3.org_1   | 2022-10-20 02:08:58,989 [ff795c6b-74b4-4669-bf8f-984925e59fb3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
scm3.org_1   | 2022-10-20 02:08:58,989 [ff795c6b-74b4-4669-bf8f-984925e59fb3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
scm3.org_1   | 2022-10-20 02:08:58,996 [ff795c6b-74b4-4669-bf8f-984925e59fb3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
scm3.org_1   | 2022-10-20 02:08:58,996 [ff795c6b-74b4-4669-bf8f-984925e59fb3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
scm3.org_1   | 2022-10-20 02:08:59,003 [ff795c6b-74b4-4669-bf8f-984925e59fb3-impl-thread1] INFO segmented.SegmentedRaftLogWorker: ff795c6b-74b4-4669-bf8f-984925e59fb3@group-3DA9FE7C4057-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
scm3.org_1   | 2022-10-20 02:08:59,003 [ff795c6b-74b4-4669-bf8f-984925e59fb3-impl-thread1] INFO segmented.SegmentedRaftLogWorker: ff795c6b-74b4-4669-bf8f-984925e59fb3@group-3DA9FE7C4057-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
scm3.org_1   | 2022-10-20 02:08:59,010 [ff795c6b-74b4-4669-bf8f-984925e59fb3-impl-thread1] INFO server.RaftServer$Division: ff795c6b-74b4-4669-bf8f-984925e59fb3@group-3DA9FE7C4057: start with initializing state, conf=-1: peers:[]|listeners:[], old=null
scm3.org_1   | 2022-10-20 02:08:59,016 [ff795c6b-74b4-4669-bf8f-984925e59fb3-impl-thread1] INFO server.RaftServer$Division: ff795c6b-74b4-4669-bf8f-984925e59fb3@group-3DA9FE7C4057: changes role from      null to FOLLOWER at term 0 for startInitializing
scm3.org_1   | 2022-10-20 02:08:59,017 [ff795c6b-74b4-4669-bf8f-984925e59fb3-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-3DA9FE7C4057,id=ff795c6b-74b4-4669-bf8f-984925e59fb3
scm3.org_1   | 2022-10-20 02:08:59,018 [ff795c6b-74b4-4669-bf8f-984925e59fb3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
scm3.org_1   | 2022-10-20 02:08:59,018 [ff795c6b-74b4-4669-bf8f-984925e59fb3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
scm3.org_1   | 2022-10-20 02:08:59,019 [ff795c6b-74b4-4669-bf8f-984925e59fb3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
scm3.org_1   | 2022-10-20 02:08:59,020 [ff795c6b-74b4-4669-bf8f-984925e59fb3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
scm3.org_1   | 2022-10-20 02:08:59,057 [Listener at 0.0.0.0/9860] INFO server.RaftServer: ff795c6b-74b4-4669-bf8f-984925e59fb3: start RPC server
scm3.org_1   | 2022-10-20 02:08:59,161 [Listener at 0.0.0.0/9860] INFO server.GrpcService: ff795c6b-74b4-4669-bf8f-984925e59fb3: GrpcService started, listening on 9894
scm3.org_1   | 2022-10-20 02:08:59,175 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-ff795c6b-74b4-4669-bf8f-984925e59fb3: Started
scm3.org_1   | 2022-10-20 02:08:59,202 [Listener at 0.0.0.0/9860] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 2 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863]
scm3.org_1   | 2022-10-20 02:09:03,722 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: ff795c6b-74b4-4669-bf8f-984925e59fb3@group-3DA9FE7C4057: receive installSnapshot: 193991a4-d526-4123-97ec-0cf0bd3049b7->ff795c6b-74b4-4669-bf8f-984925e59fb3#0-t2,notify:(t:1, i:0)
scm3.org_1   | 2022-10-20 02:09:03,792 [grpc-default-executor-0] INFO ha.SCMStateMachine: leader changed, yet current SCM is still follower.
scm3.org_1   | 2022-10-20 02:09:03,795 [grpc-default-executor-0] INFO server.RaftServer$Division: ff795c6b-74b4-4669-bf8f-984925e59fb3@group-3DA9FE7C4057: change Leader from null to 193991a4-d526-4123-97ec-0cf0bd3049b7 at term 2 for installSnapshot, leader elected after 8262ms
scm3.org_1   | 2022-10-20 02:09:03,860 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: ff795c6b-74b4-4669-bf8f-984925e59fb3@group-3DA9FE7C4057: Received notification to install snapshot at index 0
scm3.org_1   | 2022-10-20 02:09:03,893 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: ff795c6b-74b4-4669-bf8f-984925e59fb3@group-3DA9FE7C4057: InstallSnapshot notification result: ALREADY_INSTALLED, current snapshot index: -1
scm3.org_1   | 2022-10-20 02:09:04,874 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: ff795c6b-74b4-4669-bf8f-984925e59fb3@group-3DA9FE7C4057: set new configuration index: 9
scm3.org_1   | configurationEntry {
scm3.org_1   |   peers {
scm3.org_1   |     id: "193991a4-d526-4123-97ec-0cf0bd3049b7"
scm3.org_1   |     address: "scm1.org:9894"
scm3.org_1   |     startupRole: FOLLOWER
scm3.org_1   |   }
scm3.org_1   |   peers {
scm3.org_1   |     id: "473d8c0f-fcdd-4210-80f8-a6eef5407d4b"
scm3.org_1   |     address: "scm2.org:9894"
scm3.org_1   |     startupRole: FOLLOWER
scm3.org_1   |   }
scm3.org_1   | }
scm3.org_1   |  from snapshot
scm3.org_1   | 2022-10-20 02:09:04,878 [grpc-default-executor-0] INFO server.RaftServer$Division: ff795c6b-74b4-4669-bf8f-984925e59fb3@group-3DA9FE7C4057: set configuration 9: peers:[193991a4-d526-4123-97ec-0cf0bd3049b7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, 473d8c0f-fcdd-4210-80f8-a6eef5407d4b|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
scm3.org_1   | 2022-10-20 02:09:04,967 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: ff795c6b-74b4-4669-bf8f-984925e59fb3@group-3DA9FE7C4057: reply installSnapshot: 193991a4-d526-4123-97ec-0cf0bd3049b7<-ff795c6b-74b4-4669-bf8f-984925e59fb3#0:OK-t0,ALREADY_INSTALLED
scm3.org_1   | 2022-10-20 02:09:05,069 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: ff795c6b-74b4-4669-bf8f-984925e59fb3: Completed INSTALL_SNAPSHOT, lastRequest: 193991a4-d526-4123-97ec-0cf0bd3049b7->ff795c6b-74b4-4669-bf8f-984925e59fb3#0-t2,notify:(t:1, i:0)
scm3.org_1   | 2022-10-20 02:09:05,369 [ff795c6b-74b4-4669-bf8f-984925e59fb3-server-thread1] INFO impl.RoleInfo: ff795c6b-74b4-4669-bf8f-984925e59fb3: start ff795c6b-74b4-4669-bf8f-984925e59fb3@group-3DA9FE7C4057-FollowerState
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:248)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:235)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:228)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:175)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:147)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 109 failover attempts. Trying to failover immediately.
recon_1      | 2022-10-20 02:10:21,178 [pool-29-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om3 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:248)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:235)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:228)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:175)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:147)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 110 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-10-20 02:10:23,750 [pool-29-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
scm3.org_1   | 2022-10-20 02:09:05,394 [ff795c6b-74b4-4669-bf8f-984925e59fb3-server-thread1] INFO server.RaftServer$Division: ff795c6b-74b4-4669-bf8f-984925e59fb3@group-3DA9FE7C4057: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
scm3.org_1   | 2022-10-20 02:09:05,396 [ff795c6b-74b4-4669-bf8f-984925e59fb3-server-thread1] INFO server.RaftServer$Division: ff795c6b-74b4-4669-bf8f-984925e59fb3@group-3DA9FE7C4057: inconsistency entries. Reply:193991a4-d526-4123-97ec-0cf0bd3049b7<-ff795c6b-74b4-4669-bf8f-984925e59fb3#1:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
scm3.org_1   | 2022-10-20 02:09:05,555 [ff795c6b-74b4-4669-bf8f-984925e59fb3-server-thread1] INFO server.RaftServer$Division: ff795c6b-74b4-4669-bf8f-984925e59fb3@group-3DA9FE7C4057: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
scm3.org_1   | 2022-10-20 02:09:05,555 [ff795c6b-74b4-4669-bf8f-984925e59fb3-server-thread1] INFO server.RaftServer$Division: ff795c6b-74b4-4669-bf8f-984925e59fb3@group-3DA9FE7C4057: inconsistency entries. Reply:193991a4-d526-4123-97ec-0cf0bd3049b7<-ff795c6b-74b4-4669-bf8f-984925e59fb3#0:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
scm3.org_1   | 2022-10-20 02:09:05,581 [ff795c6b-74b4-4669-bf8f-984925e59fb3-server-thread1] INFO server.RaftServer$Division: ff795c6b-74b4-4669-bf8f-984925e59fb3@group-3DA9FE7C4057: set configuration 0: peers:[193991a4-d526-4123-97ec-0cf0bd3049b7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
scm3.org_1   | 2022-10-20 02:09:05,582 [ff795c6b-74b4-4669-bf8f-984925e59fb3-server-thread1] INFO server.RaftServer$Division: ff795c6b-74b4-4669-bf8f-984925e59fb3@group-3DA9FE7C4057: set configuration 1: peers:[193991a4-d526-4123-97ec-0cf0bd3049b7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
scm3.org_1   | 2022-10-20 02:09:05,584 [ff795c6b-74b4-4669-bf8f-984925e59fb3-server-thread1] INFO server.RaftServer$Division: ff795c6b-74b4-4669-bf8f-984925e59fb3@group-3DA9FE7C4057: set configuration 7: peers:[193991a4-d526-4123-97ec-0cf0bd3049b7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, 473d8c0f-fcdd-4210-80f8-a6eef5407d4b|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=peers:[193991a4-d526-4123-97ec-0cf0bd3049b7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[]
scm3.org_1   | 2022-10-20 02:09:05,584 [ff795c6b-74b4-4669-bf8f-984925e59fb3-server-thread1] INFO server.RaftServer$Division: ff795c6b-74b4-4669-bf8f-984925e59fb3@group-3DA9FE7C4057: set configuration 9: peers:[193991a4-d526-4123-97ec-0cf0bd3049b7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, 473d8c0f-fcdd-4210-80f8-a6eef5407d4b|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
scm3.org_1   | 2022-10-20 02:09:05,596 [ff795c6b-74b4-4669-bf8f-984925e59fb3-server-thread1] INFO segmented.SegmentedRaftLogWorker: ff795c6b-74b4-4669-bf8f-984925e59fb3@group-3DA9FE7C4057-SegmentedRaftLogWorker: Starting segment from index:0
scm3.org_1   | 2022-10-20 02:09:05,643 [ff795c6b-74b4-4669-bf8f-984925e59fb3-server-thread1] INFO segmented.SegmentedRaftLogWorker: ff795c6b-74b4-4669-bf8f-984925e59fb3@group-3DA9FE7C4057-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
scm3.org_1   | 2022-10-20 02:09:05,783 [ff795c6b-74b4-4669-bf8f-984925e59fb3-server-thread1] INFO server.RaftServer$Division: ff795c6b-74b4-4669-bf8f-984925e59fb3@group-3DA9FE7C4057: set configuration 0: peers:[193991a4-d526-4123-97ec-0cf0bd3049b7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
scm3.org_1   | 2022-10-20 02:09:05,789 [ff795c6b-74b4-4669-bf8f-984925e59fb3-server-thread1] INFO server.RaftServer$Division: ff795c6b-74b4-4669-bf8f-984925e59fb3@group-3DA9FE7C4057: set configuration 1: peers:[193991a4-d526-4123-97ec-0cf0bd3049b7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
scm3.org_1   | 2022-10-20 02:09:05,793 [ff795c6b-74b4-4669-bf8f-984925e59fb3-server-thread1] INFO server.RaftServer$Division: ff795c6b-74b4-4669-bf8f-984925e59fb3@group-3DA9FE7C4057: set configuration 7: peers:[193991a4-d526-4123-97ec-0cf0bd3049b7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, 473d8c0f-fcdd-4210-80f8-a6eef5407d4b|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=peers:[193991a4-d526-4123-97ec-0cf0bd3049b7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[]
scm3.org_1   | 2022-10-20 02:09:05,794 [ff795c6b-74b4-4669-bf8f-984925e59fb3-server-thread1] INFO server.RaftServer$Division: ff795c6b-74b4-4669-bf8f-984925e59fb3@group-3DA9FE7C4057: set configuration 9: peers:[193991a4-d526-4123-97ec-0cf0bd3049b7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, 473d8c0f-fcdd-4210-80f8-a6eef5407d4b|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
scm3.org_1   | 2022-10-20 02:09:06,390 [ff795c6b-74b4-4669-bf8f-984925e59fb3@group-3DA9FE7C4057-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: ff795c6b-74b4-4669-bf8f-984925e59fb3@group-3DA9FE7C4057-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/959c5f9a-2485-4f2a-8075-3da9fe7c4057/current/log_inprogress_0
scm3.org_1   | 2022-10-20 02:09:06,415 [ff795c6b-74b4-4669-bf8f-984925e59fb3@group-3DA9FE7C4057-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: ff795c6b-74b4-4669-bf8f-984925e59fb3@group-3DA9FE7C4057-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/scm-ha/959c5f9a-2485-4f2a-8075-3da9fe7c4057/current/log_inprogress_0 to /data/metadata/scm-ha/959c5f9a-2485-4f2a-8075-3da9fe7c4057/current/log_0-0
scm3.org_1   | 2022-10-20 02:09:06,444 [ff795c6b-74b4-4669-bf8f-984925e59fb3-server-thread2] INFO server.RaftServer$Division: ff795c6b-74b4-4669-bf8f-984925e59fb3@group-3DA9FE7C4057: set configuration 13: peers:[193991a4-d526-4123-97ec-0cf0bd3049b7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, ff795c6b-74b4-4669-bf8f-984925e59fb3|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, 473d8c0f-fcdd-4210-80f8-a6eef5407d4b|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=peers:[193991a4-d526-4123-97ec-0cf0bd3049b7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, 473d8c0f-fcdd-4210-80f8-a6eef5407d4b|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[]
scm3.org_1   | 2022-10-20 02:09:06,650 [ff795c6b-74b4-4669-bf8f-984925e59fb3@group-3DA9FE7C4057-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: ff795c6b-74b4-4669-bf8f-984925e59fb3@group-3DA9FE7C4057-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/959c5f9a-2485-4f2a-8075-3da9fe7c4057/current/log_inprogress_1
scm3.org_1   | 2022-10-20 02:09:06,697 [ff795c6b-74b4-4669-bf8f-984925e59fb3-server-thread2] INFO server.RaftServer$Division: ff795c6b-74b4-4669-bf8f-984925e59fb3@group-3DA9FE7C4057: set configuration 15: peers:[193991a4-d526-4123-97ec-0cf0bd3049b7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, ff795c6b-74b4-4669-bf8f-984925e59fb3|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, 473d8c0f-fcdd-4210-80f8-a6eef5407d4b|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
scm3.org_1   | 2022-10-20 02:09:06,830 [ff795c6b-74b4-4669-bf8f-984925e59fb3@group-3DA9FE7C4057-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-10-20 02:09:06,911 [ff795c6b-74b4-4669-bf8f-984925e59fb3@group-3DA9FE7C4057-StateMachineUpdater] INFO safemode.ContainerSafeModeRule: Refreshed one replica container threshold 0, currentThreshold 0
scm1.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.2.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.4.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.4.0.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.4.0.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.4.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.10.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.4.0.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.32.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.4.5.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.4.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.4.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.4.0.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.4.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.4.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.3.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.4.0.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar
scm1.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/ff6d15f5df822a5a3c776320b032fad3dd380f95 ; compiled by 'runner' on 2022-10-20T01:41Z
scm1.org_1   | STARTUP_MSG:   java = 11.0.14.1
scm1.org_1   | ************************************************************/
scm1.org_1   | 2022-10-20 02:08:15,561 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm1.org_1   | 2022-10-20 02:08:15,600 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm1.org_1   | 2022-10-20 02:08:15,634 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm1.org_1   | 2022-10-20 02:08:15,642 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm1.org_1   | 2022-10-20 02:08:15,671 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm1, RPC Address: scm1.org:9894 and Ratis port: 9894
scm1.org_1   | 2022-10-20 02:08:15,671 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm1: scm1.org
scm1.org_1   | 2022-10-20 02:08:16,169 [main] INFO client.SCMCertificateClient: Loading certificate from location:/data/metadata/scm/sub-ca/certs.
scm1.org_1   | 2022-10-20 02:08:16,255 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/CA-1.crt.
scm1.org_1   | 2022-10-20 02:08:16,257 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/1003431474332.crt.
scm1.org_1   | 2022-10-20 02:08:16,259 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/certificate.crt.
scm1.org_1   | 2022-10-20 02:08:16,347 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
scm1.org_1   | 2022-10-20 02:08:16,347 [main] INFO server.StorageContainerManager: SCM login successful.
scm1.org_1   | 2022-10-20 02:08:16,371 [main] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm1.org_1   | 2022-10-20 02:08:16,517 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm1.org_1   | 2022-10-20 02:08:16,777 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar!/network-topology-default.xml]
scm1.org_1   | 2022-10-20 02:08:16,778 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
scm1.org_1   | 2022-10-20 02:08:16,838 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
scm1.org_1   | 2022-10-20 02:08:16,857 [main] INFO ha.SCMRatisServerImpl: starting Raft server for scm:193991a4-d526-4123-97ec-0cf0bd3049b7
scm1.org_1   | 2022-10-20 02:08:16,924 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
scm1.org_1   | 2022-10-20 02:08:16,973 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
scm1.org_1   | 2022-10-20 02:08:16,974 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9894 (fallback to raft.grpc.server.port)
scm1.org_1   | 2022-10-20 02:08:16,974 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.host = null (fallback to raft.grpc.server.host)
scm1.org_1   | 2022-10-20 02:08:16,974 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9894 (fallback to raft.grpc.server.port)
scm1.org_1   | 2022-10-20 02:08:16,974 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.host = null (default)
scm1.org_1   | 2022-10-20 02:08:16,975 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2022-10-20 02:08:16,975 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
scm1.org_1   | 2022-10-20 02:08:16,976 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2022-10-20 02:08:16,977 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
scm1.org_1   | 2022-10-20 02:08:16,977 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm1.org_1   | 2022-10-20 02:08:16,985 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
scm1.org_1   | 2022-10-20 02:08:16,987 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
scm1.org_1   | 2022-10-20 02:08:16,987 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
scm1.org_1   | 2022-10-20 02:08:17,360 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
scm1.org_1   | 2022-10-20 02:08:17,362 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
scm2.org_1   | 2022-10-20 02:08:38,418 [main] INFO server.RaftServer: 473d8c0f-fcdd-4210-80f8-a6eef5407d4b: addNew group-3DA9FE7C4057:[] returns group-3DA9FE7C4057:java.util.concurrent.CompletableFuture@6544899b[Not completed]
scm2.org_1   | 2022-10-20 02:08:38,462 [pool-16-thread-1] INFO server.RaftServer$Division: 473d8c0f-fcdd-4210-80f8-a6eef5407d4b: new RaftServerImpl for group-3DA9FE7C4057:[] with SCMStateMachine:uninitialized
scm2.org_1   | 2022-10-20 02:08:38,475 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
scm2.org_1   | 2022-10-20 02:08:38,475 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
scm2.org_1   | 2022-10-20 02:08:38,475 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
scm2.org_1   | 2022-10-20 02:08:38,476 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm2.org_1   | 2022-10-20 02:08:38,476 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm2.org_1   | 2022-10-20 02:08:38,476 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
scm2.org_1   | 2022-10-20 02:08:38,513 [pool-16-thread-1] INFO server.RaftServer$Division: 473d8c0f-fcdd-4210-80f8-a6eef5407d4b@group-3DA9FE7C4057: ConfigurationManager, init=-1: peers:[]|listeners:[], old=null, confs=<EMPTY_MAP>
scm2.org_1   | 2022-10-20 02:08:38,514 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm2.org_1   | 2022-10-20 02:08:38,522 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
scm2.org_1   | 2022-10-20 02:08:38,525 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
scm2.org_1   | 2022-10-20 02:08:38,542 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
scm2.org_1   | 2022-10-20 02:08:38,551 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
scm2.org_1   | 2022-10-20 02:08:38,553 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
scm2.org_1   | 2022-10-20 02:08:38,894 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm2.org_1   | 2022-10-20 02:08:38,895 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
scm2.org_1   | 2022-10-20 02:08:38,896 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
scm2.org_1   | 2022-10-20 02:08:38,899 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
scm2.org_1   | 2022-10-20 02:08:38,899 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
scm2.org_1   | 2022-10-20 02:08:38,903 [main] INFO ha.SCMSnapshotProvider: Initializing SCM Snapshot Provider
scm2.org_1   | 2022-10-20 02:08:38,903 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
scm2.org_1   | 2022-10-20 02:08:38,904 [main] WARN ha.SCMHAUtils: SCM snapshot dir is not configured. Falling back to ozone.metadata.dirs config
scm2.org_1   | 2022-10-20 02:08:39,418 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
scm2.org_1   | 2022-10-20 02:08:39,786 [main] INFO reflections.Reflections: Reflections took 276 ms to scan 3 urls, producing 112 keys and 252 values 
scm2.org_1   | 2022-10-20 02:08:40,002 [main] INFO ha.SequenceIdGenerator: upgrade localId to 109611004723200000
scm2.org_1   | 2022-10-20 02:08:40,005 [main] INFO ha.SequenceIdGenerator: upgrade delTxnId to 0
scm2.org_1   | 2022-10-20 02:08:40,010 [main] INFO ha.SequenceIdGenerator: upgrade containerId to 0
scm2.org_1   | 2022-10-20 02:08:40,015 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
scm2.org_1   | 2022-10-20 02:08:40,184 [main] INFO node.SCMNodeManager: Entering startup safe mode.
scm2.org_1   | 2022-10-20 02:08:40,223 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
scm2.org_1   | 2022-10-20 02:08:40,226 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
scm2.org_1   | 2022-10-20 02:08:40,251 [main] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
scm2.org_1   | 2022-10-20 02:08:40,355 [main] INFO algorithms.LeaderChoosePolicyFactory: Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
scm2.org_1   | 2022-10-20 02:08:40,357 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
scm2.org_1   | 2022-10-20 02:08:40,374 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineCreator.
scm2.org_1   | 2022-10-20 02:08:40,385 [main] INFO pipeline.BackgroundPipelineCreator: Starting RatisPipelineUtilsThread.
scm2.org_1   | 2022-10-20 02:08:40,389 [main] INFO BackgroundPipelineScrubber: Starting BackgroundPipelineScrubber Service.
scm2.org_1   | 2022-10-20 02:08:40,395 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineScrubber.
scm2.org_1   | 2022-10-20 02:08:40,409 [main] INFO ExpiredContainerReplicaOpScrubber: Starting ExpiredContainerReplicaOpScrubber Service.
scm2.org_1   | 2022-10-20 02:08:40,417 [main] INFO ha.SCMServiceManager: Registering service ExpiredContainerReplicaOpScrubber.
scm2.org_1   | 2022-10-20 02:08:40,574 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
scm2.org_1   | 2022-10-20 02:08:40,667 [main] INFO ha.SCMServiceManager: Registering service SCMBlockDeletingService.
scm2.org_1   | 2022-10-20 02:08:40,876 [main] INFO replication.ReplicationManager: Starting Replication Monitor Thread.
scm2.org_1   | 2022-10-20 02:08:40,913 [main] INFO ha.SCMServiceManager: Registering service ReplicationManager.
scm2.org_1   | 2022-10-20 02:08:40,917 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm2.org_1   | 2022-10-20 02:08:40,934 [main] INFO safemode.ContainerSafeModeRule: containers with one replica threshold count 0
scm2.org_1   | 2022-10-20 02:08:40,942 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-10-20 02:08:40,944 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm2.org_1   | 2022-10-20 02:08:41,022 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
scm2.org_1   | 2022-10-20 02:08:41,119 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 200, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm2.org_1   | 2022-10-20 02:08:41,171 [Socket Reader #1 for port 9961] INFO ipc.Server: Starting Socket Reader #1 for port 9961
scm2.org_1   | 2022-10-20 02:08:42,416 [Listener at 0.0.0.0/9961] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm2.org_1   | 2022-10-20 02:08:42,422 [Listener at 0.0.0.0/9961] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm1.org_1   | 2022-10-20 02:08:17,363 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
scm1.org_1   | 2022-10-20 02:08:17,363 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm1.org_1   | 2022-10-20 02:08:17,363 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm1.org_1   | 2022-10-20 02:08:17,366 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm1.org_1   | 2022-10-20 02:08:17,368 [193991a4-d526-4123-97ec-0cf0bd3049b7-impl-thread1] INFO server.RaftServer: 193991a4-d526-4123-97ec-0cf0bd3049b7: found a subdirectory /data/metadata/scm-ha/959c5f9a-2485-4f2a-8075-3da9fe7c4057
scm1.org_1   | 2022-10-20 02:08:17,374 [main] INFO server.RaftServer: 193991a4-d526-4123-97ec-0cf0bd3049b7: addNew group-3DA9FE7C4057:[] returns group-3DA9FE7C4057:java.util.concurrent.CompletableFuture@6da54910[Not completed]
scm1.org_1   | 2022-10-20 02:08:17,389 [pool-16-thread-1] INFO server.RaftServer$Division: 193991a4-d526-4123-97ec-0cf0bd3049b7: new RaftServerImpl for group-3DA9FE7C4057:[] with SCMStateMachine:uninitialized
scm1.org_1   | 2022-10-20 02:08:17,390 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
scm1.org_1   | 2022-10-20 02:08:17,390 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
scm1.org_1   | 2022-10-20 02:08:17,390 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
scm1.org_1   | 2022-10-20 02:08:17,391 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm1.org_1   | 2022-10-20 02:08:17,391 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm1.org_1   | 2022-10-20 02:08:17,391 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
scm1.org_1   | 2022-10-20 02:08:17,402 [pool-16-thread-1] INFO server.RaftServer$Division: 193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057: ConfigurationManager, init=-1: peers:[]|listeners:[], old=null, confs=<EMPTY_MAP>
scm1.org_1   | 2022-10-20 02:08:17,403 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm1.org_1   | 2022-10-20 02:08:17,406 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
scm1.org_1   | 2022-10-20 02:08:17,406 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
scm1.org_1   | 2022-10-20 02:08:17,416 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
scm1.org_1   | 2022-10-20 02:08:17,419 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
scm1.org_1   | 2022-10-20 02:08:17,419 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
scm1.org_1   | 2022-10-20 02:08:17,554 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm1.org_1   | 2022-10-20 02:08:17,554 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
scm1.org_1   | 2022-10-20 02:08:17,555 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
scm1.org_1   | 2022-10-20 02:08:17,555 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
scm1.org_1   | 2022-10-20 02:08:17,556 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
scm1.org_1   | 2022-10-20 02:08:17,558 [main] INFO ha.SCMSnapshotProvider: Initializing SCM Snapshot Provider
scm1.org_1   | 2022-10-20 02:08:17,558 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
scm1.org_1   | 2022-10-20 02:08:17,558 [main] WARN ha.SCMHAUtils: SCM snapshot dir is not configured. Falling back to ozone.metadata.dirs config
scm1.org_1   | 2022-10-20 02:08:17,727 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
scm1.org_1   | 2022-10-20 02:08:17,837 [main] INFO reflections.Reflections: Reflections took 83 ms to scan 3 urls, producing 112 keys and 252 values 
scm1.org_1   | 2022-10-20 02:08:17,898 [main] INFO ha.SequenceIdGenerator: upgrade localId to 109611004723200000
scm1.org_1   | 2022-10-20 02:08:17,898 [main] INFO ha.SequenceIdGenerator: upgrade delTxnId to 0
scm1.org_1   | 2022-10-20 02:08:17,901 [main] INFO ha.SequenceIdGenerator: upgrade containerId to 0
scm1.org_1   | 2022-10-20 02:08:17,903 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
scm1.org_1   | 2022-10-20 02:08:17,949 [main] INFO node.SCMNodeManager: Entering startup safe mode.
scm1.org_1   | 2022-10-20 02:08:17,960 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
scm1.org_1   | 2022-10-20 02:08:17,961 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
scm1.org_1   | 2022-10-20 02:08:17,970 [main] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
scm1.org_1   | 2022-10-20 02:08:18,021 [main] INFO algorithms.LeaderChoosePolicyFactory: Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
scm1.org_1   | 2022-10-20 02:08:18,021 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
scm1.org_1   | 2022-10-20 02:08:18,027 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineCreator.
scm1.org_1   | 2022-10-20 02:08:18,027 [main] INFO pipeline.BackgroundPipelineCreator: Starting RatisPipelineUtilsThread.
scm1.org_1   | 2022-10-20 02:08:18,030 [main] INFO BackgroundPipelineScrubber: Starting BackgroundPipelineScrubber Service.
scm1.org_1   | 2022-10-20 02:08:18,033 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineScrubber.
scm1.org_1   | 2022-10-20 02:08:18,038 [main] INFO ExpiredContainerReplicaOpScrubber: Starting ExpiredContainerReplicaOpScrubber Service.
scm1.org_1   | 2022-10-20 02:08:18,038 [main] INFO ha.SCMServiceManager: Registering service ExpiredContainerReplicaOpScrubber.
scm1.org_1   | 2022-10-20 02:08:18,074 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
scm1.org_1   | 2022-10-20 02:08:18,090 [main] INFO ha.SCMServiceManager: Registering service SCMBlockDeletingService.
scm1.org_1   | 2022-10-20 02:08:18,131 [main] INFO replication.ReplicationManager: Starting Replication Monitor Thread.
scm1.org_1   | 2022-10-20 02:08:18,141 [main] INFO ha.SCMServiceManager: Registering service ReplicationManager.
scm1.org_1   | 2022-10-20 02:08:18,144 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm1.org_1   | 2022-10-20 02:08:18,151 [main] INFO safemode.ContainerSafeModeRule: containers with one replica threshold count 0
scm1.org_1   | 2022-10-20 02:08:18,154 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-10-20 02:10:23,819 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:40576
recon_1      | 2022-10-20 02:10:23,873 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-10-20 02:10:23,874 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=b2bba008-413d-43a9-8499-2749f1317dc3. Trying to get from SCM.
recon_1      | 2022-10-20 02:10:23,899 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: b2bba008-413d-43a9-8499-2749f1317dc3, Nodes: 922d5e53-2e0d-4e01-adf2-129a3cebef39{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-10-20T02:09:52.401Z[UTC]] to Recon pipeline metadata.
recon_1      | 2022-10-20 02:10:23,900 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: b2bba008-413d-43a9-8499-2749f1317dc3, Nodes: 922d5e53-2e0d-4e01-adf2-129a3cebef39{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-10-20T02:09:52.401Z[UTC]].
recon_1      | 2022-10-20 02:10:23,900 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/ONE PipelineID=b2bba008-413d-43a9-8499-2749f1317dc3 reported by 922d5e53-2e0d-4e01-adf2-129a3cebef39{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1082772173580, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-10-20 02:10:23,901 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: b2bba008-413d-43a9-8499-2749f1317dc3, Nodes: 922d5e53-2e0d-4e01-adf2-129a3cebef39{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:922d5e53-2e0d-4e01-adf2-129a3cebef39, CreationTimestamp2022-10-20T02:09:52.401Z[UTC]] moved to OPEN state
recon_1      | 2022-10-20 02:10:23,902 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=904a7869-3351-4618-b9db-44e7403e0592 reported by 922d5e53-2e0d-4e01-adf2-129a3cebef39{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1082772173580, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-10-20 02:10:28,680 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=904a7869-3351-4618-b9db-44e7403e0592 reported by 922d5e53-2e0d-4e01-adf2-129a3cebef39{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1082772173580, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm1.org_1   | 2022-10-20 02:08:18,156 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm1.org_1   | 2022-10-20 02:08:18,192 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
scm1.org_1   | 2022-10-20 02:08:18,196 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
scm1.org_1   | 2022-10-20 02:08:18,197 [main] INFO server.StorageContainerManager: Storing sub-ca certificate serialId 1003431474332 on primary SCM
scm1.org_1   | 2022-10-20 02:08:18,201 [main] INFO server.StorageContainerManager: Storing root certificate serialId 1
scm1.org_1   | 2022-10-20 02:08:18,224 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 200, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm1.org_1   | 2022-10-20 02:08:18,253 [Socket Reader #1 for port 9961] INFO ipc.Server: Starting Socket Reader #1 for port 9961
scm1.org_1   | 2022-10-20 02:08:18,886 [Listener at 0.0.0.0/9961] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm1.org_1   | 2022-10-20 02:08:18,929 [Listener at 0.0.0.0/9961] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm1.org_1   | 2022-10-20 02:08:18,937 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
scm1.org_1   | 2022-10-20 02:08:18,962 [Listener at 0.0.0.0/9861] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm1.org_1   | 2022-10-20 02:08:18,967 [Listener at 0.0.0.0/9861] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm1.org_1   | 2022-10-20 02:08:18,968 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
scm1.org_1   | 2022-10-20 02:08:18,994 [Listener at 0.0.0.0/9863] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm1.org_1   | 2022-10-20 02:08:19,003 [Listener at 0.0.0.0/9863] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm1.org_1   | 2022-10-20 02:08:19,040 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
scm1.org_1   | 2022-10-20 02:08:19,138 [Listener at 0.0.0.0/9860] INFO ha.SCMServiceManager: Registering service ContainerBalancer.
scm1.org_1   | 2022-10-20 02:08:19,139 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: 
scm1.org_1   | Container Balancer status:
scm1.org_1   | Key                            Value
scm1.org_1   | Running                        true
scm1.org_1   | Container Balancer Configuration values:
scm1.org_1   | Key                                                Value
scm1.org_1   | Threshold                                          10
scm1.org_1   | Max Datanodes to Involve per Iteration(percent)    20
scm1.org_1   | Max Size to Move per Iteration                     500GB
scm1.org_1   | Max Size Entering Target per Iteration             26GB
scm1.org_1   | Max Size Leaving Source per Iteration              26GB
scm1.org_1   | 
scm1.org_1   | 2022-10-20 02:08:19,139 [Listener at 0.0.0.0/9860] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm1.org_1   | 2022-10-20 02:08:19,139 [Listener at 0.0.0.0/9860] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
scm1.org_1   | 2022-10-20 02:08:19,150 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
scm1.org_1   | 2022-10-20 02:08:19,154 [Listener at 0.0.0.0/9860] INFO ha.SCMRatisServerImpl: starting ratis server 0.0.0.0:9894
scm1.org_1   | 2022-10-20 02:08:19,160 [193991a4-d526-4123-97ec-0cf0bd3049b7-impl-thread1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/959c5f9a-2485-4f2a-8075-3da9fe7c4057/in_use.lock acquired by nodename 8@scm1.org
scm1.org_1   | 2022-10-20 02:08:19,164 [193991a4-d526-4123-97ec-0cf0bd3049b7-impl-thread1] INFO storage.RaftStorage: Read RaftStorageMetadata{term=1, votedFor=193991a4-d526-4123-97ec-0cf0bd3049b7} from /data/metadata/scm-ha/959c5f9a-2485-4f2a-8075-3da9fe7c4057/current/raft-meta
scm1.org_1   | 2022-10-20 02:08:19,210 [193991a4-d526-4123-97ec-0cf0bd3049b7-impl-thread1] INFO server.RaftServer$Division: 193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057: set configuration 0: peers:[193991a4-d526-4123-97ec-0cf0bd3049b7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
scm1.org_1   | 2022-10-20 02:08:19,212 [193991a4-d526-4123-97ec-0cf0bd3049b7-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
scm1.org_1   | 2022-10-20 02:08:19,223 [193991a4-d526-4123-97ec-0cf0bd3049b7-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
scm1.org_1   | 2022-10-20 02:08:19,224 [193991a4-d526-4123-97ec-0cf0bd3049b7-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2022-10-20 02:08:19,225 [193991a4-d526-4123-97ec-0cf0bd3049b7-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
scm1.org_1   | 2022-10-20 02:08:19,243 [193991a4-d526-4123-97ec-0cf0bd3049b7-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
scm1.org_1   | 2022-10-20 02:08:19,248 [193991a4-d526-4123-97ec-0cf0bd3049b7-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm1.org_1   | 2022-10-20 02:08:19,253 [193991a4-d526-4123-97ec-0cf0bd3049b7-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
scm1.org_1   | 2022-10-20 02:08:19,253 [193991a4-d526-4123-97ec-0cf0bd3049b7-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
scm1.org_1   | 2022-10-20 02:08:19,258 [193991a4-d526-4123-97ec-0cf0bd3049b7-impl-thread1] INFO segmented.SegmentedRaftLogWorker: new 193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/959c5f9a-2485-4f2a-8075-3da9fe7c4057
scm1.org_1   | 2022-10-20 02:08:19,264 [193991a4-d526-4123-97ec-0cf0bd3049b7-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
scm1.org_1   | 2022-10-20 02:08:19,264 [193991a4-d526-4123-97ec-0cf0bd3049b7-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
scm1.org_1   | 2022-10-20 02:08:19,265 [193991a4-d526-4123-97ec-0cf0bd3049b7-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm1.org_1   | 2022-10-20 02:08:19,265 [193991a4-d526-4123-97ec-0cf0bd3049b7-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
scm1.org_1   | 2022-10-20 02:08:19,266 [193991a4-d526-4123-97ec-0cf0bd3049b7-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
scm1.org_1   | 2022-10-20 02:08:19,272 [193991a4-d526-4123-97ec-0cf0bd3049b7-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
scm1.org_1   | 2022-10-20 02:08:19,274 [193991a4-d526-4123-97ec-0cf0bd3049b7-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
scm1.org_1   | 2022-10-20 02:08:19,274 [193991a4-d526-4123-97ec-0cf0bd3049b7-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
scm3.org_1   | 2022-10-20 02:09:06,932 [ff795c6b-74b4-4669-bf8f-984925e59fb3@group-3DA9FE7C4057-StateMachineUpdater] INFO safemode.OneReplicaPipelineSafeModeRule: Refreshed Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm3.org_1   | 2022-10-20 02:09:06,943 [ff795c6b-74b4-4669-bf8f-984925e59fb3@group-3DA9FE7C4057-StateMachineUpdater] INFO server.SCMDatanodeProtocolServer: ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:9861
scm3.org_1   | 2022-10-20 02:09:07,084 [Listener at 0.0.0.0/9860] INFO ha.SCMHAManagerImpl: Successfully added SCM scm3 to group group-3DA9FE7C4057:[193991a4-d526-4123-97ec-0cf0bd3049b7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, ff795c6b-74b4-4669-bf8f-984925e59fb3|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, 473d8c0f-fcdd-4210-80f8-a6eef5407d4b|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]
scm3.org_1   | 2022-10-20 02:09:07,531 [Listener at 0.0.0.0/9860] INFO ha.InterSCMGrpcService: Starting SCM Grpc Service at port 9895
scm3.org_1   | 2022-10-20 02:09:07,325 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm3.org_1   | 2022-10-20 02:09:07,084 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
scm3.org_1   | 2022-10-20 02:09:07,730 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Starting token manager
scm3.org_1   | 2022-10-20 02:09:07,744 [Listener at 0.0.0.0/9860] INFO token.ContainerTokenSecretManager: Updating the current master key for generating tokens
scm3.org_1   | 2022-10-20 02:09:07,912 [ff795c6b-74b4-4669-bf8f-984925e59fb3@group-3DA9FE7C4057-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-10-20 02:09:07,912 [ff795c6b-74b4-4669-bf8f-984925e59fb3@group-3DA9FE7C4057-StateMachineUpdater] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm3.org_1   | 2022-10-20 02:09:07,912 [ff795c6b-74b4-4669-bf8f-984925e59fb3@group-3DA9FE7C4057-StateMachineUpdater] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm3.org_1   | 2022-10-20 02:09:08,106 [ff795c6b-74b4-4669-bf8f-984925e59fb3@group-3DA9FE7C4057-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-10-20 02:09:08,167 [ff795c6b-74b4-4669-bf8f-984925e59fb3@group-3DA9FE7C4057-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-10-20 02:09:08,625 [Listener at 0.0.0.0/9860] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
scm3.org_1   | 2022-10-20 02:09:08,769 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
scm3.org_1   | 2022-10-20 02:09:08,769 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
scm3.org_1   | 2022-10-20 02:09:09,970 [JvmPauseMonitor0] WARN util.JvmPauseMonitor: JvmPauseMonitor-ff795c6b-74b4-4669-bf8f-984925e59fb3: Detected pause in JVM or host machine (eg GC): pause of approximately 132170670ns.
scm3.org_1   | GC pool 'ParNew' had collection(s): count=1 time=147ms
scm3.org_1   | 2022-10-20 02:09:10,976 [Listener at 0.0.0.0/9860] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
scm3.org_1   | 2022-10-20 02:09:10,979 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm3.org_1   | 2022-10-20 02:09:10,995 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
scm3.org_1   | 2022-10-20 02:09:11,801 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
scm3.org_1   | 2022-10-20 02:09:11,802 [Listener at 0.0.0.0/9860] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
scm3.org_1   | 2022-10-20 02:09:11,802 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm3.org_1   | 2022-10-20 02:09:11,875 [Listener at 0.0.0.0/9860] INFO server.SCMSecurityProtocolServer: Starting RPC server for SCMSecurityProtocolServer. is listening at /0.0.0.0:9961
scm3.org_1   | 2022-10-20 02:09:11,881 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
scm3.org_1   | 2022-10-20 02:09:11,909 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm3.org_1   | 2022-10-20 02:09:11,909 [IPC Server listener on 9961] INFO ipc.Server: IPC Server listener on 9961: starting
scm3.org_1   | 2022-10-20 02:09:11,921 [Listener at 0.0.0.0/9860] INFO server.SCMUpdateServiceGrpcServer: SCMUpdateService starting
scm3.org_1   | 2022-10-20 02:09:12,186 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
scm3.org_1   | 2022-10-20 02:09:12,192 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
scm3.org_1   | 2022-10-20 02:09:12,193 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
scm3.org_1   | 2022-10-20 02:09:13,308 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Persist certificate serialId 1003431474332 on Scm Bootstrap Node ff795c6b-74b4-4669-bf8f-984925e59fb3
scm3.org_1   | 2022-10-20 02:09:13,407 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Persist certificate serialId 1 on Scm Bootstrap Node ff795c6b-74b4-4669-bf8f-984925e59fb3
scm3.org_1   | 2022-10-20 02:09:13,735 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1c94d976] INFO util.JvmPauseMonitor: Starting JVM pause monitor
scm3.org_1   | 2022-10-20 02:09:13,915 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
scm3.org_1   | 2022-10-20 02:09:13,915 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
scm3.org_1   | 2022-10-20 02:09:13,916 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HttpAuthType: hdds.scm.http.auth.type = kerberos
scm3.org_1   | 2022-10-20 02:09:14,157 [Listener at 0.0.0.0/9860] INFO util.log: Logging initialized @22823ms to org.eclipse.jetty.util.log.Slf4jLog
scm3.org_1   | 2022-10-20 02:09:15,070 [Listener at 0.0.0.0/9860] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
scm3.org_1   | 2022-10-20 02:09:15,095 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
scm3.org_1   | 2022-10-20 02:09:15,096 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context scm
scm3.org_1   | 2022-10-20 02:09:15,096 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
scm3.org_1   | 2022-10-20 02:09:15,110 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
scm3.org_1   | 2022-10-20 02:09:15,112 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.scm.http.auth.kerberos.principal keytabKey: hdds.scm.http.auth.kerberos.keytab
scm3.org_1   | 2022-10-20 02:09:15,335 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Jetty bound to port 9876
scm3.org_1   | 2022-10-20 02:09:15,337 [Listener at 0.0.0.0/9860] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
scm3.org_1   | 2022-10-20 02:09:15,590 [Listener at 0.0.0.0/9860] INFO server.session: DefaultSessionIdManager workerName=node0
scm3.org_1   | 2022-10-20 02:09:15,590 [Listener at 0.0.0.0/9860] INFO server.session: No SessionScavenger set, using defaults
scm3.org_1   | 2022-10-20 02:09:15,595 [Listener at 0.0.0.0/9860] INFO server.session: node0 Scavenging every 660000ms
scm3.org_1   | 2022-10-20 02:09:15,775 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm3.org_1   | 2022-10-20 02:09:15,785 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6fbfd6ed{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
scm3.org_1   | 2022-10-20 02:09:15,786 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@4be7661{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
scm3.org_1   | 2022-10-20 02:09:16,502 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm3.org_1   | 2022-10-20 02:09:16,698 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@6d1953e4{scm,/,file:///tmp/jetty-0_0_0_0-9876-hdds-server-scm-1_3_0-SNAPSHOT_jar-_-any-16971218975159064233/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar!/webapps/scm}
scm3.org_1   | 2022-10-20 02:09:16,816 [Listener at 0.0.0.0/9860] INFO server.AbstractConnector: Started ServerConnector@4b33b5b0{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
scm3.org_1   | 2022-10-20 02:09:16,816 [Listener at 0.0.0.0/9860] INFO server.Server: Started @25482ms
scm3.org_1   | 2022-10-20 02:09:16,841 [Listener at 0.0.0.0/9860] INFO impl.MetricsSinkAdapter: Sink prometheus started
scm3.org_1   | 2022-10-20 02:09:16,842 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Registered sink prometheus
scm3.org_1   | 2022-10-20 02:09:16,853 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
scm3.org_1   | 2022-10-20 02:09:24,969 [ff795c6b-74b4-4669-bf8f-984925e59fb3@group-3DA9FE7C4057-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-10-20 02:09:26,447 [ff795c6b-74b4-4669-bf8f-984925e59fb3@group-3DA9FE7C4057-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-10-20 02:09:27,073 [ff795c6b-74b4-4669-bf8f-984925e59fb3@group-3DA9FE7C4057-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-10-20 02:09:31,099 [ff795c6b-74b4-4669-bf8f-984925e59fb3@group-3DA9FE7C4057-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-10-20 02:09:32,006 [ff795c6b-74b4-4669-bf8f-984925e59fb3@group-3DA9FE7C4057-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-10-20 02:09:33,354 [ff795c6b-74b4-4669-bf8f-984925e59fb3@group-3DA9FE7C4057-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-10-20 02:09:47,258 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:56734
scm3.org_1   | 2022-10-20 02:09:47,305 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-10-20 02:09:49,261 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:34252
scm3.org_1   | 2022-10-20 02:09:49,466 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-10-20 02:09:49,919 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:57822
scm3.org_1   | 2022-10-20 02:09:49,967 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-10-20 02:09:51,123 [IPC Server handler 3 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/922d5e53-2e0d-4e01-adf2-129a3cebef39
scm3.org_1   | 2022-10-20 02:09:51,151 [IPC Server handler 3 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 922d5e53-2e0d-4e01-adf2-129a3cebef39{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1082772173580, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm3.org_1   | 2022-10-20 02:09:51,270 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm3.org_1   | 2022-10-20 02:09:51,271 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 3 required.
scm3.org_1   | 2022-10-20 02:09:51,441 [IPC Server handler 26 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/e4d9a0e3-266c-4558-944a-cafbea7b03e5
scm3.org_1   | 2022-10-20 02:09:51,442 [IPC Server handler 26 on default port 9861] INFO node.SCMNodeManager: Registered Data node : e4d9a0e3-266c-4558-944a-cafbea7b03e5{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1081094776367, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm3.org_1   | 2022-10-20 02:09:51,445 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 3 required.
scm3.org_1   | 2022-10-20 02:09:51,447 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm3.org_1   | 2022-10-20 02:09:52,063 [IPC Server handler 1 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/4026c186-2529-49de-a2d8-dcba1039e356
scm3.org_1   | 2022-10-20 02:09:52,063 [IPC Server handler 1 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 4026c186-2529-49de-a2d8-dcba1039e356{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1083227860558, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm3.org_1   | 2022-10-20 02:09:52,063 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm3.org_1   | 2022-10-20 02:09:52,064 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 3 required.
scm3.org_1   | 2022-10-20 02:09:52,064 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
recon_1      | 2022-10-20 02:10:28,680 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 904a7869-3351-4618-b9db-44e7403e0592, Nodes: 922d5e53-2e0d-4e01-adf2-129a3cebef39{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}e4d9a0e3-266c-4558-944a-cafbea7b03e5{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}4026c186-2529-49de-a2d8-dcba1039e356{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:922d5e53-2e0d-4e01-adf2-129a3cebef39, CreationTimestamp2022-10-20T02:09:52.276Z[UTC]] moved to OPEN state
recon_1      | 2022-10-20 02:10:33,088 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:55888
recon_1      | 2022-10-20 02:10:33,111 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-10-20 02:10:38,507 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:60308
recon_1      | 2022-10-20 02:10:38,531 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-10-20 02:10:58,395 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:45286
recon_1      | 2022-10-20 02:10:58,461 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-10-20 02:10:58,489 [FixedThreadPoolWithAffinityExecutor-0-0] INFO scm.ReconContainerManager: New container #1 got from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net.
recon_1      | 2022-10-20 02:10:58,700 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:50698
recon_1      | 2022-10-20 02:10:58,783 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:36482
recon_1      | 2022-10-20 02:10:58,804 [FixedThreadPoolWithAffinityExecutor-0-0] INFO scm.ReconContainerManager: Successfully added container #1 to Recon.
recon_1      | 2022-10-20 02:10:58,834 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-10-20 02:10:58,892 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-10-20 02:11:16,910 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:38952
recon_1      | 2022-10-20 02:11:16,999 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:60812
recon_1      | 2022-10-20 02:11:17,005 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48516
recon_1      | 2022-10-20 02:11:17,038 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-10-20 02:11:17,043 [FixedThreadPoolWithAffinityExecutor-0-0] INFO scm.ReconContainerManager: New container #2 got from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net.
recon_1      | 2022-10-20 02:11:17,064 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-10-20 02:11:17,072 [FixedThreadPoolWithAffinityExecutor-1-0] INFO scm.ReconContainerManager: New container #2 got from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net.
recon_1      | 2022-10-20 02:11:17,079 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-10-20 02:11:17,109 [FixedThreadPoolWithAffinityExecutor-0-0] INFO scm.ReconContainerManager: Successfully added container #2 to Recon.
recon_1      | 2022-10-20 02:11:17,141 [FixedThreadPoolWithAffinityExecutor-1-0] INFO scm.ReconContainerManager: Successfully added container #2 to Recon.
recon_1      | 2022-10-20 02:11:23,777 [pool-29-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-10-20 02:11:23,777 [pool-29-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-10-20 02:11:23,831 [pool-29-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
scm2.org_1   | 2022-10-20 02:08:42,423 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
scm2.org_1   | 2022-10-20 02:08:42,471 [Listener at 0.0.0.0/9861] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm2.org_1   | 2022-10-20 02:08:42,479 [Listener at 0.0.0.0/9861] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm2.org_1   | 2022-10-20 02:08:42,485 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
scm2.org_1   | 2022-10-20 02:08:42,537 [Listener at 0.0.0.0/9863] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm2.org_1   | 2022-10-20 02:08:42,557 [Listener at 0.0.0.0/9863] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm2.org_1   | 2022-10-20 02:08:42,563 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
scm2.org_1   | 2022-10-20 02:08:42,666 [Listener at 0.0.0.0/9860] INFO ha.SCMServiceManager: Registering service ContainerBalancer.
scm2.org_1   | 2022-10-20 02:08:42,667 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: 
scm2.org_1   | Container Balancer status:
scm2.org_1   | Key                            Value
scm2.org_1   | Running                        true
scm2.org_1   | Container Balancer Configuration values:
scm2.org_1   | Key                                                Value
scm2.org_1   | Threshold                                          10
scm2.org_1   | Max Datanodes to Involve per Iteration(percent)    20
scm2.org_1   | Max Size to Move per Iteration                     500GB
scm2.org_1   | Max Size Entering Target per Iteration             26GB
scm2.org_1   | Max Size Leaving Source per Iteration              26GB
scm2.org_1   | 
scm2.org_1   | 2022-10-20 02:08:42,667 [Listener at 0.0.0.0/9860] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm2.org_1   | 2022-10-20 02:08:42,667 [Listener at 0.0.0.0/9860] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
scm2.org_1   | 2022-10-20 02:08:42,671 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
scm2.org_1   | 2022-10-20 02:08:42,674 [Listener at 0.0.0.0/9860] INFO ha.SCMRatisServerImpl: starting ratis server 0.0.0.0:9894
scm2.org_1   | 2022-10-20 02:08:42,675 [473d8c0f-fcdd-4210-80f8-a6eef5407d4b-impl-thread1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/scm-ha/959c5f9a-2485-4f2a-8075-3da9fe7c4057 does not exist. Creating ...
scm2.org_1   | 2022-10-20 02:08:42,679 [473d8c0f-fcdd-4210-80f8-a6eef5407d4b-impl-thread1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/959c5f9a-2485-4f2a-8075-3da9fe7c4057/in_use.lock acquired by nodename 6@scm2.org
scm2.org_1   | 2022-10-20 02:08:42,691 [473d8c0f-fcdd-4210-80f8-a6eef5407d4b-impl-thread1] INFO storage.RaftStorage: Storage directory /data/metadata/scm-ha/959c5f9a-2485-4f2a-8075-3da9fe7c4057 has been successfully formatted.
scm2.org_1   | 2022-10-20 02:08:42,735 [473d8c0f-fcdd-4210-80f8-a6eef5407d4b-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
scm2.org_1   | 2022-10-20 02:08:42,755 [473d8c0f-fcdd-4210-80f8-a6eef5407d4b-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
scm2.org_1   | 2022-10-20 02:08:42,759 [473d8c0f-fcdd-4210-80f8-a6eef5407d4b-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm2.org_1   | 2022-10-20 02:08:42,760 [473d8c0f-fcdd-4210-80f8-a6eef5407d4b-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
scm2.org_1   | 2022-10-20 02:08:42,761 [473d8c0f-fcdd-4210-80f8-a6eef5407d4b-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
scm2.org_1   | 2022-10-20 02:08:42,765 [473d8c0f-fcdd-4210-80f8-a6eef5407d4b-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm2.org_1   | 2022-10-20 02:08:42,777 [473d8c0f-fcdd-4210-80f8-a6eef5407d4b-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
scm2.org_1   | 2022-10-20 02:08:42,778 [473d8c0f-fcdd-4210-80f8-a6eef5407d4b-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
scm2.org_1   | 2022-10-20 02:08:42,783 [473d8c0f-fcdd-4210-80f8-a6eef5407d4b-impl-thread1] INFO segmented.SegmentedRaftLogWorker: new 473d8c0f-fcdd-4210-80f8-a6eef5407d4b@group-3DA9FE7C4057-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/959c5f9a-2485-4f2a-8075-3da9fe7c4057
scm2.org_1   | 2022-10-20 02:08:42,785 [473d8c0f-fcdd-4210-80f8-a6eef5407d4b-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
scm2.org_1   | 2022-10-20 02:08:42,790 [473d8c0f-fcdd-4210-80f8-a6eef5407d4b-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
scm2.org_1   | 2022-10-20 02:08:42,791 [473d8c0f-fcdd-4210-80f8-a6eef5407d4b-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm2.org_1   | 2022-10-20 02:08:42,791 [473d8c0f-fcdd-4210-80f8-a6eef5407d4b-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
scm2.org_1   | 2022-10-20 02:08:42,791 [473d8c0f-fcdd-4210-80f8-a6eef5407d4b-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
scm2.org_1   | 2022-10-20 02:08:42,792 [473d8c0f-fcdd-4210-80f8-a6eef5407d4b-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
scm2.org_1   | 2022-10-20 02:08:42,792 [473d8c0f-fcdd-4210-80f8-a6eef5407d4b-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
scm2.org_1   | 2022-10-20 02:08:42,792 [473d8c0f-fcdd-4210-80f8-a6eef5407d4b-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
scm2.org_1   | 2022-10-20 02:08:42,805 [473d8c0f-fcdd-4210-80f8-a6eef5407d4b-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
scm2.org_1   | 2022-10-20 02:08:42,806 [473d8c0f-fcdd-4210-80f8-a6eef5407d4b-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
scm2.org_1   | 2022-10-20 02:08:42,808 [473d8c0f-fcdd-4210-80f8-a6eef5407d4b-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
scm2.org_1   | 2022-10-20 02:08:42,808 [473d8c0f-fcdd-4210-80f8-a6eef5407d4b-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
scm2.org_1   | 2022-10-20 02:08:42,825 [473d8c0f-fcdd-4210-80f8-a6eef5407d4b-impl-thread1] INFO segmented.SegmentedRaftLogWorker: 473d8c0f-fcdd-4210-80f8-a6eef5407d4b@group-3DA9FE7C4057-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
scm2.org_1   | 2022-10-20 02:08:42,825 [473d8c0f-fcdd-4210-80f8-a6eef5407d4b-impl-thread1] INFO segmented.SegmentedRaftLogWorker: 473d8c0f-fcdd-4210-80f8-a6eef5407d4b@group-3DA9FE7C4057-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
scm2.org_1   | 2022-10-20 02:08:42,826 [473d8c0f-fcdd-4210-80f8-a6eef5407d4b-impl-thread1] INFO server.RaftServer$Division: 473d8c0f-fcdd-4210-80f8-a6eef5407d4b@group-3DA9FE7C4057: start with initializing state, conf=-1: peers:[]|listeners:[], old=null
scm2.org_1   | 2022-10-20 02:08:42,826 [473d8c0f-fcdd-4210-80f8-a6eef5407d4b-impl-thread1] INFO server.RaftServer$Division: 473d8c0f-fcdd-4210-80f8-a6eef5407d4b@group-3DA9FE7C4057: changes role from      null to FOLLOWER at term 0 for startInitializing
scm2.org_1   | 2022-10-20 02:08:42,827 [473d8c0f-fcdd-4210-80f8-a6eef5407d4b-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-3DA9FE7C4057,id=473d8c0f-fcdd-4210-80f8-a6eef5407d4b
scm2.org_1   | 2022-10-20 02:08:42,829 [473d8c0f-fcdd-4210-80f8-a6eef5407d4b-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
scm2.org_1   | 2022-10-20 02:08:42,829 [473d8c0f-fcdd-4210-80f8-a6eef5407d4b-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
scm2.org_1   | 2022-10-20 02:08:42,829 [473d8c0f-fcdd-4210-80f8-a6eef5407d4b-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
scm2.org_1   | 2022-10-20 02:08:42,830 [473d8c0f-fcdd-4210-80f8-a6eef5407d4b-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
scm2.org_1   | 2022-10-20 02:08:42,832 [Listener at 0.0.0.0/9860] INFO server.RaftServer: 473d8c0f-fcdd-4210-80f8-a6eef5407d4b: start RPC server
scm2.org_1   | 2022-10-20 02:08:42,901 [Listener at 0.0.0.0/9860] INFO server.GrpcService: 473d8c0f-fcdd-4210-80f8-a6eef5407d4b: GrpcService started, listening on 9894
scm2.org_1   | 2022-10-20 02:08:42,940 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-473d8c0f-fcdd-4210-80f8-a6eef5407d4b: Started
scm2.org_1   | 2022-10-20 02:08:42,957 [Listener at 0.0.0.0/9860] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 2 nodes: [nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
scm2.org_1   | 2022-10-20 02:08:44,661 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: 473d8c0f-fcdd-4210-80f8-a6eef5407d4b@group-3DA9FE7C4057: receive installSnapshot: 193991a4-d526-4123-97ec-0cf0bd3049b7->473d8c0f-fcdd-4210-80f8-a6eef5407d4b#0-t2,notify:(t:1, i:0)
scm2.org_1   | 2022-10-20 02:08:44,674 [grpc-default-executor-0] INFO ha.SCMStateMachine: leader changed, yet current SCM is still follower.
scm2.org_1   | 2022-10-20 02:08:44,674 [grpc-default-executor-0] INFO server.RaftServer$Division: 473d8c0f-fcdd-4210-80f8-a6eef5407d4b@group-3DA9FE7C4057: change Leader from null to 193991a4-d526-4123-97ec-0cf0bd3049b7 at term 2 for installSnapshot, leader elected after 6132ms
scm2.org_1   | 2022-10-20 02:08:44,676 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: 473d8c0f-fcdd-4210-80f8-a6eef5407d4b@group-3DA9FE7C4057: Received notification to install snapshot at index 0
scm2.org_1   | 2022-10-20 02:08:44,690 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: 473d8c0f-fcdd-4210-80f8-a6eef5407d4b@group-3DA9FE7C4057: InstallSnapshot notification result: ALREADY_INSTALLED, current snapshot index: -1
scm2.org_1   | 2022-10-20 02:08:44,920 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: 473d8c0f-fcdd-4210-80f8-a6eef5407d4b@group-3DA9FE7C4057: set new configuration index: 1
scm2.org_1   | configurationEntry {
scm2.org_1   |   peers {
scm2.org_1   |     id: "193991a4-d526-4123-97ec-0cf0bd3049b7"
scm2.org_1   |     address: "scm1.org:9894"
scm2.org_1   |     startupRole: FOLLOWER
scm2.org_1   |   }
scm2.org_1   | }
scm2.org_1   |  from snapshot
scm2.org_1   | 2022-10-20 02:08:44,927 [grpc-default-executor-0] INFO server.RaftServer$Division: 473d8c0f-fcdd-4210-80f8-a6eef5407d4b@group-3DA9FE7C4057: set configuration 1: peers:[193991a4-d526-4123-97ec-0cf0bd3049b7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
scm2.org_1   | 2022-10-20 02:08:44,935 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: 473d8c0f-fcdd-4210-80f8-a6eef5407d4b@group-3DA9FE7C4057: reply installSnapshot: 193991a4-d526-4123-97ec-0cf0bd3049b7<-473d8c0f-fcdd-4210-80f8-a6eef5407d4b#0:OK-t0,ALREADY_INSTALLED
scm2.org_1   | 2022-10-20 02:08:44,972 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: 473d8c0f-fcdd-4210-80f8-a6eef5407d4b: Completed INSTALL_SNAPSHOT, lastRequest: 193991a4-d526-4123-97ec-0cf0bd3049b7->473d8c0f-fcdd-4210-80f8-a6eef5407d4b#0-t2,notify:(t:1, i:0)
scm2.org_1   | 2022-10-20 02:08:45,121 [473d8c0f-fcdd-4210-80f8-a6eef5407d4b-server-thread1] INFO impl.RoleInfo: 473d8c0f-fcdd-4210-80f8-a6eef5407d4b: start 473d8c0f-fcdd-4210-80f8-a6eef5407d4b@group-3DA9FE7C4057-FollowerState
scm2.org_1   | 2022-10-20 02:08:45,125 [473d8c0f-fcdd-4210-80f8-a6eef5407d4b-server-thread1] INFO server.RaftServer$Division: 473d8c0f-fcdd-4210-80f8-a6eef5407d4b@group-3DA9FE7C4057: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
scm2.org_1   | 2022-10-20 02:08:45,126 [473d8c0f-fcdd-4210-80f8-a6eef5407d4b-server-thread1] INFO server.RaftServer$Division: 473d8c0f-fcdd-4210-80f8-a6eef5407d4b@group-3DA9FE7C4057: inconsistency entries. Reply:193991a4-d526-4123-97ec-0cf0bd3049b7<-473d8c0f-fcdd-4210-80f8-a6eef5407d4b#1:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
scm2.org_1   | 2022-10-20 02:08:45,158 [473d8c0f-fcdd-4210-80f8-a6eef5407d4b-server-thread2] INFO server.RaftServer$Division: 473d8c0f-fcdd-4210-80f8-a6eef5407d4b@group-3DA9FE7C4057: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
scm2.org_1   | 2022-10-20 02:08:45,159 [473d8c0f-fcdd-4210-80f8-a6eef5407d4b-server-thread2] INFO server.RaftServer$Division: 473d8c0f-fcdd-4210-80f8-a6eef5407d4b@group-3DA9FE7C4057: inconsistency entries. Reply:193991a4-d526-4123-97ec-0cf0bd3049b7<-473d8c0f-fcdd-4210-80f8-a6eef5407d4b#0:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
scm2.org_1   | 2022-10-20 02:08:45,177 [473d8c0f-fcdd-4210-80f8-a6eef5407d4b-server-thread1] INFO server.RaftServer$Division: 473d8c0f-fcdd-4210-80f8-a6eef5407d4b@group-3DA9FE7C4057: set configuration 0: peers:[193991a4-d526-4123-97ec-0cf0bd3049b7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
scm2.org_1   | 2022-10-20 02:08:45,179 [473d8c0f-fcdd-4210-80f8-a6eef5407d4b-server-thread1] INFO server.RaftServer$Division: 473d8c0f-fcdd-4210-80f8-a6eef5407d4b@group-3DA9FE7C4057: set configuration 1: peers:[193991a4-d526-4123-97ec-0cf0bd3049b7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
scm2.org_1   | 2022-10-20 02:08:45,184 [473d8c0f-fcdd-4210-80f8-a6eef5407d4b-server-thread1] INFO segmented.SegmentedRaftLogWorker: 473d8c0f-fcdd-4210-80f8-a6eef5407d4b@group-3DA9FE7C4057-SegmentedRaftLogWorker: Starting segment from index:0
scm2.org_1   | 2022-10-20 02:08:45,218 [473d8c0f-fcdd-4210-80f8-a6eef5407d4b-server-thread1] INFO segmented.SegmentedRaftLogWorker: 473d8c0f-fcdd-4210-80f8-a6eef5407d4b@group-3DA9FE7C4057-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
scm2.org_1   | 2022-10-20 02:08:45,249 [473d8c0f-fcdd-4210-80f8-a6eef5407d4b-server-thread2] INFO server.RaftServer$Division: 473d8c0f-fcdd-4210-80f8-a6eef5407d4b@group-3DA9FE7C4057: set configuration 0: peers:[193991a4-d526-4123-97ec-0cf0bd3049b7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
scm2.org_1   | 2022-10-20 02:08:45,250 [473d8c0f-fcdd-4210-80f8-a6eef5407d4b-server-thread2] INFO server.RaftServer$Division: 473d8c0f-fcdd-4210-80f8-a6eef5407d4b@group-3DA9FE7C4057: set configuration 1: peers:[193991a4-d526-4123-97ec-0cf0bd3049b7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
scm2.org_1   | 2022-10-20 02:08:45,396 [473d8c0f-fcdd-4210-80f8-a6eef5407d4b@group-3DA9FE7C4057-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 473d8c0f-fcdd-4210-80f8-a6eef5407d4b@group-3DA9FE7C4057-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/959c5f9a-2485-4f2a-8075-3da9fe7c4057/current/log_inprogress_0
scm2.org_1   | 2022-10-20 02:08:45,402 [473d8c0f-fcdd-4210-80f8-a6eef5407d4b@group-3DA9FE7C4057-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 473d8c0f-fcdd-4210-80f8-a6eef5407d4b@group-3DA9FE7C4057-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/scm-ha/959c5f9a-2485-4f2a-8075-3da9fe7c4057/current/log_inprogress_0 to /data/metadata/scm-ha/959c5f9a-2485-4f2a-8075-3da9fe7c4057/current/log_0-0
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-10-20 02:11:46,900 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:40482
recon_1      | 2022-10-20 02:11:46,907 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34186
recon_1      | 2022-10-20 02:11:46,988 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-10-20 02:11:46,994 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:34782
recon_1      | 2022-10-20 02:11:47,011 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-10-20 02:11:47,045 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-10-20 02:12:16,933 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:43994
recon_1      | 2022-10-20 02:12:16,952 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:50854
recon_1      | 2022-10-20 02:12:16,952 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:51272
recon_1      | 2022-10-20 02:12:16,964 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-10-20 02:12:16,968 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-10-20 02:12:17,107 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-10-20 02:12:23,857 [pool-29-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-10-20 02:12:23,857 [pool-29-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-10-20 02:12:23,907 [pool-29-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm2.org_1   | 2022-10-20 02:08:45,435 [473d8c0f-fcdd-4210-80f8-a6eef5407d4b@group-3DA9FE7C4057-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 473d8c0f-fcdd-4210-80f8-a6eef5407d4b@group-3DA9FE7C4057-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/959c5f9a-2485-4f2a-8075-3da9fe7c4057/current/log_inprogress_1
scm2.org_1   | 2022-10-20 02:08:45,451 [473d8c0f-fcdd-4210-80f8-a6eef5407d4b@group-3DA9FE7C4057-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-10-20 02:08:45,459 [473d8c0f-fcdd-4210-80f8-a6eef5407d4b@group-3DA9FE7C4057-StateMachineUpdater] INFO safemode.ContainerSafeModeRule: Refreshed one replica container threshold 0, currentThreshold 0
scm2.org_1   | 2022-10-20 02:08:45,464 [473d8c0f-fcdd-4210-80f8-a6eef5407d4b@group-3DA9FE7C4057-StateMachineUpdater] INFO safemode.OneReplicaPipelineSafeModeRule: Refreshed Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm2.org_1   | 2022-10-20 02:08:45,465 [473d8c0f-fcdd-4210-80f8-a6eef5407d4b@group-3DA9FE7C4057-StateMachineUpdater] INFO server.SCMDatanodeProtocolServer: ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:9861
scm2.org_1   | 2022-10-20 02:08:45,475 [473d8c0f-fcdd-4210-80f8-a6eef5407d4b-server-thread3] INFO server.RaftServer$Division: 473d8c0f-fcdd-4210-80f8-a6eef5407d4b@group-3DA9FE7C4057: set configuration 7: peers:[193991a4-d526-4123-97ec-0cf0bd3049b7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, 473d8c0f-fcdd-4210-80f8-a6eef5407d4b|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=peers:[193991a4-d526-4123-97ec-0cf0bd3049b7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[]
scm2.org_1   | 2022-10-20 02:08:45,485 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm2.org_1   | 2022-10-20 02:08:45,506 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
scm2.org_1   | 2022-10-20 02:08:45,514 [473d8c0f-fcdd-4210-80f8-a6eef5407d4b-server-thread3] INFO server.RaftServer$Division: 473d8c0f-fcdd-4210-80f8-a6eef5407d4b@group-3DA9FE7C4057: set configuration 9: peers:[193991a4-d526-4123-97ec-0cf0bd3049b7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, 473d8c0f-fcdd-4210-80f8-a6eef5407d4b|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
scm2.org_1   | 2022-10-20 02:08:46,026 [Listener at 0.0.0.0/9860] INFO ha.SCMHAManagerImpl: Successfully added SCM scm2 to group group-3DA9FE7C4057:[193991a4-d526-4123-97ec-0cf0bd3049b7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, 473d8c0f-fcdd-4210-80f8-a6eef5407d4b|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]
scm2.org_1   | 2022-10-20 02:08:46,033 [Listener at 0.0.0.0/9860] INFO ha.InterSCMGrpcService: Starting SCM Grpc Service at port 9895
scm2.org_1   | 2022-10-20 02:08:46,045 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Starting token manager
scm2.org_1   | 2022-10-20 02:08:46,045 [Listener at 0.0.0.0/9860] INFO token.ContainerTokenSecretManager: Updating the current master key for generating tokens
scm2.org_1   | 2022-10-20 02:08:46,190 [473d8c0f-fcdd-4210-80f8-a6eef5407d4b@group-3DA9FE7C4057-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-10-20 02:08:46,190 [473d8c0f-fcdd-4210-80f8-a6eef5407d4b@group-3DA9FE7C4057-StateMachineUpdater] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm2.org_1   | 2022-10-20 02:08:46,190 [473d8c0f-fcdd-4210-80f8-a6eef5407d4b@group-3DA9FE7C4057-StateMachineUpdater] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm2.org_1   | 2022-10-20 02:08:46,243 [473d8c0f-fcdd-4210-80f8-a6eef5407d4b@group-3DA9FE7C4057-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-10-20 02:08:46,326 [Listener at 0.0.0.0/9860] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
scm2.org_1   | 2022-10-20 02:08:46,375 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
scm2.org_1   | 2022-10-20 02:08:46,375 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
scm2.org_1   | 2022-10-20 02:08:47,111 [Listener at 0.0.0.0/9860] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
scm2.org_1   | 2022-10-20 02:08:47,137 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm2.org_1   | 2022-10-20 02:08:47,236 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
scm2.org_1   | 2022-10-20 02:08:47,236 [Listener at 0.0.0.0/9860] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
scm2.org_1   | 2022-10-20 02:08:47,236 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
scm2.org_1   | 2022-10-20 02:08:47,238 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm2.org_1   | 2022-10-20 02:08:47,239 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
scm2.org_1   | 2022-10-20 02:08:47,279 [Listener at 0.0.0.0/9860] INFO server.SCMSecurityProtocolServer: Starting RPC server for SCMSecurityProtocolServer. is listening at /0.0.0.0:9961
scm2.org_1   | 2022-10-20 02:08:47,296 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm2.org_1   | 2022-10-20 02:08:47,296 [IPC Server listener on 9961] INFO ipc.Server: IPC Server listener on 9961: starting
scm2.org_1   | 2022-10-20 02:08:47,297 [Listener at 0.0.0.0/9860] INFO server.SCMUpdateServiceGrpcServer: SCMUpdateService starting
scm2.org_1   | 2022-10-20 02:08:47,494 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
scm2.org_1   | 2022-10-20 02:08:47,497 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
scm2.org_1   | 2022-10-20 02:08:47,505 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
scm2.org_1   | 2022-10-20 02:08:47,773 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Persist certificate serialId 1003431474332 on Scm Bootstrap Node 473d8c0f-fcdd-4210-80f8-a6eef5407d4b
scm2.org_1   | 2022-10-20 02:08:47,778 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Persist certificate serialId 1 on Scm Bootstrap Node 473d8c0f-fcdd-4210-80f8-a6eef5407d4b
scm2.org_1   | 2022-10-20 02:08:47,843 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5af535ff] INFO util.JvmPauseMonitor: Starting JVM pause monitor
scm2.org_1   | 2022-10-20 02:08:47,882 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
scm2.org_1   | 2022-10-20 02:08:47,882 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
scm2.org_1   | 2022-10-20 02:08:47,883 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HttpAuthType: hdds.scm.http.auth.type = kerberos
scm2.org_1   | 2022-10-20 02:08:47,971 [Listener at 0.0.0.0/9860] INFO util.log: Logging initialized @18102ms to org.eclipse.jetty.util.log.Slf4jLog
scm2.org_1   | 2022-10-20 02:08:48,320 [Listener at 0.0.0.0/9860] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
scm2.org_1   | 2022-10-20 02:08:48,346 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
scm2.org_1   | 2022-10-20 02:08:48,347 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context scm
scm2.org_1   | 2022-10-20 02:08:48,347 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
scm2.org_1   | 2022-10-20 02:08:48,347 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
scm2.org_1   | 2022-10-20 02:08:48,353 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.scm.http.auth.kerberos.principal keytabKey: hdds.scm.http.auth.kerberos.keytab
scm2.org_1   | 2022-10-20 02:08:48,433 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Jetty bound to port 9876
scm2.org_1   | 2022-10-20 02:08:48,434 [Listener at 0.0.0.0/9860] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
scm2.org_1   | 2022-10-20 02:08:48,494 [Listener at 0.0.0.0/9860] INFO server.session: DefaultSessionIdManager workerName=node0
scm2.org_1   | 2022-10-20 02:08:48,499 [Listener at 0.0.0.0/9860] INFO server.session: No SessionScavenger set, using defaults
scm2.org_1   | 2022-10-20 02:08:48,500 [Listener at 0.0.0.0/9860] INFO server.session: node0 Scavenging every 600000ms
scm2.org_1   | 2022-10-20 02:08:48,534 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm2.org_1   | 2022-10-20 02:08:48,536 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@511936ad{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
scm2.org_1   | 2022-10-20 02:08:48,536 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@26c09f3f{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
scm2.org_1   | 2022-10-20 02:08:48,780 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm2.org_1   | 2022-10-20 02:08:48,817 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@2f087301{scm,/,file:///tmp/jetty-0_0_0_0-9876-hdds-server-scm-1_3_0-SNAPSHOT_jar-_-any-9458827325704521785/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar!/webapps/scm}
scm2.org_1   | 2022-10-20 02:08:48,834 [Listener at 0.0.0.0/9860] INFO server.AbstractConnector: Started ServerConnector@3c247c8d{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
scm2.org_1   | 2022-10-20 02:08:48,834 [Listener at 0.0.0.0/9860] INFO server.Server: Started @18965ms
scm2.org_1   | 2022-10-20 02:08:48,841 [Listener at 0.0.0.0/9860] INFO impl.MetricsSinkAdapter: Sink prometheus started
scm2.org_1   | 2022-10-20 02:08:48,841 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Registered sink prometheus
scm2.org_1   | 2022-10-20 02:08:48,846 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
scm2.org_1   | 2022-10-20 02:08:50,799 [473d8c0f-fcdd-4210-80f8-a6eef5407d4b@group-3DA9FE7C4057-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-10-20 02:09:06,498 [473d8c0f-fcdd-4210-80f8-a6eef5407d4b-server-thread3] INFO server.RaftServer$Division: 473d8c0f-fcdd-4210-80f8-a6eef5407d4b@group-3DA9FE7C4057: set configuration 13: peers:[193991a4-d526-4123-97ec-0cf0bd3049b7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, ff795c6b-74b4-4669-bf8f-984925e59fb3|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, 473d8c0f-fcdd-4210-80f8-a6eef5407d4b|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=peers:[193991a4-d526-4123-97ec-0cf0bd3049b7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, 473d8c0f-fcdd-4210-80f8-a6eef5407d4b|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[]
scm2.org_1   | 2022-10-20 02:09:06,560 [473d8c0f-fcdd-4210-80f8-a6eef5407d4b-server-thread3] INFO server.RaftServer$Division: 473d8c0f-fcdd-4210-80f8-a6eef5407d4b@group-3DA9FE7C4057: set configuration 15: peers:[193991a4-d526-4123-97ec-0cf0bd3049b7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, ff795c6b-74b4-4669-bf8f-984925e59fb3|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, 473d8c0f-fcdd-4210-80f8-a6eef5407d4b|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
scm2.org_1   | 2022-10-20 02:09:24,973 [473d8c0f-fcdd-4210-80f8-a6eef5407d4b@group-3DA9FE7C4057-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-10-20 02:09:26,499 [473d8c0f-fcdd-4210-80f8-a6eef5407d4b@group-3DA9FE7C4057-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-10-20 02:09:27,058 [473d8c0f-fcdd-4210-80f8-a6eef5407d4b@group-3DA9FE7C4057-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-10-20 02:09:31,097 [473d8c0f-fcdd-4210-80f8-a6eef5407d4b@group-3DA9FE7C4057-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-10-20 02:09:32,014 [473d8c0f-fcdd-4210-80f8-a6eef5407d4b@group-3DA9FE7C4057-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-10-20 02:09:33,365 [473d8c0f-fcdd-4210-80f8-a6eef5407d4b@group-3DA9FE7C4057-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-10-20 02:09:47,303 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:53796
scm2.org_1   | 2022-10-20 02:09:47,338 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-10-20 02:09:49,119 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:46126
scm2.org_1   | 2022-10-20 02:09:49,267 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-10-20 02:09:49,931 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:57546
scm2.org_1   | 2022-10-20 02:09:50,073 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-10-20 02:09:51,181 [IPC Server handler 13 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/922d5e53-2e0d-4e01-adf2-129a3cebef39
scm2.org_1   | 2022-10-20 02:09:51,222 [IPC Server handler 13 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 922d5e53-2e0d-4e01-adf2-129a3cebef39{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1082772173580, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm2.org_1   | 2022-10-20 02:09:51,349 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm2.org_1   | 2022-10-20 02:09:51,393 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 3 required.
scm2.org_1   | 2022-10-20 02:09:51,482 [IPC Server handler 16 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/e4d9a0e3-266c-4558-944a-cafbea7b03e5
scm2.org_1   | 2022-10-20 02:09:51,503 [IPC Server handler 16 on default port 9861] INFO node.SCMNodeManager: Registered Data node : e4d9a0e3-266c-4558-944a-cafbea7b03e5{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1081094776367, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm2.org_1   | 2022-10-20 02:09:51,509 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm2.org_1   | 2022-10-20 02:09:51,523 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 3 required.
scm2.org_1   | 2022-10-20 02:09:52,080 [IPC Server handler 13 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/4026c186-2529-49de-a2d8-dcba1039e356
scm2.org_1   | 2022-10-20 02:09:52,080 [IPC Server handler 13 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 4026c186-2529-49de-a2d8-dcba1039e356{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1083227860558, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm2.org_1   | 2022-10-20 02:09:52,080 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm2.org_1   | 2022-10-20 02:09:52,082 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 3 required.
scm2.org_1   | 2022-10-20 02:09:52,082 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm2.org_1   | 2022-10-20 02:09:52,082 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
scm2.org_1   | 2022-10-20 02:09:52,082 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm2.org_1   | 2022-10-20 02:09:52,083 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-10-20 02:12:46,950 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:34336
recon_1      | 2022-10-20 02:12:47,002 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:43274
recon_1      | 2022-10-20 02:12:47,017 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-10-20 02:12:47,019 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:54808
recon_1      | 2022-10-20 02:12:47,030 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-10-20 02:12:47,081 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm2.org_1   | 2022-10-20 02:09:52,084 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm2.org_1   | 2022-10-20 02:09:52,321 [473d8c0f-fcdd-4210-80f8-a6eef5407d4b@group-3DA9FE7C4057-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 461fda09-4c27-4112-8f11-ffbe57651d3a, Nodes: e4d9a0e3-266c-4558-944a-cafbea7b03e5{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-10-20T02:09:51.773Z[UTC]].
scm2.org_1   | 2022-10-20 02:09:52,325 [473d8c0f-fcdd-4210-80f8-a6eef5407d4b@group-3DA9FE7C4057-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-10-20 02:09:52,410 [473d8c0f-fcdd-4210-80f8-a6eef5407d4b@group-3DA9FE7C4057-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 904a7869-3351-4618-b9db-44e7403e0592, Nodes: 922d5e53-2e0d-4e01-adf2-129a3cebef39{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}e4d9a0e3-266c-4558-944a-cafbea7b03e5{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}4026c186-2529-49de-a2d8-dcba1039e356{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-10-20T02:09:52.276Z[UTC]].
scm2.org_1   | 2022-10-20 02:09:52,433 [473d8c0f-fcdd-4210-80f8-a6eef5407d4b@group-3DA9FE7C4057-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-10-20 02:09:52,517 [473d8c0f-fcdd-4210-80f8-a6eef5407d4b@group-3DA9FE7C4057-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: b2bba008-413d-43a9-8499-2749f1317dc3, Nodes: 922d5e53-2e0d-4e01-adf2-129a3cebef39{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-10-20T02:09:52.401Z[UTC]].
scm2.org_1   | 2022-10-20 02:09:52,535 [473d8c0f-fcdd-4210-80f8-a6eef5407d4b@group-3DA9FE7C4057-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-10-20 02:09:52,064 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
scm3.org_1   | 2022-10-20 02:09:52,065 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm3.org_1   | 2022-10-20 02:09:52,066 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
scm3.org_1   | 2022-10-20 02:09:52,066 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm3.org_1   | 2022-10-20 02:09:52,259 [ff795c6b-74b4-4669-bf8f-984925e59fb3@group-3DA9FE7C4057-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 461fda09-4c27-4112-8f11-ffbe57651d3a, Nodes: e4d9a0e3-266c-4558-944a-cafbea7b03e5{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-10-20T02:09:51.773Z[UTC]].
scm3.org_1   | 2022-10-20 02:09:52,274 [ff795c6b-74b4-4669-bf8f-984925e59fb3@group-3DA9FE7C4057-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-10-20 02:09:52,421 [ff795c6b-74b4-4669-bf8f-984925e59fb3@group-3DA9FE7C4057-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 904a7869-3351-4618-b9db-44e7403e0592, Nodes: 922d5e53-2e0d-4e01-adf2-129a3cebef39{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}e4d9a0e3-266c-4558-944a-cafbea7b03e5{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}4026c186-2529-49de-a2d8-dcba1039e356{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-10-20T02:09:52.276Z[UTC]].
scm3.org_1   | 2022-10-20 02:09:52,421 [ff795c6b-74b4-4669-bf8f-984925e59fb3@group-3DA9FE7C4057-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-10-20 02:09:52,556 [ff795c6b-74b4-4669-bf8f-984925e59fb3@group-3DA9FE7C4057-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: b2bba008-413d-43a9-8499-2749f1317dc3, Nodes: 922d5e53-2e0d-4e01-adf2-129a3cebef39{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-10-20T02:09:52.401Z[UTC]].
scm3.org_1   | 2022-10-20 02:09:52,557 [ff795c6b-74b4-4669-bf8f-984925e59fb3@group-3DA9FE7C4057-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-10-20 02:09:52,607 [ff795c6b-74b4-4669-bf8f-984925e59fb3@group-3DA9FE7C4057-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 928115e6-57fc-4e60-abe7-d27615e20c89, Nodes: 922d5e53-2e0d-4e01-adf2-129a3cebef39{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}4026c186-2529-49de-a2d8-dcba1039e356{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}e4d9a0e3-266c-4558-944a-cafbea7b03e5{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-10-20T02:09:52.497Z[UTC]].
scm3.org_1   | 2022-10-20 02:09:52,609 [ff795c6b-74b4-4669-bf8f-984925e59fb3@group-3DA9FE7C4057-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-10-20 02:09:52,630 [ff795c6b-74b4-4669-bf8f-984925e59fb3@group-3DA9FE7C4057-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: d523f193-8112-4e25-a36e-bc1bbcbc6578, Nodes: 4026c186-2529-49de-a2d8-dcba1039e356{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-10-20T02:09:52.579Z[UTC]].
scm3.org_1   | 2022-10-20 02:09:52,630 [ff795c6b-74b4-4669-bf8f-984925e59fb3@group-3DA9FE7C4057-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-10-20 02:09:55,009 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 461fda09-4c27-4112-8f11-ffbe57651d3a, Nodes: e4d9a0e3-266c-4558-944a-cafbea7b03e5{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:e4d9a0e3-266c-4558-944a-cafbea7b03e5, CreationTimestamp2022-10-20T02:09:51.773Z[UTC]] moved to OPEN state
scm3.org_1   | 2022-10-20 02:09:55,353 [ff795c6b-74b4-4669-bf8f-984925e59fb3@group-3DA9FE7C4057-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-10-20 02:09:55,666 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm3.org_1   | 2022-10-20 02:10:00,594 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm3.org_1   | 2022-10-20 02:10:03,021 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm1.org_1   | 2022-10-20 02:08:19,289 [193991a4-d526-4123-97ec-0cf0bd3049b7-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
scm1.org_1   | 2022-10-20 02:08:19,290 [193991a4-d526-4123-97ec-0cf0bd3049b7-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
scm1.org_1   | 2022-10-20 02:08:19,290 [193991a4-d526-4123-97ec-0cf0bd3049b7-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
scm1.org_1   | 2022-10-20 02:08:19,290 [193991a4-d526-4123-97ec-0cf0bd3049b7-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
scm1.org_1   | 2022-10-20 02:08:19,312 [193991a4-d526-4123-97ec-0cf0bd3049b7-impl-thread1] INFO server.RaftServer$Division: 193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057: set configuration 0: peers:[193991a4-d526-4123-97ec-0cf0bd3049b7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
scm1.org_1   | 2022-10-20 02:08:19,312 [193991a4-d526-4123-97ec-0cf0bd3049b7-impl-thread1] INFO segmented.LogSegment: Successfully read 1 entries from segment file /data/metadata/scm-ha/959c5f9a-2485-4f2a-8075-3da9fe7c4057/current/log_inprogress_0
scm1.org_1   | 2022-10-20 02:08:19,314 [193991a4-d526-4123-97ec-0cf0bd3049b7-impl-thread1] INFO segmented.SegmentedRaftLogWorker: 193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 0
scm1.org_1   | 2022-10-20 02:08:19,314 [193991a4-d526-4123-97ec-0cf0bd3049b7-impl-thread1] INFO segmented.SegmentedRaftLogWorker: 193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
scm1.org_1   | 2022-10-20 02:08:19,372 [193991a4-d526-4123-97ec-0cf0bd3049b7-impl-thread1] INFO server.RaftServer$Division: 193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057: start as a follower, conf=0: peers:[193991a4-d526-4123-97ec-0cf0bd3049b7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
scm1.org_1   | 2022-10-20 02:08:19,373 [193991a4-d526-4123-97ec-0cf0bd3049b7-impl-thread1] INFO server.RaftServer$Division: 193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057: changes role from      null to FOLLOWER at term 1 for startAsFollower
scm1.org_1   | 2022-10-20 02:08:19,374 [193991a4-d526-4123-97ec-0cf0bd3049b7-impl-thread1] INFO impl.RoleInfo: 193991a4-d526-4123-97ec-0cf0bd3049b7: start 193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-FollowerState
scm1.org_1   | 2022-10-20 02:08:19,375 [193991a4-d526-4123-97ec-0cf0bd3049b7-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-3DA9FE7C4057,id=193991a4-d526-4123-97ec-0cf0bd3049b7
scm1.org_1   | 2022-10-20 02:08:19,377 [193991a4-d526-4123-97ec-0cf0bd3049b7-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
scm1.org_1   | 2022-10-20 02:08:19,377 [193991a4-d526-4123-97ec-0cf0bd3049b7-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
scm1.org_1   | 2022-10-20 02:08:19,378 [193991a4-d526-4123-97ec-0cf0bd3049b7-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
scm1.org_1   | 2022-10-20 02:08:19,379 [193991a4-d526-4123-97ec-0cf0bd3049b7-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
scm1.org_1   | 2022-10-20 02:08:19,390 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
scm1.org_1   | 2022-10-20 02:08:19,390 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
scm1.org_1   | 2022-10-20 02:08:19,390 [Listener at 0.0.0.0/9860] INFO server.RaftServer: 193991a4-d526-4123-97ec-0cf0bd3049b7: start RPC server
scm1.org_1   | 2022-10-20 02:08:19,439 [Listener at 0.0.0.0/9860] INFO server.GrpcService: 193991a4-d526-4123-97ec-0cf0bd3049b7: GrpcService started, listening on 9894
scm1.org_1   | 2022-10-20 02:08:19,453 [Listener at 0.0.0.0/9860] INFO ha.SCMHAManagerImpl:  scm role is FOLLOWER peers [193991a4-d526-4123-97ec-0cf0bd3049b7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]
scm1.org_1   | 2022-10-20 02:08:19,453 [Listener at 0.0.0.0/9860] INFO ha.InterSCMGrpcService: Starting SCM Grpc Service at port 9895
scm1.org_1   | 2022-10-20 02:08:19,453 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-193991a4-d526-4123-97ec-0cf0bd3049b7: Started
scm1.org_1   | 2022-10-20 02:08:19,455 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Starting token manager
scm1.org_1   | 2022-10-20 02:08:19,457 [Listener at 0.0.0.0/9860] INFO token.ContainerTokenSecretManager: Updating the current master key for generating tokens
scm1.org_1   | 2022-10-20 02:08:19,531 [Listener at 0.0.0.0/9860] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
scm1.org_1   | 2022-10-20 02:08:19,539 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
scm1.org_1   | 2022-10-20 02:08:19,539 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
scm1.org_1   | 2022-10-20 02:08:19,803 [Listener at 0.0.0.0/9860] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
scm1.org_1   | 2022-10-20 02:08:19,803 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm1.org_1   | 2022-10-20 02:08:19,804 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
scm1.org_1   | 2022-10-20 02:08:19,826 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
scm1.org_1   | 2022-10-20 02:08:19,827 [Listener at 0.0.0.0/9860] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
scm1.org_1   | 2022-10-20 02:08:19,873 [Listener at 0.0.0.0/9860] INFO server.SCMSecurityProtocolServer: Starting RPC server for SCMSecurityProtocolServer. is listening at /0.0.0.0:9961
scm1.org_1   | 2022-10-20 02:08:19,875 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm1.org_1   | 2022-10-20 02:08:19,885 [Listener at 0.0.0.0/9860] INFO server.SCMUpdateServiceGrpcServer: SCMUpdateService starting
scm1.org_1   | 2022-10-20 02:08:19,891 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
scm1.org_1   | 2022-10-20 02:08:19,891 [IPC Server listener on 9961] INFO ipc.Server: IPC Server listener on 9961: starting
scm1.org_1   | 2022-10-20 02:08:19,894 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm1.org_1   | 2022-10-20 02:08:19,947 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4ae836cf] INFO util.JvmPauseMonitor: Starting JVM pause monitor
scm1.org_1   | 2022-10-20 02:08:19,980 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
scm1.org_1   | 2022-10-20 02:08:19,981 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
scm1.org_1   | 2022-10-20 02:08:19,982 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HttpAuthType: hdds.scm.http.auth.type = kerberos
scm1.org_1   | 2022-10-20 02:08:20,053 [Listener at 0.0.0.0/9860] INFO util.log: Logging initialized @5602ms to org.eclipse.jetty.util.log.Slf4jLog
scm1.org_1   | 2022-10-20 02:08:20,220 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41800
scm1.org_1   | 2022-10-20 02:08:20,236 [Listener at 0.0.0.0/9860] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
scm2.org_1   | 2022-10-20 02:09:52,586 [473d8c0f-fcdd-4210-80f8-a6eef5407d4b@group-3DA9FE7C4057-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 928115e6-57fc-4e60-abe7-d27615e20c89, Nodes: 922d5e53-2e0d-4e01-adf2-129a3cebef39{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}4026c186-2529-49de-a2d8-dcba1039e356{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}e4d9a0e3-266c-4558-944a-cafbea7b03e5{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-10-20T02:09:52.497Z[UTC]].
scm2.org_1   | 2022-10-20 02:09:52,589 [473d8c0f-fcdd-4210-80f8-a6eef5407d4b@group-3DA9FE7C4057-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-10-20 02:09:52,632 [473d8c0f-fcdd-4210-80f8-a6eef5407d4b@group-3DA9FE7C4057-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: d523f193-8112-4e25-a36e-bc1bbcbc6578, Nodes: 4026c186-2529-49de-a2d8-dcba1039e356{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-10-20T02:09:52.579Z[UTC]].
scm2.org_1   | 2022-10-20 02:09:52,635 [473d8c0f-fcdd-4210-80f8-a6eef5407d4b@group-3DA9FE7C4057-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-10-20 02:09:54,977 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 461fda09-4c27-4112-8f11-ffbe57651d3a, Nodes: e4d9a0e3-266c-4558-944a-cafbea7b03e5{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:e4d9a0e3-266c-4558-944a-cafbea7b03e5, CreationTimestamp2022-10-20T02:09:51.773Z[UTC]] moved to OPEN state
scm2.org_1   | 2022-10-20 02:09:55,345 [473d8c0f-fcdd-4210-80f8-a6eef5407d4b@group-3DA9FE7C4057-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-10-20 02:09:55,641 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm2.org_1   | 2022-10-20 02:10:00,596 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm2.org_1   | 2022-10-20 02:10:03,021 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm2.org_1   | 2022-10-20 02:10:03,396 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: d523f193-8112-4e25-a36e-bc1bbcbc6578, Nodes: 4026c186-2529-49de-a2d8-dcba1039e356{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:4026c186-2529-49de-a2d8-dcba1039e356, CreationTimestamp2022-10-20T02:09:52.579Z[UTC]] moved to OPEN state
scm2.org_1   | 2022-10-20 02:10:03,425 [473d8c0f-fcdd-4210-80f8-a6eef5407d4b@group-3DA9FE7C4057-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-10-20 02:10:05,659 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 928115e6-57fc-4e60-abe7-d27615e20c89, Nodes: 922d5e53-2e0d-4e01-adf2-129a3cebef39{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}4026c186-2529-49de-a2d8-dcba1039e356{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}e4d9a0e3-266c-4558-944a-cafbea7b03e5{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:4026c186-2529-49de-a2d8-dcba1039e356, CreationTimestamp2022-10-20T02:09:52.497Z[UTC]] moved to OPEN state
scm2.org_1   | 2022-10-20 02:10:05,661 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm2.org_1   | 2022-10-20 02:10:05,739 [473d8c0f-fcdd-4210-80f8-a6eef5407d4b@group-3DA9FE7C4057-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 1, healthy pipeline threshold count is 1
scm2.org_1   | 2022-10-20 02:10:08,494 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
scm2.org_1   | 2022-10-20 02:10:08,495 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
scm2.org_1   | 2022-10-20 02:10:08,495 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
scm2.org_1   | 2022-10-20 02:10:08,495 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
scm2.org_1   | 2022-10-20 02:10:08,495 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm2.org_1   | 2022-10-20 02:10:08,495 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
scm2.org_1   | 2022-10-20 02:10:23,854 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:42088
scm2.org_1   | 2022-10-20 02:10:23,889 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-10-20 02:10:03,369 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: d523f193-8112-4e25-a36e-bc1bbcbc6578, Nodes: 4026c186-2529-49de-a2d8-dcba1039e356{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:4026c186-2529-49de-a2d8-dcba1039e356, CreationTimestamp2022-10-20T02:09:52.579Z[UTC]] moved to OPEN state
scm3.org_1   | 2022-10-20 02:10:03,410 [ff795c6b-74b4-4669-bf8f-984925e59fb3@group-3DA9FE7C4057-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-10-20 02:10:05,660 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 928115e6-57fc-4e60-abe7-d27615e20c89, Nodes: 922d5e53-2e0d-4e01-adf2-129a3cebef39{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}4026c186-2529-49de-a2d8-dcba1039e356{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}e4d9a0e3-266c-4558-944a-cafbea7b03e5{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:4026c186-2529-49de-a2d8-dcba1039e356, CreationTimestamp2022-10-20T02:09:52.497Z[UTC]] moved to OPEN state
scm3.org_1   | 2022-10-20 02:10:05,663 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm3.org_1   | 2022-10-20 02:10:05,730 [ff795c6b-74b4-4669-bf8f-984925e59fb3@group-3DA9FE7C4057-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 1, healthy pipeline threshold count is 1
scm3.org_1   | 2022-10-20 02:10:08,475 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
scm3.org_1   | 2022-10-20 02:10:08,475 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
scm3.org_1   | 2022-10-20 02:10:08,475 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
scm3.org_1   | 2022-10-20 02:10:08,475 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
scm3.org_1   | 2022-10-20 02:10:08,475 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm3.org_1   | 2022-10-20 02:10:08,475 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
scm3.org_1   | 2022-10-20 02:10:23,845 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:36876
scm3.org_1   | 2022-10-20 02:10:23,869 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-10-20 02:10:23,871 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: b2bba008-413d-43a9-8499-2749f1317dc3, Nodes: 922d5e53-2e0d-4e01-adf2-129a3cebef39{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:922d5e53-2e0d-4e01-adf2-129a3cebef39, CreationTimestamp2022-10-20T02:09:52.401Z[UTC]] moved to OPEN state
scm3.org_1   | 2022-10-20 02:10:28,645 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 904a7869-3351-4618-b9db-44e7403e0592, Nodes: 922d5e53-2e0d-4e01-adf2-129a3cebef39{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}e4d9a0e3-266c-4558-944a-cafbea7b03e5{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}4026c186-2529-49de-a2d8-dcba1039e356{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:922d5e53-2e0d-4e01-adf2-129a3cebef39, CreationTimestamp2022-10-20T02:09:52.276Z[UTC]] moved to OPEN state
scm3.org_1   | 2022-10-20 02:10:33,078 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:36024
scm3.org_1   | 2022-10-20 02:10:33,107 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-10-20 02:10:38,525 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:46496
scm3.org_1   | 2022-10-20 02:10:38,535 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-10-20 02:10:55,440 [ff795c6b-74b4-4669-bf8f-984925e59fb3@group-3DA9FE7C4057-StateMachineUpdater] WARN ha.SequenceIdGenerator: Failed to allocate a batch for localId, expected lastId is 0, actual lastId is 109611004723200000.
scm3.org_1   | 2022-10-20 02:10:58,406 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:34270
scm3.org_1   | 2022-10-20 02:10:58,460 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-10-20 02:10:58,708 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37272
scm1.org_1   | 2022-10-20 02:08:20,243 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
scm1.org_1   | 2022-10-20 02:08:20,244 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context scm
scm1.org_1   | 2022-10-20 02:08:20,244 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
scm1.org_1   | 2022-10-20 02:08:20,244 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
scm1.org_1   | 2022-10-20 02:08:20,247 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.scm.http.auth.kerberos.principal keytabKey: hdds.scm.http.auth.kerberos.keytab
scm1.org_1   | 2022-10-20 02:08:20,270 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-10-20 02:08:20,324 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Jetty bound to port 9876
scm1.org_1   | 2022-10-20 02:08:20,334 [Listener at 0.0.0.0/9860] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
scm1.org_1   | 2022-10-20 02:08:20,456 [Listener at 0.0.0.0/9860] INFO server.session: DefaultSessionIdManager workerName=node0
scm1.org_1   | 2022-10-20 02:08:20,471 [Listener at 0.0.0.0/9860] INFO server.session: No SessionScavenger set, using defaults
scm1.org_1   | 2022-10-20 02:08:20,471 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:32827
scm1.org_1   | 2022-10-20 02:08:20,476 [Listener at 0.0.0.0/9860] INFO server.session: node0 Scavenging every 660000ms
scm1.org_1   | 2022-10-20 02:08:20,520 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-10-20 02:08:20,544 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm1.org_1   | 2022-10-20 02:08:20,546 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@55732ae6{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
scm1.org_1   | 2022-10-20 02:08:20,547 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@56da2437{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
scm1.org_1   | 2022-10-20 02:08:20,729 [IPC Server handler 0 on default port 9961] INFO ipc.Server: IPC Server handler 0 on default port 9961, call Call#0 Retry#9 org.apache.hadoop.hdds.protocol.SCMSecurityProtocol.submitRequest from 172.25.0.115:32827
scm1.org_1   | org.apache.hadoop.hdds.ratis.ServerNotLeaderException: Server:193991a4-d526-4123-97ec-0cf0bd3049b7 is not the leader. Could not determine the leader node.
scm1.org_1   | 	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:93)
scm1.org_1   | 	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:16080)
scm1.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465)
scm1.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578)
scm1.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)
scm1.org_1   | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
scm1.org_1   | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm1.org_1   | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm1.org_1   | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
scm1.org_1   | 2022-10-20 02:08:20,873 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm1.org_1   | 2022-10-20 02:08:20,891 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@38499139{scm,/,file:///tmp/jetty-0_0_0_0-9876-hdds-server-scm-1_3_0-SNAPSHOT_jar-_-any-10395782537777876677/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar!/webapps/scm}
scm1.org_1   | 2022-10-20 02:08:20,902 [Listener at 0.0.0.0/9860] INFO server.AbstractConnector: Started ServerConnector@17eb35fa{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
scm1.org_1   | 2022-10-20 02:08:20,903 [Listener at 0.0.0.0/9860] INFO server.Server: Started @6452ms
scm1.org_1   | 2022-10-20 02:08:20,911 [Listener at 0.0.0.0/9860] INFO impl.MetricsSinkAdapter: Sink prometheus started
scm1.org_1   | 2022-10-20 02:08:20,911 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Registered sink prometheus
scm1.org_1   | 2022-10-20 02:08:20,913 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
scm1.org_1   | 2022-10-20 02:08:21,934 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:47018
scm1.org_1   | 2022-10-20 02:08:21,946 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-10-20 02:08:24,444 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-FollowerState] INFO impl.FollowerState: 193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5070726715ns, electionTimeout:5051ms
scm1.org_1   | 2022-10-20 02:08:24,445 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-FollowerState] INFO impl.RoleInfo: 193991a4-d526-4123-97ec-0cf0bd3049b7: shutdown 193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-FollowerState
scm1.org_1   | 2022-10-20 02:08:24,446 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-FollowerState] INFO server.RaftServer$Division: 193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
scm1.org_1   | 2022-10-20 02:08:24,448 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
scm1.org_1   | 2022-10-20 02:08:24,448 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-FollowerState] INFO impl.RoleInfo: 193991a4-d526-4123-97ec-0cf0bd3049b7: start 193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-LeaderElection1
scm1.org_1   | 2022-10-20 02:08:24,459 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-LeaderElection1] INFO impl.LeaderElection: 193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-LeaderElection1 ELECTION round 0: submit vote requests at term 2 for 0: peers:[193991a4-d526-4123-97ec-0cf0bd3049b7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
scm2.org_1   | 2022-10-20 02:10:23,891 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: b2bba008-413d-43a9-8499-2749f1317dc3, Nodes: 922d5e53-2e0d-4e01-adf2-129a3cebef39{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:922d5e53-2e0d-4e01-adf2-129a3cebef39, CreationTimestamp2022-10-20T02:09:52.401Z[UTC]] moved to OPEN state
scm2.org_1   | 2022-10-20 02:10:33,084 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:43494
scm2.org_1   | 2022-10-20 02:10:33,116 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-10-20 02:10:38,502 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:43378
scm2.org_1   | 2022-10-20 02:10:38,531 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-10-20 02:10:55,432 [473d8c0f-fcdd-4210-80f8-a6eef5407d4b@group-3DA9FE7C4057-StateMachineUpdater] WARN ha.SequenceIdGenerator: Failed to allocate a batch for localId, expected lastId is 0, actual lastId is 109611004723200000.
scm2.org_1   | 2022-10-20 02:10:58,396 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:40116
scm2.org_1   | 2022-10-20 02:10:58,460 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-10-20 02:10:58,699 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:52150
scm2.org_1   | 2022-10-20 02:10:58,757 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:53660
scm2.org_1   | 2022-10-20 02:10:58,835 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-10-20 02:10:58,888 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-10-20 02:11:16,860 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:44882
scm2.org_1   | 2022-10-20 02:11:16,951 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:33040
scm2.org_1   | 2022-10-20 02:11:16,952 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:52110
scm2.org_1   | 2022-10-20 02:11:16,976 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-10-20 02:11:17,017 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-10-20 02:11:17,054 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-10-20 02:11:46,957 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:49896
scm2.org_1   | 2022-10-20 02:11:46,982 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:60786
scm2.org_1   | 2022-10-20 02:11:46,993 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:46092
scm2.org_1   | 2022-10-20 02:11:47,005 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-10-20 02:11:47,021 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-10-20 02:11:47,046 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-10-20 02:12:16,966 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:52070
scm2.org_1   | 2022-10-20 02:12:17,000 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-10-20 02:12:17,017 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:41770
scm2.org_1   | 2022-10-20 02:12:17,025 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-10-20 02:12:17,086 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:43854
scm2.org_1   | 2022-10-20 02:12:17,107 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-10-20 02:12:46,966 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35042
scm2.org_1   | 2022-10-20 02:12:47,028 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:57784
scm2.org_1   | 2022-10-20 02:12:47,039 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:41342
scm2.org_1   | 2022-10-20 02:12:47,075 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-10-20 02:12:47,080 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-10-20 02:12:47,088 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-10-20 02:10:58,762 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48000
scm3.org_1   | 2022-10-20 02:10:58,843 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-10-20 02:10:58,894 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-10-20 02:11:16,901 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35586
scm3.org_1   | 2022-10-20 02:11:16,934 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:42750
scm3.org_1   | 2022-10-20 02:11:16,970 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:45760
scm3.org_1   | 2022-10-20 02:11:16,994 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-10-20 02:11:17,020 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-10-20 02:11:17,073 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-10-20 02:11:46,920 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:57172
scm3.org_1   | 2022-10-20 02:11:46,920 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:59154
scm3.org_1   | 2022-10-20 02:11:46,940 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-10-20 02:11:46,989 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-10-20 02:11:46,993 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:45646
scm3.org_1   | 2022-10-20 02:11:47,065 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-10-20 02:12:16,907 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:42094
scm3.org_1   | 2022-10-20 02:12:16,950 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:60324
scm3.org_1   | 2022-10-20 02:12:16,952 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-10-20 02:12:16,977 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-10-20 02:12:17,090 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:36114
scm3.org_1   | 2022-10-20 02:12:17,107 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-10-20 02:12:46,961 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:52942
scm3.org_1   | 2022-10-20 02:12:47,024 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35090
scm3.org_1   | 2022-10-20 02:12:47,035 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:36582
scm3.org_1   | 2022-10-20 02:12:47,046 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-10-20 02:12:47,073 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-10-20 02:12:47,081 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-10-20 02:08:24,459 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-LeaderElection1] INFO impl.LeaderElection: 193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-LeaderElection1 ELECTION round 0: result PASSED (term=2)
scm1.org_1   | 2022-10-20 02:08:24,460 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-LeaderElection1] INFO impl.RoleInfo: 193991a4-d526-4123-97ec-0cf0bd3049b7: shutdown 193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-LeaderElection1
scm1.org_1   | 2022-10-20 02:08:24,460 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-LeaderElection1] INFO server.RaftServer$Division: 193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
scm1.org_1   | 2022-10-20 02:08:24,460 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-LeaderElection1] INFO ha.SCMStateMachine: current SCM becomes leader of term 2.
scm1.org_1   | 2022-10-20 02:08:24,460 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-LeaderElection1] INFO ha.SCMContext: update <isLeader,term> from <false,0> to <true,2>
scm1.org_1   | 2022-10-20 02:08:24,463 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-LeaderElection1] INFO server.RaftServer$Division: 193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057: change Leader from null to 193991a4-d526-4123-97ec-0cf0bd3049b7 at term 2 for becomeLeader, leader elected after 7044ms
scm1.org_1   | 2022-10-20 02:08:24,471 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
scm1.org_1   | 2022-10-20 02:08:24,475 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
scm1.org_1   | 2022-10-20 02:08:24,476 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
scm1.org_1   | 2022-10-20 02:08:24,480 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
scm1.org_1   | 2022-10-20 02:08:24,480 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
scm1.org_1   | 2022-10-20 02:08:24,481 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
scm1.org_1   | 2022-10-20 02:08:24,484 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
scm1.org_1   | 2022-10-20 02:08:24,485 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
scm1.org_1   | 2022-10-20 02:08:24,489 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-LeaderElection1] INFO impl.RoleInfo: 193991a4-d526-4123-97ec-0cf0bd3049b7: start 193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-LeaderStateImpl
scm1.org_1   | 2022-10-20 02:08:24,510 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
scm1.org_1   | 2022-10-20 02:08:24,513 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/scm-ha/959c5f9a-2485-4f2a-8075-3da9fe7c4057/current/log_inprogress_0 to /data/metadata/scm-ha/959c5f9a-2485-4f2a-8075-3da9fe7c4057/current/log_0-0
scm1.org_1   | 2022-10-20 02:08:24,533 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-LeaderElection1] INFO server.RaftServer$Division: 193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057: set configuration 1: peers:[193991a4-d526-4123-97ec-0cf0bd3049b7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
scm1.org_1   | 2022-10-20 02:08:24,543 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/959c5f9a-2485-4f2a-8075-3da9fe7c4057/current/log_inprogress_1
scm1.org_1   | 2022-10-20 02:08:24,550 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-StateMachineUpdater] INFO ha.SCMContext: update <isLeaderReady> from <false> to <true>
scm1.org_1   | 2022-10-20 02:08:24,551 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-StateMachineUpdater] INFO pipeline.BackgroundPipelineCreator: Service BackgroundPipelineCreator transitions to RUNNING.
scm1.org_1   | 2022-10-20 02:08:24,560 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-10-20 02:08:24,560 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-StateMachineUpdater] INFO safemode.ContainerSafeModeRule: Refreshed one replica container threshold 0, currentThreshold 0
scm1.org_1   | 2022-10-20 02:08:24,561 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-StateMachineUpdater] INFO safemode.OneReplicaPipelineSafeModeRule: Refreshed Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm1.org_1   | 2022-10-20 02:08:24,561 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-StateMachineUpdater] INFO server.SCMDatanodeProtocolServer: ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:9861
scm1.org_1   | 2022-10-20 02:08:24,565 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm1.org_1   | 2022-10-20 02:08:24,565 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
scm1.org_1   | 2022-10-20 02:08:26,793 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for RECON recon, UUID: 7c536b99-4bf9-4353-a552-75069bb0347d
scm1.org_1   | 2022-10-20 02:08:27,191 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-10-20 02:08:27,197 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-StateMachineUpdater] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm1.org_1   | 2022-10-20 02:08:27,197 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-StateMachineUpdater] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm1.org_1   | 2022-10-20 02:08:28,350 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:34594
scm1.org_1   | 2022-10-20 02:08:28,361 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-10-20 02:08:28,362 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for scm scm2.org, nodeId: 473d8c0f-fcdd-4210-80f8-a6eef5407d4b
scm1.org_1   | 2022-10-20 02:08:29,260 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-10-20 02:08:39,986 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50942
scm1.org_1   | 2022-10-20 02:08:40,077 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-10-20 02:08:42,078 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:39351
scm1.org_1   | 2022-10-20 02:08:42,099 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-10-20 02:08:43,941 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:49182
scm1.org_1   | 2022-10-20 02:08:43,994 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-10-20 02:08:43,996 [IPC Server handler 98 on default port 9863] INFO ha.SCMRatisServerImpl: 193991a4-d526-4123-97ec-0cf0bd3049b7: Submitting SetConfiguration request to Ratis server with new SCM peers list: [193991a4-d526-4123-97ec-0cf0bd3049b7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, 473d8c0f-fcdd-4210-80f8-a6eef5407d4b|rpc:scm2.org:9894|priority:0|startupRole:FOLLOWER]
scm1.org_1   | 2022-10-20 02:08:44,019 [IPC Server handler 98 on default port 9863] INFO server.RaftServer$Division: 193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057: receive setConfiguration SetConfigurationRequest:client-A00D61090410->193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057, cid=1, seq=0, RW, null, SET_UNCONDITIONALLY, servers:[193991a4-d526-4123-97ec-0cf0bd3049b7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, 473d8c0f-fcdd-4210-80f8-a6eef5407d4b|rpc:scm2.org:9894|priority:0|startupRole:FOLLOWER], listeners:[]
scm1.org_1   | 2022-10-20 02:08:44,019 [IPC Server handler 98 on default port 9863] INFO server.RaftServer$Division: 193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-LeaderStateImpl: startSetConfiguration SetConfigurationRequest:client-A00D61090410->193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057, cid=1, seq=0, RW, null, SET_UNCONDITIONALLY, servers:[193991a4-d526-4123-97ec-0cf0bd3049b7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, 473d8c0f-fcdd-4210-80f8-a6eef5407d4b|rpc:scm2.org:9894|priority:0|startupRole:FOLLOWER], listeners:[]
scm1.org_1   | 2022-10-20 02:08:44,068 [IPC Server handler 98 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
scm1.org_1   | 2022-10-20 02:08:44,068 [IPC Server handler 98 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2022-10-20 02:08:44,069 [IPC Server handler 98 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1024 (custom)
scm1.org_1   | 2022-10-20 02:08:44,108 [IPC Server handler 98 on default port 9863] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
scm1.org_1   | 2022-10-20 02:08:44,109 [IPC Server handler 98 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm1.org_1   | 2022-10-20 02:08:44,109 [IPC Server handler 98 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm1.org_1   | 2022-10-20 02:08:44,109 [IPC Server handler 98 on default port 9863] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
scm1.org_1   | 2022-10-20 02:08:44,109 [IPC Server handler 98 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.wait-time.min = 10ms (default)
scm1.org_1   | 2022-10-20 02:08:44,137 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057->473d8c0f-fcdd-4210-80f8-a6eef5407d4b-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057->473d8c0f-fcdd-4210-80f8-a6eef5407d4b-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:1, i:0)
scm1.org_1   | 2022-10-20 02:08:44,158 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057->473d8c0f-fcdd-4210-80f8-a6eef5407d4b-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057->473d8c0f-fcdd-4210-80f8-a6eef5407d4b-GrpcLogAppender: send 193991a4-d526-4123-97ec-0cf0bd3049b7->473d8c0f-fcdd-4210-80f8-a6eef5407d4b#0-t2,notify:(t:1, i:0)
scm1.org_1   | 2022-10-20 02:08:44,169 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057->473d8c0f-fcdd-4210-80f8-a6eef5407d4b-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcServerProtocolClient: Build channel for 473d8c0f-fcdd-4210-80f8-a6eef5407d4b
scm1.org_1   | 2022-10-20 02:08:44,970 [grpc-default-executor-0] INFO server.GrpcLogAppender: 193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057->473d8c0f-fcdd-4210-80f8-a6eef5407d4b-InstallSnapshotResponseHandler: received the first reply 193991a4-d526-4123-97ec-0cf0bd3049b7<-473d8c0f-fcdd-4210-80f8-a6eef5407d4b#0:OK-t0,ALREADY_INSTALLED
scm1.org_1   | 2022-10-20 02:08:44,973 [grpc-default-executor-0] INFO server.GrpcLogAppender: 193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057->473d8c0f-fcdd-4210-80f8-a6eef5407d4b-InstallSnapshotResponseHandler: Follower snapshot is already at index 0.
scm1.org_1   | 2022-10-20 02:08:44,984 [grpc-default-executor-0] INFO leader.FollowerInfo: 193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057->473d8c0f-fcdd-4210-80f8-a6eef5407d4b: snapshotIndex: setUnconditionally 0 -> 0
scm1.org_1   | 2022-10-20 02:08:44,984 [grpc-default-executor-0] INFO leader.FollowerInfo: 193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057->473d8c0f-fcdd-4210-80f8-a6eef5407d4b: matchIndex: setUnconditionally 0 -> 0
scm1.org_1   | 2022-10-20 02:08:44,989 [grpc-default-executor-0] INFO leader.FollowerInfo: 193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057->473d8c0f-fcdd-4210-80f8-a6eef5407d4b: nextIndex: setUnconditionally 0 -> 1
scm1.org_1   | 2022-10-20 02:08:44,990 [grpc-default-executor-0] INFO leader.FollowerInfo: Follower 193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057->473d8c0f-fcdd-4210-80f8-a6eef5407d4b acknowledged installing snapshot
scm1.org_1   | 2022-10-20 02:08:44,999 [grpc-default-executor-0] INFO leader.FollowerInfo: 193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057->473d8c0f-fcdd-4210-80f8-a6eef5407d4b: nextIndex: updateToMax old=1, new=1, updated? false
scm1.org_1   | 2022-10-20 02:08:45,160 [grpc-default-executor-0] INFO leader.FollowerInfo: 193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057->473d8c0f-fcdd-4210-80f8-a6eef5407d4b: nextIndex: updateUnconditionally 7 -> 0
scm1.org_1   | 2022-10-20 02:08:45,173 [grpc-default-executor-0] INFO leader.FollowerInfo: 193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057->473d8c0f-fcdd-4210-80f8-a6eef5407d4b: nextIndex: updateUnconditionally 7 -> 0
scm1.org_1   | 2022-10-20 02:08:45,464 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-LeaderStateImpl] INFO server.RaftServer$Division: 193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057: set configuration 7: peers:[193991a4-d526-4123-97ec-0cf0bd3049b7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, 473d8c0f-fcdd-4210-80f8-a6eef5407d4b|rpc:scm2.org:9894|priority:0|startupRole:FOLLOWER]|listeners:[], old=peers:[193991a4-d526-4123-97ec-0cf0bd3049b7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[]
scm1.org_1   | 2022-10-20 02:08:45,494 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-LeaderStateImpl] INFO server.RaftServer$Division: 193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057: set configuration 9: peers:[193991a4-d526-4123-97ec-0cf0bd3049b7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, 473d8c0f-fcdd-4210-80f8-a6eef5407d4b|rpc:scm2.org:9894|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
scm1.org_1   | 2022-10-20 02:08:45,535 [IPC Server handler 98 on default port 9863] INFO ha.SCMRatisServerImpl: Successfully added new SCM: 473d8c0f-fcdd-4210-80f8-a6eef5407d4b.
scm1.org_1   | 2022-10-20 02:08:47,713 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:60596
scm1.org_1   | 2022-10-20 02:08:47,719 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-10-20 02:08:48,208 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.118:52728
scm1.org_1   | 2022-10-20 02:08:48,229 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-10-20 02:08:50,462 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.118:50702
scm1.org_1   | 2022-10-20 02:08:50,501 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-10-20 02:08:50,502 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for scm scm3.org, nodeId: ff795c6b-74b4-4669-bf8f-984925e59fb3
scm1.org_1   | 2022-10-20 02:08:50,800 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-10-20 02:08:51,649 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44806
scm1.org_1   | 2022-10-20 02:08:51,681 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-10-20 02:09:00,770 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.118:37930
scm1.org_1   | 2022-10-20 02:09:01,022 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-10-20 02:09:01,043 [IPC Server handler 96 on default port 9863] INFO ha.SCMRatisServerImpl: 193991a4-d526-4123-97ec-0cf0bd3049b7: Submitting SetConfiguration request to Ratis server with new SCM peers list: [193991a4-d526-4123-97ec-0cf0bd3049b7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, 473d8c0f-fcdd-4210-80f8-a6eef5407d4b|rpc:scm2.org:9894|priority:0|startupRole:FOLLOWER, ff795c6b-74b4-4669-bf8f-984925e59fb3|rpc:scm3.org:9894|priority:0|startupRole:FOLLOWER]
scm1.org_1   | 2022-10-20 02:09:01,048 [IPC Server handler 96 on default port 9863] INFO server.RaftServer$Division: 193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057: receive setConfiguration SetConfigurationRequest:client-A00D61090410->193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057, cid=2, seq=0, RW, null, SET_UNCONDITIONALLY, servers:[193991a4-d526-4123-97ec-0cf0bd3049b7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, 473d8c0f-fcdd-4210-80f8-a6eef5407d4b|rpc:scm2.org:9894|priority:0|startupRole:FOLLOWER, ff795c6b-74b4-4669-bf8f-984925e59fb3|rpc:scm3.org:9894|priority:0|startupRole:FOLLOWER], listeners:[]
scm1.org_1   | 2022-10-20 02:09:01,053 [IPC Server handler 96 on default port 9863] INFO server.RaftServer$Division: 193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-LeaderStateImpl: startSetConfiguration SetConfigurationRequest:client-A00D61090410->193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057, cid=2, seq=0, RW, null, SET_UNCONDITIONALLY, servers:[193991a4-d526-4123-97ec-0cf0bd3049b7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, 473d8c0f-fcdd-4210-80f8-a6eef5407d4b|rpc:scm2.org:9894|priority:0|startupRole:FOLLOWER, ff795c6b-74b4-4669-bf8f-984925e59fb3|rpc:scm3.org:9894|priority:0|startupRole:FOLLOWER], listeners:[]
scm1.org_1   | 2022-10-20 02:09:01,055 [IPC Server handler 96 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
scm1.org_1   | 2022-10-20 02:09:01,056 [IPC Server handler 96 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2022-10-20 02:09:01,063 [IPC Server handler 96 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1024 (custom)
scm1.org_1   | 2022-10-20 02:09:01,067 [IPC Server handler 96 on default port 9863] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
scm1.org_1   | 2022-10-20 02:09:01,073 [IPC Server handler 96 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm1.org_1   | 2022-10-20 02:09:01,073 [IPC Server handler 96 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm1.org_1   | 2022-10-20 02:09:01,073 [IPC Server handler 96 on default port 9863] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
scm1.org_1   | 2022-10-20 02:09:01,073 [IPC Server handler 96 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.wait-time.min = 10ms (default)
scm1.org_1   | 2022-10-20 02:09:01,094 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057->ff795c6b-74b4-4669-bf8f-984925e59fb3-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057->ff795c6b-74b4-4669-bf8f-984925e59fb3-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:1, i:0)
scm1.org_1   | 2022-10-20 02:09:01,098 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057->ff795c6b-74b4-4669-bf8f-984925e59fb3-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057->ff795c6b-74b4-4669-bf8f-984925e59fb3-GrpcLogAppender: send 193991a4-d526-4123-97ec-0cf0bd3049b7->ff795c6b-74b4-4669-bf8f-984925e59fb3#0-t2,notify:(t:1, i:0)
scm1.org_1   | 2022-10-20 02:09:01,121 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057->ff795c6b-74b4-4669-bf8f-984925e59fb3-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcServerProtocolClient: Build channel for ff795c6b-74b4-4669-bf8f-984925e59fb3
scm1.org_1   | 2022-10-20 02:09:05,063 [grpc-default-executor-1] INFO server.GrpcLogAppender: 193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057->ff795c6b-74b4-4669-bf8f-984925e59fb3-InstallSnapshotResponseHandler: received the first reply 193991a4-d526-4123-97ec-0cf0bd3049b7<-ff795c6b-74b4-4669-bf8f-984925e59fb3#0:OK-t0,ALREADY_INSTALLED
scm1.org_1   | 2022-10-20 02:09:05,068 [grpc-default-executor-1] INFO server.GrpcLogAppender: 193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057->ff795c6b-74b4-4669-bf8f-984925e59fb3-InstallSnapshotResponseHandler: Follower snapshot is already at index 0.
scm1.org_1   | 2022-10-20 02:09:05,070 [grpc-default-executor-1] INFO leader.FollowerInfo: 193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057->ff795c6b-74b4-4669-bf8f-984925e59fb3: snapshotIndex: setUnconditionally 0 -> 0
scm1.org_1   | 2022-10-20 02:09:05,070 [grpc-default-executor-1] INFO leader.FollowerInfo: 193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057->ff795c6b-74b4-4669-bf8f-984925e59fb3: matchIndex: setUnconditionally 0 -> 0
scm1.org_1   | 2022-10-20 02:09:05,070 [grpc-default-executor-1] INFO leader.FollowerInfo: 193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057->ff795c6b-74b4-4669-bf8f-984925e59fb3: nextIndex: setUnconditionally 0 -> 1
scm1.org_1   | 2022-10-20 02:09:05,070 [grpc-default-executor-1] INFO leader.FollowerInfo: Follower 193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057->ff795c6b-74b4-4669-bf8f-984925e59fb3 acknowledged installing snapshot
scm1.org_1   | 2022-10-20 02:09:05,073 [grpc-default-executor-1] INFO leader.FollowerInfo: 193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057->ff795c6b-74b4-4669-bf8f-984925e59fb3: nextIndex: updateToMax old=1, new=1, updated? false
scm1.org_1   | 2022-10-20 02:09:05,544 [grpc-default-executor-1] INFO leader.FollowerInfo: 193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057->ff795c6b-74b4-4669-bf8f-984925e59fb3: nextIndex: updateUnconditionally 13 -> 0
scm1.org_1   | 2022-10-20 02:09:05,595 [grpc-default-executor-1] INFO leader.FollowerInfo: 193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057->ff795c6b-74b4-4669-bf8f-984925e59fb3: nextIndex: updateUnconditionally 13 -> 0
scm1.org_1   | 2022-10-20 02:09:06,425 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-LeaderStateImpl] INFO server.RaftServer$Division: 193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057: set configuration 13: peers:[193991a4-d526-4123-97ec-0cf0bd3049b7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, ff795c6b-74b4-4669-bf8f-984925e59fb3|rpc:scm3.org:9894|priority:0|startupRole:FOLLOWER, 473d8c0f-fcdd-4210-80f8-a6eef5407d4b|rpc:scm2.org:9894|priority:0|startupRole:FOLLOWER]|listeners:[], old=peers:[193991a4-d526-4123-97ec-0cf0bd3049b7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, 473d8c0f-fcdd-4210-80f8-a6eef5407d4b|rpc:scm2.org:9894|priority:0|startupRole:FOLLOWER]|listeners:[]
scm1.org_1   | 2022-10-20 02:09:06,521 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-LeaderStateImpl] INFO server.RaftServer$Division: 193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057: set configuration 15: peers:[193991a4-d526-4123-97ec-0cf0bd3049b7|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, ff795c6b-74b4-4669-bf8f-984925e59fb3|rpc:scm3.org:9894|priority:0|startupRole:FOLLOWER, 473d8c0f-fcdd-4210-80f8-a6eef5407d4b|rpc:scm2.org:9894|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
scm1.org_1   | 2022-10-20 02:09:06,605 [IPC Server handler 96 on default port 9863] INFO ha.SCMRatisServerImpl: Successfully added new SCM: ff795c6b-74b4-4669-bf8f-984925e59fb3.
scm1.org_1   | 2022-10-20 02:09:08,814 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:56820
scm1.org_1   | 2022-10-20 02:09:08,934 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-10-20 02:09:12,952 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.118:57886
scm1.org_1   | 2022-10-20 02:09:12,971 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-10-20 02:09:20,257 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:36246
scm1.org_1   | 2022-10-20 02:09:20,419 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-10-20 02:09:21,653 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:46454
scm1.org_1   | 2022-10-20 02:09:21,758 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-10-20 02:09:21,823 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:42788
scm1.org_1   | 2022-10-20 02:09:21,938 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-10-20 02:09:24,455 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:42978
scm1.org_1   | 2022-10-20 02:09:24,530 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-10-20 02:09:24,530 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn 7b621abfba13, UUID: e4d9a0e3-266c-4558-944a-cafbea7b03e5
scm1.org_1   | 2022-10-20 02:09:24,958 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-10-20 02:09:26,015 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:59594
scm1.org_1   | 2022-10-20 02:09:26,212 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-10-20 02:09:26,213 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn c2c35b3075dc, UUID: 922d5e53-2e0d-4e01-adf2-129a3cebef39
scm1.org_1   | 2022-10-20 02:09:26,432 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-10-20 02:09:26,605 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:55410
scm1.org_1   | 2022-10-20 02:09:26,658 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-10-20 02:09:26,670 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn 99666f78dec4, UUID: 4026c186-2529-49de-a2d8-dcba1039e356
scm1.org_1   | 2022-10-20 02:09:27,036 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-10-20 02:09:30,681 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:39670
scm1.org_1   | 2022-10-20 02:09:30,686 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-10-20 02:09:30,711 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for om om1, UUID: b3284964-e229-40a7-8579-5dae2bfa3f4b
scm1.org_1   | 2022-10-20 02:09:31,083 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-10-20 02:09:31,812 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:41724
scm1.org_1   | 2022-10-20 02:09:31,834 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-10-20 02:09:31,849 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for om om2, UUID: c2b192f1-b9fd-4485-abd9-588a66054fa5
scm1.org_1   | 2022-10-20 02:09:31,998 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-10-20 02:09:33,162 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:47016
scm1.org_1   | 2022-10-20 02:09:33,221 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-10-20 02:09:33,238 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for om om3, UUID: 3568c585-a165-4b4a-8097-788955553b43
scm1.org_1   | 2022-10-20 02:09:33,346 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-10-20 02:09:33,384 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:43240
scm1.org_1   | 2022-10-20 02:09:33,439 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-10-20 02:09:35,097 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:51982
scm1.org_1   | 2022-10-20 02:09:35,161 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-10-20 02:09:35,720 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34062
scm1.org_1   | 2022-10-20 02:09:35,730 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-10-20 02:09:38,327 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38308
scm1.org_1   | 2022-10-20 02:09:38,403 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-10-20 02:09:47,223 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:56798
scm1.org_1   | 2022-10-20 02:09:47,226 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-10-20 02:09:49,349 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37450
scm1.org_1   | 2022-10-20 02:09:49,467 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-10-20 02:09:49,965 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:38648
scm1.org_1   | 2022-10-20 02:09:50,080 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-10-20 02:09:51,546 [IPC Server handler 29 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/e4d9a0e3-266c-4558-944a-cafbea7b03e5
scm1.org_1   | 2022-10-20 02:09:51,548 [IPC Server handler 29 on default port 9861] INFO node.SCMNodeManager: Registered Data node : e4d9a0e3-266c-4558-944a-cafbea7b03e5{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1081094776367, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm1.org_1   | 2022-10-20 02:09:51,567 [IPC Server handler 22 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/922d5e53-2e0d-4e01-adf2-129a3cebef39
scm1.org_1   | 2022-10-20 02:09:51,575 [IPC Server handler 22 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 922d5e53-2e0d-4e01-adf2-129a3cebef39{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1082772173580, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm1.org_1   | 2022-10-20 02:09:51,677 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm1.org_1   | 2022-10-20 02:09:51,684 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm1.org_1   | 2022-10-20 02:09:51,685 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 3 required.
scm1.org_1   | 2022-10-20 02:09:51,774 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=461fda09-4c27-4112-8f11-ffbe57651d3a to datanode:e4d9a0e3-266c-4558-944a-cafbea7b03e5
scm1.org_1   | 2022-10-20 02:09:51,806 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 3 required.
scm1.org_1   | 2022-10-20 02:09:52,115 [IPC Server handler 42 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/4026c186-2529-49de-a2d8-dcba1039e356
scm1.org_1   | 2022-10-20 02:09:52,118 [IPC Server handler 42 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 4026c186-2529-49de-a2d8-dcba1039e356{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1083227860558, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm1.org_1   | 2022-10-20 02:09:52,119 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm1.org_1   | 2022-10-20 02:09:52,132 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 461fda09-4c27-4112-8f11-ffbe57651d3a, Nodes: e4d9a0e3-266c-4558-944a-cafbea7b03e5{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-10-20T02:09:51.773Z[UTC]].
scm1.org_1   | 2022-10-20 02:09:52,148 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 3 required.
scm1.org_1   | 2022-10-20 02:09:52,148 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm1.org_1   | 2022-10-20 02:09:52,159 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-10-20 02:09:52,200 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
scm1.org_1   | 2022-10-20 02:09:52,219 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm1.org_1   | 2022-10-20 02:09:52,220 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
scm1.org_1   | 2022-10-20 02:09:52,220 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm1.org_1   | 2022-10-20 02:09:52,276 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=904a7869-3351-4618-b9db-44e7403e0592 to datanode:922d5e53-2e0d-4e01-adf2-129a3cebef39
scm1.org_1   | 2022-10-20 02:09:52,300 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=904a7869-3351-4618-b9db-44e7403e0592 to datanode:e4d9a0e3-266c-4558-944a-cafbea7b03e5
scm1.org_1   | 2022-10-20 02:09:52,305 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=904a7869-3351-4618-b9db-44e7403e0592 to datanode:4026c186-2529-49de-a2d8-dcba1039e356
scm1.org_1   | 2022-10-20 02:09:52,384 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 904a7869-3351-4618-b9db-44e7403e0592, Nodes: 922d5e53-2e0d-4e01-adf2-129a3cebef39{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}e4d9a0e3-266c-4558-944a-cafbea7b03e5{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}4026c186-2529-49de-a2d8-dcba1039e356{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-10-20T02:09:52.276Z[UTC]].
scm1.org_1   | 2022-10-20 02:09:52,397 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-10-20 02:09:52,401 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=b2bba008-413d-43a9-8499-2749f1317dc3 to datanode:922d5e53-2e0d-4e01-adf2-129a3cebef39
scm1.org_1   | 2022-10-20 02:09:52,488 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: b2bba008-413d-43a9-8499-2749f1317dc3, Nodes: 922d5e53-2e0d-4e01-adf2-129a3cebef39{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-10-20T02:09:52.401Z[UTC]].
scm1.org_1   | 2022-10-20 02:09:52,496 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-10-20 02:09:52,497 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=928115e6-57fc-4e60-abe7-d27615e20c89 to datanode:922d5e53-2e0d-4e01-adf2-129a3cebef39
scm1.org_1   | 2022-10-20 02:09:52,513 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=928115e6-57fc-4e60-abe7-d27615e20c89 to datanode:4026c186-2529-49de-a2d8-dcba1039e356
scm1.org_1   | 2022-10-20 02:09:52,513 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=928115e6-57fc-4e60-abe7-d27615e20c89 to datanode:e4d9a0e3-266c-4558-944a-cafbea7b03e5
scm1.org_1   | 2022-10-20 02:09:52,563 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 928115e6-57fc-4e60-abe7-d27615e20c89, Nodes: 922d5e53-2e0d-4e01-adf2-129a3cebef39{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}4026c186-2529-49de-a2d8-dcba1039e356{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}e4d9a0e3-266c-4558-944a-cafbea7b03e5{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-10-20T02:09:52.497Z[UTC]].
scm1.org_1   | 2022-10-20 02:09:52,563 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-10-20 02:09:52,563 [RatisPipelineUtilsThread - 0] INFO pipeline.PipelineManagerImpl: Pipeline: PipelineID=928115e6-57fc-4e60-abe7-d27615e20c89 contains same datanodes as previous pipelines: PipelineID=904a7869-3351-4618-b9db-44e7403e0592 nodeIds: 922d5e53-2e0d-4e01-adf2-129a3cebef39, 4026c186-2529-49de-a2d8-dcba1039e356, e4d9a0e3-266c-4558-944a-cafbea7b03e5
scm1.org_1   | 2022-10-20 02:09:52,579 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=d523f193-8112-4e25-a36e-bc1bbcbc6578 to datanode:4026c186-2529-49de-a2d8-dcba1039e356
scm1.org_1   | 2022-10-20 02:09:52,616 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: d523f193-8112-4e25-a36e-bc1bbcbc6578, Nodes: 4026c186-2529-49de-a2d8-dcba1039e356{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-10-20T02:09:52.579Z[UTC]].
scm1.org_1   | 2022-10-20 02:09:52,616 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-10-20 02:09:54,349 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:50848
scm1.org_1   | 2022-10-20 02:09:54,449 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-10-20 02:09:54,873 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:42106
scm1.org_1   | 2022-10-20 02:09:54,897 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:46603
scm1.org_1   | 2022-10-20 02:09:54,914 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-10-20 02:09:54,976 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-10-20 02:09:55,119 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 461fda09-4c27-4112-8f11-ffbe57651d3a, Nodes: e4d9a0e3-266c-4558-944a-cafbea7b03e5{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:e4d9a0e3-266c-4558-944a-cafbea7b03e5, CreationTimestamp2022-10-20T02:09:51.773Z[UTC]] moved to OPEN state
scm1.org_1   | 2022-10-20 02:09:55,314 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-10-20 02:09:55,402 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm1.org_1   | 2022-10-20 02:09:55,670 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm1.org_1   | 2022-10-20 02:09:57,477 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:40888
scm1.org_1   | 2022-10-20 02:09:57,599 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-10-20 02:10:00,617 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm1.org_1   | 2022-10-20 02:10:03,045 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm1.org_1   | 2022-10-20 02:10:03,378 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: d523f193-8112-4e25-a36e-bc1bbcbc6578, Nodes: 4026c186-2529-49de-a2d8-dcba1039e356{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:4026c186-2529-49de-a2d8-dcba1039e356, CreationTimestamp2022-10-20T02:09:52.579Z[UTC]] moved to OPEN state
scm1.org_1   | 2022-10-20 02:10:03,406 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-10-20 02:10:03,407 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm1.org_1   | 2022-10-20 02:10:04,304 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:55508
scm1.org_1   | 2022-10-20 02:10:04,334 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-10-20 02:10:04,686 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:38066
scm1.org_1   | 2022-10-20 02:10:04,704 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-10-20 02:10:05,677 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 928115e6-57fc-4e60-abe7-d27615e20c89, Nodes: 922d5e53-2e0d-4e01-adf2-129a3cebef39{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}4026c186-2529-49de-a2d8-dcba1039e356{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}e4d9a0e3-266c-4558-944a-cafbea7b03e5{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:4026c186-2529-49de-a2d8-dcba1039e356, CreationTimestamp2022-10-20T02:09:52.497Z[UTC]] moved to OPEN state
scm1.org_1   | 2022-10-20 02:10:05,722 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 1, healthy pipeline threshold count is 1
scm1.org_1   | 2022-10-20 02:10:05,727 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
scm1.org_1   | 2022-10-20 02:10:05,741 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
scm1.org_1   | 2022-10-20 02:10:05,741 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
scm1.org_1   | 2022-10-20 02:10:05,750 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
scm1.org_1   | 2022-10-20 02:10:05,750 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm1.org_1   | 2022-10-20 02:10:05,751 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
scm1.org_1   | 2022-10-20 02:10:05,755 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO BackgroundPipelineScrubber: Service BackgroundPipelineScrubber transitions to RUNNING.
scm1.org_1   | 2022-10-20 02:10:05,755 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ExpiredContainerReplicaOpScrubber: Service ExpiredContainerReplicaOpScrubber transitions to RUNNING.
scm1.org_1   | 2022-10-20 02:10:05,755 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO replication.ReplicationManager: Service ReplicationManager transitions to RUNNING.
scm1.org_1   | 2022-10-20 02:10:05,798 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN balancer.ContainerBalancer: Could not find persisted configuration for ContainerBalancer when checking if ContainerBalancer should run. ContainerBalancer should not run now.
scm1.org_1   | 2022-10-20 02:10:06,809 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:40826
scm1.org_1   | 2022-10-20 02:10:06,832 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-10-20 02:10:08,558 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47254
scm1.org_1   | 2022-10-20 02:10:08,668 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-10-20 02:10:23,878 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:32954
scm1.org_1   | 2022-10-20 02:10:23,894 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:36613
scm1.org_1   | 2022-10-20 02:10:23,896 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-10-20 02:10:23,902 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-10-20 02:10:23,904 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: b2bba008-413d-43a9-8499-2749f1317dc3, Nodes: 922d5e53-2e0d-4e01-adf2-129a3cebef39{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:922d5e53-2e0d-4e01-adf2-129a3cebef39, CreationTimestamp2022-10-20T02:09:52.401Z[UTC]] moved to OPEN state
scm1.org_1   | 2022-10-20 02:10:28,647 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 904a7869-3351-4618-b9db-44e7403e0592, Nodes: 922d5e53-2e0d-4e01-adf2-129a3cebef39{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}e4d9a0e3-266c-4558-944a-cafbea7b03e5{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}4026c186-2529-49de-a2d8-dcba1039e356{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:922d5e53-2e0d-4e01-adf2-129a3cebef39, CreationTimestamp2022-10-20T02:09:52.276Z[UTC]] moved to OPEN state
scm1.org_1   | 2022-10-20 02:10:33,089 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44084
scm1.org_1   | 2022-10-20 02:10:33,112 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-10-20 02:10:38,524 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:58250
scm1.org_1   | 2022-10-20 02:10:38,535 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-10-20 02:10:55,213 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:53302
scm1.org_1   | 2022-10-20 02:10:55,225 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-10-20 02:10:55,292 [IPC Server handler 51 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for containerId, change lastId from 0 to 1000.
scm1.org_1   | 2022-10-20 02:10:55,417 [193991a4-d526-4123-97ec-0cf0bd3049b7@group-3DA9FE7C4057-StateMachineUpdater] WARN ha.SequenceIdGenerator: Failed to allocate a batch for localId, expected lastId is 0, actual lastId is 109611004723200000.
scm1.org_1   | 2022-10-20 02:10:55,441 [IPC Server handler 51 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for localId, change lastId from 109611004723200000 to 109611004723201000.
scm1.org_1   | 2022-10-20 02:10:57,997 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:38262
scm1.org_1   | 2022-10-20 02:10:58,009 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-10-20 02:10:58,213 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:49736
scm1.org_1   | 2022-10-20 02:10:58,232 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:60066
scm1.org_1   | 2022-10-20 02:10:58,236 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-10-20 02:10:58,241 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-10-20 02:10:58,401 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48764
scm1.org_1   | 2022-10-20 02:10:58,508 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-10-20 02:10:58,610 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:34397
scm1.org_1   | 2022-10-20 02:10:58,629 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-10-20 02:10:58,723 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:55092
scm1.org_1   | 2022-10-20 02:10:58,765 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:34654
scm1.org_1   | 2022-10-20 02:10:58,835 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-10-20 02:10:58,875 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-10-20 02:11:14,506 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:54790
scm1.org_1   | 2022-10-20 02:11:14,511 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-10-20 02:11:16,900 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56422
scm1.org_1   | 2022-10-20 02:11:16,963 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:34900
scm1.org_1   | 2022-10-20 02:11:16,976 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47144
scm1.org_1   | 2022-10-20 02:11:17,022 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-10-20 02:11:17,038 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-10-20 02:11:17,080 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-10-20 02:11:17,094 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:46623
scm1.org_1   | 2022-10-20 02:11:17,099 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-10-20 02:11:40,036 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:51434
scm1.org_1   | 2022-10-20 02:11:40,039 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-10-20 02:11:47,017 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:46640
scm1.org_1   | 2022-10-20 02:11:47,022 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:55620
scm1.org_1   | 2022-10-20 02:11:47,032 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34890
scm1.org_1   | 2022-10-20 02:11:47,040 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-10-20 02:11:47,062 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-10-20 02:11:47,073 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-10-20 02:11:53,198 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:40378
scm1.org_1   | 2022-10-20 02:11:53,200 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-10-20 02:12:04,628 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:56466
scm1.org_1   | 2022-10-20 02:12:04,639 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-10-20 02:12:04,731 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:60258
scm1.org_1   | 2022-10-20 02:12:04,740 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-10-20 02:12:15,224 [IPC Server handler 87 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for delTxnId, change lastId from 0 to 1000.
scm1.org_1   | 2022-10-20 02:12:17,058 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46744
scm1.org_1   | 2022-10-20 02:12:17,065 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:52538
scm1.org_1   | 2022-10-20 02:12:17,069 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-10-20 02:12:17,070 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-10-20 02:12:17,096 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37598
scm1.org_1   | 2022-10-20 02:12:17,113 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-10-20 02:12:33,563 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:52560
scm1.org_1   | 2022-10-20 02:12:33,570 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-10-20 02:12:46,886 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:32798
scm1.org_1   | 2022-10-20 02:12:46,998 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:51392
scm1.org_1   | 2022-10-20 02:12:47,019 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:36660
scm1.org_1   | 2022-10-20 02:12:47,046 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-10-20 02:12:47,059 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-10-20 02:12:47,066 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
