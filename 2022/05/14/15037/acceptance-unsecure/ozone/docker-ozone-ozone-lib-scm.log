Attaching to ozone_datanode_2, ozone_recon_1, ozone_datanode_5, ozone_om_1, ozone_datanode_1, ozone_s3g_1, ozone_datanode_3, ozone_scm_1, ozone_datanode_4
datanode_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
datanode_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_1  | 2022-05-14 12:58:33,363 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_1  | /************************************************************
datanode_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode_1  | STARTUP_MSG:   host = 85c32a2ed606/172.18.0.6
datanode_1  | STARTUP_MSG:   args = []
datanode_1  | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
datanode_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.0.4.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.3.0-SNAPSHOT.jar
datanode_1  | STARTUP_MSG:   build = https://github.com/apache/ozone/40461504478182af509db7098d4e173011d27e5a ; compiled by 'runner' on 2022-05-14T12:47Z
datanode_1  | STARTUP_MSG:   java = 11.0.14.1
datanode_1  | ************************************************************/
datanode_1  | 2022-05-14 12:58:33,485 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_1  | 2022-05-14 12:58:35,989 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_1  | 2022-05-14 12:58:36,931 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_1  | 2022-05-14 12:58:38,015 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_1  | 2022-05-14 12:58:38,015 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_1  | 2022-05-14 12:58:39,305 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:85c32a2ed606 ip:172.18.0.6
datanode_1  | 2022-05-14 12:58:42,180 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = ERASURE_CODED_STORAGE_SUPPORT (version = 3), software layout = ERASURE_CODED_STORAGE_SUPPORT (version = 3)
datanode_1  | 2022-05-14 12:58:43,301 [main] INFO reflections.Reflections: Reflections took 878 ms to scan 2 urls, producing 87 keys and 176 values 
datanode_1  | 2022-05-14 12:58:44,231 [main] INFO statemachine.DatanodeStateMachine: Datanode State Machine Task Thread Pool size 2
datanode_1  | 2022-05-14 12:58:45,900 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_1  | 2022-05-14 12:58:45,946 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89311358976
datanode_1  | 2022-05-14 12:58:45,985 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_1  | 2022-05-14 12:58:46,008 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_1  | 2022-05-14 12:58:46,305 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_1  | 2022-05-14 12:58:46,462 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_1  | 2022-05-14 12:58:46,490 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/metadata/ratis/scmUsed not found
datanode_1  | 2022-05-14 12:58:46,535 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
datanode_1  | 2022-05-14 12:58:46,535 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/metadata/ratis
datanode_1  | 2022-05-14 12:58:46,536 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/metadata/ratis
datanode_1  | 2022-05-14 12:58:46,941 [Thread-7] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode_1  | 2022-05-14 12:58:46,955 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode_1  | 2022-05-14 12:58:59,059 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for DNAudit to [].
datanode_1  | 2022-05-14 12:58:59,808 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_1  | 2022-05-14 12:59:00,247 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
datanode_1  | 2022-05-14 12:59:01,050 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
datanode_1  | 2022-05-14 12:59:01,059 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
datanode_1  | 2022-05-14 12:59:01,075 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
datanode_1  | 2022-05-14 12:59:01,079 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_1  | 2022-05-14 12:59:01,086 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1  | 2022-05-14 12:59:01,096 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_1  | 2022-05-14 12:59:01,100 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_1  | 2022-05-14 12:59:04,488 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
datanode_1  | 2022-05-14 12:59:04,508 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode_1  | 2022-05-14 12:59:04,535 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_1  | 2022-05-14 12:59:04,749 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1  | 2022-05-14 12:59:05,497 [main] INFO server.XceiverServerGrpc: GrpcServer channel type EpollServerSocketChannel
datanode_1  | 2022-05-14 12:59:06,400 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_1  | 2022-05-14 12:59:06,500 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_1  | 2022-05-14 12:59:06,892 [main] INFO util.log: Logging initialized @43950ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_1  | 2022-05-14 12:59:07,700 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_1  | 2022-05-14 12:59:07,746 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_1  | 2022-05-14 12:59:07,835 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_1  | 2022-05-14 12:59:07,855 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_1  | 2022-05-14 12:59:07,856 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_1  | 2022-05-14 12:59:07,859 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_1  | 2022-05-14 12:59:08,349 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_1  | 2022-05-14 12:59:08,359 [main] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
datanode_1  | 2022-05-14 12:59:08,603 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_1  | 2022-05-14 12:59:08,604 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_1  | 2022-05-14 12:59:08,608 [main] INFO server.session: node0 Scavenging every 600000ms
datanode_1  | 2022-05-14 12:59:08,740 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@44587c44{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_1  | 2022-05-14 12:59:08,775 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@446cc036{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_1  | 2022-05-14 12:59:09,817 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@8b1170f{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-11737169639410131943/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_1  | 2022-05-14 12:59:09,911 [main] INFO server.AbstractConnector: Started ServerConnector@63ed5dae{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
datanode_1  | 2022-05-14 12:59:09,915 [main] INFO server.Server: Started @46973ms
datanode_1  | 2022-05-14 12:59:09,940 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_1  | 2022-05-14 12:59:09,943 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_1  | 2022-05-14 12:59:09,945 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_1  | 2022-05-14 12:59:10,010 [Datanode State Machine Daemon Thread] INFO statemachine.DatanodeStateMachine: Ozone container server started.
datanode_1  | 2022-05-14 12:59:10,398 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6cd7cf8] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_1  | 2022-05-14 12:59:11,150 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.18.0.10:9891
datanode_1  | 2022-05-14 12:59:11,760 [Datanode State Machine Task Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_1  | 2022-05-14 12:59:13,862 [EndpointStateMachine task thread for recon/172.18.0.10:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.18.0.10:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_1  | 2022-05-14 12:59:13,862 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_1  | 2022-05-14 12:59:14,864 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_1  | 2022-05-14 12:59:14,864 [EndpointStateMachine task thread for recon/172.18.0.10:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.18.0.10:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_1  | 2022-05-14 12:59:15,866 [EndpointStateMachine task thread for recon/172.18.0.10:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.18.0.10:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_1  | 2022-05-14 12:59:15,866 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_1  | 2022-05-14 12:59:16,867 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_1  | 2022-05-14 12:59:16,868 [EndpointStateMachine task thread for recon/172.18.0.10:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.18.0.10:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_1  | 2022-05-14 12:59:17,868 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_1  | 2022-05-14 12:59:17,869 [EndpointStateMachine task thread for recon/172.18.0.10:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.18.0.10:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_1  | 2022-05-14 12:59:18,869 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_1  | 2022-05-14 12:59:19,871 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_1  | 2022-05-14 12:59:20,872 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_1  | 2022-05-14 12:59:22,927 [EndpointStateMachine task thread for recon/172.18.0.10:9891 - 0 ] WARN statemachine.EndpointStateMachine: Unable to communicate to Recon server at recon:9891 for past 0 seconds.
datanode_1  | java.net.SocketTimeoutException: Call From 85c32a2ed606/172.18.0.6 to recon:9891 failed on socket timeout exception: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.18.0.6:37572 remote=recon/172.18.0.10:9891]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_1  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_1  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_1  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)
datanode_1  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:848)
datanode_1  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1577)
datanode_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1519)
datanode_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1416)
datanode_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:236)
datanode_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:123)
datanode_1  | 	at com.sun.proxy.$Proxy40.submitRequest(Unknown Source)
datanode_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:117)
datanode_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:133)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:71)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:42)
datanode_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:829)
datanode_1  | Caused by: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.18.0.6:37572 remote=recon/172.18.0.10:9891]
datanode_1  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_1  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_1  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_1  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:563)
datanode_1  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_1  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1892)
datanode_1  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1202)
datanode_1  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1098)
datanode_1  | 2022-05-14 12:59:23,202 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_1  | 2022-05-14 12:59:23,233 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_1  | 2022-05-14 12:59:23,700 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 00910f34-9556-4f5c-8864-f93205907e3c
datanode_1  | 2022-05-14 12:59:23,842 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO server.RaftServer: 00910f34-9556-4f5c-8864-f93205907e3c: start RPC server
datanode_1  | 2022-05-14 12:59:23,857 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO server.GrpcService: 00910f34-9556-4f5c-8864-f93205907e3c: GrpcService started, listening on 9856
datanode_1  | 2022-05-14 12:59:23,865 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO server.GrpcService: 00910f34-9556-4f5c-8864-f93205907e3c: GrpcService started, listening on 9857
datanode_1  | 2022-05-14 12:59:23,883 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO server.GrpcService: 00910f34-9556-4f5c-8864-f93205907e3c: GrpcService started, listening on 9858
datanode_1  | 2022-05-14 12:59:23,886 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 00910f34-9556-4f5c-8864-f93205907e3c is started using port 9858 for RATIS
datanode_1  | 2022-05-14 12:59:23,888 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 00910f34-9556-4f5c-8864-f93205907e3c is started using port 9857 for RATIS_ADMIN
datanode_1  | 2022-05-14 12:59:23,889 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 00910f34-9556-4f5c-8864-f93205907e3c is started using port 9856 for RATIS_SERVER
datanode_1  | 2022-05-14 12:59:23,890 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$324/0x00000008404d6c40@1a594613] INFO util.JvmPauseMonitor: JvmPauseMonitor-00910f34-9556-4f5c-8864-f93205907e3c: Started
datanode_1  | 2022-05-14 12:59:28,668 [Datanode State Machine Daemon Thread] ERROR datanode.RunningDatanodeState: Error in executing end point task.
datanode_1  | java.util.concurrent.ExecutionException: java.util.concurrent.TimeoutException
datanode_1  | 	at java.base/java.util.concurrent.FutureTask.report(FutureTask.java:122)
datanode_1  | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:191)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.computeNextContainerState(RunningDatanodeState.java:199)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:239)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:50)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.StateContext.execute(StateContext.java:660)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:285)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:473)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:829)
datanode_1  | Caused by: java.util.concurrent.TimeoutException
datanode_1  | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:204)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.lambda$execute$0(RunningDatanodeState.java:157)
datanode_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_1  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1  | 	... 1 more
datanode_1  | 2022-05-14 12:59:32,539 [Command processor thread] INFO server.RaftServer: 00910f34-9556-4f5c-8864-f93205907e3c: addNew group-C3BF6305580B:[54b0e747-a2bb-484f-976a-c7c0770cb588|rpc:172.18.0.9:9856|admin:172.18.0.9:9857|client:172.18.0.9:9858|priority:0, 55441846-8ccc-4390-87fc-ba015dadcaaa|rpc:172.18.0.4:9856|admin:172.18.0.4:9857|client:172.18.0.4:9858|priority:0, 00910f34-9556-4f5c-8864-f93205907e3c|rpc:172.18.0.6:9856|admin:172.18.0.6:9857|client:172.18.0.6:9858|priority:1] returns group-C3BF6305580B:java.util.concurrent.CompletableFuture@3dab8c85[Not completed]
datanode_1  | 2022-05-14 12:59:32,696 [pool-22-thread-1] INFO server.RaftServer$Division: 00910f34-9556-4f5c-8864-f93205907e3c: new RaftServerImpl for group-C3BF6305580B:[54b0e747-a2bb-484f-976a-c7c0770cb588|rpc:172.18.0.9:9856|admin:172.18.0.9:9857|client:172.18.0.9:9858|priority:0, 55441846-8ccc-4390-87fc-ba015dadcaaa|rpc:172.18.0.4:9856|admin:172.18.0.4:9857|client:172.18.0.4:9858|priority:0, 00910f34-9556-4f5c-8864-f93205907e3c|rpc:172.18.0.6:9856|admin:172.18.0.6:9857|client:172.18.0.6:9858|priority:1] with ContainerStateMachine:uninitialized
datanode_1  | 2022-05-14 12:59:32,704 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_1  | 2022-05-14 12:59:32,708 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_1  | 2022-05-14 12:59:32,711 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_1  | 2022-05-14 12:59:32,712 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode_1  | 2022-05-14 12:59:32,712 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_1  | 2022-05-14 12:59:32,718 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode_1  | 2022-05-14 12:59:32,719 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1  | 2022-05-14 12:59:32,759 [pool-22-thread-1] INFO server.RaftServer$Division: 00910f34-9556-4f5c-8864-f93205907e3c@group-C3BF6305580B: ConfigurationManager, init=-1: [54b0e747-a2bb-484f-976a-c7c0770cb588|rpc:172.18.0.9:9856|admin:172.18.0.9:9857|client:172.18.0.9:9858|priority:0, 55441846-8ccc-4390-87fc-ba015dadcaaa|rpc:172.18.0.4:9856|admin:172.18.0.4:9857|client:172.18.0.4:9858|priority:0, 00910f34-9556-4f5c-8864-f93205907e3c|rpc:172.18.0.6:9856|admin:172.18.0.6:9857|client:172.18.0.6:9858|priority:1], old=null, confs=<EMPTY_MAP>
datanode_1  | 2022-05-14 12:59:32,759 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1  | 2022-05-14 12:59:32,771 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_1  | 2022-05-14 12:59:32,848 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode_1  | 2022-05-14 12:59:32,855 [pool-22-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/503efc89-95e3-40df-aa92-c3bf6305580b does not exist. Creating ...
datanode_1  | 2022-05-14 12:59:32,935 [pool-22-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/503efc89-95e3-40df-aa92-c3bf6305580b/in_use.lock acquired by nodename 6@85c32a2ed606
datanode_1  | 2022-05-14 12:59:33,019 [pool-22-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/503efc89-95e3-40df-aa92-c3bf6305580b has been successfully formatted.
datanode_1  | 2022-05-14 12:59:33,107 [pool-22-thread-1] INFO ratis.ContainerStateMachine: group-C3BF6305580B: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_1  | 2022-05-14 12:59:33,114 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode_1  | 2022-05-14 12:59:33,117 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_1  | 2022-05-14 12:59:33,242 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_1  | 2022-05-14 12:59:33,283 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1  | 2022-05-14 12:59:33,485 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1  | 2022-05-14 12:59:33,556 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_1  | 2022-05-14 12:59:33,578 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode_1  | 2022-05-14 12:59:33,640 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: new 00910f34-9556-4f5c-8864-f93205907e3c@group-C3BF6305580B-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/503efc89-95e3-40df-aa92-c3bf6305580b
datanode_1  | 2022-05-14 12:59:33,651 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode_1  | 2022-05-14 12:59:33,652 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_1  | 2022-05-14 12:59:33,663 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1  | 2022-05-14 12:59:33,667 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_1  | 2022-05-14 12:59:33,667 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_1  | 2022-05-14 12:59:33,692 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_1  | 2022-05-14 12:59:33,693 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_1  | 2022-05-14 12:59:33,694 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_1  | 2022-05-14 12:59:33,816 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_1  | 2022-05-14 12:59:33,822 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_1  | 2022-05-14 12:59:33,902 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: 00910f34-9556-4f5c-8864-f93205907e3c@group-C3BF6305580B-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_1  | 2022-05-14 12:59:33,907 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: 00910f34-9556-4f5c-8864-f93205907e3c@group-C3BF6305580B-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_1  | 2022-05-14 12:59:33,931 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_1  | 2022-05-14 12:59:33,932 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_1  | 2022-05-14 12:59:33,949 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_1  | 2022-05-14 12:59:33,953 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_1  | 2022-05-14 12:59:33,956 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_1  | 2022-05-14 12:59:33,962 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode_1  | 2022-05-14 12:59:34,161 [pool-22-thread-1] INFO server.RaftServer$Division: 00910f34-9556-4f5c-8864-f93205907e3c@group-C3BF6305580B: start as a follower, conf=-1: [54b0e747-a2bb-484f-976a-c7c0770cb588|rpc:172.18.0.9:9856|admin:172.18.0.9:9857|client:172.18.0.9:9858|priority:0, 55441846-8ccc-4390-87fc-ba015dadcaaa|rpc:172.18.0.4:9856|admin:172.18.0.4:9857|client:172.18.0.4:9858|priority:0, 00910f34-9556-4f5c-8864-f93205907e3c|rpc:172.18.0.6:9856|admin:172.18.0.6:9857|client:172.18.0.6:9858|priority:1], old=null
datanode_1  | 2022-05-14 12:59:34,162 [pool-22-thread-1] INFO server.RaftServer$Division: 00910f34-9556-4f5c-8864-f93205907e3c@group-C3BF6305580B: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_1  | 2022-05-14 12:59:34,163 [pool-22-thread-1] INFO impl.RoleInfo: 00910f34-9556-4f5c-8864-f93205907e3c: start 00910f34-9556-4f5c-8864-f93205907e3c@group-C3BF6305580B-FollowerState
datanode_1  | 2022-05-14 12:59:34,195 [pool-22-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C3BF6305580B,id=00910f34-9556-4f5c-8864-f93205907e3c
datanode_1  | 2022-05-14 12:59:34,343 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=503efc89-95e3-40df-aa92-c3bf6305580b
datanode_1  | 2022-05-14 12:59:38,092 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=503efc89-95e3-40df-aa92-c3bf6305580b.
datanode_1  | 2022-05-14 12:59:38,099 [pool-22-thread-1] INFO server.RaftServer$Division: 00910f34-9556-4f5c-8864-f93205907e3c: new RaftServerImpl for group-8AA059D6EDB9:[00910f34-9556-4f5c-8864-f93205907e3c|rpc:172.18.0.6:9856|admin:172.18.0.6:9857|client:172.18.0.6:9858|priority:1] with ContainerStateMachine:uninitialized
datanode_1  | 2022-05-14 12:59:38,102 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_1  | 2022-05-14 12:59:38,102 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_1  | 2022-05-14 12:59:38,103 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_1  | 2022-05-14 12:59:38,103 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode_1  | 2022-05-14 12:59:38,103 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_1  | 2022-05-14 12:59:38,103 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode_1  | 2022-05-14 12:59:38,103 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1  | 2022-05-14 12:59:38,103 [pool-22-thread-1] INFO server.RaftServer$Division: 00910f34-9556-4f5c-8864-f93205907e3c@group-8AA059D6EDB9: ConfigurationManager, init=-1: [00910f34-9556-4f5c-8864-f93205907e3c|rpc:172.18.0.6:9856|admin:172.18.0.6:9857|client:172.18.0.6:9858|priority:1], old=null, confs=<EMPTY_MAP>
datanode_1  | 2022-05-14 12:59:38,104 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1  | 2022-05-14 12:59:38,104 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_1  | 2022-05-14 12:59:38,104 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode_1  | 2022-05-14 12:59:38,104 [pool-22-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/ec7d4258-8caa-4f40-bc08-8aa059d6edb9 does not exist. Creating ...
datanode_1  | 2022-05-14 12:59:38,107 [Command processor thread] INFO server.RaftServer: 00910f34-9556-4f5c-8864-f93205907e3c: addNew group-8AA059D6EDB9:[00910f34-9556-4f5c-8864-f93205907e3c|rpc:172.18.0.6:9856|admin:172.18.0.6:9857|client:172.18.0.6:9858|priority:1] returns group-8AA059D6EDB9:java.util.concurrent.CompletableFuture@17a0d40f[Not completed]
datanode_1  | 2022-05-14 12:59:38,112 [pool-22-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/ec7d4258-8caa-4f40-bc08-8aa059d6edb9/in_use.lock acquired by nodename 6@85c32a2ed606
datanode_1  | 2022-05-14 12:59:38,143 [pool-22-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/ec7d4258-8caa-4f40-bc08-8aa059d6edb9 has been successfully formatted.
datanode_1  | 2022-05-14 12:59:38,144 [pool-22-thread-1] INFO ratis.ContainerStateMachine: group-8AA059D6EDB9: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_1  | 2022-05-14 12:59:38,147 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode_1  | 2022-05-14 12:59:38,148 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_1  | 2022-05-14 12:59:38,149 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_1  | 2022-05-14 12:59:38,149 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1  | 2022-05-14 12:59:38,157 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1  | 2022-05-14 12:59:38,158 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_1  | 2022-05-14 12:59:38,158 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode_1  | 2022-05-14 12:59:38,170 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: new 00910f34-9556-4f5c-8864-f93205907e3c@group-8AA059D6EDB9-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/ec7d4258-8caa-4f40-bc08-8aa059d6edb9
datanode_1  | 2022-05-14 12:59:38,170 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode_1  | 2022-05-14 12:59:38,170 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_1  | 2022-05-14 12:59:38,171 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1  | 2022-05-14 12:59:38,171 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_1  | 2022-05-14 12:59:38,171 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_1  | 2022-05-14 12:59:38,172 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_1  | 2022-05-14 12:59:38,173 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_1  | 2022-05-14 12:59:38,176 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_1  | 2022-05-14 12:59:38,177 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_1  | 2022-05-14 12:59:38,184 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_1  | 2022-05-14 12:59:38,194 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: 00910f34-9556-4f5c-8864-f93205907e3c@group-8AA059D6EDB9-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_1  | 2022-05-14 12:59:38,194 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: 00910f34-9556-4f5c-8864-f93205907e3c@group-8AA059D6EDB9-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_1  | 2022-05-14 12:59:38,196 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_1  | 2022-05-14 12:59:38,196 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_1  | 2022-05-14 12:59:38,196 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_1  | 2022-05-14 12:59:38,196 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_1  | 2022-05-14 12:59:38,197 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_1  | 2022-05-14 12:59:38,197 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode_1  | 2022-05-14 12:59:38,198 [pool-22-thread-1] INFO server.RaftServer$Division: 00910f34-9556-4f5c-8864-f93205907e3c@group-8AA059D6EDB9: start as a follower, conf=-1: [00910f34-9556-4f5c-8864-f93205907e3c|rpc:172.18.0.6:9856|admin:172.18.0.6:9857|client:172.18.0.6:9858|priority:1], old=null
datanode_1  | 2022-05-14 12:59:38,198 [pool-22-thread-1] INFO server.RaftServer$Division: 00910f34-9556-4f5c-8864-f93205907e3c@group-8AA059D6EDB9: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_1  | 2022-05-14 12:59:38,198 [pool-22-thread-1] INFO impl.RoleInfo: 00910f34-9556-4f5c-8864-f93205907e3c: start 00910f34-9556-4f5c-8864-f93205907e3c@group-8AA059D6EDB9-FollowerState
datanode_1  | 2022-05-14 12:59:38,207 [pool-22-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-8AA059D6EDB9,id=00910f34-9556-4f5c-8864-f93205907e3c
datanode_1  | 2022-05-14 12:59:38,218 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=ec7d4258-8caa-4f40-bc08-8aa059d6edb9
datanode_1  | 2022-05-14 12:59:38,218 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=ec7d4258-8caa-4f40-bc08-8aa059d6edb9.
datanode_1  | 2022-05-14 12:59:39,276 [00910f34-9556-4f5c-8864-f93205907e3c@group-C3BF6305580B-FollowerState] INFO impl.FollowerState: 00910f34-9556-4f5c-8864-f93205907e3c@group-C3BF6305580B-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5113329311ns, electionTimeout:5082ms
datanode_1  | 2022-05-14 12:59:39,276 [00910f34-9556-4f5c-8864-f93205907e3c@group-C3BF6305580B-FollowerState] INFO impl.RoleInfo: 00910f34-9556-4f5c-8864-f93205907e3c: shutdown 00910f34-9556-4f5c-8864-f93205907e3c@group-C3BF6305580B-FollowerState
datanode_2  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
datanode_2  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_2  | 2022-05-14 12:58:30,060 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_2  | /************************************************************
datanode_2  | STARTUP_MSG: Starting HddsDatanodeService
datanode_2  | STARTUP_MSG:   host = 9979e587a74f/172.18.0.9
datanode_2  | STARTUP_MSG:   args = []
datanode_2  | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
datanode_2  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.0.4.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.3.0-SNAPSHOT.jar
datanode_2  | STARTUP_MSG:   build = https://github.com/apache/ozone/40461504478182af509db7098d4e173011d27e5a ; compiled by 'runner' on 2022-05-14T12:47Z
datanode_2  | STARTUP_MSG:   java = 11.0.14.1
datanode_2  | ************************************************************/
datanode_2  | 2022-05-14 12:58:30,134 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_2  | 2022-05-14 12:58:32,778 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_2  | 2022-05-14 12:58:33,746 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_2  | 2022-05-14 12:58:34,972 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_2  | 2022-05-14 12:58:34,972 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_2  | 2022-05-14 12:58:36,310 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:9979e587a74f ip:172.18.0.9
datanode_2  | 2022-05-14 12:58:39,397 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = ERASURE_CODED_STORAGE_SUPPORT (version = 3), software layout = ERASURE_CODED_STORAGE_SUPPORT (version = 3)
datanode_2  | 2022-05-14 12:58:40,717 [main] INFO reflections.Reflections: Reflections took 1062 ms to scan 2 urls, producing 87 keys and 176 values 
datanode_2  | 2022-05-14 12:58:41,935 [main] INFO statemachine.DatanodeStateMachine: Datanode State Machine Task Thread Pool size 2
datanode_2  | 2022-05-14 12:58:43,555 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_2  | 2022-05-14 12:58:43,608 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89311358976
datanode_2  | 2022-05-14 12:58:43,621 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_2  | 2022-05-14 12:58:43,653 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_2  | 2022-05-14 12:58:43,969 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_2  | 2022-05-14 12:58:44,066 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_2  | 2022-05-14 12:58:44,101 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/metadata/ratis/scmUsed not found
datanode_2  | 2022-05-14 12:58:44,127 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
datanode_2  | 2022-05-14 12:58:44,128 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/metadata/ratis
datanode_2  | 2022-05-14 12:58:44,129 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/metadata/ratis
datanode_2  | 2022-05-14 12:58:44,407 [Thread-7] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode_2  | 2022-05-14 12:58:44,424 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode_2  | 2022-05-14 12:58:55,721 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for DNAudit to [].
datanode_2  | 2022-05-14 12:58:56,617 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_2  | 2022-05-14 12:58:57,183 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
datanode_2  | 2022-05-14 12:58:58,624 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
datanode_2  | 2022-05-14 12:58:58,628 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
datanode_2  | 2022-05-14 12:58:58,632 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
datanode_2  | 2022-05-14 12:58:58,659 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_2  | 2022-05-14 12:58:58,675 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2  | 2022-05-14 12:58:58,709 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_2  | 2022-05-14 12:58:58,713 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_2  | 2022-05-14 12:59:01,502 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
datanode_2  | 2022-05-14 12:59:01,519 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode_2  | 2022-05-14 12:59:01,521 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_2  | 2022-05-14 12:59:01,821 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2  | 2022-05-14 12:59:02,120 [main] INFO server.XceiverServerGrpc: GrpcServer channel type EpollServerSocketChannel
datanode_2  | 2022-05-14 12:59:02,930 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_2  | 2022-05-14 12:59:03,061 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_2  | 2022-05-14 12:59:03,270 [main] INFO util.log: Logging initialized @41381ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_2  | 2022-05-14 12:59:04,166 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_2  | 2022-05-14 12:59:04,201 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_2  | 2022-05-14 12:59:04,245 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_2  | 2022-05-14 12:59:04,292 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_2  | 2022-05-14 12:59:04,299 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_2  | 2022-05-14 12:59:04,301 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_2  | 2022-05-14 12:59:04,764 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_2  | 2022-05-14 12:59:04,787 [main] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
datanode_2  | 2022-05-14 12:59:05,163 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_2  | 2022-05-14 12:59:05,164 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_2  | 2022-05-14 12:59:05,180 [main] INFO server.session: node0 Scavenging every 660000ms
datanode_2  | 2022-05-14 12:59:05,270 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@618fb1{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_4  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
datanode_4  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_4  | 2022-05-14 12:58:33,499 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_4  | /************************************************************
datanode_4  | STARTUP_MSG: Starting HddsDatanodeService
datanode_4  | STARTUP_MSG:   host = 8dcbf89c8500/172.18.0.2
datanode_4  | STARTUP_MSG:   args = []
datanode_4  | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
datanode_2  | 2022-05-14 12:59:05,280 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@33b2ba25{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_2  | 2022-05-14 12:59:06,254 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@69cb134{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-4246977554436371828/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_2  | 2022-05-14 12:59:06,359 [main] INFO server.AbstractConnector: Started ServerConnector@578198d9{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
datanode_2  | 2022-05-14 12:59:06,376 [main] INFO server.Server: Started @44476ms
datanode_2  | 2022-05-14 12:59:06,415 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_2  | 2022-05-14 12:59:06,423 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_2  | 2022-05-14 12:59:06,448 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_2  | 2022-05-14 12:59:06,487 [Datanode State Machine Daemon Thread] INFO statemachine.DatanodeStateMachine: Ozone container server started.
datanode_2  | 2022-05-14 12:59:06,721 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2d6c8033] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_2  | 2022-05-14 12:59:07,603 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.18.0.10:9891
datanode_2  | 2022-05-14 12:59:08,422 [Datanode State Machine Task Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_2  | 2022-05-14 12:59:10,693 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_2  | 2022-05-14 12:59:10,739 [EndpointStateMachine task thread for recon/172.18.0.10:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.18.0.10:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_2  | 2022-05-14 12:59:11,694 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_2  | 2022-05-14 12:59:11,740 [EndpointStateMachine task thread for recon/172.18.0.10:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.18.0.10:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_2  | 2022-05-14 12:59:12,695 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_2  | 2022-05-14 12:59:12,741 [EndpointStateMachine task thread for recon/172.18.0.10:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.18.0.10:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_2  | 2022-05-14 12:59:13,697 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_2  | 2022-05-14 12:59:13,741 [EndpointStateMachine task thread for recon/172.18.0.10:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.18.0.10:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_2  | 2022-05-14 12:59:14,698 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_2  | 2022-05-14 12:59:14,742 [EndpointStateMachine task thread for recon/172.18.0.10:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.18.0.10:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_2  | 2022-05-14 12:59:15,699 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_2  | 2022-05-14 12:59:15,743 [EndpointStateMachine task thread for recon/172.18.0.10:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.18.0.10:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_2  | 2022-05-14 12:59:16,700 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_2  | 2022-05-14 12:59:16,744 [EndpointStateMachine task thread for recon/172.18.0.10:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.18.0.10:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_2  | 2022-05-14 12:59:17,701 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_2  | 2022-05-14 12:59:17,745 [EndpointStateMachine task thread for recon/172.18.0.10:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.18.0.10:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_2  | 2022-05-14 12:59:18,702 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_2  | 2022-05-14 12:59:19,703 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_2  | 2022-05-14 12:59:20,704 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_2  | 2022-05-14 12:59:22,773 [EndpointStateMachine task thread for recon/172.18.0.10:9891 - 0 ] WARN statemachine.EndpointStateMachine: Unable to communicate to Recon server at recon:9891 for past 0 seconds.
datanode_2  | java.net.SocketTimeoutException: Call From 9979e587a74f/172.18.0.9 to recon:9891 failed on socket timeout exception: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.18.0.9:37520 remote=recon/172.18.0.10:9891]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_2  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_2  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_2  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_4  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.0.4.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.3.0-SNAPSHOT.jar
datanode_4  | STARTUP_MSG:   build = https://github.com/apache/ozone/40461504478182af509db7098d4e173011d27e5a ; compiled by 'runner' on 2022-05-14T12:47Z
datanode_4  | STARTUP_MSG:   java = 11.0.14.1
datanode_4  | ************************************************************/
datanode_4  | 2022-05-14 12:58:33,616 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_4  | 2022-05-14 12:58:35,929 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_4  | 2022-05-14 12:58:36,797 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_4  | 2022-05-14 12:58:37,827 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_4  | 2022-05-14 12:58:37,831 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_4  | 2022-05-14 12:58:39,090 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:8dcbf89c8500 ip:172.18.0.2
datanode_4  | 2022-05-14 12:58:41,949 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = ERASURE_CODED_STORAGE_SUPPORT (version = 3), software layout = ERASURE_CODED_STORAGE_SUPPORT (version = 3)
datanode_4  | 2022-05-14 12:58:43,372 [main] INFO reflections.Reflections: Reflections took 1139 ms to scan 2 urls, producing 87 keys and 176 values 
datanode_4  | 2022-05-14 12:58:44,252 [main] INFO statemachine.DatanodeStateMachine: Datanode State Machine Task Thread Pool size 2
datanode_4  | 2022-05-14 12:58:46,297 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_4  | 2022-05-14 12:58:46,448 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89311358976
datanode_4  | 2022-05-14 12:58:46,487 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_4  | 2022-05-14 12:58:46,488 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_4  | 2022-05-14 12:58:46,804 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_4  | 2022-05-14 12:58:46,944 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_4  | 2022-05-14 12:58:46,945 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/metadata/ratis/scmUsed not found
datanode_4  | 2022-05-14 12:58:46,967 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
datanode_4  | 2022-05-14 12:58:46,968 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/metadata/ratis
datanode_4  | 2022-05-14 12:58:46,968 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/metadata/ratis
datanode_4  | 2022-05-14 12:58:47,276 [Thread-7] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode_4  | 2022-05-14 12:58:47,287 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode_4  | 2022-05-14 12:58:59,342 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for DNAudit to [].
datanode_4  | 2022-05-14 12:59:00,337 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_4  | 2022-05-14 12:59:01,034 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
datanode_4  | 2022-05-14 12:59:01,658 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
datanode_4  | 2022-05-14 12:59:01,699 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
datanode_4  | 2022-05-14 12:59:01,719 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
datanode_4  | 2022-05-14 12:59:01,725 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_4  | 2022-05-14 12:59:01,739 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_4  | 2022-05-14 12:59:01,743 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_4  | 2022-05-14 12:59:01,745 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_4  | 2022-05-14 12:59:04,672 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
datanode_4  | 2022-05-14 12:59:04,686 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode_4  | 2022-05-14 12:59:04,728 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_4  | 2022-05-14 12:59:04,868 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_4  | 2022-05-14 12:59:05,180 [main] INFO server.XceiverServerGrpc: GrpcServer channel type EpollServerSocketChannel
datanode_4  | 2022-05-14 12:59:06,358 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_4  | 2022-05-14 12:59:06,496 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_4  | 2022-05-14 12:59:06,815 [main] INFO util.log: Logging initialized @43577ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_4  | 2022-05-14 12:59:08,033 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_4  | 2022-05-14 12:59:08,062 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_4  | 2022-05-14 12:59:08,156 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_4  | 2022-05-14 12:59:08,164 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_4  | 2022-05-14 12:59:08,173 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_4  | 2022-05-14 12:59:08,187 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_4  | 2022-05-14 12:59:08,548 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_4  | 2022-05-14 12:59:08,570 [main] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
datanode_4  | 2022-05-14 12:59:08,976 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_4  | 2022-05-14 12:59:08,977 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_4  | 2022-05-14 12:59:09,010 [main] INFO server.session: node0 Scavenging every 600000ms
datanode_4  | 2022-05-14 12:59:09,152 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@10b3ea72{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_2  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_2  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)
datanode_2  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:848)
datanode_2  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1577)
datanode_2  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1519)
datanode_2  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1416)
datanode_2  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:236)
datanode_2  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:123)
datanode_2  | 	at com.sun.proxy.$Proxy40.submitRequest(Unknown Source)
datanode_2  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:117)
datanode_2  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:133)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:71)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:42)
datanode_2  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:829)
datanode_2  | Caused by: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.18.0.9:37520 remote=recon/172.18.0.10:9891]
datanode_2  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_2  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_2  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_2  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_2  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_2  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_2  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_2  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_2  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:563)
datanode_2  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_2  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1892)
datanode_2  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1202)
datanode_2  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1098)
datanode_2  | 2022-05-14 12:59:23,100 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_2  | 2022-05-14 12:59:23,139 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_2  | 2022-05-14 12:59:23,697 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 54b0e747-a2bb-484f-976a-c7c0770cb588
datanode_2  | 2022-05-14 12:59:23,955 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO server.RaftServer: 54b0e747-a2bb-484f-976a-c7c0770cb588: start RPC server
datanode_2  | 2022-05-14 12:59:23,960 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO server.GrpcService: 54b0e747-a2bb-484f-976a-c7c0770cb588: GrpcService started, listening on 9856
datanode_2  | 2022-05-14 12:59:23,967 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO server.GrpcService: 54b0e747-a2bb-484f-976a-c7c0770cb588: GrpcService started, listening on 9857
datanode_2  | 2022-05-14 12:59:23,969 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO server.GrpcService: 54b0e747-a2bb-484f-976a-c7c0770cb588: GrpcService started, listening on 9858
datanode_2  | 2022-05-14 12:59:23,980 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 54b0e747-a2bb-484f-976a-c7c0770cb588 is started using port 9858 for RATIS
datanode_2  | 2022-05-14 12:59:23,981 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 54b0e747-a2bb-484f-976a-c7c0770cb588 is started using port 9857 for RATIS_ADMIN
datanode_2  | 2022-05-14 12:59:23,981 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$324/0x00000008404d6c40@6306ad21] INFO util.JvmPauseMonitor: JvmPauseMonitor-54b0e747-a2bb-484f-976a-c7c0770cb588: Started
datanode_2  | 2022-05-14 12:59:23,995 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 54b0e747-a2bb-484f-976a-c7c0770cb588 is started using port 9856 for RATIS_SERVER
datanode_2  | 2022-05-14 12:59:28,923 [Datanode State Machine Daemon Thread] ERROR datanode.RunningDatanodeState: Error in executing end point task.
datanode_2  | java.util.concurrent.ExecutionException: java.util.concurrent.TimeoutException
datanode_2  | 	at java.base/java.util.concurrent.FutureTask.report(FutureTask.java:122)
datanode_2  | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:191)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.computeNextContainerState(RunningDatanodeState.java:199)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:239)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:50)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.StateContext.execute(StateContext.java:660)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:285)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:473)
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:829)
datanode_2  | Caused by: java.util.concurrent.TimeoutException
datanode_2  | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:204)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.lambda$execute$0(RunningDatanodeState.java:157)
datanode_2  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_2  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_2  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_2  | 	... 1 more
datanode_2  | 2022-05-14 12:59:33,152 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$324/0x00000008404d6c40@6306ad21] WARN util.JvmPauseMonitor: JvmPauseMonitor-54b0e747-a2bb-484f-976a-c7c0770cb588: Detected pause in JVM or host machine (eg GC): pause of approximately 121049630ns.
datanode_2  | GC pool 'ParNew' had collection(s): count=1 time=128ms
datanode_4  | 2022-05-14 12:59:09,171 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@3f33bb6f{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_4  | 2022-05-14 12:59:10,349 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@270097ce{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-15822406649257770837/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_4  | 2022-05-14 12:59:10,444 [main] INFO server.AbstractConnector: Started ServerConnector@47f39279{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
datanode_4  | 2022-05-14 12:59:10,447 [main] INFO server.Server: Started @47207ms
datanode_4  | 2022-05-14 12:59:10,471 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_4  | 2022-05-14 12:59:10,471 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_4  | 2022-05-14 12:59:10,477 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_4  | 2022-05-14 12:59:10,481 [Datanode State Machine Daemon Thread] INFO statemachine.DatanodeStateMachine: Ozone container server started.
datanode_4  | 2022-05-14 12:59:10,737 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7bdb00ea] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_4  | 2022-05-14 12:59:11,391 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.18.0.10:9891
datanode_4  | 2022-05-14 12:59:11,741 [Datanode State Machine Task Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_4  | 2022-05-14 12:59:14,320 [EndpointStateMachine task thread for recon/172.18.0.10:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.18.0.10:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_4  | 2022-05-14 12:59:14,322 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_4  | 2022-05-14 12:59:15,323 [EndpointStateMachine task thread for recon/172.18.0.10:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.18.0.10:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_4  | 2022-05-14 12:59:15,324 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_4  | 2022-05-14 12:59:16,324 [EndpointStateMachine task thread for recon/172.18.0.10:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.18.0.10:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_4  | 2022-05-14 12:59:16,325 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_4  | 2022-05-14 12:59:17,325 [EndpointStateMachine task thread for recon/172.18.0.10:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.18.0.10:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_4  | 2022-05-14 12:59:17,326 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_4  | 2022-05-14 12:59:18,329 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_4  | 2022-05-14 12:59:19,330 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_4  | 2022-05-14 12:59:20,331 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_4  | 2022-05-14 12:59:21,332 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_4  | 2022-05-14 12:59:22,361 [EndpointStateMachine task thread for recon/172.18.0.10:9891 - 0 ] WARN statemachine.EndpointStateMachine: Unable to communicate to Recon server at recon:9891 for past 0 seconds.
datanode_4  | java.net.SocketTimeoutException: Call From 8dcbf89c8500/172.18.0.2 to recon:9891 failed on socket timeout exception: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.18.0.2:53202 remote=recon/172.18.0.10:9891]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_4  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_4  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_4  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_4  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_4  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)
datanode_4  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:848)
datanode_4  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1577)
datanode_4  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1519)
datanode_4  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1416)
datanode_4  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:236)
datanode_4  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:123)
datanode_4  | 	at com.sun.proxy.$Proxy40.submitRequest(Unknown Source)
datanode_4  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:117)
datanode_4  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:133)
datanode_4  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:71)
datanode_4  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:42)
datanode_4  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_4  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_4  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_4  | 	at java.base/java.lang.Thread.run(Thread.java:829)
datanode_4  | Caused by: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.18.0.2:53202 remote=recon/172.18.0.10:9891]
datanode_4  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_4  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_4  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_4  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_4  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_4  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_4  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_4  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_4  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:563)
datanode_4  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_4  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1892)
datanode_4  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1202)
datanode_4  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1098)
datanode_4  | 2022-05-14 12:59:23,239 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_4  | 2022-05-14 12:59:23,278 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_4  | 2022-05-14 12:59:23,789 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis d5e6fff5-66a9-4bee-add9-03aeb4a97c66
datanode_4  | 2022-05-14 12:59:23,982 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO server.RaftServer: d5e6fff5-66a9-4bee-add9-03aeb4a97c66: start RPC server
datanode_4  | 2022-05-14 12:59:23,991 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO server.GrpcService: d5e6fff5-66a9-4bee-add9-03aeb4a97c66: GrpcService started, listening on 9856
datanode_4  | 2022-05-14 12:59:23,999 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO server.GrpcService: d5e6fff5-66a9-4bee-add9-03aeb4a97c66: GrpcService started, listening on 9857
datanode_4  | 2022-05-14 12:59:23,999 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO server.GrpcService: d5e6fff5-66a9-4bee-add9-03aeb4a97c66: GrpcService started, listening on 9858
datanode_4  | 2022-05-14 12:59:24,009 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis d5e6fff5-66a9-4bee-add9-03aeb4a97c66 is started using port 9858 for RATIS
datanode_4  | 2022-05-14 12:59:24,012 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$325/0x00000008404d6840@d8c9feb] INFO util.JvmPauseMonitor: JvmPauseMonitor-d5e6fff5-66a9-4bee-add9-03aeb4a97c66: Started
datanode_4  | 2022-05-14 12:59:24,009 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis d5e6fff5-66a9-4bee-add9-03aeb4a97c66 is started using port 9857 for RATIS_ADMIN
datanode_4  | 2022-05-14 12:59:24,014 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis d5e6fff5-66a9-4bee-add9-03aeb4a97c66 is started using port 9856 for RATIS_SERVER
datanode_4  | 2022-05-14 12:59:28,902 [Datanode State Machine Daemon Thread] ERROR datanode.RunningDatanodeState: Error in executing end point task.
datanode_4  | java.util.concurrent.ExecutionException: java.util.concurrent.TimeoutException
datanode_4  | 	at java.base/java.util.concurrent.FutureTask.report(FutureTask.java:122)
datanode_4  | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:191)
datanode_4  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.computeNextContainerState(RunningDatanodeState.java:199)
datanode_4  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:239)
datanode_4  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:50)
datanode_4  | 	at org.apache.hadoop.ozone.container.common.statemachine.StateContext.execute(StateContext.java:660)
datanode_4  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:285)
datanode_4  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:473)
datanode_4  | 	at java.base/java.lang.Thread.run(Thread.java:829)
datanode_4  | Caused by: java.util.concurrent.TimeoutException
datanode_4  | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:204)
datanode_4  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.lambda$execute$0(RunningDatanodeState.java:157)
datanode_4  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_4  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_4  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_4  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_4  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_4  | 	... 1 more
datanode_4  | 2022-05-14 12:59:33,024 [Command processor thread] INFO server.RaftServer: d5e6fff5-66a9-4bee-add9-03aeb4a97c66: addNew group-4A9FA2B98460:[d5e6fff5-66a9-4bee-add9-03aeb4a97c66|rpc:172.18.0.2:9856|admin:172.18.0.2:9857|client:172.18.0.2:9858|priority:1] returns group-4A9FA2B98460:java.util.concurrent.CompletableFuture@1bd36a23[Not completed]
datanode_4  | 2022-05-14 12:59:33,173 [pool-22-thread-1] INFO server.RaftServer$Division: d5e6fff5-66a9-4bee-add9-03aeb4a97c66: new RaftServerImpl for group-4A9FA2B98460:[d5e6fff5-66a9-4bee-add9-03aeb4a97c66|rpc:172.18.0.2:9856|admin:172.18.0.2:9857|client:172.18.0.2:9858|priority:1] with ContainerStateMachine:uninitialized
datanode_4  | 2022-05-14 12:59:33,208 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_4  | 2022-05-14 12:59:33,215 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_4  | 2022-05-14 12:59:33,215 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_4  | 2022-05-14 12:59:33,216 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode_4  | 2022-05-14 12:59:33,216 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_4  | 2022-05-14 12:59:33,216 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode_4  | 2022-05-14 12:59:33,216 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_4  | 2022-05-14 12:59:33,298 [pool-22-thread-1] INFO server.RaftServer$Division: d5e6fff5-66a9-4bee-add9-03aeb4a97c66@group-4A9FA2B98460: ConfigurationManager, init=-1: [d5e6fff5-66a9-4bee-add9-03aeb4a97c66|rpc:172.18.0.2:9856|admin:172.18.0.2:9857|client:172.18.0.2:9858|priority:1], old=null, confs=<EMPTY_MAP>
datanode_4  | 2022-05-14 12:59:33,298 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_4  | 2022-05-14 12:59:33,302 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_4  | 2022-05-14 12:59:33,302 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode_2  | 2022-05-14 12:59:33,156 [Command processor thread] INFO server.RaftServer: 54b0e747-a2bb-484f-976a-c7c0770cb588: addNew group-C3BF6305580B:[54b0e747-a2bb-484f-976a-c7c0770cb588|rpc:172.18.0.9:9856|admin:172.18.0.9:9857|client:172.18.0.9:9858|priority:0, 55441846-8ccc-4390-87fc-ba015dadcaaa|rpc:172.18.0.4:9856|admin:172.18.0.4:9857|client:172.18.0.4:9858|priority:0, 00910f34-9556-4f5c-8864-f93205907e3c|rpc:172.18.0.6:9856|admin:172.18.0.6:9857|client:172.18.0.6:9858|priority:1] returns group-C3BF6305580B:java.util.concurrent.CompletableFuture@744151c9[Not completed]
datanode_2  | 2022-05-14 12:59:33,412 [pool-22-thread-1] INFO server.RaftServer$Division: 54b0e747-a2bb-484f-976a-c7c0770cb588: new RaftServerImpl for group-C3BF6305580B:[54b0e747-a2bb-484f-976a-c7c0770cb588|rpc:172.18.0.9:9856|admin:172.18.0.9:9857|client:172.18.0.9:9858|priority:0, 55441846-8ccc-4390-87fc-ba015dadcaaa|rpc:172.18.0.4:9856|admin:172.18.0.4:9857|client:172.18.0.4:9858|priority:0, 00910f34-9556-4f5c-8864-f93205907e3c|rpc:172.18.0.6:9856|admin:172.18.0.6:9857|client:172.18.0.6:9858|priority:1] with ContainerStateMachine:uninitialized
datanode_2  | 2022-05-14 12:59:33,424 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_2  | 2022-05-14 12:59:33,446 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_2  | 2022-05-14 12:59:33,447 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_2  | 2022-05-14 12:59:33,447 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode_2  | 2022-05-14 12:59:33,447 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_2  | 2022-05-14 12:59:33,447 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode_2  | 2022-05-14 12:59:33,449 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2  | 2022-05-14 12:59:33,496 [pool-22-thread-1] INFO server.RaftServer$Division: 54b0e747-a2bb-484f-976a-c7c0770cb588@group-C3BF6305580B: ConfigurationManager, init=-1: [54b0e747-a2bb-484f-976a-c7c0770cb588|rpc:172.18.0.9:9856|admin:172.18.0.9:9857|client:172.18.0.9:9858|priority:0, 55441846-8ccc-4390-87fc-ba015dadcaaa|rpc:172.18.0.4:9856|admin:172.18.0.4:9857|client:172.18.0.4:9858|priority:0, 00910f34-9556-4f5c-8864-f93205907e3c|rpc:172.18.0.6:9856|admin:172.18.0.6:9857|client:172.18.0.6:9858|priority:1], old=null, confs=<EMPTY_MAP>
datanode_2  | 2022-05-14 12:59:33,502 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2  | 2022-05-14 12:59:33,535 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_2  | 2022-05-14 12:59:33,544 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode_2  | 2022-05-14 12:59:33,553 [pool-22-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/503efc89-95e3-40df-aa92-c3bf6305580b does not exist. Creating ...
datanode_2  | 2022-05-14 12:59:33,634 [pool-22-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/503efc89-95e3-40df-aa92-c3bf6305580b/in_use.lock acquired by nodename 7@9979e587a74f
datanode_2  | 2022-05-14 12:59:33,719 [pool-22-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/503efc89-95e3-40df-aa92-c3bf6305580b has been successfully formatted.
datanode_2  | 2022-05-14 12:59:33,813 [pool-22-thread-1] INFO ratis.ContainerStateMachine: group-C3BF6305580B: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_2  | 2022-05-14 12:59:33,835 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode_2  | 2022-05-14 12:59:33,877 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_2  | 2022-05-14 12:59:34,018 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_2  | 2022-05-14 12:59:34,045 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2  | 2022-05-14 12:59:34,211 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2  | 2022-05-14 12:59:34,272 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_2  | 2022-05-14 12:59:34,282 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode_2  | 2022-05-14 12:59:34,330 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: new 54b0e747-a2bb-484f-976a-c7c0770cb588@group-C3BF6305580B-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/503efc89-95e3-40df-aa92-c3bf6305580b
datanode_2  | 2022-05-14 12:59:34,347 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode_2  | 2022-05-14 12:59:34,351 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_2  | 2022-05-14 12:59:34,359 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2  | 2022-05-14 12:59:34,367 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_2  | 2022-05-14 12:59:34,367 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_2  | 2022-05-14 12:59:34,374 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_2  | 2022-05-14 12:59:34,385 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_2  | 2022-05-14 12:59:34,391 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_2  | 2022-05-14 12:59:34,469 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_2  | 2022-05-14 12:59:34,472 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_2  | 2022-05-14 12:59:34,537 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: 54b0e747-a2bb-484f-976a-c7c0770cb588@group-C3BF6305580B-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_2  | 2022-05-14 12:59:34,545 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: 54b0e747-a2bb-484f-976a-c7c0770cb588@group-C3BF6305580B-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_2  | 2022-05-14 12:59:34,564 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_2  | 2022-05-14 12:59:34,578 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_2  | 2022-05-14 12:59:34,588 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_2  | 2022-05-14 12:59:34,591 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_2  | 2022-05-14 12:59:34,593 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_2  | 2022-05-14 12:59:34,598 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode_2  | 2022-05-14 12:59:34,779 [pool-22-thread-1] INFO server.RaftServer$Division: 54b0e747-a2bb-484f-976a-c7c0770cb588@group-C3BF6305580B: start as a follower, conf=-1: [54b0e747-a2bb-484f-976a-c7c0770cb588|rpc:172.18.0.9:9856|admin:172.18.0.9:9857|client:172.18.0.9:9858|priority:0, 55441846-8ccc-4390-87fc-ba015dadcaaa|rpc:172.18.0.4:9856|admin:172.18.0.4:9857|client:172.18.0.4:9858|priority:0, 00910f34-9556-4f5c-8864-f93205907e3c|rpc:172.18.0.6:9856|admin:172.18.0.6:9857|client:172.18.0.6:9858|priority:1], old=null
datanode_2  | 2022-05-14 12:59:34,780 [pool-22-thread-1] INFO server.RaftServer$Division: 54b0e747-a2bb-484f-976a-c7c0770cb588@group-C3BF6305580B: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_2  | 2022-05-14 12:59:34,786 [pool-22-thread-1] INFO impl.RoleInfo: 54b0e747-a2bb-484f-976a-c7c0770cb588: start 54b0e747-a2bb-484f-976a-c7c0770cb588@group-C3BF6305580B-FollowerState
datanode_2  | 2022-05-14 12:59:34,799 [pool-22-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C3BF6305580B,id=54b0e747-a2bb-484f-976a-c7c0770cb588
datanode_2  | 2022-05-14 12:59:34,855 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=503efc89-95e3-40df-aa92-c3bf6305580b
datanode_2  | 2022-05-14 12:59:37,882 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=503efc89-95e3-40df-aa92-c3bf6305580b.
datanode_2  | 2022-05-14 12:59:37,890 [pool-22-thread-1] INFO server.RaftServer$Division: 54b0e747-a2bb-484f-976a-c7c0770cb588: new RaftServerImpl for group-7A48E9FEEF0D:[54b0e747-a2bb-484f-976a-c7c0770cb588|rpc:172.18.0.9:9856|admin:172.18.0.9:9857|client:172.18.0.9:9858|priority:1] with ContainerStateMachine:uninitialized
datanode_2  | 2022-05-14 12:59:37,892 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_2  | 2022-05-14 12:59:37,892 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_2  | 2022-05-14 12:59:37,893 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_2  | 2022-05-14 12:59:37,893 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode_2  | 2022-05-14 12:59:37,893 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_2  | 2022-05-14 12:59:37,893 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode_2  | 2022-05-14 12:59:37,894 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2  | 2022-05-14 12:59:37,894 [pool-22-thread-1] INFO server.RaftServer$Division: 54b0e747-a2bb-484f-976a-c7c0770cb588@group-7A48E9FEEF0D: ConfigurationManager, init=-1: [54b0e747-a2bb-484f-976a-c7c0770cb588|rpc:172.18.0.9:9856|admin:172.18.0.9:9857|client:172.18.0.9:9858|priority:1], old=null, confs=<EMPTY_MAP>
datanode_2  | 2022-05-14 12:59:37,893 [Command processor thread] INFO server.RaftServer: 54b0e747-a2bb-484f-976a-c7c0770cb588: addNew group-7A48E9FEEF0D:[54b0e747-a2bb-484f-976a-c7c0770cb588|rpc:172.18.0.9:9856|admin:172.18.0.9:9857|client:172.18.0.9:9858|priority:1] returns group-7A48E9FEEF0D:java.util.concurrent.CompletableFuture@13fccfaf[Not completed]
datanode_2  | 2022-05-14 12:59:37,894 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2  | 2022-05-14 12:59:37,896 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_2  | 2022-05-14 12:59:37,896 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode_2  | 2022-05-14 12:59:37,906 [pool-22-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/1fd8b2e8-f580-4de7-855d-7a48e9feef0d does not exist. Creating ...
datanode_2  | 2022-05-14 12:59:37,916 [pool-22-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/1fd8b2e8-f580-4de7-855d-7a48e9feef0d/in_use.lock acquired by nodename 7@9979e587a74f
datanode_2  | 2022-05-14 12:59:37,930 [pool-22-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/1fd8b2e8-f580-4de7-855d-7a48e9feef0d has been successfully formatted.
datanode_2  | 2022-05-14 12:59:37,930 [pool-22-thread-1] INFO ratis.ContainerStateMachine: group-7A48E9FEEF0D: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_2  | 2022-05-14 12:59:37,932 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode_2  | 2022-05-14 12:59:37,933 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_2  | 2022-05-14 12:59:37,949 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_2  | 2022-05-14 12:59:37,950 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2  | 2022-05-14 12:59:37,951 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2  | 2022-05-14 12:59:38,019 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_2  | 2022-05-14 12:59:38,019 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode_2  | 2022-05-14 12:59:38,019 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: new 54b0e747-a2bb-484f-976a-c7c0770cb588@group-7A48E9FEEF0D-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/1fd8b2e8-f580-4de7-855d-7a48e9feef0d
datanode_2  | 2022-05-14 12:59:38,019 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode_2  | 2022-05-14 12:59:38,019 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_2  | 2022-05-14 12:59:38,019 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2  | 2022-05-14 12:59:38,019 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_2  | 2022-05-14 12:59:38,020 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_2  | 2022-05-14 12:59:38,020 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_2  | 2022-05-14 12:59:38,020 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_2  | 2022-05-14 12:59:38,020 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_2  | 2022-05-14 12:59:38,025 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_2  | 2022-05-14 12:59:38,028 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_2  | 2022-05-14 12:59:38,031 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: 54b0e747-a2bb-484f-976a-c7c0770cb588@group-7A48E9FEEF0D-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_2  | 2022-05-14 12:59:38,032 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: 54b0e747-a2bb-484f-976a-c7c0770cb588@group-7A48E9FEEF0D-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_2  | 2022-05-14 12:59:38,043 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_2  | 2022-05-14 12:59:38,043 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_2  | 2022-05-14 12:59:38,043 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_2  | 2022-05-14 12:59:38,043 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_2  | 2022-05-14 12:59:38,044 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_1  | 2022-05-14 12:59:39,277 [00910f34-9556-4f5c-8864-f93205907e3c@group-C3BF6305580B-FollowerState] INFO server.RaftServer$Division: 00910f34-9556-4f5c-8864-f93205907e3c@group-C3BF6305580B: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_1  | 2022-05-14 12:59:39,310 [00910f34-9556-4f5c-8864-f93205907e3c@group-C3BF6305580B-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode_1  | 2022-05-14 12:59:39,331 [00910f34-9556-4f5c-8864-f93205907e3c@group-C3BF6305580B-FollowerState] INFO impl.RoleInfo: 00910f34-9556-4f5c-8864-f93205907e3c: start 00910f34-9556-4f5c-8864-f93205907e3c@group-C3BF6305580B-LeaderElection1
datanode_1  | 2022-05-14 12:59:39,361 [grpc-default-executor-1] INFO server.RaftServer$Division: 00910f34-9556-4f5c-8864-f93205907e3c@group-C3BF6305580B: receive requestVote(ELECTION, 55441846-8ccc-4390-87fc-ba015dadcaaa, group-C3BF6305580B, 1, (t:0, i:0))
datanode_1  | 2022-05-14 12:59:39,364 [grpc-default-executor-1] INFO impl.VoteContext: 00910f34-9556-4f5c-8864-f93205907e3c@group-C3BF6305580B-CANDIDATE: reject ELECTION from 55441846-8ccc-4390-87fc-ba015dadcaaa: our priority 1 > candidate's priority 0
datanode_1  | 2022-05-14 12:59:39,366 [grpc-default-executor-1] INFO server.RaftServer$Division: 00910f34-9556-4f5c-8864-f93205907e3c@group-C3BF6305580B: changes role from CANDIDATE to FOLLOWER at term 1 for candidate:55441846-8ccc-4390-87fc-ba015dadcaaa
datanode_1  | 2022-05-14 12:59:39,366 [grpc-default-executor-1] INFO impl.RoleInfo: 00910f34-9556-4f5c-8864-f93205907e3c: shutdown 00910f34-9556-4f5c-8864-f93205907e3c@group-C3BF6305580B-LeaderElection1
datanode_1  | 2022-05-14 12:59:39,369 [grpc-default-executor-1] INFO impl.RoleInfo: 00910f34-9556-4f5c-8864-f93205907e3c: start 00910f34-9556-4f5c-8864-f93205907e3c@group-C3BF6305580B-FollowerState
datanode_1  | 2022-05-14 12:59:39,370 [00910f34-9556-4f5c-8864-f93205907e3c@group-C3BF6305580B-LeaderElection1] INFO impl.LeaderElection: 00910f34-9556-4f5c-8864-f93205907e3c@group-C3BF6305580B-LeaderElection1: skip running since this is already CLOSING
datanode_1  | 2022-05-14 12:59:39,399 [grpc-default-executor-1] INFO server.RaftServer$Division: 00910f34-9556-4f5c-8864-f93205907e3c@group-C3BF6305580B replies to ELECTION vote request: 55441846-8ccc-4390-87fc-ba015dadcaaa<-00910f34-9556-4f5c-8864-f93205907e3c#0:FAIL-t1. Peer's state: 00910f34-9556-4f5c-8864-f93205907e3c@group-C3BF6305580B:t1, leader=null, voted=null, raftlog=00910f34-9556-4f5c-8864-f93205907e3c@group-C3BF6305580B-SegmentedRaftLog:OPENED:c-1, conf=-1: [54b0e747-a2bb-484f-976a-c7c0770cb588|rpc:172.18.0.9:9856|admin:172.18.0.9:9857|client:172.18.0.9:9858|priority:0, 55441846-8ccc-4390-87fc-ba015dadcaaa|rpc:172.18.0.4:9856|admin:172.18.0.4:9857|client:172.18.0.4:9858|priority:0, 00910f34-9556-4f5c-8864-f93205907e3c|rpc:172.18.0.6:9856|admin:172.18.0.6:9857|client:172.18.0.6:9858|priority:1], old=null
datanode_1  | 2022-05-14 12:59:43,311 [00910f34-9556-4f5c-8864-f93205907e3c@group-8AA059D6EDB9-FollowerState] INFO impl.FollowerState: 00910f34-9556-4f5c-8864-f93205907e3c@group-8AA059D6EDB9-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5112665597ns, electionTimeout:5104ms
datanode_1  | 2022-05-14 12:59:43,312 [00910f34-9556-4f5c-8864-f93205907e3c@group-8AA059D6EDB9-FollowerState] INFO impl.RoleInfo: 00910f34-9556-4f5c-8864-f93205907e3c: shutdown 00910f34-9556-4f5c-8864-f93205907e3c@group-8AA059D6EDB9-FollowerState
datanode_1  | 2022-05-14 12:59:43,312 [00910f34-9556-4f5c-8864-f93205907e3c@group-8AA059D6EDB9-FollowerState] INFO server.RaftServer$Division: 00910f34-9556-4f5c-8864-f93205907e3c@group-8AA059D6EDB9: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_1  | 2022-05-14 12:59:43,313 [00910f34-9556-4f5c-8864-f93205907e3c@group-8AA059D6EDB9-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode_1  | 2022-05-14 12:59:43,313 [00910f34-9556-4f5c-8864-f93205907e3c@group-8AA059D6EDB9-FollowerState] INFO impl.RoleInfo: 00910f34-9556-4f5c-8864-f93205907e3c: start 00910f34-9556-4f5c-8864-f93205907e3c@group-8AA059D6EDB9-LeaderElection2
datanode_1  | 2022-05-14 12:59:43,324 [00910f34-9556-4f5c-8864-f93205907e3c@group-8AA059D6EDB9-LeaderElection2] INFO impl.LeaderElection: 00910f34-9556-4f5c-8864-f93205907e3c@group-8AA059D6EDB9-LeaderElection2 ELECTION round 0: submit vote requests at term 1 for -1: [00910f34-9556-4f5c-8864-f93205907e3c|rpc:172.18.0.6:9856|admin:172.18.0.6:9857|client:172.18.0.6:9858|priority:1], old=null
datanode_1  | 2022-05-14 12:59:43,327 [00910f34-9556-4f5c-8864-f93205907e3c@group-8AA059D6EDB9-LeaderElection2] INFO impl.LeaderElection: 00910f34-9556-4f5c-8864-f93205907e3c@group-8AA059D6EDB9-LeaderElection2 ELECTION round 0: result PASSED (term=1)
datanode_1  | 2022-05-14 12:59:43,331 [00910f34-9556-4f5c-8864-f93205907e3c@group-8AA059D6EDB9-LeaderElection2] INFO impl.RoleInfo: 00910f34-9556-4f5c-8864-f93205907e3c: shutdown 00910f34-9556-4f5c-8864-f93205907e3c@group-8AA059D6EDB9-LeaderElection2
datanode_1  | 2022-05-14 12:59:43,331 [00910f34-9556-4f5c-8864-f93205907e3c@group-8AA059D6EDB9-LeaderElection2] INFO server.RaftServer$Division: 00910f34-9556-4f5c-8864-f93205907e3c@group-8AA059D6EDB9: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_1  | 2022-05-14 12:59:43,332 [00910f34-9556-4f5c-8864-f93205907e3c@group-8AA059D6EDB9-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-8AA059D6EDB9 with new leaderId: 00910f34-9556-4f5c-8864-f93205907e3c
datanode_1  | 2022-05-14 12:59:43,334 [00910f34-9556-4f5c-8864-f93205907e3c@group-8AA059D6EDB9-LeaderElection2] INFO server.RaftServer$Division: 00910f34-9556-4f5c-8864-f93205907e3c@group-8AA059D6EDB9: change Leader from null to 00910f34-9556-4f5c-8864-f93205907e3c at term 1 for becomeLeader, leader elected after 5184ms
datanode_1  | 2022-05-14 12:59:43,361 [00910f34-9556-4f5c-8864-f93205907e3c@group-8AA059D6EDB9-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_1  | 2022-05-14 12:59:43,365 [00910f34-9556-4f5c-8864-f93205907e3c@group-8AA059D6EDB9-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_1  | 2022-05-14 12:59:43,377 [00910f34-9556-4f5c-8864-f93205907e3c@group-8AA059D6EDB9-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode_1  | 2022-05-14 12:59:43,396 [00910f34-9556-4f5c-8864-f93205907e3c@group-8AA059D6EDB9-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_1  | 2022-05-14 12:59:43,400 [00910f34-9556-4f5c-8864-f93205907e3c@group-8AA059D6EDB9-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_1  | 2022-05-14 12:59:43,401 [00910f34-9556-4f5c-8864-f93205907e3c@group-8AA059D6EDB9-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_1  | 2022-05-14 12:59:43,413 [00910f34-9556-4f5c-8864-f93205907e3c@group-8AA059D6EDB9-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_1  | 2022-05-14 12:59:43,424 [00910f34-9556-4f5c-8864-f93205907e3c@group-8AA059D6EDB9-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
datanode_1  | 2022-05-14 12:59:43,434 [00910f34-9556-4f5c-8864-f93205907e3c@group-8AA059D6EDB9-LeaderElection2] INFO impl.RoleInfo: 00910f34-9556-4f5c-8864-f93205907e3c: start 00910f34-9556-4f5c-8864-f93205907e3c@group-8AA059D6EDB9-LeaderStateImpl
datanode_1  | 2022-05-14 12:59:43,498 [00910f34-9556-4f5c-8864-f93205907e3c@group-8AA059D6EDB9-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: 00910f34-9556-4f5c-8864-f93205907e3c@group-8AA059D6EDB9-SegmentedRaftLogWorker: Starting segment from index:0
datanode_1  | 2022-05-14 12:59:43,619 [00910f34-9556-4f5c-8864-f93205907e3c@group-8AA059D6EDB9-LeaderElection2] INFO server.RaftServer$Division: 00910f34-9556-4f5c-8864-f93205907e3c@group-8AA059D6EDB9: set configuration 0: [00910f34-9556-4f5c-8864-f93205907e3c|rpc:172.18.0.6:9856|admin:172.18.0.6:9857|client:172.18.0.6:9858|dataStream:|priority:1], old=null
datanode_1  | 2022-05-14 12:59:43,760 [00910f34-9556-4f5c-8864-f93205907e3c@group-8AA059D6EDB9-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 00910f34-9556-4f5c-8864-f93205907e3c@group-8AA059D6EDB9-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/ec7d4258-8caa-4f40-bc08-8aa059d6edb9/current/log_inprogress_0
datanode_1  | 2022-05-14 12:59:44,391 [00910f34-9556-4f5c-8864-f93205907e3c@group-C3BF6305580B-FollowerState] INFO impl.FollowerState: 00910f34-9556-4f5c-8864-f93205907e3c@group-C3BF6305580B-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5022218002ns, electionTimeout:5014ms
datanode_1  | 2022-05-14 12:59:44,391 [00910f34-9556-4f5c-8864-f93205907e3c@group-C3BF6305580B-FollowerState] INFO impl.RoleInfo: 00910f34-9556-4f5c-8864-f93205907e3c: shutdown 00910f34-9556-4f5c-8864-f93205907e3c@group-C3BF6305580B-FollowerState
datanode_1  | 2022-05-14 12:59:44,392 [00910f34-9556-4f5c-8864-f93205907e3c@group-C3BF6305580B-FollowerState] INFO server.RaftServer$Division: 00910f34-9556-4f5c-8864-f93205907e3c@group-C3BF6305580B: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
datanode_1  | 2022-05-14 12:59:44,392 [00910f34-9556-4f5c-8864-f93205907e3c@group-C3BF6305580B-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode_1  | 2022-05-14 12:59:44,392 [00910f34-9556-4f5c-8864-f93205907e3c@group-C3BF6305580B-FollowerState] INFO impl.RoleInfo: 00910f34-9556-4f5c-8864-f93205907e3c: start 00910f34-9556-4f5c-8864-f93205907e3c@group-C3BF6305580B-LeaderElection3
datanode_1  | 2022-05-14 12:59:44,395 [00910f34-9556-4f5c-8864-f93205907e3c@group-C3BF6305580B-LeaderElection3] INFO impl.LeaderElection: 00910f34-9556-4f5c-8864-f93205907e3c@group-C3BF6305580B-LeaderElection3 ELECTION round 0: submit vote requests at term 2 for -1: [54b0e747-a2bb-484f-976a-c7c0770cb588|rpc:172.18.0.9:9856|admin:172.18.0.9:9857|client:172.18.0.9:9858|priority:0, 55441846-8ccc-4390-87fc-ba015dadcaaa|rpc:172.18.0.4:9856|admin:172.18.0.4:9857|client:172.18.0.4:9858|priority:0, 00910f34-9556-4f5c-8864-f93205907e3c|rpc:172.18.0.6:9856|admin:172.18.0.6:9857|client:172.18.0.6:9858|priority:1], old=null
datanode_1  | 2022-05-14 12:59:44,480 [00910f34-9556-4f5c-8864-f93205907e3c@group-C3BF6305580B-LeaderElection3] INFO impl.LeaderElection: 00910f34-9556-4f5c-8864-f93205907e3c@group-C3BF6305580B-LeaderElection3: ELECTION PASSED received 1 response(s) and 0 exception(s):
datanode_1  | 2022-05-14 12:59:44,480 [00910f34-9556-4f5c-8864-f93205907e3c@group-C3BF6305580B-LeaderElection3] INFO impl.LeaderElection:   Response 0: 00910f34-9556-4f5c-8864-f93205907e3c<-54b0e747-a2bb-484f-976a-c7c0770cb588#0:OK-t2
datanode_1  | 2022-05-14 12:59:44,480 [00910f34-9556-4f5c-8864-f93205907e3c@group-C3BF6305580B-LeaderElection3] INFO impl.LeaderElection: 00910f34-9556-4f5c-8864-f93205907e3c@group-C3BF6305580B-LeaderElection3 ELECTION round 0: result PASSED
datanode_1  | 2022-05-14 12:59:44,480 [00910f34-9556-4f5c-8864-f93205907e3c@group-C3BF6305580B-LeaderElection3] INFO impl.RoleInfo: 00910f34-9556-4f5c-8864-f93205907e3c: shutdown 00910f34-9556-4f5c-8864-f93205907e3c@group-C3BF6305580B-LeaderElection3
datanode_1  | 2022-05-14 12:59:44,481 [00910f34-9556-4f5c-8864-f93205907e3c@group-C3BF6305580B-LeaderElection3] INFO server.RaftServer$Division: 00910f34-9556-4f5c-8864-f93205907e3c@group-C3BF6305580B: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
datanode_1  | 2022-05-14 12:59:44,481 [00910f34-9556-4f5c-8864-f93205907e3c@group-C3BF6305580B-LeaderElection3] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-C3BF6305580B with new leaderId: 00910f34-9556-4f5c-8864-f93205907e3c
datanode_1  | 2022-05-14 12:59:44,482 [00910f34-9556-4f5c-8864-f93205907e3c@group-C3BF6305580B-LeaderElection3] INFO server.RaftServer$Division: 00910f34-9556-4f5c-8864-f93205907e3c@group-C3BF6305580B: change Leader from null to 00910f34-9556-4f5c-8864-f93205907e3c at term 2 for becomeLeader, leader elected after 11367ms
datanode_1  | 2022-05-14 12:59:44,482 [00910f34-9556-4f5c-8864-f93205907e3c@group-C3BF6305580B-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_1  | 2022-05-14 12:59:44,482 [00910f34-9556-4f5c-8864-f93205907e3c@group-C3BF6305580B-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_1  | 2022-05-14 12:59:44,483 [00910f34-9556-4f5c-8864-f93205907e3c@group-C3BF6305580B-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode_1  | 2022-05-14 12:59:44,483 [00910f34-9556-4f5c-8864-f93205907e3c@group-C3BF6305580B-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_1  | 2022-05-14 12:59:44,497 [00910f34-9556-4f5c-8864-f93205907e3c@group-C3BF6305580B-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_1  | 2022-05-14 12:59:44,498 [00910f34-9556-4f5c-8864-f93205907e3c@group-C3BF6305580B-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_1  | 2022-05-14 12:59:44,501 [00910f34-9556-4f5c-8864-f93205907e3c@group-C3BF6305580B-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_1  | 2022-05-14 12:59:44,501 [00910f34-9556-4f5c-8864-f93205907e3c@group-C3BF6305580B-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
datanode_1  | 2022-05-14 12:59:44,529 [00910f34-9556-4f5c-8864-f93205907e3c@group-C3BF6305580B-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_1  | 2022-05-14 12:59:44,535 [00910f34-9556-4f5c-8864-f93205907e3c@group-C3BF6305580B-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1  | 2022-05-14 12:59:44,535 [00910f34-9556-4f5c-8864-f93205907e3c@group-C3BF6305580B-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_1  | 2022-05-14 12:59:44,544 [00910f34-9556-4f5c-8864-f93205907e3c@group-C3BF6305580B-LeaderElection3] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_1  | 2022-05-14 12:59:44,546 [00910f34-9556-4f5c-8864-f93205907e3c@group-C3BF6305580B-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_1  | 2022-05-14 12:59:44,548 [00910f34-9556-4f5c-8864-f93205907e3c@group-C3BF6305580B-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1  | 2022-05-14 12:59:44,570 [00910f34-9556-4f5c-8864-f93205907e3c@group-C3BF6305580B-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_1  | 2022-05-14 12:59:44,570 [00910f34-9556-4f5c-8864-f93205907e3c@group-C3BF6305580B-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1  | 2022-05-14 12:59:44,570 [00910f34-9556-4f5c-8864-f93205907e3c@group-C3BF6305580B-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_1  | 2022-05-14 12:59:44,575 [00910f34-9556-4f5c-8864-f93205907e3c@group-C3BF6305580B-LeaderElection3] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_1  | 2022-05-14 12:59:44,575 [00910f34-9556-4f5c-8864-f93205907e3c@group-C3BF6305580B-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_1  | 2022-05-14 12:59:44,575 [00910f34-9556-4f5c-8864-f93205907e3c@group-C3BF6305580B-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_4  | 2022-05-14 12:59:33,327 [pool-22-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/74934bef-4747-4536-b24b-4a9fa2b98460 does not exist. Creating ...
datanode_4  | 2022-05-14 12:59:33,357 [pool-22-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/74934bef-4747-4536-b24b-4a9fa2b98460/in_use.lock acquired by nodename 7@8dcbf89c8500
datanode_4  | 2022-05-14 12:59:33,398 [pool-22-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/74934bef-4747-4536-b24b-4a9fa2b98460 has been successfully formatted.
datanode_4  | 2022-05-14 12:59:33,436 [pool-22-thread-1] INFO ratis.ContainerStateMachine: group-4A9FA2B98460: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_4  | 2022-05-14 12:59:33,437 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode_4  | 2022-05-14 12:59:33,597 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_4  | 2022-05-14 12:59:33,746 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_4  | 2022-05-14 12:59:33,759 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_4  | 2022-05-14 12:59:34,029 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_4  | 2022-05-14 12:59:34,068 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_4  | 2022-05-14 12:59:34,085 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode_4  | 2022-05-14 12:59:34,165 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: new d5e6fff5-66a9-4bee-add9-03aeb4a97c66@group-4A9FA2B98460-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/74934bef-4747-4536-b24b-4a9fa2b98460
datanode_4  | 2022-05-14 12:59:34,173 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode_4  | 2022-05-14 12:59:34,174 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_4  | 2022-05-14 12:59:34,177 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_4  | 2022-05-14 12:59:34,199 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_4  | 2022-05-14 12:59:34,199 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_4  | 2022-05-14 12:59:34,201 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_4  | 2022-05-14 12:59:34,204 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_4  | 2022-05-14 12:59:34,205 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_4  | 2022-05-14 12:59:34,308 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_4  | 2022-05-14 12:59:34,335 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_4  | 2022-05-14 12:59:34,366 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: d5e6fff5-66a9-4bee-add9-03aeb4a97c66@group-4A9FA2B98460-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_4  | 2022-05-14 12:59:34,385 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: d5e6fff5-66a9-4bee-add9-03aeb4a97c66@group-4A9FA2B98460-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_4  | 2022-05-14 12:59:34,423 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_4  | 2022-05-14 12:59:34,427 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_4  | 2022-05-14 12:59:34,428 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_4  | 2022-05-14 12:59:34,441 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_4  | 2022-05-14 12:59:34,447 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_4  | 2022-05-14 12:59:34,447 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode_4  | 2022-05-14 12:59:34,653 [pool-22-thread-1] INFO server.RaftServer$Division: d5e6fff5-66a9-4bee-add9-03aeb4a97c66@group-4A9FA2B98460: start as a follower, conf=-1: [d5e6fff5-66a9-4bee-add9-03aeb4a97c66|rpc:172.18.0.2:9856|admin:172.18.0.2:9857|client:172.18.0.2:9858|priority:1], old=null
datanode_4  | 2022-05-14 12:59:34,670 [pool-22-thread-1] INFO server.RaftServer$Division: d5e6fff5-66a9-4bee-add9-03aeb4a97c66@group-4A9FA2B98460: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_4  | 2022-05-14 12:59:34,680 [pool-22-thread-1] INFO impl.RoleInfo: d5e6fff5-66a9-4bee-add9-03aeb4a97c66: start d5e6fff5-66a9-4bee-add9-03aeb4a97c66@group-4A9FA2B98460-FollowerState
datanode_4  | 2022-05-14 12:59:34,715 [pool-22-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-4A9FA2B98460,id=d5e6fff5-66a9-4bee-add9-03aeb4a97c66
datanode_4  | 2022-05-14 12:59:34,795 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=74934bef-4747-4536-b24b-4a9fa2b98460
datanode_4  | 2022-05-14 12:59:34,796 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=74934bef-4747-4536-b24b-4a9fa2b98460.
datanode_4  | 2022-05-14 12:59:39,704 [d5e6fff5-66a9-4bee-add9-03aeb4a97c66@group-4A9FA2B98460-FollowerState] INFO impl.FollowerState: d5e6fff5-66a9-4bee-add9-03aeb4a97c66@group-4A9FA2B98460-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5024389750ns, electionTimeout:5008ms
datanode_4  | 2022-05-14 12:59:39,706 [d5e6fff5-66a9-4bee-add9-03aeb4a97c66@group-4A9FA2B98460-FollowerState] INFO impl.RoleInfo: d5e6fff5-66a9-4bee-add9-03aeb4a97c66: shutdown d5e6fff5-66a9-4bee-add9-03aeb4a97c66@group-4A9FA2B98460-FollowerState
datanode_4  | 2022-05-14 12:59:39,706 [d5e6fff5-66a9-4bee-add9-03aeb4a97c66@group-4A9FA2B98460-FollowerState] INFO server.RaftServer$Division: d5e6fff5-66a9-4bee-add9-03aeb4a97c66@group-4A9FA2B98460: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_4  | 2022-05-14 12:59:39,710 [d5e6fff5-66a9-4bee-add9-03aeb4a97c66@group-4A9FA2B98460-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode_4  | 2022-05-14 12:59:39,711 [d5e6fff5-66a9-4bee-add9-03aeb4a97c66@group-4A9FA2B98460-FollowerState] INFO impl.RoleInfo: d5e6fff5-66a9-4bee-add9-03aeb4a97c66: start d5e6fff5-66a9-4bee-add9-03aeb4a97c66@group-4A9FA2B98460-LeaderElection1
datanode_4  | 2022-05-14 12:59:39,721 [d5e6fff5-66a9-4bee-add9-03aeb4a97c66@group-4A9FA2B98460-LeaderElection1] INFO impl.LeaderElection: d5e6fff5-66a9-4bee-add9-03aeb4a97c66@group-4A9FA2B98460-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [d5e6fff5-66a9-4bee-add9-03aeb4a97c66|rpc:172.18.0.2:9856|admin:172.18.0.2:9857|client:172.18.0.2:9858|priority:1], old=null
datanode_4  | 2022-05-14 12:59:39,722 [d5e6fff5-66a9-4bee-add9-03aeb4a97c66@group-4A9FA2B98460-LeaderElection1] INFO impl.LeaderElection: d5e6fff5-66a9-4bee-add9-03aeb4a97c66@group-4A9FA2B98460-LeaderElection1 ELECTION round 0: result PASSED (term=1)
datanode_4  | 2022-05-14 12:59:39,725 [d5e6fff5-66a9-4bee-add9-03aeb4a97c66@group-4A9FA2B98460-LeaderElection1] INFO impl.RoleInfo: d5e6fff5-66a9-4bee-add9-03aeb4a97c66: shutdown d5e6fff5-66a9-4bee-add9-03aeb4a97c66@group-4A9FA2B98460-LeaderElection1
datanode_4  | 2022-05-14 12:59:39,726 [d5e6fff5-66a9-4bee-add9-03aeb4a97c66@group-4A9FA2B98460-LeaderElection1] INFO server.RaftServer$Division: d5e6fff5-66a9-4bee-add9-03aeb4a97c66@group-4A9FA2B98460: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_4  | 2022-05-14 12:59:39,727 [d5e6fff5-66a9-4bee-add9-03aeb4a97c66@group-4A9FA2B98460-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-4A9FA2B98460 with new leaderId: d5e6fff5-66a9-4bee-add9-03aeb4a97c66
datanode_4  | 2022-05-14 12:59:39,729 [d5e6fff5-66a9-4bee-add9-03aeb4a97c66@group-4A9FA2B98460-LeaderElection1] INFO server.RaftServer$Division: d5e6fff5-66a9-4bee-add9-03aeb4a97c66@group-4A9FA2B98460: change Leader from null to d5e6fff5-66a9-4bee-add9-03aeb4a97c66 at term 1 for becomeLeader, leader elected after 6290ms
datanode_4  | 2022-05-14 12:59:39,746 [d5e6fff5-66a9-4bee-add9-03aeb4a97c66@group-4A9FA2B98460-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_4  | 2022-05-14 12:59:39,766 [d5e6fff5-66a9-4bee-add9-03aeb4a97c66@group-4A9FA2B98460-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_4  | 2022-05-14 12:59:39,768 [d5e6fff5-66a9-4bee-add9-03aeb4a97c66@group-4A9FA2B98460-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode_4  | 2022-05-14 12:59:39,780 [d5e6fff5-66a9-4bee-add9-03aeb4a97c66@group-4A9FA2B98460-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_4  | 2022-05-14 12:59:39,783 [d5e6fff5-66a9-4bee-add9-03aeb4a97c66@group-4A9FA2B98460-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_4  | 2022-05-14 12:59:39,784 [d5e6fff5-66a9-4bee-add9-03aeb4a97c66@group-4A9FA2B98460-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_4  | 2022-05-14 12:59:39,799 [d5e6fff5-66a9-4bee-add9-03aeb4a97c66@group-4A9FA2B98460-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_4  | 2022-05-14 12:59:39,801 [d5e6fff5-66a9-4bee-add9-03aeb4a97c66@group-4A9FA2B98460-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
datanode_4  | 2022-05-14 12:59:39,803 [d5e6fff5-66a9-4bee-add9-03aeb4a97c66@group-4A9FA2B98460-LeaderElection1] INFO impl.RoleInfo: d5e6fff5-66a9-4bee-add9-03aeb4a97c66: start d5e6fff5-66a9-4bee-add9-03aeb4a97c66@group-4A9FA2B98460-LeaderStateImpl
datanode_4  | 2022-05-14 12:59:39,845 [d5e6fff5-66a9-4bee-add9-03aeb4a97c66@group-4A9FA2B98460-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: d5e6fff5-66a9-4bee-add9-03aeb4a97c66@group-4A9FA2B98460-SegmentedRaftLogWorker: Starting segment from index:0
datanode_4  | 2022-05-14 12:59:39,967 [d5e6fff5-66a9-4bee-add9-03aeb4a97c66@group-4A9FA2B98460-LeaderElection1] INFO server.RaftServer$Division: d5e6fff5-66a9-4bee-add9-03aeb4a97c66@group-4A9FA2B98460: set configuration 0: [d5e6fff5-66a9-4bee-add9-03aeb4a97c66|rpc:172.18.0.2:9856|admin:172.18.0.2:9857|client:172.18.0.2:9858|dataStream:|priority:1], old=null
datanode_4  | 2022-05-14 12:59:40,141 [d5e6fff5-66a9-4bee-add9-03aeb4a97c66@group-4A9FA2B98460-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: d5e6fff5-66a9-4bee-add9-03aeb4a97c66@group-4A9FA2B98460-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/74934bef-4747-4536-b24b-4a9fa2b98460/current/log_inprogress_0
datanode_1  | 2022-05-14 12:59:44,580 [00910f34-9556-4f5c-8864-f93205907e3c@group-C3BF6305580B-LeaderElection3] INFO impl.RoleInfo: 00910f34-9556-4f5c-8864-f93205907e3c: start 00910f34-9556-4f5c-8864-f93205907e3c@group-C3BF6305580B-LeaderStateImpl
datanode_1  | 2022-05-14 12:59:44,587 [00910f34-9556-4f5c-8864-f93205907e3c@group-C3BF6305580B-LeaderElection3] INFO segmented.SegmentedRaftLogWorker: 00910f34-9556-4f5c-8864-f93205907e3c@group-C3BF6305580B-SegmentedRaftLogWorker: Starting segment from index:0
datanode_1  | 2022-05-14 12:59:44,592 [00910f34-9556-4f5c-8864-f93205907e3c@group-C3BF6305580B-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 00910f34-9556-4f5c-8864-f93205907e3c@group-C3BF6305580B-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/503efc89-95e3-40df-aa92-c3bf6305580b/current/log_inprogress_0
datanode_1  | 2022-05-14 12:59:44,615 [00910f34-9556-4f5c-8864-f93205907e3c@group-C3BF6305580B-LeaderElection3] INFO server.RaftServer$Division: 00910f34-9556-4f5c-8864-f93205907e3c@group-C3BF6305580B: set configuration 0: [54b0e747-a2bb-484f-976a-c7c0770cb588|rpc:172.18.0.9:9856|admin:172.18.0.9:9857|client:172.18.0.9:9858|dataStream:|priority:0, 55441846-8ccc-4390-87fc-ba015dadcaaa|rpc:172.18.0.4:9856|admin:172.18.0.4:9857|client:172.18.0.4:9858|dataStream:|priority:0, 00910f34-9556-4f5c-8864-f93205907e3c|rpc:172.18.0.6:9856|admin:172.18.0.6:9857|client:172.18.0.6:9858|dataStream:|priority:1], old=null
datanode_1  | 2022-05-14 13:33:00,219 [ContainerOp-503efc89-95e3-40df-aa92-c3bf6305580b-2] INFO keyvalue.KeyValueContainer: Container 1 is synced with bcsId 2784.
datanode_1  | 2022-05-14 13:33:00,219 [ContainerOp-503efc89-95e3-40df-aa92-c3bf6305580b-2] INFO keyvalue.KeyValueContainer: Container 1 is synced with bcsId 2784.
datanode_1  | 2022-05-14 13:33:00,237 [ContainerOp-503efc89-95e3-40df-aa92-c3bf6305580b-2] INFO keyvalue.KeyValueContainer: Container 1 is closed with bcsId 2784.
datanode_1  | 2022-05-14 13:33:26,249 [org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@3458dab6] INFO commandhandler.DeleteBlocksCommandHandler: Start to delete container blocks, TXIDs=[32(0),1(0),33(0),2(0),5(0),8(0),11(0),12(0),18(0),27(0),28(0),29(0),30(0),31(0)], numOfContainers=1, numOfBlocks=122
datanode_1  | 2022-05-14 13:34:24,019 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200104.block
datanode_1  | 2022-05-14 13:34:24,020 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200107.block
datanode_1  | 2022-05-14 13:34:24,020 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200110.block
datanode_1  | 2022-05-14 13:34:24,020 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200115.block
datanode_1  | 2022-05-14 13:34:24,020 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200118.block
datanode_1  | 2022-05-14 13:34:24,020 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200119.block
datanode_1  | 2022-05-14 13:34:24,021 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200120.block
datanode_1  | 2022-05-14 13:34:24,021 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200121.block
datanode_1  | 2022-05-14 13:34:24,021 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200200.block
datanode_1  | 2022-05-14 13:34:24,021 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200213.block
datanode_1  | 2022-05-14 13:34:24,021 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200214.block
datanode_1  | 2022-05-14 13:34:24,022 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200307.block
datanode_1  | 2022-05-14 13:34:24,022 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200310.block
datanode_1  | 2022-05-14 13:34:24,024 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200313.block
datanode_1  | 2022-05-14 13:34:24,025 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200317.block
datanode_1  | 2022-05-14 13:34:24,025 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200319.block
datanode_1  | 2022-05-14 13:34:24,025 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200321.block
datanode_1  | 2022-05-14 13:34:24,025 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200323.block
datanode_1  | 2022-05-14 13:34:24,026 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200324.block
datanode_1  | 2022-05-14 13:34:24,026 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200303.block
datanode_1  | 2022-05-14 13:34:24,034 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200305.block
datanode_1  | 2022-05-14 13:34:24,035 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200308.block
datanode_1  | 2022-05-14 13:34:24,035 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200311.block
datanode_1  | 2022-05-14 13:34:24,035 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200315.block
datanode_1  | 2022-05-14 13:34:24,036 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200318.block
datanode_1  | 2022-05-14 13:34:24,036 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200320.block
datanode_1  | 2022-05-14 13:34:24,036 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200322.block
datanode_1  | 2022-05-14 13:34:24,036 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200304.block
datanode_1  | 2022-05-14 13:34:24,036 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200306.block
datanode_1  | 2022-05-14 13:34:24,037 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200309.block
datanode_1  | 2022-05-14 13:34:24,037 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200312.block
datanode_1  | 2022-05-14 13:34:24,039 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200314.block
datanode_1  | 2022-05-14 13:34:24,039 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200316.block
datanode_1  | 2022-05-14 13:34:24,039 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200297.block
datanode_1  | 2022-05-14 13:34:24,039 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200298.block
datanode_1  | 2022-05-14 13:34:24,040 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200299.block
datanode_1  | 2022-05-14 13:34:24,040 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200300.block
datanode_1  | 2022-05-14 13:34:24,040 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200301.block
datanode_1  | 2022-05-14 13:34:24,045 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200302.block
datanode_1  | 2022-05-14 13:34:24,045 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200268.block
datanode_1  | 2022-05-14 13:34:24,045 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200269.block
datanode_1  | 2022-05-14 13:34:24,045 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200270.block
datanode_1  | 2022-05-14 13:34:24,045 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200271.block
datanode_1  | 2022-05-14 13:34:24,046 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200272.block
datanode_1  | 2022-05-14 13:34:24,046 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200291.block
datanode_1  | 2022-05-14 13:34:24,046 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200292.block
datanode_1  | 2022-05-14 13:34:24,046 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200293.block
datanode_1  | 2022-05-14 13:34:24,046 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200294.block
datanode_1  | 2022-05-14 13:34:24,046 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200295.block
datanode_1  | 2022-05-14 13:34:24,047 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200366.block
datanode_1  | 2022-05-14 13:34:24,047 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200367.block
datanode_1  | 2022-05-14 13:34:24,047 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200368.block
datanode_1  | 2022-05-14 13:34:24,058 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200369.block
datanode_1  | 2022-05-14 13:34:24,058 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200370.block
datanode_1  | 2022-05-14 13:34:24,060 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200371.block
datanode_1  | 2022-05-14 13:34:24,060 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200372.block
datanode_1  | 2022-05-14 13:34:24,061 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200373.block
datanode_1  | 2022-05-14 13:34:24,061 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200374.block
datanode_1  | 2022-05-14 13:34:24,061 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200375.block
datanode_1  | 2022-05-14 13:34:24,065 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200390.block
datanode_1  | 2022-05-14 13:34:24,066 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200391.block
datanode_1  | 2022-05-14 13:34:24,066 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200392.block
datanode_1  | 2022-05-14 13:34:24,066 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200388.block
datanode_1  | 2022-05-14 13:34:24,067 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200393.block
datanode_1  | 2022-05-14 13:34:24,067 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200394.block
datanode_1  | 2022-05-14 13:34:24,068 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200401.block
datanode_1  | 2022-05-14 13:34:24,068 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200402.block
datanode_1  | 2022-05-14 13:34:24,071 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200494.block
datanode_1  | 2022-05-14 13:34:24,072 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200497.block
datanode_1  | 2022-05-14 13:34:24,074 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200500.block
datanode_1  | 2022-05-14 13:34:24,077 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200503.block
datanode_1  | 2022-05-14 13:34:24,077 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200505.block
datanode_1  | 2022-05-14 13:34:24,078 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200508.block
datanode_1  | 2022-05-14 13:34:24,079 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200509.block
datanode_1  | 2022-05-14 13:34:24,080 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200511.block
datanode_1  | 2022-05-14 13:34:24,081 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200491.block
datanode_1  | 2022-05-14 13:34:24,083 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200493.block
datanode_1  | 2022-05-14 13:34:24,084 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200496.block
datanode_1  | 2022-05-14 13:34:24,087 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200499.block
datanode_1  | 2022-05-14 13:34:24,088 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200502.block
datanode_1  | 2022-05-14 13:34:24,088 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200507.block
datanode_1  | 2022-05-14 13:34:24,089 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200510.block
datanode_1  | 2022-05-14 13:34:24,093 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200512.block
datanode_1  | 2022-05-14 13:34:24,094 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200492.block
datanode_1  | 2022-05-14 13:34:24,094 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200495.block
datanode_1  | 2022-05-14 13:34:24,096 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200498.block
datanode_1  | 2022-05-14 13:34:24,097 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200501.block
datanode_1  | 2022-05-14 13:34:24,100 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200504.block
datanode_1  | 2022-05-14 13:34:24,101 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200506.block
datanode_1  | 2022-05-14 13:34:24,101 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200456.block
datanode_1  | 2022-05-14 13:34:24,104 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200457.block
datanode_1  | 2022-05-14 13:34:24,106 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200458.block
datanode_1  | 2022-05-14 13:34:24,108 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200459.block
datanode_1  | 2022-05-14 13:34:24,109 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200460.block
datanode_3  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
datanode_3  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_3  | 2022-05-14 12:58:29,264 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_3  | /************************************************************
datanode_3  | STARTUP_MSG: Starting HddsDatanodeService
datanode_3  | STARTUP_MSG:   host = a9a0b51623f6/172.18.0.4
datanode_3  | STARTUP_MSG:   args = []
datanode_3  | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
datanode_2  | 2022-05-14 12:59:38,044 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode_2  | 2022-05-14 12:59:38,052 [pool-22-thread-1] INFO server.RaftServer$Division: 54b0e747-a2bb-484f-976a-c7c0770cb588@group-7A48E9FEEF0D: start as a follower, conf=-1: [54b0e747-a2bb-484f-976a-c7c0770cb588|rpc:172.18.0.9:9856|admin:172.18.0.9:9857|client:172.18.0.9:9858|priority:1], old=null
datanode_2  | 2022-05-14 12:59:38,052 [pool-22-thread-1] INFO server.RaftServer$Division: 54b0e747-a2bb-484f-976a-c7c0770cb588@group-7A48E9FEEF0D: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_2  | 2022-05-14 12:59:38,052 [pool-22-thread-1] INFO impl.RoleInfo: 54b0e747-a2bb-484f-976a-c7c0770cb588: start 54b0e747-a2bb-484f-976a-c7c0770cb588@group-7A48E9FEEF0D-FollowerState
datanode_2  | 2022-05-14 12:59:38,061 [pool-22-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-7A48E9FEEF0D,id=54b0e747-a2bb-484f-976a-c7c0770cb588
datanode_2  | 2022-05-14 12:59:38,066 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=1fd8b2e8-f580-4de7-855d-7a48e9feef0d
datanode_2  | 2022-05-14 12:59:38,071 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=1fd8b2e8-f580-4de7-855d-7a48e9feef0d.
datanode_2  | 2022-05-14 12:59:39,298 [grpc-default-executor-1] INFO server.RaftServer$Division: 54b0e747-a2bb-484f-976a-c7c0770cb588@group-C3BF6305580B: receive requestVote(ELECTION, 55441846-8ccc-4390-87fc-ba015dadcaaa, group-C3BF6305580B, 1, (t:0, i:0))
datanode_2  | 2022-05-14 12:59:39,312 [grpc-default-executor-1] INFO impl.VoteContext: 54b0e747-a2bb-484f-976a-c7c0770cb588@group-C3BF6305580B-FOLLOWER: accept ELECTION from 55441846-8ccc-4390-87fc-ba015dadcaaa: our priority 0 <= candidate's priority 0
datanode_2  | 2022-05-14 12:59:39,312 [grpc-default-executor-1] INFO server.RaftServer$Division: 54b0e747-a2bb-484f-976a-c7c0770cb588@group-C3BF6305580B: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:55441846-8ccc-4390-87fc-ba015dadcaaa
datanode_2  | 2022-05-14 12:59:39,315 [grpc-default-executor-1] INFO impl.RoleInfo: 54b0e747-a2bb-484f-976a-c7c0770cb588: shutdown 54b0e747-a2bb-484f-976a-c7c0770cb588@group-C3BF6305580B-FollowerState
datanode_2  | 2022-05-14 12:59:39,317 [grpc-default-executor-1] INFO impl.RoleInfo: 54b0e747-a2bb-484f-976a-c7c0770cb588: start 54b0e747-a2bb-484f-976a-c7c0770cb588@group-C3BF6305580B-FollowerState
datanode_2  | 2022-05-14 12:59:39,318 [54b0e747-a2bb-484f-976a-c7c0770cb588@group-C3BF6305580B-FollowerState] INFO impl.FollowerState: 54b0e747-a2bb-484f-976a-c7c0770cb588@group-C3BF6305580B-FollowerState was interrupted: {}
datanode_2  | java.lang.InterruptedException: sleep interrupted
datanode_2  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode_2  | 	at java.base/java.lang.Thread.sleep(Thread.java:334)
datanode_2  | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
datanode_2  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
datanode_2  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
datanode_2  | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
datanode_2  | 2022-05-14 12:59:39,354 [grpc-default-executor-1] INFO server.RaftServer$Division: 54b0e747-a2bb-484f-976a-c7c0770cb588@group-C3BF6305580B replies to ELECTION vote request: 55441846-8ccc-4390-87fc-ba015dadcaaa<-54b0e747-a2bb-484f-976a-c7c0770cb588#0:OK-t1. Peer's state: 54b0e747-a2bb-484f-976a-c7c0770cb588@group-C3BF6305580B:t1, leader=null, voted=55441846-8ccc-4390-87fc-ba015dadcaaa, raftlog=54b0e747-a2bb-484f-976a-c7c0770cb588@group-C3BF6305580B-SegmentedRaftLog:OPENED:c-1, conf=-1: [54b0e747-a2bb-484f-976a-c7c0770cb588|rpc:172.18.0.9:9856|admin:172.18.0.9:9857|client:172.18.0.9:9858|priority:0, 55441846-8ccc-4390-87fc-ba015dadcaaa|rpc:172.18.0.4:9856|admin:172.18.0.4:9857|client:172.18.0.4:9858|priority:0, 00910f34-9556-4f5c-8864-f93205907e3c|rpc:172.18.0.6:9856|admin:172.18.0.6:9857|client:172.18.0.6:9858|priority:1], old=null
datanode_2  | 2022-05-14 12:59:43,123 [54b0e747-a2bb-484f-976a-c7c0770cb588@group-7A48E9FEEF0D-FollowerState] INFO impl.FollowerState: 54b0e747-a2bb-484f-976a-c7c0770cb588@group-7A48E9FEEF0D-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5070930763ns, electionTimeout:5051ms
datanode_2  | 2022-05-14 12:59:43,124 [54b0e747-a2bb-484f-976a-c7c0770cb588@group-7A48E9FEEF0D-FollowerState] INFO impl.RoleInfo: 54b0e747-a2bb-484f-976a-c7c0770cb588: shutdown 54b0e747-a2bb-484f-976a-c7c0770cb588@group-7A48E9FEEF0D-FollowerState
datanode_2  | 2022-05-14 12:59:43,124 [54b0e747-a2bb-484f-976a-c7c0770cb588@group-7A48E9FEEF0D-FollowerState] INFO server.RaftServer$Division: 54b0e747-a2bb-484f-976a-c7c0770cb588@group-7A48E9FEEF0D: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_2  | 2022-05-14 12:59:43,127 [54b0e747-a2bb-484f-976a-c7c0770cb588@group-7A48E9FEEF0D-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode_2  | 2022-05-14 12:59:43,127 [54b0e747-a2bb-484f-976a-c7c0770cb588@group-7A48E9FEEF0D-FollowerState] INFO impl.RoleInfo: 54b0e747-a2bb-484f-976a-c7c0770cb588: start 54b0e747-a2bb-484f-976a-c7c0770cb588@group-7A48E9FEEF0D-LeaderElection1
datanode_2  | 2022-05-14 12:59:43,136 [54b0e747-a2bb-484f-976a-c7c0770cb588@group-7A48E9FEEF0D-LeaderElection1] INFO impl.LeaderElection: 54b0e747-a2bb-484f-976a-c7c0770cb588@group-7A48E9FEEF0D-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [54b0e747-a2bb-484f-976a-c7c0770cb588|rpc:172.18.0.9:9856|admin:172.18.0.9:9857|client:172.18.0.9:9858|priority:1], old=null
datanode_2  | 2022-05-14 12:59:43,137 [54b0e747-a2bb-484f-976a-c7c0770cb588@group-7A48E9FEEF0D-LeaderElection1] INFO impl.LeaderElection: 54b0e747-a2bb-484f-976a-c7c0770cb588@group-7A48E9FEEF0D-LeaderElection1 ELECTION round 0: result PASSED (term=1)
datanode_2  | 2022-05-14 12:59:43,137 [54b0e747-a2bb-484f-976a-c7c0770cb588@group-7A48E9FEEF0D-LeaderElection1] INFO impl.RoleInfo: 54b0e747-a2bb-484f-976a-c7c0770cb588: shutdown 54b0e747-a2bb-484f-976a-c7c0770cb588@group-7A48E9FEEF0D-LeaderElection1
datanode_2  | 2022-05-14 12:59:43,138 [54b0e747-a2bb-484f-976a-c7c0770cb588@group-7A48E9FEEF0D-LeaderElection1] INFO server.RaftServer$Division: 54b0e747-a2bb-484f-976a-c7c0770cb588@group-7A48E9FEEF0D: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_2  | 2022-05-14 12:59:43,138 [54b0e747-a2bb-484f-976a-c7c0770cb588@group-7A48E9FEEF0D-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-7A48E9FEEF0D with new leaderId: 54b0e747-a2bb-484f-976a-c7c0770cb588
datanode_2  | 2022-05-14 12:59:43,157 [54b0e747-a2bb-484f-976a-c7c0770cb588@group-7A48E9FEEF0D-LeaderElection1] INFO server.RaftServer$Division: 54b0e747-a2bb-484f-976a-c7c0770cb588@group-7A48E9FEEF0D: change Leader from null to 54b0e747-a2bb-484f-976a-c7c0770cb588 at term 1 for becomeLeader, leader elected after 5205ms
datanode_2  | 2022-05-14 12:59:43,169 [54b0e747-a2bb-484f-976a-c7c0770cb588@group-7A48E9FEEF0D-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_2  | 2022-05-14 12:59:43,174 [54b0e747-a2bb-484f-976a-c7c0770cb588@group-7A48E9FEEF0D-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_2  | 2022-05-14 12:59:43,185 [54b0e747-a2bb-484f-976a-c7c0770cb588@group-7A48E9FEEF0D-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode_2  | 2022-05-14 12:59:43,190 [54b0e747-a2bb-484f-976a-c7c0770cb588@group-7A48E9FEEF0D-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_2  | 2022-05-14 12:59:43,196 [54b0e747-a2bb-484f-976a-c7c0770cb588@group-7A48E9FEEF0D-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_5  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
datanode_5  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_5  | 2022-05-14 12:58:35,428 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_5  | /************************************************************
datanode_5  | STARTUP_MSG: Starting HddsDatanodeService
datanode_5  | STARTUP_MSG:   host = bb2dfb20fd37/172.18.0.8
datanode_5  | STARTUP_MSG:   args = []
datanode_5  | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
datanode_3  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.0.4.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.3.0-SNAPSHOT.jar
datanode_3  | STARTUP_MSG:   build = https://github.com/apache/ozone/40461504478182af509db7098d4e173011d27e5a ; compiled by 'runner' on 2022-05-14T12:47Z
datanode_3  | STARTUP_MSG:   java = 11.0.14.1
datanode_3  | ************************************************************/
datanode_3  | 2022-05-14 12:58:29,354 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_3  | 2022-05-14 12:58:31,718 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_3  | 2022-05-14 12:58:32,603 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_3  | 2022-05-14 12:58:33,857 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_3  | 2022-05-14 12:58:33,857 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_3  | 2022-05-14 12:58:34,930 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:a9a0b51623f6 ip:172.18.0.4
datanode_3  | 2022-05-14 12:58:37,823 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = ERASURE_CODED_STORAGE_SUPPORT (version = 3), software layout = ERASURE_CODED_STORAGE_SUPPORT (version = 3)
datanode_3  | 2022-05-14 12:58:38,951 [main] INFO reflections.Reflections: Reflections took 859 ms to scan 2 urls, producing 87 keys and 176 values 
datanode_3  | 2022-05-14 12:58:40,028 [main] INFO statemachine.DatanodeStateMachine: Datanode State Machine Task Thread Pool size 2
datanode_3  | 2022-05-14 12:58:42,080 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_3  | 2022-05-14 12:58:42,188 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89311358976
datanode_3  | 2022-05-14 12:58:42,263 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_3  | 2022-05-14 12:58:42,268 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_3  | 2022-05-14 12:58:42,562 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_3  | 2022-05-14 12:58:42,706 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_3  | 2022-05-14 12:58:42,715 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/metadata/ratis/scmUsed not found
datanode_3  | 2022-05-14 12:58:42,738 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
datanode_3  | 2022-05-14 12:58:42,748 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/metadata/ratis
datanode_3  | 2022-05-14 12:58:42,751 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/metadata/ratis
datanode_3  | 2022-05-14 12:58:43,057 [Thread-7] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode_3  | 2022-05-14 12:58:43,064 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode_3  | 2022-05-14 12:58:54,414 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for DNAudit to [].
datanode_3  | 2022-05-14 12:58:55,422 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_3  | 2022-05-14 12:58:56,021 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
datanode_3  | 2022-05-14 12:58:57,180 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
datanode_3  | 2022-05-14 12:58:57,181 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
datanode_3  | 2022-05-14 12:58:57,198 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
datanode_3  | 2022-05-14 12:58:57,207 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_3  | 2022-05-14 12:58:57,208 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | 2022-05-14 12:58:57,219 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_3  | 2022-05-14 12:58:57,256 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_3  | 2022-05-14 12:59:00,596 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
datanode_3  | 2022-05-14 12:59:00,616 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode_3  | 2022-05-14 12:59:00,616 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_3  | 2022-05-14 12:59:00,748 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3  | 2022-05-14 12:59:01,188 [main] INFO server.XceiverServerGrpc: GrpcServer channel type EpollServerSocketChannel
datanode_3  | 2022-05-14 12:59:02,102 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_3  | 2022-05-14 12:59:02,209 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_3  | 2022-05-14 12:59:02,508 [main] INFO util.log: Logging initialized @40781ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_3  | 2022-05-14 12:59:03,506 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_3  | 2022-05-14 12:59:03,550 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_3  | 2022-05-14 12:59:03,607 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_3  | 2022-05-14 12:59:03,624 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_3  | 2022-05-14 12:59:03,627 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_3  | 2022-05-14 12:59:03,627 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_3  | 2022-05-14 12:59:04,076 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_1  | 2022-05-14 13:34:24,109 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200485.block
datanode_1  | 2022-05-14 13:34:24,116 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200486.block
datanode_1  | 2022-05-14 13:34:24,117 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200487.block
datanode_5  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.0.4.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.3.0-SNAPSHOT.jar
datanode_5  | STARTUP_MSG:   build = https://github.com/apache/ozone/40461504478182af509db7098d4e173011d27e5a ; compiled by 'runner' on 2022-05-14T12:47Z
datanode_5  | STARTUP_MSG:   java = 11.0.14.1
datanode_5  | ************************************************************/
datanode_5  | 2022-05-14 12:58:35,512 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_5  | 2022-05-14 12:58:38,101 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_5  | 2022-05-14 12:58:39,106 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_5  | 2022-05-14 12:58:40,540 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_5  | 2022-05-14 12:58:40,541 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_5  | 2022-05-14 12:58:41,936 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:bb2dfb20fd37 ip:172.18.0.8
datanode_5  | 2022-05-14 12:58:44,539 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = ERASURE_CODED_STORAGE_SUPPORT (version = 3), software layout = ERASURE_CODED_STORAGE_SUPPORT (version = 3)
datanode_5  | 2022-05-14 12:58:45,597 [main] INFO reflections.Reflections: Reflections took 808 ms to scan 2 urls, producing 87 keys and 176 values 
datanode_5  | 2022-05-14 12:58:46,715 [main] INFO statemachine.DatanodeStateMachine: Datanode State Machine Task Thread Pool size 2
datanode_5  | 2022-05-14 12:58:48,442 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_5  | 2022-05-14 12:58:48,552 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89311358976
datanode_5  | 2022-05-14 12:58:48,616 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_5  | 2022-05-14 12:58:48,621 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_5  | 2022-05-14 12:58:48,977 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_5  | 2022-05-14 12:58:49,162 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_5  | 2022-05-14 12:58:49,168 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/metadata/ratis/scmUsed not found
datanode_5  | 2022-05-14 12:58:49,181 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
datanode_5  | 2022-05-14 12:58:49,187 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/metadata/ratis
datanode_5  | 2022-05-14 12:58:49,192 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/metadata/ratis
datanode_5  | 2022-05-14 12:58:49,560 [Thread-7] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode_5  | 2022-05-14 12:58:49,585 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode_5  | 2022-05-14 12:59:01,667 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for DNAudit to [].
datanode_5  | 2022-05-14 12:59:02,888 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_5  | 2022-05-14 12:59:03,377 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
datanode_5  | 2022-05-14 12:59:04,674 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
datanode_5  | 2022-05-14 12:59:04,683 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
datanode_5  | 2022-05-14 12:59:04,691 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
datanode_5  | 2022-05-14 12:59:04,735 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_5  | 2022-05-14 12:59:04,747 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_5  | 2022-05-14 12:59:04,751 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_5  | 2022-05-14 12:59:04,759 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_5  | 2022-05-14 12:59:07,946 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
datanode_5  | 2022-05-14 12:59:07,991 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode_5  | 2022-05-14 12:59:07,994 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_5  | 2022-05-14 12:59:08,160 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_5  | 2022-05-14 12:59:08,450 [main] INFO server.XceiverServerGrpc: GrpcServer channel type EpollServerSocketChannel
datanode_5  | 2022-05-14 12:59:09,677 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_5  | 2022-05-14 12:59:09,814 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_5  | 2022-05-14 12:59:10,099 [main] INFO util.log: Logging initialized @45175ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_5  | 2022-05-14 12:59:10,852 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_5  | 2022-05-14 12:59:10,931 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_5  | 2022-05-14 12:59:10,955 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_5  | 2022-05-14 12:59:10,963 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_5  | 2022-05-14 12:59:10,971 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_5  | 2022-05-14 12:59:10,971 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_5  | 2022-05-14 12:59:11,304 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_5  | 2022-05-14 12:59:11,320 [main] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
datanode_5  | 2022-05-14 12:59:11,555 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_5  | 2022-05-14 12:59:11,566 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_5  | 2022-05-14 12:59:11,568 [main] INFO server.session: node0 Scavenging every 600000ms
datanode_5  | 2022-05-14 12:59:11,681 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@618fb1{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om_1        | 2022-05-14 12:58:38,000 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om_1        | /************************************************************
om_1        | STARTUP_MSG: Starting OzoneManager
om_1        | STARTUP_MSG:   host = cb49fc765711/172.18.0.7
om_1        | STARTUP_MSG:   args = [--init]
om_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
om_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.38.0.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.38.0.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.38.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.23.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.38.0.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.38.0.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-2.0.38.Final.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.19.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.38.0.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.38.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.38.Final.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.0.4.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar
om_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/40461504478182af509db7098d4e173011d27e5a ; compiled by 'runner' on 2022-05-14T12:48Z
om_1        | STARTUP_MSG:   java = 11.0.14.1
om_1        | ************************************************************/
om_1        | 2022-05-14 12:58:38,108 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om_1        | 2022-05-14 12:58:46,939 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for OMAudit to [].
om_1        | 2022-05-14 12:58:50,797 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
om_1        | 2022-05-14 12:58:51,479 [main] INFO ha.OMHANodeDetails: Configuration does not have ozone.om.address set. Falling back to the default OM address om/172.18.0.7:9862
om_1        | 2022-05-14 12:58:51,480 [main] INFO ha.OMHANodeDetails: OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
om_1        | 2022-05-14 12:58:51,491 [main] INFO ha.OMHANodeDetails: OM Node ID is not set. Setting it to the default ID: om1
om_1        | 2022-05-14 12:58:51,685 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1        | 2022-05-14 12:58:57,721 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From cb49fc765711/172.18.0.7 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy32.send over nodeId=scmNodeId,nodeAddress=scm/172.18.0.3:9863 after 1 failover attempts. Trying to failover after sleeping for 2000ms.
om_1        | 2022-05-14 12:58:59,722 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From cb49fc765711/172.18.0.7 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy32.send over nodeId=scmNodeId,nodeAddress=scm/172.18.0.3:9863 after 2 failover attempts. Trying to failover after sleeping for 2000ms.
om_1        | 2022-05-14 12:59:01,724 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From cb49fc765711/172.18.0.7 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy32.send over nodeId=scmNodeId,nodeAddress=scm/172.18.0.3:9863 after 3 failover attempts. Trying to failover after sleeping for 2000ms.
om_1        | 2022-05-14 12:59:03,725 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From cb49fc765711/172.18.0.7 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy32.send over nodeId=scmNodeId,nodeAddress=scm/172.18.0.3:9863 after 4 failover attempts. Trying to failover after sleeping for 2000ms.
om_1        | 2022-05-14 12:59:05,727 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From cb49fc765711/172.18.0.7 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy32.send over nodeId=scmNodeId,nodeAddress=scm/172.18.0.3:9863 after 5 failover attempts. Trying to failover after sleeping for 2000ms.
om_1        | 2022-05-14 12:59:07,729 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From cb49fc765711/172.18.0.7 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy32.send over nodeId=scmNodeId,nodeAddress=scm/172.18.0.3:9863 after 6 failover attempts. Trying to failover after sleeping for 2000ms.
om_1        | 2022-05-14 12:59:09,731 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From cb49fc765711/172.18.0.7 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy32.send over nodeId=scmNodeId,nodeAddress=scm/172.18.0.3:9863 after 7 failover attempts. Trying to failover after sleeping for 2000ms.
om_1        | 2022-05-14 12:59:11,733 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From cb49fc765711/172.18.0.7 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy32.send over nodeId=scmNodeId,nodeAddress=scm/172.18.0.3:9863 after 8 failover attempts. Trying to failover after sleeping for 2000ms.
om_1        | 2022-05-14 12:59:13,734 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From cb49fc765711/172.18.0.7 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy32.send over nodeId=scmNodeId,nodeAddress=scm/172.18.0.3:9863 after 9 failover attempts. Trying to failover after sleeping for 2000ms.
om_1        | 2022-05-14 12:59:15,736 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From cb49fc765711/172.18.0.7 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy32.send over nodeId=scmNodeId,nodeAddress=scm/172.18.0.3:9863 after 10 failover attempts. Trying to failover after sleeping for 2000ms.
om_1        | 2022-05-14 12:59:17,737 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From cb49fc765711/172.18.0.7 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy32.send over nodeId=scmNodeId,nodeAddress=scm/172.18.0.3:9863 after 11 failover attempts. Trying to failover after sleeping for 2000ms.
om_1        | 2022-05-14 12:59:19,739 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From cb49fc765711/172.18.0.7 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy32.send over nodeId=scmNodeId,nodeAddress=scm/172.18.0.3:9863 after 12 failover attempts. Trying to failover after sleeping for 2000ms.
om_1        | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-b57acd13-b274-4901-b263-891afc26c373;layoutVersion=2
om_1        | 2022-05-14 12:59:23,364 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
om_1        | /************************************************************
om_1        | SHUTDOWN_MSG: Shutting down OzoneManager at cb49fc765711/172.18.0.7
om_1        | ************************************************************/
om_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om_1        | 2022-05-14 12:59:30,037 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om_1        | /************************************************************
om_1        | STARTUP_MSG: Starting OzoneManager
om_1        | STARTUP_MSG:   host = cb49fc765711/172.18.0.7
om_1        | STARTUP_MSG:   args = []
om_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
om_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.38.0.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.38.0.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.38.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.23.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.38.0.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.38.0.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-2.0.38.Final.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.19.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.38.0.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.38.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.38.Final.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.0.4.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar
om_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/40461504478182af509db7098d4e173011d27e5a ; compiled by 'runner' on 2022-05-14T12:48Z
om_1        | STARTUP_MSG:   java = 11.0.14.1
om_1        | ************************************************************/
om_1        | 2022-05-14 12:59:30,045 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om_1        | 2022-05-14 12:59:31,091 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for OMAudit to [].
om_1        | 2022-05-14 12:59:31,951 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
om_1        | 2022-05-14 12:59:32,089 [main] INFO ha.OMHANodeDetails: Configuration does not have ozone.om.address set. Falling back to the default OM address om/172.18.0.7:9862
om_1        | 2022-05-14 12:59:32,089 [main] INFO ha.OMHANodeDetails: OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
om_1        | 2022-05-14 12:59:32,089 [main] INFO ha.OMHANodeDetails: OM Node ID is not set. Setting it to the default ID: om1
om_1        | 2022-05-14 12:59:32,147 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1        | 2022-05-14 12:59:32,222 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = BUCKET_LAYOUT_SUPPORT (version = 2), software layout = BUCKET_LAYOUT_SUPPORT (version = 2)
datanode_2  | 2022-05-14 12:59:43,197 [54b0e747-a2bb-484f-976a-c7c0770cb588@group-7A48E9FEEF0D-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_2  | 2022-05-14 12:59:43,216 [54b0e747-a2bb-484f-976a-c7c0770cb588@group-7A48E9FEEF0D-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_2  | 2022-05-14 12:59:43,226 [54b0e747-a2bb-484f-976a-c7c0770cb588@group-7A48E9FEEF0D-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
datanode_2  | 2022-05-14 12:59:43,232 [54b0e747-a2bb-484f-976a-c7c0770cb588@group-7A48E9FEEF0D-LeaderElection1] INFO impl.RoleInfo: 54b0e747-a2bb-484f-976a-c7c0770cb588: start 54b0e747-a2bb-484f-976a-c7c0770cb588@group-7A48E9FEEF0D-LeaderStateImpl
datanode_2  | 2022-05-14 12:59:43,282 [54b0e747-a2bb-484f-976a-c7c0770cb588@group-7A48E9FEEF0D-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 54b0e747-a2bb-484f-976a-c7c0770cb588@group-7A48E9FEEF0D-SegmentedRaftLogWorker: Starting segment from index:0
datanode_2  | 2022-05-14 12:59:43,370 [54b0e747-a2bb-484f-976a-c7c0770cb588@group-7A48E9FEEF0D-LeaderElection1] INFO server.RaftServer$Division: 54b0e747-a2bb-484f-976a-c7c0770cb588@group-7A48E9FEEF0D: set configuration 0: [54b0e747-a2bb-484f-976a-c7c0770cb588|rpc:172.18.0.9:9856|admin:172.18.0.9:9857|client:172.18.0.9:9858|dataStream:|priority:1], old=null
datanode_2  | 2022-05-14 12:59:43,511 [54b0e747-a2bb-484f-976a-c7c0770cb588@group-7A48E9FEEF0D-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 54b0e747-a2bb-484f-976a-c7c0770cb588@group-7A48E9FEEF0D-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/1fd8b2e8-f580-4de7-855d-7a48e9feef0d/current/log_inprogress_0
datanode_2  | 2022-05-14 12:59:44,469 [grpc-default-executor-1] INFO server.RaftServer$Division: 54b0e747-a2bb-484f-976a-c7c0770cb588@group-C3BF6305580B: receive requestVote(ELECTION, 00910f34-9556-4f5c-8864-f93205907e3c, group-C3BF6305580B, 2, (t:0, i:0))
datanode_2  | 2022-05-14 12:59:44,469 [grpc-default-executor-1] INFO impl.VoteContext: 54b0e747-a2bb-484f-976a-c7c0770cb588@group-C3BF6305580B-FOLLOWER: accept ELECTION from 00910f34-9556-4f5c-8864-f93205907e3c: our priority 0 <= candidate's priority 1
datanode_2  | 2022-05-14 12:59:44,469 [grpc-default-executor-1] INFO server.RaftServer$Division: 54b0e747-a2bb-484f-976a-c7c0770cb588@group-C3BF6305580B: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:00910f34-9556-4f5c-8864-f93205907e3c
datanode_2  | 2022-05-14 12:59:44,469 [grpc-default-executor-1] INFO impl.RoleInfo: 54b0e747-a2bb-484f-976a-c7c0770cb588: shutdown 54b0e747-a2bb-484f-976a-c7c0770cb588@group-C3BF6305580B-FollowerState
datanode_2  | 2022-05-14 12:59:44,469 [54b0e747-a2bb-484f-976a-c7c0770cb588@group-C3BF6305580B-FollowerState] INFO impl.FollowerState: 54b0e747-a2bb-484f-976a-c7c0770cb588@group-C3BF6305580B-FollowerState was interrupted: {}
datanode_2  | java.lang.InterruptedException: sleep interrupted
datanode_2  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode_2  | 	at java.base/java.lang.Thread.sleep(Thread.java:334)
datanode_2  | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
datanode_2  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
datanode_2  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
datanode_2  | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
datanode_2  | 2022-05-14 12:59:44,470 [grpc-default-executor-1] INFO impl.RoleInfo: 54b0e747-a2bb-484f-976a-c7c0770cb588: start 54b0e747-a2bb-484f-976a-c7c0770cb588@group-C3BF6305580B-FollowerState
datanode_2  | 2022-05-14 12:59:44,473 [grpc-default-executor-1] INFO server.RaftServer$Division: 54b0e747-a2bb-484f-976a-c7c0770cb588@group-C3BF6305580B replies to ELECTION vote request: 00910f34-9556-4f5c-8864-f93205907e3c<-54b0e747-a2bb-484f-976a-c7c0770cb588#0:OK-t2. Peer's state: 54b0e747-a2bb-484f-976a-c7c0770cb588@group-C3BF6305580B:t2, leader=null, voted=00910f34-9556-4f5c-8864-f93205907e3c, raftlog=54b0e747-a2bb-484f-976a-c7c0770cb588@group-C3BF6305580B-SegmentedRaftLog:OPENED:c-1, conf=-1: [54b0e747-a2bb-484f-976a-c7c0770cb588|rpc:172.18.0.9:9856|admin:172.18.0.9:9857|client:172.18.0.9:9858|priority:0, 55441846-8ccc-4390-87fc-ba015dadcaaa|rpc:172.18.0.4:9856|admin:172.18.0.4:9857|client:172.18.0.4:9858|priority:0, 00910f34-9556-4f5c-8864-f93205907e3c|rpc:172.18.0.6:9856|admin:172.18.0.6:9857|client:172.18.0.6:9858|priority:1], old=null
datanode_2  | 2022-05-14 12:59:44,672 [grpc-default-executor-1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-C3BF6305580B with new leaderId: 00910f34-9556-4f5c-8864-f93205907e3c
datanode_2  | 2022-05-14 12:59:44,679 [grpc-default-executor-1] INFO server.RaftServer$Division: 54b0e747-a2bb-484f-976a-c7c0770cb588@group-C3BF6305580B: change Leader from null to 00910f34-9556-4f5c-8864-f93205907e3c at term 2 for appendEntries, leader elected after 10838ms
datanode_2  | 2022-05-14 12:59:44,758 [grpc-default-executor-1] INFO server.RaftServer$Division: 54b0e747-a2bb-484f-976a-c7c0770cb588@group-C3BF6305580B: set configuration 0: [54b0e747-a2bb-484f-976a-c7c0770cb588|rpc:172.18.0.9:9856|admin:172.18.0.9:9857|client:172.18.0.9:9858|dataStream:|priority:0, 55441846-8ccc-4390-87fc-ba015dadcaaa|rpc:172.18.0.4:9856|admin:172.18.0.4:9857|client:172.18.0.4:9858|dataStream:|priority:0, 00910f34-9556-4f5c-8864-f93205907e3c|rpc:172.18.0.6:9856|admin:172.18.0.6:9857|client:172.18.0.6:9858|dataStream:|priority:1], old=null
datanode_2  | 2022-05-14 12:59:44,759 [grpc-default-executor-1] INFO segmented.SegmentedRaftLogWorker: 54b0e747-a2bb-484f-976a-c7c0770cb588@group-C3BF6305580B-SegmentedRaftLogWorker: Starting segment from index:0
datanode_2  | 2022-05-14 12:59:44,760 [54b0e747-a2bb-484f-976a-c7c0770cb588@group-C3BF6305580B-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 54b0e747-a2bb-484f-976a-c7c0770cb588@group-C3BF6305580B-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/503efc89-95e3-40df-aa92-c3bf6305580b/current/log_inprogress_0
datanode_2  | 2022-05-14 13:33:00,229 [ContainerOp-503efc89-95e3-40df-aa92-c3bf6305580b-4] INFO keyvalue.KeyValueContainer: Container 1 is synced with bcsId 2784.
datanode_2  | 2022-05-14 13:33:00,230 [ContainerOp-503efc89-95e3-40df-aa92-c3bf6305580b-4] INFO keyvalue.KeyValueContainer: Container 1 is synced with bcsId 2784.
datanode_2  | 2022-05-14 13:33:00,256 [ContainerOp-503efc89-95e3-40df-aa92-c3bf6305580b-4] INFO keyvalue.KeyValueContainer: Container 1 is closed with bcsId 2784.
datanode_2  | 2022-05-14 13:33:26,768 [org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@23d060c2] INFO commandhandler.DeleteBlocksCommandHandler: Start to delete container blocks, TXIDs=[32(0),1(0),33(0),2(0),5(0),8(0),11(0),12(0),18(0),27(0),28(0),29(0),30(0),31(0)], numOfContainers=1, numOfBlocks=122
datanode_2  | 2022-05-14 13:34:24,053 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200104.block
datanode_2  | 2022-05-14 13:34:24,059 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200107.block
datanode_2  | 2022-05-14 13:34:24,060 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200110.block
datanode_2  | 2022-05-14 13:34:24,061 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200115.block
datanode_2  | 2022-05-14 13:34:24,061 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200118.block
datanode_3  | 2022-05-14 12:59:04,100 [main] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
datanode_3  | 2022-05-14 12:59:04,558 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_3  | 2022-05-14 12:59:04,568 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_3  | 2022-05-14 12:59:04,591 [main] INFO server.session: node0 Scavenging every 600000ms
datanode_3  | 2022-05-14 12:59:04,730 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@10b3ea72{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_5  | 2022-05-14 12:59:11,696 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@33b2ba25{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_5  | 2022-05-14 12:59:12,278 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@69cb134{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-10037077558392627352/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_5  | 2022-05-14 12:59:12,336 [main] INFO server.AbstractConnector: Started ServerConnector@578198d9{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
datanode_5  | 2022-05-14 12:59:12,337 [main] INFO server.Server: Started @47412ms
datanode_5  | 2022-05-14 12:59:12,358 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_5  | 2022-05-14 12:59:12,358 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_5  | 2022-05-14 12:59:12,363 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_5  | 2022-05-14 12:59:12,392 [Datanode State Machine Daemon Thread] INFO statemachine.DatanodeStateMachine: Ozone container server started.
datanode_5  | 2022-05-14 12:59:12,519 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@626fa814] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_5  | 2022-05-14 12:59:13,117 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.18.0.10:9891
datanode_5  | 2022-05-14 12:59:13,417 [Datanode State Machine Task Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_5  | 2022-05-14 12:59:15,809 [EndpointStateMachine task thread for recon/172.18.0.10:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.18.0.10:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_5  | 2022-05-14 12:59:15,814 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_5  | 2022-05-14 12:59:16,814 [EndpointStateMachine task thread for recon/172.18.0.10:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.18.0.10:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_5  | 2022-05-14 12:59:16,815 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_5  | 2022-05-14 12:59:17,815 [EndpointStateMachine task thread for recon/172.18.0.10:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.18.0.10:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_5  | 2022-05-14 12:59:17,819 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_5  | 2022-05-14 12:59:18,820 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_5  | 2022-05-14 12:59:19,823 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_5  | 2022-05-14 12:59:20,823 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_5  | 2022-05-14 12:59:22,872 [EndpointStateMachine task thread for recon/172.18.0.10:9891 - 0 ] WARN statemachine.EndpointStateMachine: Unable to communicate to Recon server at recon:9891 for past 0 seconds.
datanode_5  | java.net.SocketTimeoutException: Call From bb2dfb20fd37/172.18.0.8 to recon:9891 failed on socket timeout exception: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.18.0.8:50198 remote=recon/172.18.0.10:9891]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_5  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_5  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_5  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_5  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_5  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)
datanode_5  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:848)
datanode_5  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1577)
datanode_5  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1519)
datanode_5  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1416)
datanode_5  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:236)
datanode_5  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:123)
datanode_5  | 	at com.sun.proxy.$Proxy40.submitRequest(Unknown Source)
datanode_5  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:117)
datanode_5  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:133)
datanode_5  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:71)
datanode_5  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:42)
datanode_5  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_5  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_5  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_5  | 	at java.base/java.lang.Thread.run(Thread.java:829)
datanode_5  | Caused by: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.18.0.8:50198 remote=recon/172.18.0.10:9891]
datanode_5  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_5  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_5  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_5  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_5  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_3  | 2022-05-14 12:59:04,739 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@3f33bb6f{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_3  | 2022-05-14 12:59:05,594 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@270097ce{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-16357897883298010674/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_3  | 2022-05-14 12:59:05,669 [main] INFO server.AbstractConnector: Started ServerConnector@47f39279{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
datanode_3  | 2022-05-14 12:59:05,669 [main] INFO server.Server: Started @43942ms
datanode_3  | 2022-05-14 12:59:05,672 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_3  | 2022-05-14 12:59:05,687 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_3  | 2022-05-14 12:59:05,689 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_3  | 2022-05-14 12:59:05,703 [Datanode State Machine Daemon Thread] INFO statemachine.DatanodeStateMachine: Ozone container server started.
datanode_3  | 2022-05-14 12:59:06,141 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7bb07284] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_3  | 2022-05-14 12:59:06,887 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.18.0.10:9891
datanode_3  | 2022-05-14 12:59:07,341 [Datanode State Machine Task Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_3  | 2022-05-14 12:59:09,982 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_3  | 2022-05-14 12:59:09,999 [EndpointStateMachine task thread for recon/172.18.0.10:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.18.0.10:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_3  | 2022-05-14 12:59:10,987 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_3  | 2022-05-14 12:59:11,001 [EndpointStateMachine task thread for recon/172.18.0.10:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.18.0.10:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_3  | 2022-05-14 12:59:11,989 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_3  | 2022-05-14 12:59:12,002 [EndpointStateMachine task thread for recon/172.18.0.10:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.18.0.10:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_3  | 2022-05-14 12:59:12,989 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_3  | 2022-05-14 12:59:13,003 [EndpointStateMachine task thread for recon/172.18.0.10:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.18.0.10:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_3  | 2022-05-14 12:59:13,991 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_3  | 2022-05-14 12:59:14,003 [EndpointStateMachine task thread for recon/172.18.0.10:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.18.0.10:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_3  | 2022-05-14 12:59:14,992 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_3  | 2022-05-14 12:59:15,005 [EndpointStateMachine task thread for recon/172.18.0.10:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.18.0.10:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_3  | 2022-05-14 12:59:15,994 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_3  | 2022-05-14 12:59:16,005 [EndpointStateMachine task thread for recon/172.18.0.10:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.18.0.10:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_3  | 2022-05-14 12:59:16,995 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_3  | 2022-05-14 12:59:17,006 [EndpointStateMachine task thread for recon/172.18.0.10:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.18.0.10:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_3  | 2022-05-14 12:59:17,996 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_3  | 2022-05-14 12:59:18,997 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_3  | 2022-05-14 12:59:19,998 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_3  | 2022-05-14 12:59:20,999 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.18.0.3:9861. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_3  | 2022-05-14 12:59:22,041 [EndpointStateMachine task thread for recon/172.18.0.10:9891 - 0 ] WARN statemachine.EndpointStateMachine: Unable to communicate to Recon server at recon:9891 for past 0 seconds.
datanode_3  | java.net.SocketTimeoutException: Call From a9a0b51623f6/172.18.0.4 to recon:9891 failed on socket timeout exception: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.18.0.4:42604 remote=recon/172.18.0.10:9891]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_3  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_2  | 2022-05-14 13:34:24,062 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200119.block
datanode_2  | 2022-05-14 13:34:24,062 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200120.block
datanode_2  | 2022-05-14 13:34:24,063 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200121.block
datanode_2  | 2022-05-14 13:34:24,065 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200200.block
datanode_2  | 2022-05-14 13:34:24,066 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200213.block
datanode_2  | 2022-05-14 13:34:24,066 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200214.block
datanode_2  | 2022-05-14 13:34:24,067 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200307.block
datanode_2  | 2022-05-14 13:34:24,067 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200310.block
datanode_2  | 2022-05-14 13:34:24,068 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200313.block
datanode_2  | 2022-05-14 13:34:24,068 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200317.block
datanode_2  | 2022-05-14 13:34:24,074 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200319.block
datanode_2  | 2022-05-14 13:34:24,075 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200321.block
datanode_2  | 2022-05-14 13:34:24,076 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200323.block
datanode_2  | 2022-05-14 13:34:24,077 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200324.block
datanode_2  | 2022-05-14 13:34:24,078 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200303.block
datanode_2  | 2022-05-14 13:34:24,079 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200305.block
datanode_2  | 2022-05-14 13:34:24,079 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200308.block
datanode_2  | 2022-05-14 13:34:24,080 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200311.block
datanode_2  | 2022-05-14 13:34:24,080 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200315.block
datanode_2  | 2022-05-14 13:34:24,082 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200318.block
datanode_2  | 2022-05-14 13:34:24,082 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200320.block
datanode_2  | 2022-05-14 13:34:24,083 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200322.block
datanode_2  | 2022-05-14 13:34:24,084 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200304.block
datanode_2  | 2022-05-14 13:34:24,084 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200306.block
datanode_2  | 2022-05-14 13:34:24,085 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200309.block
datanode_2  | 2022-05-14 13:34:24,087 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200312.block
datanode_2  | 2022-05-14 13:34:24,088 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200314.block
datanode_2  | 2022-05-14 13:34:24,089 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200316.block
datanode_2  | 2022-05-14 13:34:24,089 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200297.block
datanode_2  | 2022-05-14 13:34:24,090 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200298.block
datanode_2  | 2022-05-14 13:34:24,093 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200299.block
datanode_2  | 2022-05-14 13:34:24,094 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200300.block
datanode_2  | 2022-05-14 13:34:24,094 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200301.block
datanode_2  | 2022-05-14 13:34:24,094 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200302.block
datanode_2  | 2022-05-14 13:34:24,095 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200268.block
datanode_2  | 2022-05-14 13:34:24,095 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200269.block
datanode_5  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_5  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_5  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_5  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:563)
datanode_5  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_5  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1892)
datanode_2  | 2022-05-14 13:34:24,095 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200270.block
datanode_2  | 2022-05-14 13:34:24,096 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200271.block
datanode_2  | 2022-05-14 13:34:24,096 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200272.block
datanode_2  | 2022-05-14 13:34:24,097 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200291.block
datanode_2  | 2022-05-14 13:34:24,099 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200292.block
datanode_2  | 2022-05-14 13:34:24,099 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200293.block
datanode_2  | 2022-05-14 13:34:24,099 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200294.block
datanode_2  | 2022-05-14 13:34:24,100 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200295.block
datanode_2  | 2022-05-14 13:34:24,100 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200366.block
datanode_2  | 2022-05-14 13:34:24,101 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200367.block
datanode_2  | 2022-05-14 13:34:24,101 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200368.block
datanode_2  | 2022-05-14 13:34:24,102 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200369.block
datanode_2  | 2022-05-14 13:34:24,105 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200370.block
datanode_2  | 2022-05-14 13:34:24,106 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200371.block
datanode_2  | 2022-05-14 13:34:24,108 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200372.block
datanode_2  | 2022-05-14 13:34:24,109 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200373.block
datanode_2  | 2022-05-14 13:34:24,109 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200374.block
datanode_2  | 2022-05-14 13:34:24,110 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200375.block
datanode_2  | 2022-05-14 13:34:24,110 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200390.block
datanode_2  | 2022-05-14 13:34:24,112 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200391.block
datanode_2  | 2022-05-14 13:34:24,113 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200392.block
datanode_2  | 2022-05-14 13:34:24,113 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200388.block
datanode_2  | 2022-05-14 13:34:24,115 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200393.block
datanode_2  | 2022-05-14 13:34:24,115 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200394.block
datanode_2  | 2022-05-14 13:34:24,115 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200401.block
datanode_2  | 2022-05-14 13:34:24,116 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200402.block
datanode_2  | 2022-05-14 13:34:24,116 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200494.block
datanode_2  | 2022-05-14 13:34:24,120 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200497.block
datanode_2  | 2022-05-14 13:34:24,120 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200500.block
datanode_2  | 2022-05-14 13:34:24,122 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200503.block
datanode_2  | 2022-05-14 13:34:24,123 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200505.block
datanode_2  | 2022-05-14 13:34:24,126 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200508.block
datanode_2  | 2022-05-14 13:34:24,127 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200509.block
datanode_2  | 2022-05-14 13:34:24,127 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200511.block
datanode_2  | 2022-05-14 13:34:24,128 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200491.block
datanode_2  | 2022-05-14 13:34:24,130 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200493.block
datanode_1  | 2022-05-14 13:34:24,119 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200488.block
datanode_1  | 2022-05-14 13:34:24,121 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200489.block
datanode_1  | 2022-05-14 13:34:24,122 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200490.block
datanode_1  | 2022-05-14 13:34:24,123 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200479.block
datanode_1  | 2022-05-14 13:34:24,123 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200480.block
datanode_1  | 2022-05-14 13:34:24,127 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200481.block
datanode_1  | 2022-05-14 13:34:24,127 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200482.block
datanode_1  | 2022-05-14 13:34:24,128 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200483.block
datanode_1  | 2022-05-14 13:34:24,130 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200578.block
datanode_1  | 2022-05-14 13:34:24,130 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200579.block
datanode_1  | 2022-05-14 13:34:24,131 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200580.block
datanode_1  | 2022-05-14 13:34:24,131 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200581.block
datanode_1  | 2022-05-14 13:34:24,132 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200582.block
datanode_1  | 2022-05-14 13:34:24,132 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200554.block
datanode_1  | 2022-05-14 13:34:24,132 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200555.block
datanode_1  | 2022-05-14 13:34:24,133 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200556.block
datanode_1  | 2022-05-14 13:34:24,134 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200557.block
datanode_1  | 2022-05-14 13:34:24,136 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200558.block
datanode_1  | 2022-05-14 13:34:24,137 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200559.block
datanode_1  | 2022-05-14 13:34:24,138 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200560.block
datanode_1  | 2022-05-14 13:34:24,139 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200561.block
datanode_1  | 2022-05-14 13:34:24,140 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200562.block
datanode_1  | 2022-05-14 13:34:24,140 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200563.block
datanode_1  | 2022-05-14 13:34:24,141 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200576.block
datanode_1  | 2022-05-14 13:34:24,153 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200598.block
datanode_5  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1202)
datanode_5  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1098)
datanode_5  | 2022-05-14 12:59:23,238 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_5  | 2022-05-14 12:59:23,255 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_5  | 2022-05-14 12:59:23,944 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis f3166980-8467-4e9a-9c6e-144f4303af87
datanode_5  | 2022-05-14 12:59:24,082 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO server.RaftServer: f3166980-8467-4e9a-9c6e-144f4303af87: start RPC server
datanode_5  | 2022-05-14 12:59:24,098 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO server.GrpcService: f3166980-8467-4e9a-9c6e-144f4303af87: GrpcService started, listening on 9856
datanode_5  | 2022-05-14 12:59:24,102 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO server.GrpcService: f3166980-8467-4e9a-9c6e-144f4303af87: GrpcService started, listening on 9857
datanode_5  | 2022-05-14 12:59:24,105 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO server.GrpcService: f3166980-8467-4e9a-9c6e-144f4303af87: GrpcService started, listening on 9858
datanode_5  | 2022-05-14 12:59:24,114 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis f3166980-8467-4e9a-9c6e-144f4303af87 is started using port 9858 for RATIS
datanode_5  | 2022-05-14 12:59:24,115 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis f3166980-8467-4e9a-9c6e-144f4303af87 is started using port 9857 for RATIS_ADMIN
datanode_5  | 2022-05-14 12:59:24,116 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis f3166980-8467-4e9a-9c6e-144f4303af87 is started using port 9856 for RATIS_SERVER
datanode_5  | 2022-05-14 12:59:24,117 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$325/0x00000008404d6840@2b7c5623] INFO util.JvmPauseMonitor: JvmPauseMonitor-f3166980-8467-4e9a-9c6e-144f4303af87: Started
datanode_5  | 2022-05-14 12:59:28,593 [Datanode State Machine Daemon Thread] ERROR datanode.RunningDatanodeState: Error in executing end point task.
datanode_5  | java.util.concurrent.ExecutionException: java.util.concurrent.TimeoutException
datanode_5  | 	at java.base/java.util.concurrent.FutureTask.report(FutureTask.java:122)
datanode_5  | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:191)
datanode_5  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.computeNextContainerState(RunningDatanodeState.java:199)
datanode_5  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:239)
datanode_5  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:50)
datanode_5  | 	at org.apache.hadoop.ozone.container.common.statemachine.StateContext.execute(StateContext.java:660)
datanode_5  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:285)
datanode_5  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:473)
datanode_5  | 	at java.base/java.lang.Thread.run(Thread.java:829)
datanode_5  | Caused by: java.util.concurrent.TimeoutException
datanode_5  | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:204)
datanode_5  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.lambda$execute$0(RunningDatanodeState.java:157)
datanode_5  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_5  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_5  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_5  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_5  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_5  | 	... 1 more
datanode_5  | 2022-05-14 12:59:32,733 [Command processor thread] INFO server.RaftServer: f3166980-8467-4e9a-9c6e-144f4303af87: addNew group-382BCCACC254:[f3166980-8467-4e9a-9c6e-144f4303af87|rpc:172.18.0.8:9856|admin:172.18.0.8:9857|client:172.18.0.8:9858|priority:1] returns group-382BCCACC254:java.util.concurrent.CompletableFuture@46c9dfea[Not completed]
datanode_5  | 2022-05-14 12:59:32,853 [pool-22-thread-1] INFO server.RaftServer$Division: f3166980-8467-4e9a-9c6e-144f4303af87: new RaftServerImpl for group-382BCCACC254:[f3166980-8467-4e9a-9c6e-144f4303af87|rpc:172.18.0.8:9856|admin:172.18.0.8:9857|client:172.18.0.8:9858|priority:1] with ContainerStateMachine:uninitialized
datanode_5  | 2022-05-14 12:59:32,872 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_5  | 2022-05-14 12:59:32,880 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_5  | 2022-05-14 12:59:32,880 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_5  | 2022-05-14 12:59:32,880 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode_5  | 2022-05-14 12:59:32,880 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_5  | 2022-05-14 12:59:32,881 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode_5  | 2022-05-14 12:59:32,882 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_5  | 2022-05-14 12:59:32,926 [pool-22-thread-1] INFO server.RaftServer$Division: f3166980-8467-4e9a-9c6e-144f4303af87@group-382BCCACC254: ConfigurationManager, init=-1: [f3166980-8467-4e9a-9c6e-144f4303af87|rpc:172.18.0.8:9856|admin:172.18.0.8:9857|client:172.18.0.8:9858|priority:1], old=null, confs=<EMPTY_MAP>
datanode_5  | 2022-05-14 12:59:32,934 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_5  | 2022-05-14 12:59:32,968 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_5  | 2022-05-14 12:59:32,973 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode_5  | 2022-05-14 12:59:32,996 [pool-22-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/a879b83f-d447-4d1a-b7cc-382bccacc254 does not exist. Creating ...
datanode_5  | 2022-05-14 12:59:33,048 [pool-22-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/a879b83f-d447-4d1a-b7cc-382bccacc254/in_use.lock acquired by nodename 6@bb2dfb20fd37
datanode_5  | 2022-05-14 12:59:33,099 [pool-22-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/a879b83f-d447-4d1a-b7cc-382bccacc254 has been successfully formatted.
datanode_5  | 2022-05-14 12:59:33,207 [pool-22-thread-1] INFO ratis.ContainerStateMachine: group-382BCCACC254: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_5  | 2022-05-14 12:59:33,232 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode_5  | 2022-05-14 12:59:33,267 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_5  | 2022-05-14 12:59:33,363 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_2  | 2022-05-14 13:34:24,131 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200496.block
datanode_2  | 2022-05-14 13:34:24,132 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200499.block
datanode_2  | 2022-05-14 13:34:24,133 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200502.block
datanode_2  | 2022-05-14 13:34:24,135 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200507.block
datanode_2  | 2022-05-14 13:34:24,137 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200510.block
datanode_2  | 2022-05-14 13:34:24,139 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200512.block
datanode_2  | 2022-05-14 13:34:24,146 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200492.block
datanode_2  | 2022-05-14 13:34:24,147 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200495.block
datanode_2  | 2022-05-14 13:34:24,147 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200498.block
datanode_2  | 2022-05-14 13:34:24,148 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200501.block
datanode_2  | 2022-05-14 13:34:24,150 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200504.block
datanode_2  | 2022-05-14 13:34:24,151 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200506.block
datanode_2  | 2022-05-14 13:34:24,151 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200456.block
datanode_2  | 2022-05-14 13:34:24,152 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200457.block
datanode_2  | 2022-05-14 13:34:24,152 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200458.block
datanode_2  | 2022-05-14 13:34:24,153 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200459.block
datanode_2  | 2022-05-14 13:34:24,155 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200460.block
datanode_2  | 2022-05-14 13:34:24,155 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200485.block
datanode_2  | 2022-05-14 13:34:24,156 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200486.block
datanode_2  | 2022-05-14 13:34:24,159 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200487.block
datanode_2  | 2022-05-14 13:34:24,162 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200488.block
datanode_2  | 2022-05-14 13:34:24,162 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200489.block
datanode_2  | 2022-05-14 13:34:24,163 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200490.block
datanode_2  | 2022-05-14 13:34:24,163 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200479.block
datanode_2  | 2022-05-14 13:34:24,164 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200480.block
datanode_2  | 2022-05-14 13:34:24,164 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200481.block
datanode_2  | 2022-05-14 13:34:24,166 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200482.block
datanode_2  | 2022-05-14 13:34:24,167 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200483.block
datanode_2  | 2022-05-14 13:34:24,167 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200578.block
datanode_2  | 2022-05-14 13:34:24,171 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200579.block
datanode_2  | 2022-05-14 13:34:24,173 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200580.block
datanode_2  | 2022-05-14 13:34:24,174 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200581.block
datanode_2  | 2022-05-14 13:34:24,176 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200582.block
datanode_2  | 2022-05-14 13:34:24,177 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200554.block
datanode_2  | 2022-05-14 13:34:24,177 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200555.block
datanode_3  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_3  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_3  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_3  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)
datanode_3  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:848)
datanode_3  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1577)
datanode_3  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1519)
datanode_3  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1416)
datanode_3  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:236)
datanode_3  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:123)
datanode_3  | 	at com.sun.proxy.$Proxy40.submitRequest(Unknown Source)
datanode_3  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:117)
datanode_3  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:133)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:71)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:42)
datanode_3  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:829)
datanode_3  | Caused by: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.18.0.4:42604 remote=recon/172.18.0.10:9891]
datanode_3  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_3  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_3  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_3  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_3  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_3  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_3  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_3  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_3  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:563)
datanode_3  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_3  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1892)
datanode_3  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1202)
datanode_3  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1098)
datanode_3  | 2022-05-14 12:59:23,349 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_3  | 2022-05-14 12:59:23,375 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_3  | 2022-05-14 12:59:23,956 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 55441846-8ccc-4390-87fc-ba015dadcaaa
datanode_3  | 2022-05-14 12:59:24,147 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO server.RaftServer: 55441846-8ccc-4390-87fc-ba015dadcaaa: start RPC server
datanode_3  | 2022-05-14 12:59:24,157 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO server.GrpcService: 55441846-8ccc-4390-87fc-ba015dadcaaa: GrpcService started, listening on 9856
datanode_3  | 2022-05-14 12:59:24,158 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO server.GrpcService: 55441846-8ccc-4390-87fc-ba015dadcaaa: GrpcService started, listening on 9857
datanode_3  | 2022-05-14 12:59:24,159 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO server.GrpcService: 55441846-8ccc-4390-87fc-ba015dadcaaa: GrpcService started, listening on 9858
datanode_3  | 2022-05-14 12:59:24,169 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 55441846-8ccc-4390-87fc-ba015dadcaaa is started using port 9858 for RATIS
datanode_3  | 2022-05-14 12:59:24,170 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 55441846-8ccc-4390-87fc-ba015dadcaaa is started using port 9857 for RATIS_ADMIN
datanode_3  | 2022-05-14 12:59:24,170 [EndpointStateMachine task thread for scm/172.18.0.3:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 55441846-8ccc-4390-87fc-ba015dadcaaa is started using port 9856 for RATIS_SERVER
datanode_3  | 2022-05-14 12:59:24,171 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$325/0x00000008404d6840@3521ce58] INFO util.JvmPauseMonitor: JvmPauseMonitor-55441846-8ccc-4390-87fc-ba015dadcaaa: Started
datanode_3  | 2022-05-14 12:59:28,622 [Datanode State Machine Daemon Thread] ERROR datanode.RunningDatanodeState: Error in executing end point task.
datanode_3  | java.util.concurrent.ExecutionException: java.util.concurrent.TimeoutException
datanode_3  | 	at java.base/java.util.concurrent.FutureTask.report(FutureTask.java:122)
datanode_3  | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:191)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.computeNextContainerState(RunningDatanodeState.java:199)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:239)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:50)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.StateContext.execute(StateContext.java:660)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:285)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:473)
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:829)
datanode_3  | Caused by: java.util.concurrent.TimeoutException
datanode_3  | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:204)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.lambda$execute$0(RunningDatanodeState.java:157)
datanode_3  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_3  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_3  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_3  | 	... 1 more
datanode_3  | 2022-05-14 12:59:32,423 [Command processor thread] INFO server.RaftServer: 55441846-8ccc-4390-87fc-ba015dadcaaa: addNew group-C7743FC36AC3:[55441846-8ccc-4390-87fc-ba015dadcaaa|rpc:172.18.0.4:9856|admin:172.18.0.4:9857|client:172.18.0.4:9858|priority:1] returns group-C7743FC36AC3:java.util.concurrent.CompletableFuture@4bbe6b60[Not completed]
datanode_2  | 2022-05-14 13:34:24,177 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200556.block
datanode_2  | 2022-05-14 13:34:24,183 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200557.block
datanode_2  | 2022-05-14 13:34:24,186 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200558.block
datanode_2  | 2022-05-14 13:34:24,187 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200559.block
datanode_2  | 2022-05-14 13:34:24,187 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200560.block
datanode_2  | 2022-05-14 13:34:24,188 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200561.block
datanode_2  | 2022-05-14 13:34:24,189 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200562.block
datanode_2  | 2022-05-14 13:34:24,191 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200563.block
datanode_2  | 2022-05-14 13:34:24,193 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200576.block
datanode_2  | 2022-05-14 13:34:24,194 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200598.block
om_1        | 2022-05-14 12:59:33,265 [main] INFO reflections.Reflections: Reflections took 930 ms to scan 1 urls, producing 103 keys and 280 values [using 2 cores]
om_1        | 2022-05-14 12:59:33,533 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1        | 2022-05-14 12:59:39,149 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1        | 2022-05-14 12:59:39,945 [main] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
om_1        | 2022-05-14 12:59:39,948 [main] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
om_1        | 2022-05-14 12:59:40,798 [main] INFO om.OzoneManager: Created Volume s3v With Owner hadoop required for S3Gateway operations.
om_1        | 2022-05-14 12:59:41,005 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om_1        | 2022-05-14 12:59:41,006 [main] WARN utils.OzoneManagerRatisUtils: ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
om_1        | 2022-05-14 12:59:41,057 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
om_1        | 2022-05-14 12:59:41,079 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om_1        | 2022-05-14 12:59:41,154 [main] INFO ratis.OzoneManagerRatisServer: Instantiating OM Ratis server with groupID: omServiceIdDefault and peers: om:9872
om_1        | 2022-05-14 12:59:41,181 [main] INFO ratis.OzoneManagerStateMachine: LastAppliedIndex is set from TransactionInfo from OM DB as (t:0, i:~)
om_1        | 2022-05-14 12:59:41,248 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
om_1        | 2022-05-14 12:59:41,438 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
om_1        | 2022-05-14 12:59:41,448 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om_1        | 2022-05-14 12:59:41,450 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
om_1        | 2022-05-14 12:59:41,450 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om_1        | 2022-05-14 12:59:41,450 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om_1        | 2022-05-14 12:59:41,454 [main] INFO server.GrpcService: raft.grpc.message.size.max = 33554432 (custom)
om_1        | 2022-05-14 12:59:41,462 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om_1        | 2022-05-14 12:59:41,468 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
om_1        | 2022-05-14 12:59:41,470 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om_1        | 2022-05-14 12:59:41,975 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
om_1        | 2022-05-14 12:59:41,977 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om_1        | 2022-05-14 12:59:41,977 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_5  | 2022-05-14 12:59:33,367 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_5  | 2022-05-14 12:59:33,498 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_5  | 2022-05-14 12:59:33,631 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_5  | 2022-05-14 12:59:33,634 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode_5  | 2022-05-14 12:59:33,692 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: new f3166980-8467-4e9a-9c6e-144f4303af87@group-382BCCACC254-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/a879b83f-d447-4d1a-b7cc-382bccacc254
datanode_5  | 2022-05-14 12:59:33,702 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode_5  | 2022-05-14 12:59:33,702 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_5  | 2022-05-14 12:59:33,718 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_5  | 2022-05-14 12:59:33,726 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_5  | 2022-05-14 12:59:33,731 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_5  | 2022-05-14 12:59:33,741 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_5  | 2022-05-14 12:59:33,745 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_5  | 2022-05-14 12:59:33,759 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_5  | 2022-05-14 12:59:33,865 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_5  | 2022-05-14 12:59:33,866 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_5  | 2022-05-14 12:59:33,952 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: f3166980-8467-4e9a-9c6e-144f4303af87@group-382BCCACC254-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_5  | 2022-05-14 12:59:33,962 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: f3166980-8467-4e9a-9c6e-144f4303af87@group-382BCCACC254-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_5  | 2022-05-14 12:59:33,989 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_5  | 2022-05-14 12:59:33,990 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_5  | 2022-05-14 12:59:33,991 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_5  | 2022-05-14 12:59:33,993 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_5  | 2022-05-14 12:59:34,003 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_5  | 2022-05-14 12:59:34,007 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode_5  | 2022-05-14 12:59:34,234 [pool-22-thread-1] INFO server.RaftServer$Division: f3166980-8467-4e9a-9c6e-144f4303af87@group-382BCCACC254: start as a follower, conf=-1: [f3166980-8467-4e9a-9c6e-144f4303af87|rpc:172.18.0.8:9856|admin:172.18.0.8:9857|client:172.18.0.8:9858|priority:1], old=null
datanode_5  | 2022-05-14 12:59:34,248 [pool-22-thread-1] INFO server.RaftServer$Division: f3166980-8467-4e9a-9c6e-144f4303af87@group-382BCCACC254: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_5  | 2022-05-14 12:59:34,253 [pool-22-thread-1] INFO impl.RoleInfo: f3166980-8467-4e9a-9c6e-144f4303af87: start f3166980-8467-4e9a-9c6e-144f4303af87@group-382BCCACC254-FollowerState
datanode_5  | 2022-05-14 12:59:34,305 [pool-22-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-382BCCACC254,id=f3166980-8467-4e9a-9c6e-144f4303af87
datanode_5  | 2022-05-14 12:59:34,415 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=a879b83f-d447-4d1a-b7cc-382bccacc254
datanode_5  | 2022-05-14 12:59:34,420 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=a879b83f-d447-4d1a-b7cc-382bccacc254.
datanode_5  | 2022-05-14 12:59:39,323 [f3166980-8467-4e9a-9c6e-144f4303af87@group-382BCCACC254-FollowerState] INFO impl.FollowerState: f3166980-8467-4e9a-9c6e-144f4303af87@group-382BCCACC254-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5069864848ns, electionTimeout:5007ms
datanode_5  | 2022-05-14 12:59:39,344 [f3166980-8467-4e9a-9c6e-144f4303af87@group-382BCCACC254-FollowerState] INFO impl.RoleInfo: f3166980-8467-4e9a-9c6e-144f4303af87: shutdown f3166980-8467-4e9a-9c6e-144f4303af87@group-382BCCACC254-FollowerState
datanode_5  | 2022-05-14 12:59:39,345 [f3166980-8467-4e9a-9c6e-144f4303af87@group-382BCCACC254-FollowerState] INFO server.RaftServer$Division: f3166980-8467-4e9a-9c6e-144f4303af87@group-382BCCACC254: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_5  | 2022-05-14 12:59:39,355 [f3166980-8467-4e9a-9c6e-144f4303af87@group-382BCCACC254-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode_5  | 2022-05-14 12:59:39,355 [f3166980-8467-4e9a-9c6e-144f4303af87@group-382BCCACC254-FollowerState] INFO impl.RoleInfo: f3166980-8467-4e9a-9c6e-144f4303af87: start f3166980-8467-4e9a-9c6e-144f4303af87@group-382BCCACC254-LeaderElection1
datanode_5  | 2022-05-14 12:59:39,384 [f3166980-8467-4e9a-9c6e-144f4303af87@group-382BCCACC254-LeaderElection1] INFO impl.LeaderElection: f3166980-8467-4e9a-9c6e-144f4303af87@group-382BCCACC254-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [f3166980-8467-4e9a-9c6e-144f4303af87|rpc:172.18.0.8:9856|admin:172.18.0.8:9857|client:172.18.0.8:9858|priority:1], old=null
datanode_5  | 2022-05-14 12:59:39,385 [f3166980-8467-4e9a-9c6e-144f4303af87@group-382BCCACC254-LeaderElection1] INFO impl.LeaderElection: f3166980-8467-4e9a-9c6e-144f4303af87@group-382BCCACC254-LeaderElection1 ELECTION round 0: result PASSED (term=1)
datanode_5  | 2022-05-14 12:59:39,396 [f3166980-8467-4e9a-9c6e-144f4303af87@group-382BCCACC254-LeaderElection1] INFO impl.RoleInfo: f3166980-8467-4e9a-9c6e-144f4303af87: shutdown f3166980-8467-4e9a-9c6e-144f4303af87@group-382BCCACC254-LeaderElection1
datanode_5  | 2022-05-14 12:59:39,396 [f3166980-8467-4e9a-9c6e-144f4303af87@group-382BCCACC254-LeaderElection1] INFO server.RaftServer$Division: f3166980-8467-4e9a-9c6e-144f4303af87@group-382BCCACC254: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_5  | 2022-05-14 12:59:39,396 [f3166980-8467-4e9a-9c6e-144f4303af87@group-382BCCACC254-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-382BCCACC254 with new leaderId: f3166980-8467-4e9a-9c6e-144f4303af87
datanode_5  | 2022-05-14 12:59:39,421 [f3166980-8467-4e9a-9c6e-144f4303af87@group-382BCCACC254-LeaderElection1] INFO server.RaftServer$Division: f3166980-8467-4e9a-9c6e-144f4303af87@group-382BCCACC254: change Leader from null to f3166980-8467-4e9a-9c6e-144f4303af87 at term 1 for becomeLeader, leader elected after 6165ms
datanode_5  | 2022-05-14 12:59:39,433 [f3166980-8467-4e9a-9c6e-144f4303af87@group-382BCCACC254-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
om_1        | 2022-05-14 12:59:42,006 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om_1        | 2022-05-14 12:59:42,038 [main] INFO server.RaftServer: om1: addNew group-C5BA1605619E:[om1|rpc:om:9872|priority:0] returns group-C5BA1605619E:java.util.concurrent.CompletableFuture@506d7fed[Not completed]
om_1        | 2022-05-14 12:59:42,038 [main] INFO om.OzoneManager: OzoneManager Ratis server initialized at port 9872
om_1        | 2022-05-14 12:59:42,072 [pool-23-thread-1] INFO server.RaftServer$Division: om1: new RaftServerImpl for group-C5BA1605619E:[om1|rpc:om:9872|priority:0] with OzoneManagerStateMachine:uninitialized
om_1        | 2022-05-14 12:59:42,087 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
om_1        | 2022-05-14 12:59:42,087 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
om_1        | 2022-05-14 12:59:42,087 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
om_1        | 2022-05-14 12:59:42,088 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om_1        | 2022-05-14 12:59:42,088 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om_1        | 2022-05-14 12:59:42,107 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
om_1        | 2022-05-14 12:59:42,108 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om_1        | 2022-05-14 12:59:42,136 [pool-23-thread-1] INFO server.RaftServer$Division: om1@group-C5BA1605619E: ConfigurationManager, init=-1: [om1|rpc:om:9872|priority:0], old=null, confs=<EMPTY_MAP>
om_1        | 2022-05-14 12:59:42,136 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om_1        | 2022-05-14 12:59:42,142 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om_1        | 2022-05-14 12:59:42,145 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
om_1        | 2022-05-14 12:59:42,146 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/bf265839-605b-3f16-9796-c5ba1605619e does not exist. Creating ...
om_1        | 2022-05-14 12:59:42,158 [main] INFO om.OzoneManager: Creating RPC Server
om_1        | 2022-05-14 12:59:42,197 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/bf265839-605b-3f16-9796-c5ba1605619e/in_use.lock acquired by nodename 8@cb49fc765711
om_1        | 2022-05-14 12:59:42,264 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/bf265839-605b-3f16-9796-c5ba1605619e has been successfully formatted.
om_1        | 2022-05-14 12:59:42,273 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
om_1        | 2022-05-14 12:59:42,287 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
om_1        | 2022-05-14 12:59:42,317 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om_1        | 2022-05-14 12:59:42,334 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om_1        | 2022-05-14 12:59:42,392 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om_1        | 2022-05-14 12:59:42,422 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
om_1        | 2022-05-14 12:59:42,422 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
om_1        | 2022-05-14 12:59:42,443 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new om1@group-C5BA1605619E-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/bf265839-605b-3f16-9796-c5ba1605619e
om_1        | 2022-05-14 12:59:42,461 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
om_1        | 2022-05-14 12:59:42,462 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
om_1        | 2022-05-14 12:59:42,463 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om_1        | 2022-05-14 12:59:42,463 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
om_1        | 2022-05-14 12:59:42,464 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
om_1        | 2022-05-14 12:59:42,502 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
om_1        | 2022-05-14 12:59:42,502 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om_1        | 2022-05-14 12:59:42,508 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
om_1        | 2022-05-14 12:59:42,604 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
om_1        | 2022-05-14 12:59:42,604 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
om_1        | 2022-05-14 12:59:42,650 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: om1@group-C5BA1605619E-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
om_1        | 2022-05-14 12:59:42,658 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: om1@group-C5BA1605619E-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
om_1        | 2022-05-14 12:59:42,680 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
om_1        | 2022-05-14 12:59:42,687 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 400000 (default)
om_1        | 2022-05-14 12:59:42,696 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
om_1        | 2022-05-14 12:59:42,697 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = true (custom)
om_1        | 2022-05-14 12:59:42,700 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 300s (custom)
om_1        | 2022-05-14 12:59:42,707 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
om_1        | 2022-05-14 12:59:43,934 [main] INFO reflections.Reflections: Reflections took 1551 ms to scan 8 urls, producing 21 keys and 386 values [using 2 cores]
om_1        | 2022-05-14 12:59:44,545 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
datanode_3  | 2022-05-14 12:59:32,479 [pool-22-thread-1] INFO server.RaftServer$Division: 55441846-8ccc-4390-87fc-ba015dadcaaa: new RaftServerImpl for group-C7743FC36AC3:[55441846-8ccc-4390-87fc-ba015dadcaaa|rpc:172.18.0.4:9856|admin:172.18.0.4:9857|client:172.18.0.4:9858|priority:1] with ContainerStateMachine:uninitialized
datanode_3  | 2022-05-14 12:59:32,481 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_3  | 2022-05-14 12:59:32,482 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_3  | 2022-05-14 12:59:32,482 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_3  | 2022-05-14 12:59:32,482 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode_3  | 2022-05-14 12:59:32,482 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_3  | 2022-05-14 12:59:32,483 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode_3  | 2022-05-14 12:59:32,483 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3  | 2022-05-14 12:59:32,492 [pool-22-thread-1] INFO server.RaftServer$Division: 55441846-8ccc-4390-87fc-ba015dadcaaa@group-C7743FC36AC3: ConfigurationManager, init=-1: [55441846-8ccc-4390-87fc-ba015dadcaaa|rpc:172.18.0.4:9856|admin:172.18.0.4:9857|client:172.18.0.4:9858|priority:1], old=null, confs=<EMPTY_MAP>
datanode_3  | 2022-05-14 12:59:32,499 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3  | 2022-05-14 12:59:32,517 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_3  | 2022-05-14 12:59:32,520 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode_3  | 2022-05-14 12:59:32,524 [pool-22-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/bb9400ad-6f37-4998-976e-c7743fc36ac3 does not exist. Creating ...
datanode_3  | 2022-05-14 12:59:32,554 [pool-22-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/bb9400ad-6f37-4998-976e-c7743fc36ac3/in_use.lock acquired by nodename 8@a9a0b51623f6
datanode_3  | 2022-05-14 12:59:32,580 [pool-22-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/bb9400ad-6f37-4998-976e-c7743fc36ac3 has been successfully formatted.
datanode_3  | 2022-05-14 12:59:32,739 [pool-22-thread-1] INFO ratis.ContainerStateMachine: group-C7743FC36AC3: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_3  | 2022-05-14 12:59:32,771 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode_3  | 2022-05-14 12:59:32,799 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_3  | 2022-05-14 12:59:32,868 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_3  | 2022-05-14 12:59:32,882 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | 2022-05-14 12:59:33,002 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3  | 2022-05-14 12:59:33,054 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_3  | 2022-05-14 12:59:33,063 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode_3  | 2022-05-14 12:59:33,098 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: new 55441846-8ccc-4390-87fc-ba015dadcaaa@group-C7743FC36AC3-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/bb9400ad-6f37-4998-976e-c7743fc36ac3
datanode_3  | 2022-05-14 12:59:33,102 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode_3  | 2022-05-14 12:59:33,105 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_3  | 2022-05-14 12:59:33,115 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3  | 2022-05-14 12:59:33,119 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_3  | 2022-05-14 12:59:33,126 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_3  | 2022-05-14 12:59:33,164 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_3  | 2022-05-14 12:59:33,175 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_3  | 2022-05-14 12:59:33,175 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_3  | 2022-05-14 12:59:33,241 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_3  | 2022-05-14 12:59:33,249 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_3  | 2022-05-14 12:59:33,343 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: 55441846-8ccc-4390-87fc-ba015dadcaaa@group-C7743FC36AC3-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_3  | 2022-05-14 12:59:33,350 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: 55441846-8ccc-4390-87fc-ba015dadcaaa@group-C7743FC36AC3-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_3  | 2022-05-14 12:59:33,364 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_3  | 2022-05-14 12:59:33,366 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_3  | 2022-05-14 12:59:33,369 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_3  | 2022-05-14 12:59:33,371 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_3  | 2022-05-14 12:59:33,374 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_3  | 2022-05-14 12:59:33,381 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode_3  | 2022-05-14 12:59:33,582 [pool-22-thread-1] INFO server.RaftServer$Division: 55441846-8ccc-4390-87fc-ba015dadcaaa@group-C7743FC36AC3: start as a follower, conf=-1: [55441846-8ccc-4390-87fc-ba015dadcaaa|rpc:172.18.0.4:9856|admin:172.18.0.4:9857|client:172.18.0.4:9858|priority:1], old=null
datanode_3  | 2022-05-14 12:59:33,588 [pool-22-thread-1] INFO server.RaftServer$Division: 55441846-8ccc-4390-87fc-ba015dadcaaa@group-C7743FC36AC3: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_3  | 2022-05-14 12:59:33,596 [pool-22-thread-1] INFO impl.RoleInfo: 55441846-8ccc-4390-87fc-ba015dadcaaa: start 55441846-8ccc-4390-87fc-ba015dadcaaa@group-C7743FC36AC3-FollowerState
datanode_3  | 2022-05-14 12:59:33,642 [pool-22-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C7743FC36AC3,id=55441846-8ccc-4390-87fc-ba015dadcaaa
datanode_3  | 2022-05-14 12:59:33,745 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=bb9400ad-6f37-4998-976e-c7743fc36ac3
datanode_3  | 2022-05-14 12:59:33,747 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=bb9400ad-6f37-4998-976e-c7743fc36ac3.
datanode_3  | 2022-05-14 12:59:33,747 [Command processor thread] INFO server.RaftServer: 55441846-8ccc-4390-87fc-ba015dadcaaa: addNew group-C3BF6305580B:[54b0e747-a2bb-484f-976a-c7c0770cb588|rpc:172.18.0.9:9856|admin:172.18.0.9:9857|client:172.18.0.9:9858|priority:0, 55441846-8ccc-4390-87fc-ba015dadcaaa|rpc:172.18.0.4:9856|admin:172.18.0.4:9857|client:172.18.0.4:9858|priority:0, 00910f34-9556-4f5c-8864-f93205907e3c|rpc:172.18.0.6:9856|admin:172.18.0.6:9857|client:172.18.0.6:9858|priority:1] returns group-C3BF6305580B:java.util.concurrent.CompletableFuture@564585a1[Not completed]
datanode_3  | 2022-05-14 12:59:33,813 [pool-22-thread-1] INFO server.RaftServer$Division: 55441846-8ccc-4390-87fc-ba015dadcaaa: new RaftServerImpl for group-C3BF6305580B:[54b0e747-a2bb-484f-976a-c7c0770cb588|rpc:172.18.0.9:9856|admin:172.18.0.9:9857|client:172.18.0.9:9858|priority:0, 55441846-8ccc-4390-87fc-ba015dadcaaa|rpc:172.18.0.4:9856|admin:172.18.0.4:9857|client:172.18.0.4:9858|priority:0, 00910f34-9556-4f5c-8864-f93205907e3c|rpc:172.18.0.6:9856|admin:172.18.0.6:9857|client:172.18.0.6:9858|priority:1] with ContainerStateMachine:uninitialized
datanode_3  | 2022-05-14 12:59:33,819 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_3  | 2022-05-14 12:59:33,821 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_3  | 2022-05-14 12:59:33,821 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_3  | 2022-05-14 12:59:33,824 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode_3  | 2022-05-14 12:59:33,827 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_3  | 2022-05-14 12:59:33,827 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode_3  | 2022-05-14 12:59:33,827 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3  | 2022-05-14 12:59:33,828 [pool-22-thread-1] INFO server.RaftServer$Division: 55441846-8ccc-4390-87fc-ba015dadcaaa@group-C3BF6305580B: ConfigurationManager, init=-1: [54b0e747-a2bb-484f-976a-c7c0770cb588|rpc:172.18.0.9:9856|admin:172.18.0.9:9857|client:172.18.0.9:9858|priority:0, 55441846-8ccc-4390-87fc-ba015dadcaaa|rpc:172.18.0.4:9856|admin:172.18.0.4:9857|client:172.18.0.4:9858|priority:0, 00910f34-9556-4f5c-8864-f93205907e3c|rpc:172.18.0.6:9856|admin:172.18.0.6:9857|client:172.18.0.6:9858|priority:1], old=null, confs=<EMPTY_MAP>
datanode_3  | 2022-05-14 12:59:33,828 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3  | 2022-05-14 12:59:33,828 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_3  | 2022-05-14 12:59:33,829 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode_3  | 2022-05-14 12:59:33,829 [pool-22-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/503efc89-95e3-40df-aa92-c3bf6305580b does not exist. Creating ...
datanode_3  | 2022-05-14 12:59:33,840 [pool-22-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/503efc89-95e3-40df-aa92-c3bf6305580b/in_use.lock acquired by nodename 8@a9a0b51623f6
datanode_3  | 2022-05-14 12:59:33,845 [pool-22-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/503efc89-95e3-40df-aa92-c3bf6305580b has been successfully formatted.
datanode_3  | 2022-05-14 12:59:33,846 [pool-22-thread-1] INFO ratis.ContainerStateMachine: group-C3BF6305580B: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_3  | 2022-05-14 12:59:33,847 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode_3  | 2022-05-14 12:59:33,851 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_3  | 2022-05-14 12:59:33,851 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_3  | 2022-05-14 12:59:33,851 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | 2022-05-14 12:59:33,851 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3  | 2022-05-14 12:59:33,852 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_3  | 2022-05-14 12:59:33,891 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode_3  | 2022-05-14 12:59:33,933 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: new 55441846-8ccc-4390-87fc-ba015dadcaaa@group-C3BF6305580B-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/503efc89-95e3-40df-aa92-c3bf6305580b
datanode_3  | 2022-05-14 12:59:33,933 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode_3  | 2022-05-14 12:59:33,933 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_3  | 2022-05-14 12:59:33,934 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3  | 2022-05-14 12:59:33,934 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_3  | 2022-05-14 12:59:33,934 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_3  | 2022-05-14 12:59:33,934 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_3  | 2022-05-14 12:59:33,935 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_3  | 2022-05-14 12:59:33,935 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_3  | 2022-05-14 12:59:33,936 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_3  | 2022-05-14 12:59:33,943 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_3  | 2022-05-14 12:59:33,952 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: 55441846-8ccc-4390-87fc-ba015dadcaaa@group-C3BF6305580B-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_3  | 2022-05-14 12:59:33,955 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: 55441846-8ccc-4390-87fc-ba015dadcaaa@group-C3BF6305580B-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_3  | 2022-05-14 12:59:33,976 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_3  | 2022-05-14 12:59:33,987 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_3  | 2022-05-14 12:59:33,992 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_3  | 2022-05-14 12:59:33,994 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_3  | 2022-05-14 12:59:33,995 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_3  | 2022-05-14 12:59:34,001 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
om_1        | 2022-05-14 12:59:44,591 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om_1        | 2022-05-14 12:59:45,528 [Listener at om/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om_1        | 2022-05-14 12:59:45,544 [Listener at om/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om_1        | 2022-05-14 12:59:45,544 [Listener at om/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om_1        | 2022-05-14 12:59:45,579 [Listener at om/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om/172.18.0.7:9862
om_1        | 2022-05-14 12:59:45,580 [Listener at om/9862] INFO ratis.OzoneManagerRatisServer: Starting OzoneManagerRatisServer om1 at port 9872
datanode_3  | 2022-05-14 12:59:34,004 [pool-22-thread-1] INFO server.RaftServer$Division: 55441846-8ccc-4390-87fc-ba015dadcaaa@group-C3BF6305580B: start as a follower, conf=-1: [54b0e747-a2bb-484f-976a-c7c0770cb588|rpc:172.18.0.9:9856|admin:172.18.0.9:9857|client:172.18.0.9:9858|priority:0, 55441846-8ccc-4390-87fc-ba015dadcaaa|rpc:172.18.0.4:9856|admin:172.18.0.4:9857|client:172.18.0.4:9858|priority:0, 00910f34-9556-4f5c-8864-f93205907e3c|rpc:172.18.0.6:9856|admin:172.18.0.6:9857|client:172.18.0.6:9858|priority:1], old=null
datanode_3  | 2022-05-14 12:59:34,029 [pool-22-thread-1] INFO server.RaftServer$Division: 55441846-8ccc-4390-87fc-ba015dadcaaa@group-C3BF6305580B: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_3  | 2022-05-14 12:59:34,029 [pool-22-thread-1] INFO impl.RoleInfo: 55441846-8ccc-4390-87fc-ba015dadcaaa: start 55441846-8ccc-4390-87fc-ba015dadcaaa@group-C3BF6305580B-FollowerState
datanode_3  | 2022-05-14 12:59:34,112 [pool-22-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C3BF6305580B,id=55441846-8ccc-4390-87fc-ba015dadcaaa
datanode_3  | 2022-05-14 12:59:34,151 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=503efc89-95e3-40df-aa92-c3bf6305580b
datanode_3  | 2022-05-14 12:59:38,012 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=503efc89-95e3-40df-aa92-c3bf6305580b.
datanode_3  | 2022-05-14 12:59:38,716 [55441846-8ccc-4390-87fc-ba015dadcaaa@group-C7743FC36AC3-FollowerState] INFO impl.FollowerState: 55441846-8ccc-4390-87fc-ba015dadcaaa@group-C7743FC36AC3-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5120090513ns, electionTimeout:5074ms
datanode_3  | 2022-05-14 12:59:38,716 [55441846-8ccc-4390-87fc-ba015dadcaaa@group-C7743FC36AC3-FollowerState] INFO impl.RoleInfo: 55441846-8ccc-4390-87fc-ba015dadcaaa: shutdown 55441846-8ccc-4390-87fc-ba015dadcaaa@group-C7743FC36AC3-FollowerState
datanode_3  | 2022-05-14 12:59:38,717 [55441846-8ccc-4390-87fc-ba015dadcaaa@group-C7743FC36AC3-FollowerState] INFO server.RaftServer$Division: 55441846-8ccc-4390-87fc-ba015dadcaaa@group-C7743FC36AC3: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_3  | 2022-05-14 12:59:38,720 [55441846-8ccc-4390-87fc-ba015dadcaaa@group-C7743FC36AC3-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode_3  | 2022-05-14 12:59:38,720 [55441846-8ccc-4390-87fc-ba015dadcaaa@group-C7743FC36AC3-FollowerState] INFO impl.RoleInfo: 55441846-8ccc-4390-87fc-ba015dadcaaa: start 55441846-8ccc-4390-87fc-ba015dadcaaa@group-C7743FC36AC3-LeaderElection1
datanode_3  | 2022-05-14 12:59:38,729 [55441846-8ccc-4390-87fc-ba015dadcaaa@group-C7743FC36AC3-LeaderElection1] INFO impl.LeaderElection: 55441846-8ccc-4390-87fc-ba015dadcaaa@group-C7743FC36AC3-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [55441846-8ccc-4390-87fc-ba015dadcaaa|rpc:172.18.0.4:9856|admin:172.18.0.4:9857|client:172.18.0.4:9858|priority:1], old=null
datanode_3  | 2022-05-14 12:59:38,730 [55441846-8ccc-4390-87fc-ba015dadcaaa@group-C7743FC36AC3-LeaderElection1] INFO impl.LeaderElection: 55441846-8ccc-4390-87fc-ba015dadcaaa@group-C7743FC36AC3-LeaderElection1 ELECTION round 0: result PASSED (term=1)
datanode_3  | 2022-05-14 12:59:38,730 [55441846-8ccc-4390-87fc-ba015dadcaaa@group-C7743FC36AC3-LeaderElection1] INFO impl.RoleInfo: 55441846-8ccc-4390-87fc-ba015dadcaaa: shutdown 55441846-8ccc-4390-87fc-ba015dadcaaa@group-C7743FC36AC3-LeaderElection1
datanode_3  | 2022-05-14 12:59:38,731 [55441846-8ccc-4390-87fc-ba015dadcaaa@group-C7743FC36AC3-LeaderElection1] INFO server.RaftServer$Division: 55441846-8ccc-4390-87fc-ba015dadcaaa@group-C7743FC36AC3: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_3  | 2022-05-14 12:59:38,731 [55441846-8ccc-4390-87fc-ba015dadcaaa@group-C7743FC36AC3-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-C7743FC36AC3 with new leaderId: 55441846-8ccc-4390-87fc-ba015dadcaaa
datanode_3  | 2022-05-14 12:59:38,733 [55441846-8ccc-4390-87fc-ba015dadcaaa@group-C7743FC36AC3-LeaderElection1] INFO server.RaftServer$Division: 55441846-8ccc-4390-87fc-ba015dadcaaa@group-C7743FC36AC3: change Leader from null to 55441846-8ccc-4390-87fc-ba015dadcaaa at term 1 for becomeLeader, leader elected after 5968ms
datanode_3  | 2022-05-14 12:59:38,750 [55441846-8ccc-4390-87fc-ba015dadcaaa@group-C7743FC36AC3-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_3  | 2022-05-14 12:59:38,778 [55441846-8ccc-4390-87fc-ba015dadcaaa@group-C7743FC36AC3-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_3  | 2022-05-14 12:59:38,779 [55441846-8ccc-4390-87fc-ba015dadcaaa@group-C7743FC36AC3-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode_3  | 2022-05-14 12:59:38,784 [55441846-8ccc-4390-87fc-ba015dadcaaa@group-C7743FC36AC3-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_3  | 2022-05-14 12:59:38,788 [55441846-8ccc-4390-87fc-ba015dadcaaa@group-C7743FC36AC3-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_3  | 2022-05-14 12:59:38,789 [55441846-8ccc-4390-87fc-ba015dadcaaa@group-C7743FC36AC3-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_3  | 2022-05-14 12:59:38,797 [55441846-8ccc-4390-87fc-ba015dadcaaa@group-C7743FC36AC3-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_3  | 2022-05-14 12:59:38,799 [55441846-8ccc-4390-87fc-ba015dadcaaa@group-C7743FC36AC3-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
datanode_3  | 2022-05-14 12:59:38,804 [55441846-8ccc-4390-87fc-ba015dadcaaa@group-C7743FC36AC3-LeaderElection1] INFO impl.RoleInfo: 55441846-8ccc-4390-87fc-ba015dadcaaa: start 55441846-8ccc-4390-87fc-ba015dadcaaa@group-C7743FC36AC3-LeaderStateImpl
datanode_3  | 2022-05-14 12:59:38,831 [55441846-8ccc-4390-87fc-ba015dadcaaa@group-C7743FC36AC3-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 55441846-8ccc-4390-87fc-ba015dadcaaa@group-C7743FC36AC3-SegmentedRaftLogWorker: Starting segment from index:0
datanode_3  | 2022-05-14 12:59:38,902 [55441846-8ccc-4390-87fc-ba015dadcaaa@group-C7743FC36AC3-LeaderElection1] INFO server.RaftServer$Division: 55441846-8ccc-4390-87fc-ba015dadcaaa@group-C7743FC36AC3: set configuration 0: [55441846-8ccc-4390-87fc-ba015dadcaaa|rpc:172.18.0.4:9856|admin:172.18.0.4:9857|client:172.18.0.4:9858|dataStream:|priority:1], old=null
datanode_3  | 2022-05-14 12:59:39,012 [55441846-8ccc-4390-87fc-ba015dadcaaa@group-C7743FC36AC3-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 55441846-8ccc-4390-87fc-ba015dadcaaa@group-C7743FC36AC3-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/bb9400ad-6f37-4998-976e-c7743fc36ac3/current/log_inprogress_0
datanode_3  | 2022-05-14 12:59:39,226 [55441846-8ccc-4390-87fc-ba015dadcaaa@group-C3BF6305580B-FollowerState] INFO impl.FollowerState: 55441846-8ccc-4390-87fc-ba015dadcaaa@group-C3BF6305580B-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5196546287ns, electionTimeout:5111ms
datanode_3  | 2022-05-14 12:59:39,227 [55441846-8ccc-4390-87fc-ba015dadcaaa@group-C3BF6305580B-FollowerState] INFO impl.RoleInfo: 55441846-8ccc-4390-87fc-ba015dadcaaa: shutdown 55441846-8ccc-4390-87fc-ba015dadcaaa@group-C3BF6305580B-FollowerState
datanode_3  | 2022-05-14 12:59:39,227 [55441846-8ccc-4390-87fc-ba015dadcaaa@group-C3BF6305580B-FollowerState] INFO server.RaftServer$Division: 55441846-8ccc-4390-87fc-ba015dadcaaa@group-C3BF6305580B: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_3  | 2022-05-14 12:59:39,228 [55441846-8ccc-4390-87fc-ba015dadcaaa@group-C3BF6305580B-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode_3  | 2022-05-14 12:59:39,228 [55441846-8ccc-4390-87fc-ba015dadcaaa@group-C3BF6305580B-FollowerState] INFO impl.RoleInfo: 55441846-8ccc-4390-87fc-ba015dadcaaa: start 55441846-8ccc-4390-87fc-ba015dadcaaa@group-C3BF6305580B-LeaderElection2
datanode_3  | 2022-05-14 12:59:39,234 [55441846-8ccc-4390-87fc-ba015dadcaaa@group-C3BF6305580B-LeaderElection2] INFO impl.LeaderElection: 55441846-8ccc-4390-87fc-ba015dadcaaa@group-C3BF6305580B-LeaderElection2 ELECTION round 0: submit vote requests at term 1 for -1: [54b0e747-a2bb-484f-976a-c7c0770cb588|rpc:172.18.0.9:9856|admin:172.18.0.9:9857|client:172.18.0.9:9858|priority:0, 55441846-8ccc-4390-87fc-ba015dadcaaa|rpc:172.18.0.4:9856|admin:172.18.0.4:9857|client:172.18.0.4:9858|priority:0, 00910f34-9556-4f5c-8864-f93205907e3c|rpc:172.18.0.6:9856|admin:172.18.0.6:9857|client:172.18.0.6:9858|priority:1], old=null
datanode_3  | 2022-05-14 12:59:39,419 [55441846-8ccc-4390-87fc-ba015dadcaaa@group-C3BF6305580B-LeaderElection2] INFO impl.LeaderElection: 55441846-8ccc-4390-87fc-ba015dadcaaa@group-C3BF6305580B-LeaderElection2: ELECTION REJECTED received 2 response(s) and 0 exception(s):
datanode_3  | 2022-05-14 12:59:39,424 [55441846-8ccc-4390-87fc-ba015dadcaaa@group-C3BF6305580B-LeaderElection2] INFO impl.LeaderElection:   Response 0: 55441846-8ccc-4390-87fc-ba015dadcaaa<-54b0e747-a2bb-484f-976a-c7c0770cb588#0:OK-t1
datanode_3  | 2022-05-14 12:59:39,427 [55441846-8ccc-4390-87fc-ba015dadcaaa@group-C3BF6305580B-LeaderElection2] INFO impl.LeaderElection:   Response 1: 55441846-8ccc-4390-87fc-ba015dadcaaa<-00910f34-9556-4f5c-8864-f93205907e3c#0:FAIL-t1
datanode_3  | 2022-05-14 12:59:39,428 [55441846-8ccc-4390-87fc-ba015dadcaaa@group-C3BF6305580B-LeaderElection2] INFO impl.LeaderElection: 55441846-8ccc-4390-87fc-ba015dadcaaa@group-C3BF6305580B-LeaderElection2 ELECTION round 0: result REJECTED
datanode_3  | 2022-05-14 12:59:39,429 [55441846-8ccc-4390-87fc-ba015dadcaaa@group-C3BF6305580B-LeaderElection2] INFO server.RaftServer$Division: 55441846-8ccc-4390-87fc-ba015dadcaaa@group-C3BF6305580B: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
datanode_3  | 2022-05-14 12:59:39,429 [55441846-8ccc-4390-87fc-ba015dadcaaa@group-C3BF6305580B-LeaderElection2] INFO impl.RoleInfo: 55441846-8ccc-4390-87fc-ba015dadcaaa: shutdown 55441846-8ccc-4390-87fc-ba015dadcaaa@group-C3BF6305580B-LeaderElection2
datanode_3  | 2022-05-14 12:59:39,429 [55441846-8ccc-4390-87fc-ba015dadcaaa@group-C3BF6305580B-LeaderElection2] INFO impl.RoleInfo: 55441846-8ccc-4390-87fc-ba015dadcaaa: start 55441846-8ccc-4390-87fc-ba015dadcaaa@group-C3BF6305580B-FollowerState
datanode_3  | 2022-05-14 12:59:44,467 [grpc-default-executor-0] INFO server.RaftServer$Division: 55441846-8ccc-4390-87fc-ba015dadcaaa@group-C3BF6305580B: receive requestVote(ELECTION, 00910f34-9556-4f5c-8864-f93205907e3c, group-C3BF6305580B, 2, (t:0, i:0))
datanode_3  | 2022-05-14 12:59:44,472 [grpc-default-executor-0] INFO impl.VoteContext: 55441846-8ccc-4390-87fc-ba015dadcaaa@group-C3BF6305580B-FOLLOWER: accept ELECTION from 00910f34-9556-4f5c-8864-f93205907e3c: our priority 0 <= candidate's priority 1
datanode_3  | 2022-05-14 12:59:44,474 [grpc-default-executor-0] INFO server.RaftServer$Division: 55441846-8ccc-4390-87fc-ba015dadcaaa@group-C3BF6305580B: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:00910f34-9556-4f5c-8864-f93205907e3c
datanode_3  | 2022-05-14 12:59:44,474 [grpc-default-executor-0] INFO impl.RoleInfo: 55441846-8ccc-4390-87fc-ba015dadcaaa: shutdown 55441846-8ccc-4390-87fc-ba015dadcaaa@group-C3BF6305580B-FollowerState
datanode_3  | 2022-05-14 12:59:44,478 [55441846-8ccc-4390-87fc-ba015dadcaaa@group-C3BF6305580B-FollowerState] INFO impl.FollowerState: 55441846-8ccc-4390-87fc-ba015dadcaaa@group-C3BF6305580B-FollowerState was interrupted: {}
datanode_3  | java.lang.InterruptedException: sleep interrupted
datanode_3  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode_3  | 	at java.base/java.lang.Thread.sleep(Thread.java:334)
datanode_3  | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
datanode_3  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
datanode_3  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
datanode_3  | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
datanode_3  | 2022-05-14 12:59:44,481 [grpc-default-executor-0] INFO impl.RoleInfo: 55441846-8ccc-4390-87fc-ba015dadcaaa: start 55441846-8ccc-4390-87fc-ba015dadcaaa@group-C3BF6305580B-FollowerState
datanode_3  | 2022-05-14 12:59:44,488 [grpc-default-executor-0] INFO server.RaftServer$Division: 55441846-8ccc-4390-87fc-ba015dadcaaa@group-C3BF6305580B replies to ELECTION vote request: 00910f34-9556-4f5c-8864-f93205907e3c<-55441846-8ccc-4390-87fc-ba015dadcaaa#0:OK-t2. Peer's state: 55441846-8ccc-4390-87fc-ba015dadcaaa@group-C3BF6305580B:t2, leader=null, voted=00910f34-9556-4f5c-8864-f93205907e3c, raftlog=55441846-8ccc-4390-87fc-ba015dadcaaa@group-C3BF6305580B-SegmentedRaftLog:OPENED:c-1, conf=-1: [54b0e747-a2bb-484f-976a-c7c0770cb588|rpc:172.18.0.9:9856|admin:172.18.0.9:9857|client:172.18.0.9:9858|priority:0, 55441846-8ccc-4390-87fc-ba015dadcaaa|rpc:172.18.0.4:9856|admin:172.18.0.4:9857|client:172.18.0.4:9858|priority:0, 00910f34-9556-4f5c-8864-f93205907e3c|rpc:172.18.0.6:9856|admin:172.18.0.6:9857|client:172.18.0.6:9858|priority:1], old=null
datanode_3  | 2022-05-14 12:59:44,666 [grpc-default-executor-0] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-C3BF6305580B with new leaderId: 00910f34-9556-4f5c-8864-f93205907e3c
datanode_3  | 2022-05-14 12:59:44,674 [grpc-default-executor-0] INFO server.RaftServer$Division: 55441846-8ccc-4390-87fc-ba015dadcaaa@group-C3BF6305580B: change Leader from null to 00910f34-9556-4f5c-8864-f93205907e3c at term 2 for appendEntries, leader elected after 10819ms
datanode_3  | 2022-05-14 12:59:44,744 [grpc-default-executor-0] INFO server.RaftServer$Division: 55441846-8ccc-4390-87fc-ba015dadcaaa@group-C3BF6305580B: set configuration 0: [54b0e747-a2bb-484f-976a-c7c0770cb588|rpc:172.18.0.9:9856|admin:172.18.0.9:9857|client:172.18.0.9:9858|dataStream:|priority:0, 55441846-8ccc-4390-87fc-ba015dadcaaa|rpc:172.18.0.4:9856|admin:172.18.0.4:9857|client:172.18.0.4:9858|dataStream:|priority:0, 00910f34-9556-4f5c-8864-f93205907e3c|rpc:172.18.0.6:9856|admin:172.18.0.6:9857|client:172.18.0.6:9858|dataStream:|priority:1], old=null
datanode_3  | 2022-05-14 12:59:44,754 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: 55441846-8ccc-4390-87fc-ba015dadcaaa@group-C3BF6305580B-SegmentedRaftLogWorker: Starting segment from index:0
datanode_3  | 2022-05-14 12:59:44,757 [55441846-8ccc-4390-87fc-ba015dadcaaa@group-C3BF6305580B-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 55441846-8ccc-4390-87fc-ba015dadcaaa@group-C3BF6305580B-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/503efc89-95e3-40df-aa92-c3bf6305580b/current/log_inprogress_0
datanode_3  | 2022-05-14 13:33:00,243 [ContainerOp-503efc89-95e3-40df-aa92-c3bf6305580b-4] INFO keyvalue.KeyValueContainer: Container 1 is synced with bcsId 2784.
datanode_3  | 2022-05-14 13:33:00,243 [ContainerOp-503efc89-95e3-40df-aa92-c3bf6305580b-4] INFO keyvalue.KeyValueContainer: Container 1 is synced with bcsId 2784.
datanode_3  | 2022-05-14 13:33:00,257 [ContainerOp-503efc89-95e3-40df-aa92-c3bf6305580b-4] INFO keyvalue.KeyValueContainer: Container 1 is closed with bcsId 2784.
datanode_3  | 2022-05-14 13:33:27,903 [org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@1b732dd] INFO commandhandler.DeleteBlocksCommandHandler: Start to delete container blocks, TXIDs=[32(0),1(0),33(0),2(0),5(0),8(0),11(0),12(0),18(0),27(0),28(0),29(0),30(0),31(0)], numOfContainers=1, numOfBlocks=122
datanode_3  | 2022-05-14 13:34:24,297 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200104.block
om_1        | 2022-05-14 12:59:45,581 [Listener at om/9862] INFO server.RaftServer$Division: om1@group-C5BA1605619E: start as a follower, conf=-1: [om1|rpc:om:9872|priority:0], old=null
om_1        | 2022-05-14 12:59:45,583 [Listener at om/9862] INFO server.RaftServer$Division: om1@group-C5BA1605619E: changes role from      null to FOLLOWER at term 0 for startAsFollower
om_1        | 2022-05-14 12:59:45,585 [Listener at om/9862] INFO impl.RoleInfo: om1: start om1@group-C5BA1605619E-FollowerState
om_1        | 2022-05-14 12:59:45,588 [Listener at om/9862] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C5BA1605619E,id=om1
om_1        | 2022-05-14 12:59:45,594 [Listener at om/9862] INFO server.RaftServer: om1: start RPC server
om_1        | 2022-05-14 12:59:45,643 [Listener at om/9862] INFO server.GrpcService: om1: GrpcService started, listening on 9872
om_1        | 2022-05-14 12:59:45,659 [Listener at om/9862] INFO om.OzoneManager: Version File has different layout version (2) than OM DB (null). That is expected if this OM has never been finalized to a newer layout version.
om_1        | 2022-05-14 12:59:45,661 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$385/0x00000008405a7c40@6a6b4536] INFO util.JvmPauseMonitor: JvmPauseMonitor-om1: Started
om_1        | 2022-05-14 12:59:45,719 [Listener at om/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om_1        | 2022-05-14 12:59:45,719 [Listener at om/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
om_1        | 2022-05-14 12:59:45,746 [Listener at om/9862] INFO util.log: Logging initialized @21419ms to org.eclipse.jetty.util.log.Slf4jLog
om_1        | 2022-05-14 12:59:45,867 [Listener at om/9862] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
om_1        | 2022-05-14 12:59:45,873 [Listener at om/9862] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
om_1        | 2022-05-14 12:59:45,878 [Listener at om/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om_1        | 2022-05-14 12:59:45,880 [Listener at om/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
om_1        | 2022-05-14 12:59:45,881 [Listener at om/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
om_1        | 2022-05-14 12:59:45,881 [Listener at om/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
om_1        | 2022-05-14 12:59:45,920 [Listener at om/9862] INFO http.HttpServer2: Jetty bound to port 9874
om_1        | 2022-05-14 12:59:45,922 [Listener at om/9862] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
om_1        | 2022-05-14 12:59:45,964 [Listener at om/9862] INFO server.session: DefaultSessionIdManager workerName=node0
om_1        | 2022-05-14 12:59:45,964 [Listener at om/9862] INFO server.session: No SessionScavenger set, using defaults
om_1        | 2022-05-14 12:59:45,966 [Listener at om/9862] INFO server.session: node0 Scavenging every 600000ms
om_1        | 2022-05-14 12:59:45,980 [Listener at om/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@38657ca8{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om_1        | 2022-05-14 12:59:45,981 [Listener at om/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1205d422{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om_1        | 2022-05-14 12:59:46,100 [Listener at om/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@31d07dd9{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-ozone-manager-1_3_0-SNAPSHOT_jar-_-any-18000556150987129116/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/ozoneManager}
om_1        | 2022-05-14 12:59:46,109 [Listener at om/9862] INFO server.AbstractConnector: Started ServerConnector@66589578{HTTP/1.1, (http/1.1)}{0.0.0.0:9874}
om_1        | 2022-05-14 12:59:46,110 [Listener at om/9862] INFO server.Server: Started @21782ms
om_1        | 2022-05-14 12:59:46,112 [Listener at om/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
om_1        | 2022-05-14 12:59:46,112 [Listener at om/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
om_1        | 2022-05-14 12:59:46,114 [Listener at om/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
om_1        | 2022-05-14 12:59:46,114 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om_1        | 2022-05-14 12:59:46,118 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om_1        | 2022-05-14 12:59:46,180 [Listener at om/9862] INFO om.TrashPolicyOzone: The configured checkpoint interval is 0 minutes. Using an interval of 1 minutes that is used for deletion instead
om_1        | 2022-05-14 12:59:46,181 [Listener at om/9862] INFO om.TrashPolicyOzone: Ozone Manager trash configuration: Deletion interval = 1 minutes, Emptier interval = 1 minutes.
om_1        | 2022-05-14 12:59:46,295 [Listener at om/9862] INFO om.GrpcOzoneManagerServer: GrpcOzoneManagerServer is started using port 8981
om_1        | 2022-05-14 12:59:46,307 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4d026a3a] INFO util.JvmPauseMonitor: Starting JVM pause monitor
om_1        | 2022-05-14 12:59:50,668 [om1@group-C5BA1605619E-FollowerState] INFO impl.FollowerState: om1@group-C5BA1605619E-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5083078725ns, electionTimeout:5076ms
om_1        | 2022-05-14 12:59:50,669 [om1@group-C5BA1605619E-FollowerState] INFO impl.RoleInfo: om1: shutdown om1@group-C5BA1605619E-FollowerState
om_1        | 2022-05-14 12:59:50,670 [om1@group-C5BA1605619E-FollowerState] INFO server.RaftServer$Division: om1@group-C5BA1605619E: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
om_1        | 2022-05-14 12:59:50,673 [om1@group-C5BA1605619E-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
om_1        | 2022-05-14 12:59:50,673 [om1@group-C5BA1605619E-FollowerState] INFO impl.RoleInfo: om1: start om1@group-C5BA1605619E-LeaderElection1
om_1        | 2022-05-14 12:59:50,690 [om1@group-C5BA1605619E-LeaderElection1] INFO impl.LeaderElection: om1@group-C5BA1605619E-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [om1|rpc:om:9872|priority:0], old=null
om_1        | 2022-05-14 12:59:50,691 [om1@group-C5BA1605619E-LeaderElection1] INFO impl.LeaderElection: om1@group-C5BA1605619E-LeaderElection1 ELECTION round 0: result PASSED (term=1)
om_1        | 2022-05-14 12:59:50,691 [om1@group-C5BA1605619E-LeaderElection1] INFO impl.RoleInfo: om1: shutdown om1@group-C5BA1605619E-LeaderElection1
om_1        | 2022-05-14 12:59:50,692 [om1@group-C5BA1605619E-LeaderElection1] INFO server.RaftServer$Division: om1@group-C5BA1605619E: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
om_1        | 2022-05-14 12:59:50,692 [om1@group-C5BA1605619E-LeaderElection1] INFO server.RaftServer$Division: om1@group-C5BA1605619E: change Leader from null to om1 at term 1 for becomeLeader, leader elected after 8418ms
om_1        | 2022-05-14 12:59:50,698 [om1@group-C5BA1605619E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
om_1        | 2022-05-14 12:59:50,709 [om1@group-C5BA1605619E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
om_1        | 2022-05-14 12:59:50,711 [om1@group-C5BA1605619E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
om_1        | 2022-05-14 12:59:50,719 [om1@group-C5BA1605619E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
om_1        | 2022-05-14 12:59:50,720 [om1@group-C5BA1605619E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
om_1        | 2022-05-14 12:59:50,721 [om1@group-C5BA1605619E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
om_1        | 2022-05-14 12:59:50,730 [om1@group-C5BA1605619E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
om_1        | 2022-05-14 12:59:50,732 [om1@group-C5BA1605619E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
om_1        | 2022-05-14 12:59:50,737 [om1@group-C5BA1605619E-LeaderElection1] INFO impl.RoleInfo: om1: start om1@group-C5BA1605619E-LeaderStateImpl
om_1        | 2022-05-14 12:59:50,783 [om1@group-C5BA1605619E-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: om1@group-C5BA1605619E-SegmentedRaftLogWorker: Starting segment from index:0
om_1        | 2022-05-14 12:59:50,878 [om1@group-C5BA1605619E-LeaderElection1] INFO server.RaftServer$Division: om1@group-C5BA1605619E: set configuration 0: [om1|rpc:om:9872|admin:|client:|dataStream:|priority:0], old=null
om_1        | 2022-05-14 12:59:51,021 [om1@group-C5BA1605619E-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: om1@group-C5BA1605619E-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_0
om_1        | 2022-05-14 12:59:51,180 [om1@group-C5BA1605619E-StateMachineUpdater] INFO ratis.OzoneManagerStateMachine: Received Configuration change notification from Ratis. New Peer list:
om_1        | [id: "om1"
om_1        | address: "om:9872"
om_1        | ]
datanode_3  | 2022-05-14 13:34:24,302 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200107.block
datanode_3  | 2022-05-14 13:34:24,303 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200110.block
datanode_3  | 2022-05-14 13:34:24,303 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200115.block
datanode_3  | 2022-05-14 13:34:24,303 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200118.block
datanode_3  | 2022-05-14 13:34:24,304 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200119.block
datanode_3  | 2022-05-14 13:34:24,304 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200120.block
datanode_3  | 2022-05-14 13:34:24,304 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200121.block
datanode_3  | 2022-05-14 13:34:24,306 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200200.block
datanode_3  | 2022-05-14 13:34:24,306 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200213.block
datanode_3  | 2022-05-14 13:34:24,306 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200214.block
datanode_3  | 2022-05-14 13:34:24,307 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200307.block
datanode_3  | 2022-05-14 13:34:24,309 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200310.block
datanode_3  | 2022-05-14 13:34:24,309 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200313.block
datanode_3  | 2022-05-14 13:34:24,310 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200317.block
datanode_3  | 2022-05-14 13:34:24,312 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200319.block
datanode_3  | 2022-05-14 13:34:24,313 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200321.block
datanode_3  | 2022-05-14 13:34:24,313 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200323.block
datanode_3  | 2022-05-14 13:34:24,314 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200324.block
datanode_3  | 2022-05-14 13:34:24,314 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200303.block
datanode_3  | 2022-05-14 13:34:24,314 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200305.block
datanode_3  | 2022-05-14 13:34:24,315 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200308.block
datanode_3  | 2022-05-14 13:34:24,318 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200311.block
datanode_3  | 2022-05-14 13:34:24,318 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200315.block
datanode_3  | 2022-05-14 13:34:24,319 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200318.block
datanode_3  | 2022-05-14 13:34:24,319 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200320.block
datanode_3  | 2022-05-14 13:34:24,319 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200322.block
datanode_3  | 2022-05-14 13:34:24,320 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200304.block
datanode_3  | 2022-05-14 13:34:24,320 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200306.block
datanode_3  | 2022-05-14 13:34:24,323 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200309.block
datanode_3  | 2022-05-14 13:34:24,323 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200312.block
datanode_3  | 2022-05-14 13:34:24,323 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200314.block
datanode_3  | 2022-05-14 13:34:24,324 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200316.block
datanode_3  | 2022-05-14 13:34:24,324 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200297.block
datanode_3  | 2022-05-14 13:34:24,324 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200298.block
datanode_3  | 2022-05-14 13:34:24,325 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200299.block
datanode_3  | 2022-05-14 13:34:24,327 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200300.block
datanode_5  | 2022-05-14 12:59:39,445 [f3166980-8467-4e9a-9c6e-144f4303af87@group-382BCCACC254-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_5  | 2022-05-14 12:59:39,447 [f3166980-8467-4e9a-9c6e-144f4303af87@group-382BCCACC254-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode_5  | 2022-05-14 12:59:39,456 [f3166980-8467-4e9a-9c6e-144f4303af87@group-382BCCACC254-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_5  | 2022-05-14 12:59:39,456 [f3166980-8467-4e9a-9c6e-144f4303af87@group-382BCCACC254-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_5  | 2022-05-14 12:59:39,457 [f3166980-8467-4e9a-9c6e-144f4303af87@group-382BCCACC254-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_5  | 2022-05-14 12:59:39,465 [f3166980-8467-4e9a-9c6e-144f4303af87@group-382BCCACC254-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_5  | 2022-05-14 12:59:39,471 [f3166980-8467-4e9a-9c6e-144f4303af87@group-382BCCACC254-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
datanode_5  | 2022-05-14 12:59:39,495 [f3166980-8467-4e9a-9c6e-144f4303af87@group-382BCCACC254-LeaderElection1] INFO impl.RoleInfo: f3166980-8467-4e9a-9c6e-144f4303af87: start f3166980-8467-4e9a-9c6e-144f4303af87@group-382BCCACC254-LeaderStateImpl
datanode_5  | 2022-05-14 12:59:39,537 [f3166980-8467-4e9a-9c6e-144f4303af87@group-382BCCACC254-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: f3166980-8467-4e9a-9c6e-144f4303af87@group-382BCCACC254-SegmentedRaftLogWorker: Starting segment from index:0
datanode_5  | 2022-05-14 12:59:39,660 [f3166980-8467-4e9a-9c6e-144f4303af87@group-382BCCACC254-LeaderElection1] INFO server.RaftServer$Division: f3166980-8467-4e9a-9c6e-144f4303af87@group-382BCCACC254: set configuration 0: [f3166980-8467-4e9a-9c6e-144f4303af87|rpc:172.18.0.8:9856|admin:172.18.0.8:9857|client:172.18.0.8:9858|dataStream:|priority:1], old=null
datanode_5  | 2022-05-14 12:59:39,763 [f3166980-8467-4e9a-9c6e-144f4303af87@group-382BCCACC254-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: f3166980-8467-4e9a-9c6e-144f4303af87@group-382BCCACC254-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/a879b83f-d447-4d1a-b7cc-382bccacc254/current/log_inprogress_0
om_1        | 2022-05-14 13:00:07,703 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:vol1 for user:hadoop
om_1        | 2022-05-14 13:00:15,534 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket of layout LEGACY in volume: vol1
om_1        | 2022-05-14 13:00:22,417 [qtp1144965385-47] INFO utils.DBCheckpointServlet: Received request to obtain DB checkpoint snapshot
om_1        | 2022-05-14 13:00:22,480 [qtp1144965385-47] INFO db.RDBCheckpointManager: Created checkpoint at /data/metadata/db.checkpoints/om.db_checkpoint_1652533222428 in 50 milliseconds
om_1        | 2022-05-14 13:00:22,618 [qtp1144965385-47] INFO utils.DBCheckpointServlet: Time taken to write the checkpoint to response output stream: 136 milliseconds
om_1        | 2022-05-14 13:00:22,618 [qtp1144965385-47] INFO db.RocksDBCheckpoint: Cleaning up RocksDB checkpoint at /data/metadata/db.checkpoints/om.db_checkpoint_1652533222428
om_1        | 2022-05-14 13:01:12,760 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: auditparser0 of layout LEGACY in volume: vol1
om_1        | 2022-05-14 13:01:12,770 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: auditparser1 of layout LEGACY in volume: vol1
om_1        | 2022-05-14 13:01:12,778 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: auditparser2 of layout LEGACY in volume: vol1
om_1        | 2022-05-14 13:01:12,788 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: auditparser3 of layout LEGACY in volume: vol1
om_1        | 2022-05-14 13:01:12,795 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: auditparser4 of layout LEGACY in volume: vol1
om_1        | 2022-05-14 13:01:17,926 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket1 of layout LEGACY in volume: vol1
om_1        | 2022-05-14 13:02:18,487 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:87193-source for user:hadoop
om_1        | 2022-05-14 13:02:22,532 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:87193-target for user:hadoop
om_1        | 2022-05-14 13:02:26,471 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: dangling-link of layout LEGACY in volume: 87193-target
om_1        | 2022-05-14 13:02:34,065 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link1 of layout LEGACY in volume: 87193-target
om_1        | 2022-05-14 13:02:38,115 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket1 of layout LEGACY in volume: 87193-source
om_1        | 2022-05-14 13:03:54,974 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link2 of layout LEGACY in volume: 87193-target
om_1        | 2022-05-14 13:03:58,923 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:link2 in volume:87193-target
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:204)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:254)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:524)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:319)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:04:02,848 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket3 of layout LEGACY in volume: 87193-target
om_1        | 2022-05-14 13:04:06,809 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket3 in volume:87193-target
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:204)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:254)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:524)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:319)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:04:10,809 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: loop2 of layout LEGACY in volume: 87193-target
om_1        | 2022-05-14 13:04:14,491 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: loop3 of layout LEGACY in volume: 87193-target
recon_1     | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
recon_1     | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
recon_1     | 2022-05-14 12:58:33,489 [main] INFO recon.ReconServer: STARTUP_MSG: 
recon_1     | /************************************************************
recon_1     | STARTUP_MSG: Starting ReconServer
recon_1     | STARTUP_MSG:   host = 9d191a647150/172.18.0.10
recon_1     | STARTUP_MSG:   args = []
recon_1     | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
om_1        | 2022-05-14 13:04:18,250 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: loop1 of layout LEGACY in volume: 87193-target
om_1        | 2022-05-14 13:04:25,821 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link3 of layout LEGACY in volume: 87193-target
om_1        | 2022-05-14 13:04:57,261 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:20527-without-scheme for user:hadoop
om_1        | 2022-05-14 13:05:00,002 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:05:00,006 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:05:00,006 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:05:17,245 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bb1 of layout LEGACY in volume: 20527-without-scheme
om_1        | 2022-05-14 13:06:00,001 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:06:00,002 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
recon_1     | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/hk2-utils-2.5.0.jar:/opt/hadoop/share/ozone/lib/jakarta.inject-2.6.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/sqlite-jdbc-3.25.2.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.38.0.jar:/opt/hadoop/share/ozone/lib/aopalliance-repackaged-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/guice-4.0.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-2.33.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.38.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jakarta.xml.bind-api-2.3.3.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jakarta.validation-api-2.0.2.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.38.0.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.38.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-tools-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jooq-3.11.10.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/osgi-resource-locator-1.0.3.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/spring-beans-5.2.20.RELEASE.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/derby-10.14.2.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/spring-core-5.2.20.RELEASE.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/jooq-codegen-3.11.10.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/spring-tx-5.2.20.RELEASE.jar:/opt/hadoop/share/ozone/lib/jersey-entity-filtering-2.33.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/guice-servlet-4.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/guice-bridge-2.5.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.0.1.jar:/opt/hadoop/share/ozone/lib/hk2-locator-2.6.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/aopalliance-1.0.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.38.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.38.0.jar:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jakarta.ws.rs-api-2.1.6.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.23.0.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.38.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-module-jaxb-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-core-2.33.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-2.0.38.Final.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/guice-multibindings-4.0.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.19.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/bonecp-0.8.0.RELEASE.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hk2-api-2.5.0.jar:/opt/hadoop/share/ozone/lib/javax.inject-1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-client-2.33.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jersey-hk2-2.33.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jersey-media-jaxb-2.33.jar:/opt/hadoop/share/ozone/lib/jakarta.annotation-api-1.3.5.jar:/opt/hadoop/share/ozone/lib/jersey-server-2.33.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.38.Final.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.0.4.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/guice-assistedinject-4.0.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-media-json-jackson-2.33.jar:/opt/hadoop/share/ozone/lib/jooq-meta-3.11.10.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/ozone-reconcodegen-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/jersey-common-2.33.jar:/opt/hadoop/share/ozone/lib/spring-jdbc-5.2.20.RELEASE.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/spring-jcl-5.2.20.RELEASE.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-recon-1.3.0-SNAPSHOT.jar
recon_1     | STARTUP_MSG:   build = https://github.com/apache/ozone/40461504478182af509db7098d4e173011d27e5a ; compiled by 'runner' on 2022-05-14T12:48Z
recon_1     | STARTUP_MSG:   java = 11.0.14.1
recon_1     | ************************************************************/
recon_1     | 2022-05-14 12:58:33,589 [main] INFO recon.ReconServer: registered UNIX signal handlers for [TERM, HUP, INT]
recon_1     | 2022-05-14 12:58:40,540 [main] INFO reflections.Reflections: Reflections took 580 ms to scan 1 urls, producing 13 keys and 35 values 
recon_1     | 2022-05-14 12:58:46,651 [main] INFO recon.ReconServer: Initializing Recon server...
recon_1     | 2022-05-14 12:58:48,993 [main] INFO persistence.DefaultDataSourceProvider: JDBC Url for Recon : jdbc:derby:/data/metadata/recon/ozone_recon_derby.db 
recon_1     | 2022-05-14 12:58:58,849 [main] INFO codegen.SqlDbUtils: Created derby database at jdbc:derby:/data/metadata/recon/ozone_recon_derby.db.
recon_1     | WARNING: An illegal reflective access operation has occurred
recon_1     | WARNING: Illegal reflective access by org.jooq.tools.reflect.Reflect (file:/opt/hadoop/share/ozone/lib/jooq-3.11.10.jar) to constructor java.lang.invoke.MethodHandles$Lookup(java.lang.Class)
recon_1     | WARNING: Please consider reporting this to the maintainers of org.jooq.tools.reflect.Reflect
recon_1     | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
recon_1     | WARNING: All illegal access operations will be denied in a future release
recon_1     | 2022-05-14 12:59:01,459 [main] INFO persistence.DefaultDataSourceProvider: JDBC Url for Recon : jdbc:derby:/data/metadata/recon/ozone_recon_derby.db 
recon_1     | 2022-05-14 12:59:01,728 [main] INFO codegen.SqlDbUtils: Created derby database at jdbc:derby:/data/metadata/recon/ozone_recon_derby.db.
recon_1     | 2022-05-14 12:59:01,775 [main] INFO recon.ReconServer: Creating Recon Schema.
recon_1     | 2022-05-14 12:59:09,325 [main] INFO http.BaseHttpServer: Starting Web-server for recon at: http://0.0.0.0:9888
recon_1     | 2022-05-14 12:59:09,557 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
recon_1     | 2022-05-14 12:59:09,735 [main] INFO util.log: Logging initialized @44625ms to org.eclipse.jetty.util.log.Slf4jLog
recon_1     | 2022-05-14 12:59:10,772 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
recon_1     | 2022-05-14 12:59:10,840 [main] WARN http.HttpRequestLog: Jetty request log can only be enabled using Log4j
recon_1     | 2022-05-14 12:59:10,935 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
recon_1     | 2022-05-14 12:59:10,947 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context recon
recon_1     | 2022-05-14 12:59:10,947 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
recon_1     | 2022-05-14 12:59:10,947 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
recon_1     | 2022-05-14 12:59:12,109 [main] INFO tasks.ReconTaskControllerImpl: Registered task ContainerKeyMapperTask with controller.
recon_1     | 2022-05-14 12:59:13,107 [main] INFO tasks.ReconTaskControllerImpl: Registered task FileSizeCountTask with controller.
recon_1     | 2022-05-14 12:59:13,155 [main] INFO tasks.ReconTaskControllerImpl: Registered task TableCountTask with controller.
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
datanode_3  | 2022-05-14 13:34:24,327 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200301.block
datanode_3  | 2022-05-14 13:34:24,327 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200302.block
datanode_3  | 2022-05-14 13:34:24,331 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200268.block
datanode_3  | 2022-05-14 13:34:24,331 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200269.block
datanode_3  | 2022-05-14 13:34:24,331 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200270.block
datanode_3  | 2022-05-14 13:34:24,332 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200271.block
datanode_3  | 2022-05-14 13:34:24,332 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200272.block
datanode_3  | 2022-05-14 13:34:24,332 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200291.block
datanode_3  | 2022-05-14 13:34:24,333 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200292.block
datanode_3  | 2022-05-14 13:34:24,333 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200293.block
datanode_3  | 2022-05-14 13:34:24,335 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200294.block
datanode_3  | 2022-05-14 13:34:24,335 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200295.block
datanode_3  | 2022-05-14 13:34:24,336 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200366.block
datanode_3  | 2022-05-14 13:34:24,338 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200367.block
datanode_3  | 2022-05-14 13:34:24,339 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200368.block
datanode_3  | 2022-05-14 13:34:24,339 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200369.block
datanode_3  | 2022-05-14 13:34:24,343 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200370.block
datanode_3  | 2022-05-14 13:34:24,343 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200371.block
datanode_3  | 2022-05-14 13:34:24,344 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200372.block
datanode_3  | 2022-05-14 13:34:24,344 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200373.block
datanode_3  | 2022-05-14 13:34:24,345 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200374.block
datanode_3  | 2022-05-14 13:34:24,347 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200375.block
datanode_3  | 2022-05-14 13:34:24,347 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200390.block
datanode_3  | 2022-05-14 13:34:24,348 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200391.block
datanode_3  | 2022-05-14 13:34:24,348 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200392.block
datanode_3  | 2022-05-14 13:34:24,351 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200388.block
datanode_3  | 2022-05-14 13:34:24,351 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200393.block
datanode_3  | 2022-05-14 13:34:24,351 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200394.block
datanode_3  | 2022-05-14 13:34:24,352 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200401.block
datanode_3  | 2022-05-14 13:34:24,352 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200402.block
datanode_3  | 2022-05-14 13:34:24,352 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200494.block
datanode_3  | 2022-05-14 13:34:24,355 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200497.block
datanode_3  | 2022-05-14 13:34:24,355 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200500.block
datanode_3  | 2022-05-14 13:34:24,358 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200503.block
datanode_3  | 2022-05-14 13:34:24,359 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200505.block
datanode_3  | 2022-05-14 13:34:24,359 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200508.block
recon_1     | 2022-05-14 12:59:13,195 [main] INFO tasks.ReconTaskControllerImpl: Registered task NSSummaryTask with controller.
recon_1     | 2022-05-14 12:59:13,289 [main] INFO ozone.OmUtils: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
recon_1     | 2022-05-14 12:59:13,289 [main] INFO ozone.OmUtils: No OzoneManager ServiceID configured.
recon_1     | 2022-05-14 12:59:15,130 [main] WARN recon.ReconUtils: ozone.recon.om.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1     | 2022-05-14 12:59:15,613 [main] WARN recon.ReconUtils: ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1     | 2022-05-14 12:59:15,770 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar!/network-topology-default.xml]
recon_1     | 2022-05-14 12:59:15,772 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
recon_1     | 2022-05-14 12:59:15,949 [main] WARN db.DBStoreBuilder: ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1     | 2022-05-14 12:59:16,235 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = ERASURE_CODED_STORAGE_SUPPORT (version = 3), software layout = ERASURE_CODED_STORAGE_SUPPORT (version = 3)
recon_1     | 2022-05-14 12:59:16,370 [main] INFO reflections.Reflections: Reflections took 120 ms to scan 3 urls, producing 105 keys and 221 values 
recon_1     | 2022-05-14 12:59:16,481 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
recon_1     | 2022-05-14 12:59:16,556 [main] WARN server.ServerUtils: ozone.scm.dead.node.interval value = 45000 is smaller than min = 60000 based on the key value of ozone.scm.stale.node.interval, reset to the min value 60000.
recon_1     | 2022-05-14 12:59:16,562 [main] INFO node.SCMNodeManager: Entering startup safe mode.
recon_1     | 2022-05-14 12:59:16,587 [main] INFO scm.ReconNodeManager: Loaded 0 nodes from node DB.
recon_1     | 2022-05-14 12:59:16,596 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
recon_1     | 2022-05-14 12:59:16,655 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
recon_1     | 2022-05-14 12:59:16,741 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
recon_1     | 2022-05-14 12:59:16,903 [Socket Reader #1 for port 9891] INFO ipc.Server: Starting Socket Reader #1 for port 9891
recon_1     | 2022-05-14 12:59:16,975 [Listener at 0.0.0.0/9891] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
recon_1     | 2022-05-14 12:59:17,167 [Listener at 0.0.0.0/9891] INFO recon.ReconServer: Recon server initialized successfully!
recon_1     | 2022-05-14 12:59:17,167 [Listener at 0.0.0.0/9891] INFO recon.ReconServer: Starting Recon server
recon_1     | 2022-05-14 12:59:17,356 [Listener at 0.0.0.0/9891] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
recon_1     | 2022-05-14 12:59:17,395 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
recon_1     | 2022-05-14 12:59:17,396 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Recon metrics system started
recon_1     | 2022-05-14 12:59:17,823 [Listener at 0.0.0.0/9891] INFO http.HttpServer2: Jetty bound to port 9888
recon_1     | 2022-05-14 12:59:17,824 [Listener at 0.0.0.0/9891] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
recon_1     | 2022-05-14 12:59:17,948 [Listener at 0.0.0.0/9891] INFO server.session: DefaultSessionIdManager workerName=node0
recon_1     | 2022-05-14 12:59:17,950 [Listener at 0.0.0.0/9891] INFO server.session: No SessionScavenger set, using defaults
recon_1     | 2022-05-14 12:59:17,952 [Listener at 0.0.0.0/9891] INFO server.session: node0 Scavenging every 600000ms
recon_1     | 2022-05-14 12:59:17,999 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1fba3fd6{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
recon_1     | 2022-05-14 12:59:18,002 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6d5508a5{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-recon-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
recon_1     | 2022-05-14 12:59:21,801 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@24f3e945{recon,/,file:///tmp/jetty-0_0_0_0-9888-ozone-recon-1_3_0-SNAPSHOT_jar-_-any-13079655664490775209/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-recon-1.3.0-SNAPSHOT.jar!/webapps/recon}
recon_1     | 2022-05-14 12:59:21,812 [Listener at 0.0.0.0/9891] INFO server.AbstractConnector: Started ServerConnector@5a4b8e25{HTTP/1.1, (http/1.1)}{0.0.0.0:9888}
recon_1     | 2022-05-14 12:59:21,813 [Listener at 0.0.0.0/9891] INFO server.Server: Started @56710ms
recon_1     | 2022-05-14 12:59:21,822 [Listener at 0.0.0.0/9891] INFO impl.MetricsSinkAdapter: Sink prometheus started
recon_1     | 2022-05-14 12:59:21,822 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Registered sink prometheus
recon_1     | 2022-05-14 12:59:21,824 [Listener at 0.0.0.0/9891] INFO http.BaseHttpServer: HTTP server of recon listening at http://0.0.0.0:9888
recon_1     | 2022-05-14 12:59:21,824 [Listener at 0.0.0.0/9891] INFO impl.OzoneManagerServiceProviderImpl: Starting Ozone Manager Service Provider.
recon_1     | 2022-05-14 12:59:21,839 [Listener at 0.0.0.0/9891] INFO impl.OzoneManagerServiceProviderImpl: Registered OmDeltaRequest task 
recon_1     | 2022-05-14 12:59:21,850 [Listener at 0.0.0.0/9891] INFO impl.OzoneManagerServiceProviderImpl: Registered OmSnapshotRequest task 
recon_1     | 2022-05-14 12:59:21,851 [Listener at 0.0.0.0/9891] INFO recovery.ReconOmMetadataManagerImpl: Starting ReconOMMetadataManagerImpl
recon_1     | 2022-05-14 12:59:21,851 [Listener at 0.0.0.0/9891] WARN recon.ReconUtils: ozone.recon.om.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1     | 2022-05-14 12:59:21,852 [Listener at 0.0.0.0/9891] INFO tasks.ReconTaskControllerImpl: Starting Recon Task Controller.
recon_1     | 2022-05-14 12:59:21,855 [Listener at 0.0.0.0/9891] INFO scm.ReconStorageContainerManagerFacade: Recon ScmDatanodeProtocol RPC server is listening at /0.0.0.0:9891
recon_1     | 2022-05-14 12:59:26,444 [Listener at 0.0.0.0/9891] INFO scm.ReconStorageContainerManagerFacade: Obtained 0 pipelines from SCM.
recon_1     | 2022-05-14 12:59:26,449 [Listener at 0.0.0.0/9891] INFO scm.ReconPipelineManager: Recon has 0 pipelines in house.
recon_1     | 2022-05-14 12:59:26,450 [Listener at 0.0.0.0/9891] INFO server.SCMDatanodeProtocolServer: ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:9891
recon_1     | 2022-05-14 12:59:26,479 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
recon_1     | 2022-05-14 12:59:26,812 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Registered ContainerHealthTask task 
recon_1     | 2022-05-14 12:59:26,817 [IPC Server listener on 9891] INFO ipc.Server: IPC Server listener on 9891: starting
recon_1     | 2022-05-14 12:59:26,852 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Starting ContainerHealthTask Thread.
recon_1     | 2022-05-14 12:59:26,915 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Registered PipelineSyncTask task 
recon_1     | 2022-05-14 12:59:26,916 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Starting PipelineSyncTask Thread.
datanode_3  | 2022-05-14 13:34:24,363 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200509.block
datanode_3  | 2022-05-14 13:34:24,363 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200511.block
datanode_3  | 2022-05-14 13:34:24,364 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200491.block
datanode_3  | 2022-05-14 13:34:24,365 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200493.block
datanode_3  | 2022-05-14 13:34:24,368 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200496.block
datanode_3  | 2022-05-14 13:34:24,369 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200499.block
datanode_3  | 2022-05-14 13:34:24,369 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200502.block
datanode_3  | 2022-05-14 13:34:24,370 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200507.block
datanode_3  | 2022-05-14 13:34:24,373 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200510.block
datanode_3  | 2022-05-14 13:34:24,374 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200512.block
datanode_3  | 2022-05-14 13:34:24,374 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200492.block
datanode_3  | 2022-05-14 13:34:24,375 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200495.block
datanode_3  | 2022-05-14 13:34:24,378 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200498.block
datanode_3  | 2022-05-14 13:34:24,379 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200501.block
datanode_3  | 2022-05-14 13:34:24,379 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200504.block
datanode_3  | 2022-05-14 13:34:24,380 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200506.block
datanode_3  | 2022-05-14 13:34:24,383 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200456.block
datanode_3  | 2022-05-14 13:34:24,384 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200457.block
datanode_3  | 2022-05-14 13:34:24,384 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200458.block
datanode_3  | 2022-05-14 13:34:24,385 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200459.block
datanode_3  | 2022-05-14 13:34:24,387 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200460.block
datanode_3  | 2022-05-14 13:34:24,387 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200485.block
datanode_3  | 2022-05-14 13:34:24,388 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200486.block
datanode_3  | 2022-05-14 13:34:24,393 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200487.block
datanode_3  | 2022-05-14 13:34:24,393 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200488.block
datanode_3  | 2022-05-14 13:34:24,394 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200489.block
datanode_3  | 2022-05-14 13:34:24,394 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200490.block
datanode_3  | 2022-05-14 13:34:24,395 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200479.block
datanode_3  | 2022-05-14 13:34:24,395 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200480.block
datanode_3  | 2022-05-14 13:34:24,396 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200481.block
datanode_3  | 2022-05-14 13:34:24,396 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200482.block
datanode_3  | 2022-05-14 13:34:24,397 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200483.block
datanode_3  | 2022-05-14 13:34:24,397 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200578.block
datanode_3  | 2022-05-14 13:34:24,397 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200579.block
datanode_3  | 2022-05-14 13:34:24,398 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200580.block
datanode_3  | 2022-05-14 13:34:24,398 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200581.block
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:06:00,003 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:07:00,001 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:07:00,002 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:07:00,002 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1       | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
s3g_1       | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
s3g_1       | 2022-05-14 12:58:36,082 [main] INFO http.BaseHttpServer: Starting Web-server for s3gateway at: http://0.0.0.0:9878
s3g_1       | 2022-05-14 12:58:36,091 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
s3g_1       | 2022-05-14 12:58:36,475 [main] INFO util.log: Logging initialized @13064ms to org.eclipse.jetty.util.log.Slf4jLog
s3g_1       | 2022-05-14 12:58:37,454 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
s3g_1       | 2022-05-14 12:58:37,683 [main] INFO http.HttpRequestLog: Http request log for http.requests.s3gateway is not defined
s3g_1       | 2022-05-14 12:58:37,784 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
s3g_1       | 2022-05-14 12:58:37,792 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context s3gateway
s3g_1       | 2022-05-14 12:58:37,800 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
s3g_1       | 2022-05-14 12:58:37,801 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
s3g_1       | 2022-05-14 12:58:38,961 [main] INFO s3.Gateway: STARTUP_MSG: 
s3g_1       | /************************************************************
s3g_1       | STARTUP_MSG: Starting Gateway
s3g_1       | STARTUP_MSG:   host = 4161df62d962/172.18.0.5
s3g_1       | STARTUP_MSG:   args = []
s3g_1       | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
om_1        | 2022-05-14 13:07:48,737 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:20527-without-scheme for user:hadoop
om_1        | 2022-05-14 13:08:00,002 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
datanode_3  | 2022-05-14 13:34:24,398 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200582.block
datanode_3  | 2022-05-14 13:34:24,399 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200554.block
datanode_3  | 2022-05-14 13:34:24,399 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200555.block
datanode_3  | 2022-05-14 13:34:24,400 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200556.block
datanode_3  | 2022-05-14 13:34:24,400 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200557.block
datanode_3  | 2022-05-14 13:34:24,401 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200558.block
datanode_3  | 2022-05-14 13:34:24,401 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200559.block
datanode_3  | 2022-05-14 13:34:24,401 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200560.block
datanode_3  | 2022-05-14 13:34:24,402 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200561.block
datanode_3  | 2022-05-14 13:34:24,402 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200562.block
datanode_3  | 2022-05-14 13:34:24,403 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200563.block
datanode_3  | 2022-05-14 13:34:24,403 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200576.block
datanode_3  | 2022-05-14 13:34:24,404 [BlockDeletingService#9] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-b57acd13-b274-4901-b263-891afc26c373/current/containerDir0/1/chunks/109611004723200598.block
s3g_1       | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/hk2-utils-2.5.0.jar:/opt/hadoop/share/ozone/lib/jakarta.inject-2.6.1.jar:/opt/hadoop/share/ozone/lib/hk2-locator-2.6.1.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/aopalliance-repackaged-2.5.0.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.38.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.interceptor-api-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.38.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/javax.el-api-3.0.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.38.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jakarta.ws.rs-api-2.1.6.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jackson-dataformat-xml-2.13.2.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.23.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.38.0.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.38.0.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-module-jaxb-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-core-2.33.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-2.0.38.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jakarta.xml.bind-api-2.3.3.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.19.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/cdi-api-1.2.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hk2-api-2.5.0.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/javax.inject-1.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/jakarta.validation-api-2.0.2.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.38.0.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.38.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-client-2.33.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jersey-hk2-2.33.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/jersey-media-jaxb-2.33.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jakarta.annotation-api-1.3.5.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jersey-server-2.33.jar:/opt/hadoop/share/ozone/lib/jersey-cdi1x-2.33.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/osgi-resource-locator-1.0.3.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.38.Final.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.0.4.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/jersey-common-2.33.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/weld-servlet-2.4.7.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-s3gateway-1.3.0-SNAPSHOT.jar
s3g_1       | STARTUP_MSG:   build = https://github.com/apache/ozone/40461504478182af509db7098d4e173011d27e5a ; compiled by 'runner' on 2022-05-14T12:48Z
s3g_1       | STARTUP_MSG:   java = 11.0.14.1
s3g_1       | ************************************************************/
s3g_1       | 2022-05-14 12:58:39,052 [main] INFO s3.Gateway: registered UNIX signal handlers for [TERM, HUP, INT]
s3g_1       | 2022-05-14 12:58:39,483 [main] INFO s3.Gateway: Starting Ozone S3 gateway
s3g_1       | 2022-05-14 12:58:39,533 [main] INFO http.HttpServer2: Jetty bound to port 9878
s3g_1       | 2022-05-14 12:58:39,559 [main] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
s3g_1       | 2022-05-14 12:58:39,977 [main] INFO server.session: DefaultSessionIdManager workerName=node0
s3g_1       | 2022-05-14 12:58:39,981 [main] INFO server.session: No SessionScavenger set, using defaults
s3g_1       | 2022-05-14 12:58:40,016 [main] INFO server.session: node0 Scavenging every 660000ms
s3g_1       | 2022-05-14 12:58:40,162 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@4a3329b9{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
s3g_1       | 2022-05-14 12:58:40,184 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@618c5d94{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-s3gateway-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
s3g_1       | WARNING: An illegal reflective access operation has occurred
s3g_1       | WARNING: Illegal reflective access by org.jboss.weld.util.reflection.Formats (file:/opt/hadoop/share/ozone/lib/weld-servlet-2.4.7.Final.jar) to constructor com.sun.org.apache.bcel.internal.classfile.ClassParser(java.io.InputStream,java.lang.String)
s3g_1       | WARNING: Please consider reporting this to the maintainers of org.jboss.weld.util.reflection.Formats
s3g_1       | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
s3g_1       | WARNING: All illegal access operations will be denied in a future release
s3g_1       | May 14, 2022 12:59:10 PM org.glassfish.jersey.internal.Errors logErrors
s3g_1       | WARNING: The following warnings have been detected: WARNING: A HTTP GET method, public javax.ws.rs.core.Response org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.get(java.lang.String,java.lang.String,java.lang.String,int,java.lang.String,java.io.InputStream) throws java.io.IOException,org.apache.hadoop.ozone.s3.exception.OS3Exception, should not consume any entity.
s3g_1       | 
s3g_1       | 2022-05-14 12:59:10,555 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@995ad50{s3gateway,/,file:///tmp/jetty-0_0_0_0-9878-ozone-s3gateway-1_3_0-SNAPSHOT_jar-_-any-11070334284371430969/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-s3gateway-1.3.0-SNAPSHOT.jar!/webapps/s3gateway}
s3g_1       | 2022-05-14 12:59:10,622 [main] INFO server.AbstractConnector: Started ServerConnector@1bc715b8{HTTP/1.1, (http/1.1)}{0.0.0.0:9878}
s3g_1       | 2022-05-14 12:59:10,623 [main] INFO server.Server: Started @47226ms
s3g_1       | 2022-05-14 12:59:10,633 [main] INFO http.BaseHttpServer: HTTP server of s3gateway listening at http://0.0.0.0:9878
s3g_1       | 2022-05-14 12:59:11,407 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
s3g_1       | 2022-05-14 12:59:11,542 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
recon_1     | 2022-05-14 12:59:27,371 [IPC Server handler 3 on default port 9891] INFO ipc.Server: IPC Server handler 3 on default port 9891: skipped Call#1 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 172.18.0.2:53202
recon_1     | 2022-05-14 12:59:27,376 [IPC Server handler 9 on default port 9891] INFO ipc.Server: IPC Server handler 9 on default port 9891: skipped Call#1 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 172.18.0.6:37572
recon_1     | 2022-05-14 12:59:27,376 [IPC Server handler 8 on default port 9891] INFO ipc.Server: IPC Server handler 8 on default port 9891: skipped Call#1 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 172.18.0.8:50198
recon_1     | 2022-05-14 12:59:27,376 [IPC Server handler 7 on default port 9891] INFO ipc.Server: IPC Server handler 7 on default port 9891: skipped Call#0 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 172.18.0.4:42604
recon_1     | 2022-05-14 12:59:27,371 [IPC Server handler 6 on default port 9891] INFO ipc.Server: IPC Server handler 6 on default port 9891: skipped Call#2 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 172.18.0.4:42678
recon_1     | 2022-05-14 12:59:27,456 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 0 pipelines in house.
recon_1     | 2022-05-14 12:59:27,481 [PipelineSyncTask] INFO scm.ReconPipelineManager: Adding new pipeline PipelineID=74934bef-4747-4536-b24b-4a9fa2b98460 from SCM.
recon_1     | 2022-05-14 12:59:28,044 [PipelineSyncTask] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 74934bef-4747-4536-b24b-4a9fa2b98460, Nodes: d5e6fff5-66a9-4bee-add9-03aeb4a97c66{ip: 172.18.0.2, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-05-14T12:59:26.216Z[UTC]].
recon_1     | 2022-05-14 12:59:28,117 [PipelineSyncTask] INFO scm.ReconPipelineManager: Adding new pipeline PipelineID=1fd8b2e8-f580-4de7-855d-7a48e9feef0d from SCM.
recon_1     | 2022-05-14 12:59:28,128 [PipelineSyncTask] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 1fd8b2e8-f580-4de7-855d-7a48e9feef0d, Nodes: 54b0e747-a2bb-484f-976a-c7c0770cb588{ip: 172.18.0.9, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-05-14T12:59:26.229Z[UTC]].
recon_1     | 2022-05-14 12:59:28,144 [PipelineSyncTask] INFO scm.ReconPipelineManager: Adding new pipeline PipelineID=a879b83f-d447-4d1a-b7cc-382bccacc254 from SCM.
recon_1     | 2022-05-14 12:59:28,156 [PipelineSyncTask] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: a879b83f-d447-4d1a-b7cc-382bccacc254, Nodes: f3166980-8467-4e9a-9c6e-144f4303af87{ip: 172.18.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-05-14T12:59:26.246Z[UTC]].
recon_1     | 2022-05-14 12:59:28,183 [PipelineSyncTask] INFO scm.ReconPipelineManager: Adding new pipeline PipelineID=503efc89-95e3-40df-aa92-c3bf6305580b from SCM.
recon_1     | 2022-05-14 12:59:28,234 [PipelineSyncTask] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 503efc89-95e3-40df-aa92-c3bf6305580b, Nodes: 00910f34-9556-4f5c-8864-f93205907e3c{ip: 172.18.0.6, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}55441846-8ccc-4390-87fc-ba015dadcaaa{ip: 172.18.0.4, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}54b0e747-a2bb-484f-976a-c7c0770cb588{ip: 172.18.0.9, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-05-14T12:59:26.181Z[UTC]].
recon_1     | 2022-05-14 12:59:28,243 [PipelineSyncTask] INFO scm.ReconPipelineManager: Adding new pipeline PipelineID=ec7d4258-8caa-4f40-bc08-8aa059d6edb9 from SCM.
recon_1     | 2022-05-14 12:59:28,255 [PipelineSyncTask] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: ec7d4258-8caa-4f40-bc08-8aa059d6edb9, Nodes: 00910f34-9556-4f5c-8864-f93205907e3c{ip: 172.18.0.6, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-05-14T12:59:26.194Z[UTC]].
recon_1     | 2022-05-14 12:59:28,275 [PipelineSyncTask] INFO scm.ReconPipelineManager: Adding new pipeline PipelineID=bb9400ad-6f37-4998-976e-c7743fc36ac3 from SCM.
recon_1     | 2022-05-14 12:59:28,288 [PipelineSyncTask] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: bb9400ad-6f37-4998-976e-c7743fc36ac3, Nodes: 55441846-8ccc-4390-87fc-ba015dadcaaa{ip: 172.18.0.4, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-05-14T12:59:25.742Z[UTC]].
recon_1     | 2022-05-14 12:59:28,400 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 1365 milliseconds.
recon_1     | 2022-05-14 12:59:29,336 [IPC Server handler 5 on default port 9891] WARN ipc.Server: IPC Server handler 5 on default port 9891, call Call#2 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 172.18.0.8:50264: output error
recon_1     | 2022-05-14 12:59:29,363 [IPC Server handler 4 on default port 9891] WARN ipc.Server: IPC Server handler 4 on default port 9891, call Call#2 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 172.18.0.2:53276: output error
recon_1     | 2022-05-14 12:59:29,374 [IPC Server handler 4 on default port 9891] INFO ipc.Server: IPC Server handler 4 on default port 9891 caught an exception
recon_1     | java.nio.channels.ClosedChannelException
recon_1     | 	at java.base/sun.nio.ch.SocketChannelImpl.ensureOpenAndConnected(SocketChannelImpl.java:180)
recon_1     | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:452)
recon_1     | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3605)
recon_1     | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:141)
recon_1     | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1667)
recon_1     | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1737)
recon_1     | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2837)
recon_1     | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1809)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1117)
recon_1     | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:909)
recon_1     | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:895)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1052)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1     | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1     | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1     | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1     | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1     | 2022-05-14 12:59:29,347 [IPC Server handler 0 on default port 9891] WARN ipc.Server: IPC Server handler 0 on default port 9891, call Call#2 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 172.18.0.9:37586: output error
recon_1     | 2022-05-14 12:59:29,392 [IPC Server handler 0 on default port 9891] INFO ipc.Server: IPC Server handler 0 on default port 9891 caught an exception
recon_1     | java.nio.channels.ClosedChannelException
recon_1     | 	at java.base/sun.nio.ch.SocketChannelImpl.ensureOpenAndConnected(SocketChannelImpl.java:180)
recon_1     | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:452)
recon_1     | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3605)
recon_1     | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:141)
recon_1     | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1667)
recon_1     | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1737)
recon_1     | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2837)
recon_1     | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1809)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1117)
recon_1     | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:909)
recon_1     | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:895)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1052)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1     | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1     | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1     | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1     | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1     | 2022-05-14 12:59:29,337 [IPC Server handler 2 on default port 9891] WARN ipc.Server: IPC Server handler 2 on default port 9891, call Call#0 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 172.18.0.9:37520: output error
recon_1     | 2022-05-14 12:59:29,392 [IPC Server handler 2 on default port 9891] INFO ipc.Server: IPC Server handler 2 on default port 9891 caught an exception
recon_1     | java.nio.channels.ClosedChannelException
recon_1     | 	at java.base/sun.nio.ch.SocketChannelImpl.ensureOpenAndConnected(SocketChannelImpl.java:180)
recon_1     | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:452)
recon_1     | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3605)
recon_1     | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:141)
recon_1     | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1667)
recon_1     | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1737)
recon_1     | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2837)
recon_1     | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1809)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1117)
recon_1     | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:909)
recon_1     | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:895)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1052)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1     | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1     | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1     | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1     | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1     | 2022-05-14 12:59:29,337 [IPC Server handler 1 on default port 9891] WARN ipc.Server: IPC Server handler 1 on default port 9891, call Call#2 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 172.18.0.6:37634: output error
recon_1     | 2022-05-14 12:59:29,371 [IPC Server handler 5 on default port 9891] INFO ipc.Server: IPC Server handler 5 on default port 9891 caught an exception
recon_1     | java.nio.channels.ClosedChannelException
recon_1     | 	at java.base/sun.nio.ch.SocketChannelImpl.ensureOpenAndConnected(SocketChannelImpl.java:180)
recon_1     | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:452)
recon_1     | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3605)
recon_1     | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:141)
recon_1     | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1667)
recon_1     | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1737)
recon_1     | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2837)
recon_1     | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1809)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1117)
recon_1     | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:909)
recon_1     | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:895)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1052)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1     | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1     | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1     | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1     | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1     | 2022-05-14 12:59:29,396 [IPC Server handler 1 on default port 9891] INFO ipc.Server: IPC Server handler 1 on default port 9891 caught an exception
recon_1     | java.nio.channels.ClosedChannelException
recon_1     | 	at java.base/sun.nio.ch.SocketChannelImpl.ensureOpenAndConnected(SocketChannelImpl.java:180)
recon_1     | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:452)
recon_1     | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3605)
recon_1     | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:141)
recon_1     | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1667)
recon_1     | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1737)
recon_1     | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2837)
recon_1     | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1809)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1117)
recon_1     | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:909)
recon_1     | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:895)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1052)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1       | 2022-05-14 12:59:11,543 [main] INFO impl.MetricsSystemImpl: S3Gateway metrics system started
s3g_1       | 2022-05-14 12:59:11,568 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
s3g_1       | 2022-05-14 12:59:11,569 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
s3g_1       | 2022-05-14 13:20:14,116 [qtp2096539129-22] INFO audit.AuditLogger: Refresh DebugCmdSet for S3GAudit to [].
s3g_1       | 2022-05-14 13:20:14,130 [qtp2096539129-22] INFO ozone.OmUtils: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
s3g_1       | 2022-05-14 13:20:14,130 [qtp2096539129-22] INFO ozone.OmUtils: No OzoneManager ServiceID configured.
s3g_1       | 2022-05-14 13:20:16,113 [qtp2096539129-22] WARN erasurecode.ErasureCodeNative: ISA-L support is not available in your platform... using builtin-java codec where applicable
s3g_1       | 2022-05-14 13:20:16,273 [qtp2096539129-22] WARN impl.MetricsSystemImpl: S3Gateway metrics system already initialized!
s3g_1       | 2022-05-14 13:20:29,943 [qtp2096539129-23] INFO rpc.RpcClient: Creating Bucket: s3v/ozone-test-ccygokppjg, with dlfknslnfslf as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-05-14 13:20:29,963 [qtp2096539129-23] INFO endpoint.BucketEndpoint: Location is /ozone-test-ccygokppjg
s3g_1       | 2022-05-14 13:20:33,212 [qtp2096539129-20] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-pbfxtsgvfe, with dlfknslnfslf as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-05-14 13:20:33,218 [qtp2096539129-20] INFO endpoint.BucketEndpoint: Location is /bucket-pbfxtsgvfe
s3g_1       | 2022-05-14 13:20:44,154 [qtp2096539129-24] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-5523706137, with dlfknslnfslf as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-05-14 13:20:44,158 [qtp2096539129-24] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-5523706137
s3g_1       | 2022-05-14 13:20:44,859 [qtp2096539129-24] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-5201943209, with dlfknslnfslf as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-05-14 13:20:44,863 [qtp2096539129-24] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-5201943209
s3g_1       | 2022-05-14 13:20:45,555 [qtp2096539129-24] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-5201943209, with dlfknslnfslf as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-05-14 13:20:45,562 [qtp2096539129-24] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-5201943209
s3g_1       | 2022-05-14 13:20:54,280 [qtp2096539129-24] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-3330795596, with dlfknslnfslf as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-05-14 13:20:54,287 [qtp2096539129-24] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-3330795596
s3g_1       | 2022-05-14 13:21:13,289 [qtp2096539129-24] ERROR signature.AuthorizationV4HeaderParser: AWS access id shouldn't be empty. credential:/20220514/us-west-1/s3/aws4_request
s3g_1       | May 14, 2022 1:21:13 PM org.glassfish.jersey.internal.Errors logErrors
s3g_1       | WARNING: The following warnings have been detected: WARNING: Unknown HK2 failure detected:
s3g_1       | MultiException stack 1 of 1
s3g_1       | javax.ws.rs.WebApplicationException: The authorization header you provided is invalid.
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.wrapOS3Exception(OzoneClientProducer.java:138)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getSignature(OzoneClientProducer.java:99)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor20.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:874)
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:127)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:69)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:103)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:46)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:53)
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:129)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:463)
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:46)
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2102)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:758)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:08:00,003 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:08:00,003 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:08:00,564 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bb1 of layout LEGACY in volume: 20527-without-scheme
om_1        | 2022-05-14 13:08:23,540 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:90266-with-host for user:hadoop
om_1        | 2022-05-14 13:08:43,544 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bb1 of layout LEGACY in volume: 90266-with-host
om_1        | 2022-05-14 13:09:00,002 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:09:00,003 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:721)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:691)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:09:00,004 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:10:00,001 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:10:00,003 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:10:00,007 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:11:00,001 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:160)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:30)
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:105)
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:260)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:51)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:86)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:89)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:89)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:89)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:69)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:38)
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:173)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:247)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1679)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:11:00,002 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:11:00,002 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:11:15,116 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:90266-with-host for user:hadoop
om_1        | 2022-05-14 13:11:27,079 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bb1 of layout LEGACY in volume: 90266-with-host
om_1        | 2022-05-14 13:11:46,404 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:90266-acls for user:hadoop
om_1        | 2022-05-14 13:12:00,001 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:12:00,002 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
recon_1     | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1     | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1     | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1     | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:12:00,003 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
recon_1     | 2022-05-14 12:59:31,438 [IPC Server handler 0 on default port 9891] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/55441846-8ccc-4390-87fc-ba015dadcaaa
recon_1     | 2022-05-14 12:59:31,445 [IPC Server handler 0 on default port 9891] INFO node.SCMNodeManager: Registered Data node : 55441846-8ccc-4390-87fc-ba015dadcaaa{ip: 172.18.0.4, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1     | 2022-05-14 12:59:31,507 [IPC Server handler 18 on default port 9891] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/00910f34-9556-4f5c-8864-f93205907e3c
recon_1     | 2022-05-14 12:59:31,531 [IPC Server handler 18 on default port 9891] INFO node.SCMNodeManager: Registered Data node : 00910f34-9556-4f5c-8864-f93205907e3c{ip: 172.18.0.6, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1     | 2022-05-14 12:59:31,513 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node 55441846-8ccc-4390-87fc-ba015dadcaaa to Node DB.
recon_1     | 2022-05-14 12:59:31,552 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node 00910f34-9556-4f5c-8864-f93205907e3c to Node DB.
recon_1     | 2022-05-14 12:59:31,619 [IPC Server handler 46 on default port 9891] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/f3166980-8467-4e9a-9c6e-144f4303af87
recon_1     | 2022-05-14 12:59:31,622 [IPC Server handler 46 on default port 9891] INFO node.SCMNodeManager: Registered Data node : f3166980-8467-4e9a-9c6e-144f4303af87{ip: 172.18.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1     | 2022-05-14 12:59:31,626 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node f3166980-8467-4e9a-9c6e-144f4303af87 to Node DB.
recon_1     | 2022-05-14 12:59:31,910 [IPC Server handler 9 on default port 9891] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/54b0e747-a2bb-484f-976a-c7c0770cb588
recon_1     | 2022-05-14 12:59:31,910 [IPC Server handler 8 on default port 9891] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/d5e6fff5-66a9-4bee-add9-03aeb4a97c66
recon_1     | 2022-05-14 12:59:31,910 [IPC Server handler 9 on default port 9891] INFO node.SCMNodeManager: Registered Data node : 54b0e747-a2bb-484f-976a-c7c0770cb588{ip: 172.18.0.9, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1     | 2022-05-14 12:59:31,911 [IPC Server handler 8 on default port 9891] INFO node.SCMNodeManager: Registered Data node : d5e6fff5-66a9-4bee-add9-03aeb4a97c66{ip: 172.18.0.2, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1     | 2022-05-14 12:59:31,911 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node 54b0e747-a2bb-484f-976a-c7c0770cb588 to Node DB.
recon_1     | 2022-05-14 12:59:31,914 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node d5e6fff5-66a9-4bee-add9-03aeb4a97c66 to Node DB.
recon_1     | 2022-05-14 12:59:32,874 [IPC Server handler 87 on default port 9891] INFO scm.ReconNodeManager: Sending ReregisterCommand() for ozone_datanode_3.ozone_default
recon_1     | 2022-05-14 12:59:32,881 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/ONE PipelineID=bb9400ad-6f37-4998-976e-c7743fc36ac3 reported by 55441846-8ccc-4390-87fc-ba015dadcaaa{ip: 172.18.0.4, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1     | 2022-05-14 12:59:32,883 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: bb9400ad-6f37-4998-976e-c7743fc36ac3, Nodes: 55441846-8ccc-4390-87fc-ba015dadcaaa{ip: 172.18.0.4, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:55441846-8ccc-4390-87fc-ba015dadcaaa, CreationTimestamp2022-05-14T12:59:25.742Z[UTC]] moved to OPEN state
recon_1     | 2022-05-14 12:59:33,368 [IPC Server handler 2 on default port 9891] INFO scm.ReconNodeManager: Sending ReregisterCommand() for ozone_datanode_1.ozone_default
recon_1     | 2022-05-14 12:59:33,369 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=503efc89-95e3-40df-aa92-c3bf6305580b reported by 00910f34-9556-4f5c-8864-f93205907e3c{ip: 172.18.0.6, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1     | 2022-05-14 12:59:33,598 [IPC Server handler 18 on default port 9891] INFO scm.ReconNodeManager: Sending ReregisterCommand() for ozone_datanode_5.ozone_default
recon_1     | 2022-05-14 12:59:33,605 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/ONE PipelineID=a879b83f-d447-4d1a-b7cc-382bccacc254 reported by f3166980-8467-4e9a-9c6e-144f4303af87{ip: 172.18.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1     | 2022-05-14 12:59:33,607 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: a879b83f-d447-4d1a-b7cc-382bccacc254, Nodes: f3166980-8467-4e9a-9c6e-144f4303af87{ip: 172.18.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:f3166980-8467-4e9a-9c6e-144f4303af87, CreationTimestamp2022-05-14T12:59:26.246Z[UTC]] moved to OPEN state
recon_1     | 2022-05-14 12:59:33,892 [IPC Server handler 9 on default port 9891] INFO scm.ReconNodeManager: Sending ReregisterCommand() for ozone_datanode_4.ozone_default
recon_1     | 2022-05-14 12:59:33,898 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/ONE PipelineID=74934bef-4747-4536-b24b-4a9fa2b98460 reported by d5e6fff5-66a9-4bee-add9-03aeb4a97c66{ip: 172.18.0.2, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1     | 2022-05-14 12:59:33,900 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 74934bef-4747-4536-b24b-4a9fa2b98460, Nodes: d5e6fff5-66a9-4bee-add9-03aeb4a97c66{ip: 172.18.0.2, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:d5e6fff5-66a9-4bee-add9-03aeb4a97c66, CreationTimestamp2022-05-14T12:59:26.216Z[UTC]] moved to OPEN state
recon_1     | 2022-05-14 12:59:33,966 [IPC Server handler 8 on default port 9891] INFO scm.ReconNodeManager: Updating nodeDB for ozone_datanode_3.ozone_default
recon_1     | 2022-05-14 12:59:33,967 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=503efc89-95e3-40df-aa92-c3bf6305580b reported by 55441846-8ccc-4390-87fc-ba015dadcaaa{ip: 172.18.0.4, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1     | 2022-05-14 12:59:34,156 [IPC Server handler 11 on default port 9891] INFO scm.ReconNodeManager: Sending ReregisterCommand() for ozone_datanode_2.ozone_default
recon_1     | 2022-05-14 12:59:34,157 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=503efc89-95e3-40df-aa92-c3bf6305580b reported by 54b0e747-a2bb-484f-976a-c7c0770cb588{ip: 172.18.0.9, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1     | 2022-05-14 12:59:37,944 [IPC Server handler 8 on default port 9891] INFO scm.ReconNodeManager: Updating nodeDB for ozone_datanode_2.ozone_default
recon_1     | 2022-05-14 12:59:37,946 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/ONE PipelineID=1fd8b2e8-f580-4de7-855d-7a48e9feef0d reported by 54b0e747-a2bb-484f-976a-c7c0770cb588{ip: 172.18.0.9, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1     | 2022-05-14 12:59:37,947 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 1fd8b2e8-f580-4de7-855d-7a48e9feef0d, Nodes: 54b0e747-a2bb-484f-976a-c7c0770cb588{ip: 172.18.0.9, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:54b0e747-a2bb-484f-976a-c7c0770cb588, CreationTimestamp2022-05-14T12:59:26.229Z[UTC]] moved to OPEN state
recon_1     | 2022-05-14 12:59:37,948 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=503efc89-95e3-40df-aa92-c3bf6305580b reported by 54b0e747-a2bb-484f-976a-c7c0770cb588{ip: 172.18.0.9, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1     | 2022-05-14 12:59:38,139 [IPC Server handler 11 on default port 9891] INFO scm.ReconNodeManager: Updating nodeDB for ozone_datanode_1.ozone_default
recon_1     | 2022-05-14 12:59:38,141 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=503efc89-95e3-40df-aa92-c3bf6305580b reported by 00910f34-9556-4f5c-8864-f93205907e3c{ip: 172.18.0.6, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1     | 2022-05-14 12:59:38,141 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/ONE PipelineID=ec7d4258-8caa-4f40-bc08-8aa059d6edb9 reported by 00910f34-9556-4f5c-8864-f93205907e3c{ip: 172.18.0.6, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1     | 2022-05-14 12:59:38,141 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: ec7d4258-8caa-4f40-bc08-8aa059d6edb9, Nodes: 00910f34-9556-4f5c-8864-f93205907e3c{ip: 172.18.0.6, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:00910f34-9556-4f5c-8864-f93205907e3c, CreationTimestamp2022-05-14T12:59:26.194Z[UTC]] moved to OPEN state
recon_1     | 2022-05-14 12:59:38,162 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=503efc89-95e3-40df-aa92-c3bf6305580b reported by 00910f34-9556-4f5c-8864-f93205907e3c{ip: 172.18.0.6, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1     | 2022-05-14 12:59:38,216 [IPC Server handler 3 on default port 9891] INFO scm.ReconNodeManager: Updating nodeDB for ozone_datanode_5.ozone_default
recon_1     | 2022-05-14 12:59:38,442 [IPC Server handler 14 on default port 9891] INFO scm.ReconNodeManager: Updating nodeDB for ozone_datanode_4.ozone_default
recon_1     | 2022-05-14 12:59:38,737 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=503efc89-95e3-40df-aa92-c3bf6305580b reported by 55441846-8ccc-4390-87fc-ba015dadcaaa{ip: 172.18.0.4, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1     | 2022-05-14 12:59:42,934 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=503efc89-95e3-40df-aa92-c3bf6305580b reported by 54b0e747-a2bb-484f-976a-c7c0770cb588{ip: 172.18.0.9, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1     | 2022-05-14 12:59:43,143 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=503efc89-95e3-40df-aa92-c3bf6305580b reported by 54b0e747-a2bb-484f-976a-c7c0770cb588{ip: 172.18.0.9, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1     | 2022-05-14 12:59:43,339 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=503efc89-95e3-40df-aa92-c3bf6305580b reported by 00910f34-9556-4f5c-8864-f93205907e3c{ip: 172.18.0.6, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:12:17,541 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bb1 of layout LEGACY in volume: 90266-acls
om_1        | 2022-05-14 13:12:25,338 [OM StateMachine ApplyTransaction Thread - 0] ERROR acl.OMBucketAddAclRequest: Add acl [user:superuser1:rwxy[ACCESS]] to path /90266-acls/bb1 failed, because acl already exist
om_1        | 2022-05-14 13:13:00,001 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:13:00,002 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:13:00,003 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:13:58,815 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:90266-without-host for user:hadoop
om_1        | 2022-05-14 13:14:00,001 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
scm_1       | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm_1       | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm_1       | 2022-05-14 12:58:41,881 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm_1       | /************************************************************
scm_1       | STARTUP_MSG: Starting StorageContainerManager
scm_1       | STARTUP_MSG:   host = a41d3b00e3fd/172.18.0.3
scm_1       | STARTUP_MSG:   args = [--init]
scm_1       | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
recon_1     | 2022-05-14 12:59:44,493 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=503efc89-95e3-40df-aa92-c3bf6305580b reported by 00910f34-9556-4f5c-8864-f93205907e3c{ip: 172.18.0.6, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1     | 2022-05-14 12:59:44,494 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 503efc89-95e3-40df-aa92-c3bf6305580b, Nodes: 00910f34-9556-4f5c-8864-f93205907e3c{ip: 172.18.0.6, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}55441846-8ccc-4390-87fc-ba015dadcaaa{ip: 172.18.0.4, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}54b0e747-a2bb-484f-976a-c7c0770cb588{ip: 172.18.0.9, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:00910f34-9556-4f5c-8864-f93205907e3c, CreationTimestamp2022-05-14T12:59:26.181Z[UTC]] moved to OPEN state
recon_1     | 2022-05-14 13:00:21,853 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2022-05-14 13:00:21,853 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1     | 2022-05-14 13:00:22,717 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Got new checkpoint from OM : /data/metadata/om.snapshot.db_1652533221854
recon_1     | 2022-05-14 13:00:22,733 [pool-16-thread-1] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
recon_1     | 2022-05-14 13:00:22,735 [pool-16-thread-1] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
recon_1     | 2022-05-14 13:00:22,948 [pool-16-thread-1] INFO recovery.ReconOmMetadataManagerImpl: Created OM DB handle from snapshot at /data/metadata/om.snapshot.db_1652533221854.
recon_1     | 2022-05-14 13:00:23,023 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Calling reprocess on Recon tasks.
recon_1     | 2022-05-14 13:00:23,028 [pool-17-thread-1] INFO tasks.NSSummaryTask: Completed a reprocess run of NSSummaryTask
recon_1     | 2022-05-14 13:00:23,321 [pool-17-thread-1] INFO tasks.TableCountTask: Completed a 'reprocess' run of TableCountTask.
recon_1     | 2022-05-14 13:00:23,321 [pool-17-thread-1] INFO tasks.ContainerKeyMapperTask: Starting a 'reprocess' run of ContainerKeyMapperTask.
recon_1     | 2022-05-14 13:00:23,326 [pool-17-thread-1] INFO tasks.ContainerKeyMapperTask: Completed 'reprocess' of ContainerKeyMapperTask.
recon_1     | 2022-05-14 13:00:23,326 [pool-17-thread-1] INFO tasks.ContainerKeyMapperTask: It took me 0.005 seconds to process 0 keys.
recon_1     | 2022-05-14 13:00:23,340 [pool-17-thread-1] INFO tasks.FileSizeCountTask: Deleted 0 records from "FILE_COUNT_BY_SIZE"
recon_1     | 2022-05-14 13:00:23,341 [pool-17-thread-1] INFO tasks.FileSizeCountTask: Completed a 'reprocess' run of FileSizeCountTask.
recon_1     | 2022-05-14 13:00:41,900 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: New container #1 got from ozone_datanode_1.ozone_default.
recon_1     | 2022-05-14 13:00:42,018 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: Successfully added container #1 to Recon.
recon_1     | 2022-05-14 13:01:23,348 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2022-05-14 13:01:23,351 [pool-16-thread-1] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
recon_1     | 2022-05-14 13:01:23,351 [pool-16-thread-1] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
recon_1     | 2022-05-14 13:01:23,351 [pool-16-thread-1] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
recon_1     | 2022-05-14 13:01:23,351 [pool-16-thread-1] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
recon_1     | 2022-05-14 13:01:23,351 [pool-16-thread-1] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
recon_1     | 2022-05-14 13:01:23,351 [pool-16-thread-1] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
recon_1     | 2022-05-14 13:01:23,351 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2022-05-14 13:01:23,351 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 8 
recon_1     | 2022-05-14 13:01:23,615 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 84, SequenceNumber diff: 252, SequenceNumber Lag from OM 0.
recon_1     | 2022-05-14 13:01:23,615 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 252 records
recon_1     | 2022-05-14 13:01:23,642 [pool-17-thread-1] INFO tasks.NSSummaryTask: Completed a process run of NSSummaryTask
recon_1     | 2022-05-14 13:01:24,049 [pool-17-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
recon_1     | 2022-05-14 13:01:24,106 [pool-17-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 39 OM DB update event(s).
recon_1     | 2022-05-14 13:01:24,196 [pool-17-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2022-05-14 13:02:24,247 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2022-05-14 13:02:24,247 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2022-05-14 13:02:24,249 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 260 
recon_1     | 2022-05-14 13:02:24,348 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 128, SequenceNumber diff: 384, SequenceNumber Lag from OM 0.
recon_1     | 2022-05-14 13:02:24,348 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 384 records
recon_1     | 2022-05-14 13:02:24,362 [pool-17-thread-1] INFO tasks.NSSummaryTask: Completed a process run of NSSummaryTask
recon_1     | 2022-05-14 13:02:24,575 [pool-17-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
recon_1     | 2022-05-14 13:02:24,589 [pool-17-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 63 OM DB update event(s).
recon_1     | 2022-05-14 13:02:24,609 [pool-17-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2022-05-14 13:03:24,619 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2022-05-14 13:03:24,619 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2022-05-14 13:03:24,619 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 644 
recon_1     | 2022-05-14 13:03:24,637 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 8, SequenceNumber diff: 25, SequenceNumber Lag from OM 0.
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:14:00,001 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.0.4.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar
scm_1       | STARTUP_MSG:   build = https://github.com/apache/ozone/40461504478182af509db7098d4e173011d27e5a ; compiled by 'runner' on 2022-05-14T12:47Z
scm_1       | STARTUP_MSG:   java = 11.0.14.1
scm_1       | ************************************************************/
scm_1       | 2022-05-14 12:58:42,150 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm_1       | 2022-05-14 12:58:43,911 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1       | 2022-05-14 12:58:44,647 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm_1       | 2022-05-14 12:58:44,647 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm_1       | 2022-05-14 12:58:46,128 [main] INFO server.StorageContainerManager: SCM initialization succeeded. Current cluster id for sd=/data/metadata/scm; cid=CID-b57acd13-b274-4901-b263-891afc26c373; layoutVersion=3; scmId=ba44fb0e-70d4-4828-a51c-46eac1f3d9c5
scm_1       | 2022-05-14 12:58:46,418 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
scm_1       | /************************************************************
scm_1       | SHUTDOWN_MSG: Shutting down StorageContainerManager at a41d3b00e3fd/172.18.0.3
scm_1       | ************************************************************/
scm_1       | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm_1       | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm_1       | 2022-05-14 12:59:11,219 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm_1       | /************************************************************
scm_1       | STARTUP_MSG: Starting StorageContainerManager
scm_1       | STARTUP_MSG:   host = a41d3b00e3fd/172.18.0.3
scm_1       | STARTUP_MSG:   args = []
scm_1       | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
scm_1       | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.0.4.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar
scm_1       | STARTUP_MSG:   build = https://github.com/apache/ozone/40461504478182af509db7098d4e173011d27e5a ; compiled by 'runner' on 2022-05-14T12:47Z
scm_1       | STARTUP_MSG:   java = 11.0.14.1
scm_1       | ************************************************************/
scm_1       | 2022-05-14 12:59:11,380 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm_1       | 2022-05-14 12:59:12,472 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm_1       | 2022-05-14 12:59:12,489 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm_1       | 2022-05-14 12:59:13,452 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1       | 2022-05-14 12:59:13,740 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = ERASURE_CODED_STORAGE_SUPPORT (version = 3), software layout = ERASURE_CODED_STORAGE_SUPPORT (version = 3)
scm_1       | 2022-05-14 12:59:15,002 [main] INFO reflections.Reflections: Reflections took 631 ms to scan 3 urls, producing 105 keys and 221 values 
scm_1       | 2022-05-14 12:59:16,814 [main] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1       | 2022-05-14 12:59:17,202 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1       | 2022-05-14 12:59:17,914 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar!/network-topology-default.xml]
scm_1       | 2022-05-14 12:59:17,917 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
scm_1       | 2022-05-14 12:59:18,093 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
scm_1       | 2022-05-14 12:59:18,146 [main] INFO ha.SequenceIdGenerator: upgrade localId to 109611004723200000
scm_1       | 2022-05-14 12:59:18,146 [main] INFO ha.SequenceIdGenerator: upgrade delTxnId to 0
scm_1       | 2022-05-14 12:59:18,150 [main] INFO ha.SequenceIdGenerator: upgrade containerId to 0
scm_1       | 2022-05-14 12:59:18,153 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
scm_1       | 2022-05-14 12:59:18,283 [main] WARN server.ServerUtils: ozone.scm.dead.node.interval value = 45000 is smaller than min = 60000 based on the key value of ozone.scm.stale.node.interval, reset to the min value 60000.
scm_1       | 2022-05-14 12:59:18,295 [main] INFO node.SCMNodeManager: Entering startup safe mode.
scm_1       | 2022-05-14 12:59:18,333 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
scm_1       | 2022-05-14 12:59:18,363 [main] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
scm_1       | 2022-05-14 12:59:18,564 [main] INFO algorithms.LeaderChoosePolicyFactory: Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
scm_1       | 2022-05-14 12:59:18,564 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
scm_1       | 2022-05-14 12:59:18,581 [main] INFO pipeline.BackgroundPipelineCreator: Starting RatisPipelineUtilsThread.
scm_1       | 2022-05-14 12:59:18,594 [main] INFO pipeline.BackgroundPipelineScrubber: Starting BackgroundPipelineScrubber Service.
scm_1       | 2022-05-14 12:59:18,596 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineCreator.
scm_1       | 2022-05-14 12:59:18,596 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineScrubber.
scm_1       | 2022-05-14 12:59:18,672 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
scm_1       | 2022-05-14 12:59:18,725 [main] INFO ha.SCMServiceManager: Registering service SCMBlockDeletingService.
scm_1       | 2022-05-14 12:59:18,785 [main] INFO ha.SCMServiceManager: Registering service ReplicationManager.
scm_1       | 2022-05-14 12:59:18,786 [main] INFO replication.ReplicationManager: Starting Replication Monitor Thread.
scm_1       | 2022-05-14 12:59:18,825 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1       | Caused by: org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1       | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.newError(S3ErrorTable.java:139)
s3g_1       | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.newError(S3ErrorTable.java:126)
s3g_1       | 	at org.apache.hadoop.ozone.s3.signature.AuthorizationV4HeaderParser.parseCredentials(AuthorizationV4HeaderParser.java:171)
s3g_1       | 	at org.apache.hadoop.ozone.s3.signature.AuthorizationV4HeaderParser.parseSignature(AuthorizationV4HeaderParser.java:91)
s3g_1       | 	at org.apache.hadoop.ozone.s3.signature.AWSSignatureProcessor.parseSignature(AWSSignatureProcessor.java:70)
s3g_1       | 	at org.apache.hadoop.ozone.s3.signature.AWSSignatureProcessor$Proxy$_$$_WeldClientProxy.parseSignature(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getSignature(OzoneClientProducer.java:80)
s3g_1       | 	... 114 more
s3g_1       | 
s3g_1       | 
recon_1     | 2022-05-14 13:03:24,638 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 25 records
recon_1     | 2022-05-14 13:03:24,648 [pool-17-thread-1] INFO tasks.NSSummaryTask: Completed a process run of NSSummaryTask
recon_1     | 2022-05-14 13:03:24,858 [pool-17-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
recon_1     | 2022-05-14 13:03:24,859 [pool-17-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 3 OM DB update event(s).
recon_1     | 2022-05-14 13:03:24,873 [pool-17-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2022-05-14 13:04:24,883 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2022-05-14 13:04:24,884 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2022-05-14 13:04:24,884 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 669 
recon_1     | 2022-05-14 13:04:24,891 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 10, SequenceNumber diff: 23, SequenceNumber Lag from OM 0.
recon_1     | 2022-05-14 13:04:24,891 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 23 records
recon_1     | 2022-05-14 13:04:24,903 [pool-17-thread-1] INFO tasks.NSSummaryTask: Completed a process run of NSSummaryTask
recon_1     | 2022-05-14 13:04:25,127 [pool-17-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
recon_1     | 2022-05-14 13:04:25,128 [pool-17-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 0 OM DB update event(s).
recon_1     | 2022-05-14 13:04:25,128 [pool-17-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2022-05-14 13:04:26,897 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 26 milliseconds to process 0 existing database records.
recon_1     | 2022-05-14 13:04:26,910 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 13 milliseconds for processing 1 containers.
recon_1     | 2022-05-14 13:04:28,924 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 6 pipelines in house.
recon_1     | 2022-05-14 13:04:28,936 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 25 milliseconds.
recon_1     | 2022-05-14 13:05:25,139 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2022-05-14 13:05:25,139 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2022-05-14 13:05:25,139 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 692 
recon_1     | 2022-05-14 13:05:25,149 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 7, SequenceNumber diff: 20, SequenceNumber Lag from OM 0.
recon_1     | 2022-05-14 13:05:25,149 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 20 records
recon_1     | 2022-05-14 13:05:25,155 [pool-17-thread-1] INFO tasks.NSSummaryTask: Completed a process run of NSSummaryTask
recon_1     | 2022-05-14 13:05:25,312 [pool-17-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
recon_1     | 2022-05-14 13:05:25,312 [pool-17-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 1 OM DB update event(s).
recon_1     | 2022-05-14 13:05:25,317 [pool-17-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2022-05-14 13:05:51,799 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: New container #2 got from ozone_datanode_4.ozone_default.
recon_1     | 2022-05-14 13:05:51,811 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: Successfully added container #2 to Recon.
recon_1     | 2022-05-14 13:06:24,805 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: New container #3 got from ozone_datanode_1.ozone_default.
recon_1     | 2022-05-14 13:06:24,812 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: Successfully added container #3 to Recon.
recon_1     | 2022-05-14 13:06:25,343 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2022-05-14 13:06:25,344 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2022-05-14 13:06:25,344 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 712 
recon_1     | 2022-05-14 13:06:25,367 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 8, SequenceNumber diff: 24, SequenceNumber Lag from OM 0.
recon_1     | 2022-05-14 13:06:25,367 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 24 records
recon_1     | 2022-05-14 13:06:25,370 [pool-17-thread-1] INFO tasks.NSSummaryTask: Completed a process run of NSSummaryTask
recon_1     | 2022-05-14 13:06:25,520 [pool-17-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
recon_1     | 2022-05-14 13:06:25,538 [pool-17-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 4 OM DB update event(s).
recon_1     | 2022-05-14 13:06:25,548 [pool-17-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2022-05-14 13:07:25,560 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2022-05-14 13:07:25,561 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2022-05-14 13:07:25,561 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 736 
recon_1     | 2022-05-14 13:07:25,569 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 7, SequenceNumber diff: 20, SequenceNumber Lag from OM 0.
recon_1     | 2022-05-14 13:07:25,569 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 20 records
recon_1     | 2022-05-14 13:07:25,571 [pool-17-thread-1] INFO tasks.NSSummaryTask: Completed a process run of NSSummaryTask
recon_1     | 2022-05-14 13:07:25,712 [pool-17-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
recon_1     | 2022-05-14 13:07:25,715 [pool-17-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 4 OM DB update event(s).
recon_1     | 2022-05-14 13:07:25,727 [pool-17-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2022-05-14 13:08:25,740 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2022-05-14 13:08:25,741 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2022-05-14 13:08:25,741 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 756 
recon_1     | 2022-05-14 13:08:25,750 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 9, SequenceNumber diff: 25, SequenceNumber Lag from OM 0.
recon_1     | 2022-05-14 13:08:25,751 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 25 records
recon_1     | 2022-05-14 13:08:25,760 [pool-17-thread-1] INFO tasks.NSSummaryTask: Completed a process run of NSSummaryTask
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:14:00,002 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:14:18,966 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bb1 of layout LEGACY in volume: 90266-without-host
om_1        | 2022-05-14 13:15:00,003 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:15:00,007 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:15:00,007 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:16:00,001 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 87193-target
recon_1     | 2022-05-14 13:08:25,880 [pool-17-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
recon_1     | 2022-05-14 13:08:25,880 [pool-17-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 0 OM DB update event(s).
recon_1     | 2022-05-14 13:08:25,880 [pool-17-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2022-05-14 13:09:25,891 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2022-05-14 13:09:25,892 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2022-05-14 13:09:25,892 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 781 
recon_1     | 2022-05-14 13:09:25,908 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 5, SequenceNumber diff: 13, SequenceNumber Lag from OM 0.
recon_1     | 2022-05-14 13:09:25,909 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 13 records
recon_1     | 2022-05-14 13:09:25,913 [pool-17-thread-1] INFO tasks.NSSummaryTask: Completed a process run of NSSummaryTask
recon_1     | 2022-05-14 13:09:26,004 [pool-17-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
recon_1     | 2022-05-14 13:09:26,004 [pool-17-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 1 OM DB update event(s).
recon_1     | 2022-05-14 13:09:26,009 [pool-17-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2022-05-14 13:09:26,911 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 1 milliseconds to process 0 existing database records.
recon_1     | 2022-05-14 13:09:26,914 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 3 milliseconds for processing 3 containers.
recon_1     | 2022-05-14 13:09:28,958 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 6 pipelines in house.
recon_1     | 2022-05-14 13:09:28,962 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 13 milliseconds.
recon_1     | 2022-05-14 13:09:51,777 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: New container #4 got from ozone_datanode_5.ozone_default.
recon_1     | 2022-05-14 13:09:51,786 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: Successfully added container #4 to Recon.
recon_1     | 2022-05-14 13:10:26,018 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2022-05-14 13:10:26,018 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2022-05-14 13:10:26,018 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 794 
recon_1     | 2022-05-14 13:10:26,025 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 8, SequenceNumber diff: 25, SequenceNumber Lag from OM 0.
recon_1     | 2022-05-14 13:10:26,025 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 25 records
recon_1     | 2022-05-14 13:10:26,027 [pool-17-thread-1] INFO tasks.NSSummaryTask: Completed a process run of NSSummaryTask
recon_1     | 2022-05-14 13:10:26,189 [pool-17-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
recon_1     | 2022-05-14 13:10:26,198 [pool-17-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 6 OM DB update event(s).
recon_1     | 2022-05-14 13:10:26,201 [pool-17-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2022-05-14 13:11:26,213 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2022-05-14 13:11:26,214 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2022-05-14 13:11:26,214 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 819 
recon_1     | 2022-05-14 13:11:26,232 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 9, SequenceNumber diff: 24, SequenceNumber Lag from OM 0.
recon_1     | 2022-05-14 13:11:26,232 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 24 records
recon_1     | 2022-05-14 13:11:26,235 [pool-17-thread-1] INFO tasks.NSSummaryTask: Completed a process run of NSSummaryTask
recon_1     | 2022-05-14 13:11:26,363 [pool-17-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
recon_1     | 2022-05-14 13:11:26,366 [pool-17-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 1 OM DB update event(s).
recon_1     | 2022-05-14 13:11:26,370 [pool-17-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2022-05-14 13:12:26,374 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2022-05-14 13:12:26,374 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2022-05-14 13:12:26,374 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 843 
recon_1     | 2022-05-14 13:12:26,391 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 9, SequenceNumber diff: 22, SequenceNumber Lag from OM 0.
recon_1     | 2022-05-14 13:12:26,391 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 22 records
recon_1     | 2022-05-14 13:12:26,393 [pool-17-thread-1] INFO tasks.NSSummaryTask: Completed a process run of NSSummaryTask
recon_1     | 2022-05-14 13:12:26,503 [pool-17-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
recon_1     | 2022-05-14 13:12:26,503 [pool-17-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 0 OM DB update event(s).
recon_1     | 2022-05-14 13:12:26,503 [pool-17-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2022-05-14 13:13:26,511 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2022-05-14 13:13:26,512 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2022-05-14 13:13:26,512 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 865 
recon_1     | 2022-05-14 13:13:26,543 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 8, SequenceNumber diff: 18, SequenceNumber Lag from OM 0.
recon_1     | 2022-05-14 13:13:26,543 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 18 records
recon_1     | 2022-05-14 13:13:26,546 [pool-17-thread-1] INFO tasks.NSSummaryTask: Completed a process run of NSSummaryTask
recon_1     | 2022-05-14 13:13:26,661 [pool-17-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
recon_1     | 2022-05-14 13:13:26,674 [pool-17-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 4 OM DB update event(s).
recon_1     | 2022-05-14 13:13:26,678 [pool-17-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2022-05-14 13:14:26,697 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2022-05-14 13:14:26,698 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:16:00,001 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:16:00,001 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:16:48,514 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:90266-without-host for user:hadoop
om_1        | 2022-05-14 13:17:00,003 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:17:00,004 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
recon_1     | 2022-05-14 13:14:26,698 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 883 
recon_1     | 2022-05-14 13:14:26,713 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 7, SequenceNumber diff: 18, SequenceNumber Lag from OM 0.
recon_1     | 2022-05-14 13:14:26,713 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 18 records
recon_1     | 2022-05-14 13:14:26,715 [pool-17-thread-1] INFO tasks.NSSummaryTask: Completed a process run of NSSummaryTask
recon_1     | 2022-05-14 13:14:26,813 [pool-17-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
recon_1     | 2022-05-14 13:14:26,814 [pool-17-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 1 OM DB update event(s).
recon_1     | 2022-05-14 13:14:26,827 [pool-17-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2022-05-14 13:14:26,915 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 1 milliseconds to process 0 existing database records.
recon_1     | 2022-05-14 13:14:26,917 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 2 milliseconds for processing 4 containers.
recon_1     | 2022-05-14 13:14:28,984 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 6 pipelines in house.
recon_1     | 2022-05-14 13:14:28,989 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 22 milliseconds.
recon_1     | 2022-05-14 13:14:53,119 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: New container #5 got from ozone_datanode_3.ozone_default.
recon_1     | 2022-05-14 13:14:53,127 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: Successfully added container #5 to Recon.
recon_1     | 2022-05-14 13:15:25,939 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: New container #6 got from ozone_datanode_2.ozone_default.
recon_1     | 2022-05-14 13:15:25,953 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: Successfully added container #6 to Recon.
recon_1     | 2022-05-14 13:15:26,840 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2022-05-14 13:15:26,841 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2022-05-14 13:15:26,841 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 901 
recon_1     | 2022-05-14 13:15:26,862 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 8, SequenceNumber diff: 24, SequenceNumber Lag from OM 0.
recon_1     | 2022-05-14 13:15:26,862 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 24 records
recon_1     | 2022-05-14 13:15:26,874 [pool-17-thread-1] INFO tasks.NSSummaryTask: Completed a process run of NSSummaryTask
recon_1     | 2022-05-14 13:15:26,971 [pool-17-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
recon_1     | 2022-05-14 13:15:26,985 [pool-17-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 4 OM DB update event(s).
recon_1     | 2022-05-14 13:15:26,989 [pool-17-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2022-05-14 13:16:26,994 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2022-05-14 13:16:26,994 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2022-05-14 13:16:26,994 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 925 
recon_1     | 2022-05-14 13:16:27,008 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 7, SequenceNumber diff: 20, SequenceNumber Lag from OM 0.
recon_1     | 2022-05-14 13:16:27,008 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 20 records
recon_1     | 2022-05-14 13:16:27,014 [pool-17-thread-1] INFO tasks.NSSummaryTask: Completed a process run of NSSummaryTask
recon_1     | 2022-05-14 13:16:27,154 [pool-17-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
recon_1     | 2022-05-14 13:16:27,159 [pool-17-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 4 OM DB update event(s).
recon_1     | 2022-05-14 13:16:27,161 [pool-17-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2022-05-14 13:17:27,173 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2022-05-14 13:17:27,174 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2022-05-14 13:17:27,174 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 945 
recon_1     | 2022-05-14 13:17:27,185 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 10, SequenceNumber diff: 28, SequenceNumber Lag from OM 0.
recon_1     | 2022-05-14 13:17:27,185 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 28 records
recon_1     | 2022-05-14 13:17:27,186 [pool-17-thread-1] INFO tasks.NSSummaryTask: Completed a process run of NSSummaryTask
recon_1     | 2022-05-14 13:17:27,271 [pool-17-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
recon_1     | 2022-05-14 13:17:27,273 [pool-17-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 1 OM DB update event(s).
recon_1     | 2022-05-14 13:17:27,276 [pool-17-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2022-05-14 13:18:27,283 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2022-05-14 13:18:27,284 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2022-05-14 13:18:27,284 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 973 
recon_1     | 2022-05-14 13:18:27,294 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 9, SequenceNumber diff: 29, SequenceNumber Lag from OM 0.
recon_1     | 2022-05-14 13:18:27,294 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 29 records
recon_1     | 2022-05-14 13:18:27,303 [pool-17-thread-1] INFO tasks.NSSummaryTask: Completed a process run of NSSummaryTask
recon_1     | 2022-05-14 13:18:27,376 [pool-17-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
recon_1     | 2022-05-14 13:18:27,377 [pool-17-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 4 OM DB update event(s).
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:17:00,004 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
scm_1       | 2022-05-14 12:59:18,844 [main] INFO safemode.ContainerSafeModeRule: containers with one replica threshold count 0
scm_1       | 2022-05-14 12:59:18,867 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
scm_1       | 2022-05-14 12:59:18,878 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm_1       | 2022-05-14 12:59:20,202 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm_1       | 2022-05-14 12:59:20,394 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1       | 2022-05-14 12:59:20,489 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
scm_1       | 2022-05-14 12:59:20,606 [Listener at 0.0.0.0/9861] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm_1       | 2022-05-14 12:59:20,638 [Listener at 0.0.0.0/9861] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1       | 2022-05-14 12:59:20,645 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
scm_1       | 2022-05-14 12:59:20,714 [Listener at 0.0.0.0/9863] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm_1       | 2022-05-14 12:59:20,768 [Listener at 0.0.0.0/9863] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1       | 2022-05-14 12:59:20,782 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
scm_1       | 2022-05-14 12:59:21,002 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: 
scm_1       | Container Balancer status:
scm_1       | Key                            Value
scm_1       | Running                        false
scm_1       | Container Balancer Configuration values:
scm_1       | Key                                                Value
scm_1       | Threshold                                          10
scm_1       | Max Datanodes to Involve per Iteration(percent)    20
scm_1       | Max Size to Move per Iteration                     500GB
scm_1       | Max Size Entering Target per Iteration             26GB
scm_1       | Max Size Leaving Source per Iteration              26GB
scm_1       | 
scm_1       | 2022-05-14 12:59:21,010 [Listener at 0.0.0.0/9860] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm_1       | 2022-05-14 12:59:21,010 [Listener at 0.0.0.0/9860] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
scm_1       | 2022-05-14 12:59:21,024 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
scm_1       | 2022-05-14 12:59:21,307 [Listener at 0.0.0.0/9860] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
scm_1       | 2022-05-14 12:59:21,359 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
scm_1       | 2022-05-14 12:59:21,359 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
scm_1       | 2022-05-14 12:59:21,992 [Listener at 0.0.0.0/9860] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
scm_1       | 2022-05-14 12:59:21,999 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm_1       | 2022-05-14 12:59:22,101 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
scm_1       | 2022-05-14 12:59:22,110 [Listener at 0.0.0.0/9860] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
scm_1       | 2022-05-14 12:59:22,003 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
scm_1       | 2022-05-14 12:59:22,111 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm_1       | 2022-05-14 12:59:22,112 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
scm_1       | 2022-05-14 12:59:22,146 [Listener at 0.0.0.0/9860] INFO server.SCMDatanodeProtocolServer: ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:9861
scm_1       | 2022-05-14 12:59:22,200 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
scm_1       | 2022-05-14 12:59:22,236 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm_1       | 2022-05-14 12:59:22,293 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@14983265] INFO util.JvmPauseMonitor: Starting JVM pause monitor
scm_1       | 2022-05-14 12:59:22,399 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
scm_1       | 2022-05-14 12:59:22,399 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
scm_1       | 2022-05-14 12:59:22,429 [Listener at 0.0.0.0/9860] INFO util.log: Logging initialized @32643ms to org.eclipse.jetty.util.log.Slf4jLog
scm_1       | 2022-05-14 12:59:22,712 [Listener at 0.0.0.0/9860] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
scm_1       | 2022-05-14 12:59:22,723 [Listener at 0.0.0.0/9860] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
scm_1       | 2022-05-14 12:59:22,732 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
scm_1       | 2022-05-14 12:59:22,766 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
scm_1       | 2022-05-14 12:59:22,767 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
scm_1       | 2022-05-14 12:59:22,767 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
scm_1       | 2022-05-14 12:59:22,885 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Jetty bound to port 9876
scm_1       | 2022-05-14 12:59:22,889 [Listener at 0.0.0.0/9860] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
scm_1       | 2022-05-14 12:59:23,395 [Listener at 0.0.0.0/9860] INFO server.session: DefaultSessionIdManager workerName=node0
scm_1       | 2022-05-14 12:59:23,403 [Listener at 0.0.0.0/9860] INFO server.session: No SessionScavenger set, using defaults
scm_1       | 2022-05-14 12:59:23,409 [Listener at 0.0.0.0/9860] INFO server.session: node0 Scavenging every 660000ms
scm_1       | 2022-05-14 12:59:23,840 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1fb00a6d{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
scm_1       | 2022-05-14 12:59:23,872 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5bc40f5d{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
s3g_1       | 2022-05-14 13:21:47,935 [qtp2096539129-21] ERROR endpoint.ObjectEndpoint: Exception occurred in PutObject
s3g_1       | 2022-05-14 13:22:12,680 [qtp2096539129-24] ERROR endpoint.ObjectEndpoint: Exception occurred in PutObject
s3g_1       | 2022-05-14 13:22:13,385 [qtp2096539129-23] ERROR endpoint.ObjectEndpoint: Exception occurred in PutObject
s3g_1       | 2022-05-14 13:22:29,330 [qtp2096539129-23] INFO rpc.RpcClient: Creating Bucket: s3v/destbucket-51219, with dlfknslnfslf as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-05-14 13:22:29,337 [qtp2096539129-23] INFO endpoint.BucketEndpoint: Location is /destbucket-51219
s3g_1       | 2022-05-14 13:22:31,715 [qtp2096539129-24] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
s3g_1       | 2022-05-14 13:22:34,699 [qtp2096539129-24] ERROR endpoint.ObjectEndpoint: Exception occurred in PutObject
s3g_1       | 2022-05-14 13:22:35,397 [qtp2096539129-23] ERROR endpoint.ObjectEndpoint: Exception occurred in PutObject
s3g_1       | 2022-05-14 13:22:36,764 [qtp2096539129-23] ERROR endpoint.ObjectEndpoint: Exception occurred in PutObject
s3g_1       | 2022-05-14 13:24:20,599 [qtp2096539129-23] INFO rpc.RpcClient: Creating Bucket: s3v/ozone-test-zqmnulnemk, with dlfknslnfslf as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-05-14 13:24:20,604 [qtp2096539129-23] INFO endpoint.BucketEndpoint: Location is /ozone-test-zqmnulnemk
s3g_1       | 2022-05-14 13:24:23,080 [qtp2096539129-19] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-xnvouwczbq, with dlfknslnfslf as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-05-14 13:24:23,084 [qtp2096539129-19] INFO endpoint.BucketEndpoint: Location is /bucket-xnvouwczbq
s3g_1       | 2022-05-14 13:24:53,979 [qtp2096539129-20] ERROR signature.AuthorizationV4HeaderParser: AWS access id shouldn't be empty. credential:/20220514/us-west-1/s3/aws4_request
s3g_1       | May 14, 2022 1:24:53 PM org.glassfish.jersey.internal.Errors logErrors
s3g_1       | WARNING: The following warnings have been detected: WARNING: Unknown HK2 failure detected:
s3g_1       | MultiException stack 1 of 1
s3g_1       | javax.ws.rs.WebApplicationException: The authorization header you provided is invalid.
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.wrapOS3Exception(OzoneClientProducer.java:138)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getSignature(OzoneClientProducer.java:99)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor20.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:874)
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:127)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:69)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:103)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:46)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:53)
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:129)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:463)
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:46)
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2102)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:758)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:721)
recon_1     | 2022-05-14 13:18:27,378 [pool-17-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2022-05-14 13:19:26,918 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 1 milliseconds to process 0 existing database records.
recon_1     | 2022-05-14 13:19:26,921 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 2 milliseconds for processing 6 containers.
recon_1     | 2022-05-14 13:19:27,382 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:17:00,765 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bb1 of layout LEGACY in volume: 90266-without-host
om_1        | 2022-05-14 13:17:39,679 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:spjqh for user:hadoop
om_1        | 2022-05-14 13:17:43,612 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: mybucket1 of layout LEGACY in volume: spjqh
om_1        | 2022-05-14 13:18:00,001 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:18:00,002 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:18:00,002 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:18:06,163 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: mybucket2 of layout LEGACY in volume: spjqh
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:691)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:160)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:30)
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:105)
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:260)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:51)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:86)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:89)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:89)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:89)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:69)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:38)
scm_1       | 2022-05-14 12:59:24,878 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@7b9d602c{scm,/,file:///tmp/jetty-0_0_0_0-9876-hdds-server-scm-1_3_0-SNAPSHOT_jar-_-any-17258522869369123758/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar!/webapps/scm}
scm_1       | 2022-05-14 12:59:25,152 [Listener at 0.0.0.0/9860] INFO server.AbstractConnector: Started ServerConnector@7890fbf9{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
scm_1       | 2022-05-14 12:59:25,152 [Listener at 0.0.0.0/9860] INFO server.Server: Started @35366ms
scm_1       | 2022-05-14 12:59:25,175 [IPC Server handler 4 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/55441846-8ccc-4390-87fc-ba015dadcaaa
scm_1       | 2022-05-14 12:59:25,191 [Listener at 0.0.0.0/9860] INFO impl.MetricsSinkAdapter: Sink prometheus started
scm_1       | 2022-05-14 12:59:25,191 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Registered sink prometheus
scm_1       | 2022-05-14 12:59:25,271 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
scm_1       | 2022-05-14 12:59:25,179 [IPC Server handler 3 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/f3166980-8467-4e9a-9c6e-144f4303af87
scm_1       | 2022-05-14 12:59:25,190 [IPC Server handler 0 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/00910f34-9556-4f5c-8864-f93205907e3c
scm_1       | 2022-05-14 12:59:25,332 [IPC Server handler 24 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/d5e6fff5-66a9-4bee-add9-03aeb4a97c66
scm_1       | 2022-05-14 12:59:25,351 [IPC Server handler 25 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/54b0e747-a2bb-484f-976a-c7c0770cb588
scm_1       | 2022-05-14 12:59:25,355 [IPC Server handler 3 on default port 9861] INFO node.SCMNodeManager: Registered Data node : f3166980-8467-4e9a-9c6e-144f4303af87{ip: 172.18.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm_1       | 2022-05-14 12:59:25,356 [IPC Server handler 25 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 54b0e747-a2bb-484f-976a-c7c0770cb588{ip: 172.18.0.9, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm_1       | 2022-05-14 12:59:25,356 [IPC Server handler 0 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 00910f34-9556-4f5c-8864-f93205907e3c{ip: 172.18.0.6, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm_1       | 2022-05-14 12:59:25,357 [IPC Server handler 24 on default port 9861] INFO node.SCMNodeManager: Registered Data node : d5e6fff5-66a9-4bee-add9-03aeb4a97c66{ip: 172.18.0.2, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm_1       | 2022-05-14 12:59:25,357 [IPC Server handler 4 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 55441846-8ccc-4390-87fc-ba015dadcaaa{ip: 172.18.0.4, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm_1       | 2022-05-14 12:59:25,409 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1       | 2022-05-14 12:59:25,567 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm_1       | 2022-05-14 12:59:25,567 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1       | 2022-05-14 12:59:25,573 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm_1       | 2022-05-14 12:59:25,595 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 5 required.
scm_1       | 2022-05-14 12:59:25,610 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 5 required.
scm_1       | 2022-05-14 12:59:25,613 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm_1       | 2022-05-14 12:59:25,613 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 5 required.
scm_1       | 2022-05-14 12:59:25,613 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 4 DataNodes registered, 5 required.
scm_1       | 2022-05-14 12:59:25,613 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm_1       | 2022-05-14 12:59:25,614 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 5 DataNodes registered, 5 required.
scm_1       | 2022-05-14 12:59:25,614 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm_1       | 2022-05-14 12:59:25,614 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
scm_1       | 2022-05-14 12:59:25,614 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm_1       | 2022-05-14 12:59:25,615 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm_1       | 2022-05-14 12:59:25,722 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
scm_1       | 2022-05-14 12:59:25,741 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm_1       | 2022-05-14 12:59:25,780 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=bb9400ad-6f37-4998-976e-c7743fc36ac3 to datanode:55441846-8ccc-4390-87fc-ba015dadcaaa
scm_1       | 2022-05-14 12:59:26,114 [RatisPipelineUtilsThread - 0] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: bb9400ad-6f37-4998-976e-c7743fc36ac3, Nodes: 55441846-8ccc-4390-87fc-ba015dadcaaa{ip: 172.18.0.4, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-05-14T12:59:25.742Z[UTC]].
scm_1       | 2022-05-14 12:59:26,181 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=503efc89-95e3-40df-aa92-c3bf6305580b to datanode:00910f34-9556-4f5c-8864-f93205907e3c
recon_1     | 2022-05-14 13:19:27,383 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2022-05-14 13:19:27,383 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 1002 
recon_1     | 2022-05-14 13:19:27,400 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 9, SequenceNumber diff: 29, SequenceNumber Lag from OM 0.
recon_1     | 2022-05-14 13:19:27,401 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 29 records
recon_1     | 2022-05-14 13:19:27,403 [pool-17-thread-1] INFO tasks.NSSummaryTask: Completed a process run of NSSummaryTask
recon_1     | 2022-05-14 13:19:27,471 [pool-17-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
recon_1     | 2022-05-14 13:19:27,475 [pool-17-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 4 OM DB update event(s).
recon_1     | 2022-05-14 13:19:27,480 [pool-17-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2022-05-14 13:19:29,007 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 6 pipelines in house.
recon_1     | 2022-05-14 13:19:29,009 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 8 milliseconds.
recon_1     | 2022-05-14 13:20:17,228 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: New container #7 got from ozone_datanode_1.ozone_default.
recon_1     | 2022-05-14 13:20:17,240 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=b2302968-6590-4efd-b3d4-88f98845679b not found. Cannot add container #7
recon_1     | 2022-05-14 13:20:17,249 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] WARN scm.ReconIncrementalContainerReportHandler: Container 7 not found!
recon_1     | 2022-05-14 13:20:17,264 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: New container #7 got from ozone_datanode_4.ozone_default.
recon_1     | 2022-05-14 13:20:17,277 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=b2302968-6590-4efd-b3d4-88f98845679b not found. Cannot add container #7
recon_1     | 2022-05-14 13:20:17,277 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] WARN scm.ReconIncrementalContainerReportHandler: Container 7 not found!
recon_1     | 2022-05-14 13:20:17,294 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: New container #7 got from ozone_datanode_5.ozone_default.
recon_1     | 2022-05-14 13:20:17,298 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=b2302968-6590-4efd-b3d4-88f98845679b not found. Cannot add container #7
recon_1     | 2022-05-14 13:20:17,299 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] WARN scm.ReconIncrementalContainerReportHandler: Container 7 not found!
recon_1     | 2022-05-14 13:20:18,320 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: New container #8 got from ozone_datanode_1.ozone_default.
recon_1     | 2022-05-14 13:20:18,326 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=60ee7a26-489d-44d6-b8c5-9e342c88bb63 not found. Cannot add container #8
recon_1     | 2022-05-14 13:20:18,328 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] WARN scm.ReconIncrementalContainerReportHandler: Container 8 not found!
recon_1     | 2022-05-14 13:20:18,329 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: New container #8 got from ozone_datanode_5.ozone_default.
recon_1     | 2022-05-14 13:20:18,333 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=60ee7a26-489d-44d6-b8c5-9e342c88bb63 not found. Cannot add container #8
recon_1     | 2022-05-14 13:20:18,334 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] WARN scm.ReconIncrementalContainerReportHandler: Container 8 not found!
recon_1     | 2022-05-14 13:20:18,366 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: New container #8 got from ozone_datanode_3.ozone_default.
recon_1     | 2022-05-14 13:20:18,370 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=60ee7a26-489d-44d6-b8c5-9e342c88bb63 not found. Cannot add container #8
recon_1     | 2022-05-14 13:20:18,370 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] WARN scm.ReconIncrementalContainerReportHandler: Container 8 not found!
recon_1     | 2022-05-14 13:20:21,359 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: New container #9 got from ozone_datanode_3.ozone_default.
recon_1     | 2022-05-14 13:20:21,368 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=6e6105cc-e733-4e24-b11b-36605179c86d not found. Cannot add container #9
recon_1     | 2022-05-14 13:20:21,368 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] WARN scm.ReconIncrementalContainerReportHandler: Container 9 not found!
recon_1     | 2022-05-14 13:20:21,372 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: New container #9 got from ozone_datanode_4.ozone_default.
recon_1     | 2022-05-14 13:20:21,386 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=6e6105cc-e733-4e24-b11b-36605179c86d not found. Cannot add container #9
recon_1     | 2022-05-14 13:20:21,386 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] WARN scm.ReconIncrementalContainerReportHandler: Container 9 not found!
recon_1     | 2022-05-14 13:20:21,386 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: New container #9 got from ozone_datanode_5.ozone_default.
recon_1     | 2022-05-14 13:20:21,391 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=6e6105cc-e733-4e24-b11b-36605179c86d not found. Cannot add container #9
recon_1     | 2022-05-14 13:20:21,392 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] WARN scm.ReconIncrementalContainerReportHandler: Container 9 not found!
recon_1     | 2022-05-14 13:20:27,484 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2022-05-14 13:20:27,484 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2022-05-14 13:20:27,484 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 1031 
recon_1     | 2022-05-14 13:20:27,494 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 8, SequenceNumber diff: 24, SequenceNumber Lag from OM 0.
recon_1     | 2022-05-14 13:20:27,497 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 24 records
recon_1     | 2022-05-14 13:20:27,499 [pool-17-thread-1] INFO tasks.NSSummaryTask: Completed a process run of NSSummaryTask
recon_1     | 2022-05-14 13:20:27,569 [pool-17-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
scm_1       | 2022-05-14 12:59:26,184 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=503efc89-95e3-40df-aa92-c3bf6305580b to datanode:55441846-8ccc-4390-87fc-ba015dadcaaa
scm_1       | 2022-05-14 12:59:26,184 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=503efc89-95e3-40df-aa92-c3bf6305580b to datanode:54b0e747-a2bb-484f-976a-c7c0770cb588
scm_1       | 2022-05-14 12:59:26,186 [RatisPipelineUtilsThread - 0] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 503efc89-95e3-40df-aa92-c3bf6305580b, Nodes: 00910f34-9556-4f5c-8864-f93205907e3c{ip: 172.18.0.6, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}55441846-8ccc-4390-87fc-ba015dadcaaa{ip: 172.18.0.4, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}54b0e747-a2bb-484f-976a-c7c0770cb588{ip: 172.18.0.9, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-05-14T12:59:26.181Z[UTC]].
scm_1       | 2022-05-14 12:59:26,194 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=ec7d4258-8caa-4f40-bc08-8aa059d6edb9 to datanode:00910f34-9556-4f5c-8864-f93205907e3c
scm_1       | 2022-05-14 12:59:26,195 [RatisPipelineUtilsThread - 0] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: ec7d4258-8caa-4f40-bc08-8aa059d6edb9, Nodes: 00910f34-9556-4f5c-8864-f93205907e3c{ip: 172.18.0.6, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-05-14T12:59:26.194Z[UTC]].
scm_1       | 2022-05-14 12:59:26,216 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=74934bef-4747-4536-b24b-4a9fa2b98460 to datanode:d5e6fff5-66a9-4bee-add9-03aeb4a97c66
scm_1       | 2022-05-14 12:59:26,222 [RatisPipelineUtilsThread - 0] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 74934bef-4747-4536-b24b-4a9fa2b98460, Nodes: d5e6fff5-66a9-4bee-add9-03aeb4a97c66{ip: 172.18.0.2, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-05-14T12:59:26.216Z[UTC]].
scm_1       | 2022-05-14 12:59:26,229 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=1fd8b2e8-f580-4de7-855d-7a48e9feef0d to datanode:54b0e747-a2bb-484f-976a-c7c0770cb588
scm_1       | 2022-05-14 12:59:26,230 [RatisPipelineUtilsThread - 0] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 1fd8b2e8-f580-4de7-855d-7a48e9feef0d, Nodes: 54b0e747-a2bb-484f-976a-c7c0770cb588{ip: 172.18.0.9, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-05-14T12:59:26.229Z[UTC]].
scm_1       | 2022-05-14 12:59:26,246 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=a879b83f-d447-4d1a-b7cc-382bccacc254 to datanode:f3166980-8467-4e9a-9c6e-144f4303af87
scm_1       | 2022-05-14 12:59:26,247 [RatisPipelineUtilsThread - 0] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: a879b83f-d447-4d1a-b7cc-382bccacc254, Nodes: f3166980-8467-4e9a-9c6e-144f4303af87{ip: 172.18.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-05-14T12:59:26.246Z[UTC]].
scm_1       | 2022-05-14 12:59:32,929 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: bb9400ad-6f37-4998-976e-c7743fc36ac3, Nodes: 55441846-8ccc-4390-87fc-ba015dadcaaa{ip: 172.18.0.4, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:55441846-8ccc-4390-87fc-ba015dadcaaa, CreationTimestamp2022-05-14T12:59:25.742Z[UTC]] moved to OPEN state
scm_1       | 2022-05-14 12:59:33,049 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1       | 2022-05-14 12:59:33,617 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: a879b83f-d447-4d1a-b7cc-382bccacc254, Nodes: f3166980-8467-4e9a-9c6e-144f4303af87{ip: 172.18.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:f3166980-8467-4e9a-9c6e-144f4303af87, CreationTimestamp2022-05-14T12:59:26.246Z[UTC]] moved to OPEN state
scm_1       | 2022-05-14 12:59:33,683 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1       | 2022-05-14 12:59:33,830 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 74934bef-4747-4536-b24b-4a9fa2b98460, Nodes: d5e6fff5-66a9-4bee-add9-03aeb4a97c66{ip: 172.18.0.2, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:d5e6fff5-66a9-4bee-add9-03aeb4a97c66, CreationTimestamp2022-05-14T12:59:26.216Z[UTC]] moved to OPEN state
scm_1       | 2022-05-14 12:59:33,847 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1       | 2022-05-14 12:59:33,955 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:173)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:247)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1679)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1       | Caused by: org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1       | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.newError(S3ErrorTable.java:139)
s3g_1       | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.newError(S3ErrorTable.java:126)
recon_1     | 2022-05-14 13:20:27,581 [pool-17-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 3 OM DB update event(s).
recon_1     | 2022-05-14 13:20:27,586 [pool-17-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2022-05-14 13:20:30,245 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: New container #10 got from ozone_datanode_5.ozone_default.
recon_1     | 2022-05-14 13:20:30,251 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=eea4bf28-37f5-4124-9157-cb84720170a9 not found. Cannot add container #10
recon_1     | 2022-05-14 13:20:30,251 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] WARN scm.ReconIncrementalContainerReportHandler: Container 10 not found!
recon_1     | 2022-05-14 13:20:30,274 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: New container #10 got from ozone_datanode_3.ozone_default.
recon_1     | 2022-05-14 13:20:30,277 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=eea4bf28-37f5-4124-9157-cb84720170a9 not found. Cannot add container #10
recon_1     | 2022-05-14 13:20:30,277 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] WARN scm.ReconIncrementalContainerReportHandler: Container 10 not found!
recon_1     | 2022-05-14 13:20:30,346 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: New container #10 got from ozone_datanode_4.ozone_default.
recon_1     | 2022-05-14 13:20:30,350 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=eea4bf28-37f5-4124-9157-cb84720170a9 not found. Cannot add container #10
recon_1     | 2022-05-14 13:20:30,350 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] WARN scm.ReconIncrementalContainerReportHandler: Container 10 not found!
recon_1     | 2022-05-14 13:20:30,646 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: New container #11 got from ozone_datanode_3.ozone_default.
recon_1     | 2022-05-14 13:20:30,648 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=85665b57-79bd-4721-8990-6434b89cf0f5 not found. Cannot add container #11
recon_1     | 2022-05-14 13:20:30,648 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] WARN scm.ReconIncrementalContainerReportHandler: Container 11 not found!
recon_1     | 2022-05-14 13:20:30,711 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: New container #11 got from ozone_datanode_5.ozone_default.
recon_1     | 2022-05-14 13:20:30,716 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=85665b57-79bd-4721-8990-6434b89cf0f5 not found. Cannot add container #11
recon_1     | 2022-05-14 13:20:30,716 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] WARN scm.ReconIncrementalContainerReportHandler: Container 11 not found!
recon_1     | 2022-05-14 13:20:30,724 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: New container #11 got from ozone_datanode_4.ozone_default.
recon_1     | 2022-05-14 13:20:30,727 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=85665b57-79bd-4721-8990-6434b89cf0f5 not found. Cannot add container #11
recon_1     | 2022-05-14 13:20:30,728 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] WARN scm.ReconIncrementalContainerReportHandler: Container 11 not found!
recon_1     | 2022-05-14 13:20:31,288 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: New container #9 got from ozone_datanode_1.ozone_default.
recon_1     | 2022-05-14 13:20:31,298 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=6e6105cc-e733-4e24-b11b-36605179c86d not found. Cannot add container #9
recon_1     | 2022-05-14 13:20:31,298 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] WARN scm.ReconIncrementalContainerReportHandler: Container 9 not found!
recon_1     | 2022-05-14 13:20:31,347 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: New container #9 got from ozone_datanode_2.ozone_default.
recon_1     | 2022-05-14 13:20:31,351 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=6e6105cc-e733-4e24-b11b-36605179c86d not found. Cannot add container #9
recon_1     | 2022-05-14 13:20:31,353 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] WARN scm.ReconIncrementalContainerReportHandler: Container 9 not found!
recon_1     | 2022-05-14 13:20:31,881 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: New container #7 got from ozone_datanode_2.ozone_default.
recon_1     | 2022-05-14 13:20:31,885 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=b2302968-6590-4efd-b3d4-88f98845679b not found. Cannot add container #7
recon_1     | 2022-05-14 13:20:31,886 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] WARN scm.ReconIncrementalContainerReportHandler: Container 7 not found!
recon_1     | 2022-05-14 13:20:31,896 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: New container #7 got from ozone_datanode_3.ozone_default.
recon_1     | 2022-05-14 13:20:31,899 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=b2302968-6590-4efd-b3d4-88f98845679b not found. Cannot add container #7
recon_1     | 2022-05-14 13:20:31,899 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] WARN scm.ReconIncrementalContainerReportHandler: Container 7 not found!
recon_1     | 2022-05-14 13:20:32,107 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: New container #10 got from ozone_datanode_2.ozone_default.
recon_1     | 2022-05-14 13:20:32,110 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=eea4bf28-37f5-4124-9157-cb84720170a9 not found. Cannot add container #10
recon_1     | 2022-05-14 13:20:32,110 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] WARN scm.ReconIncrementalContainerReportHandler: Container 10 not found!
recon_1     | 2022-05-14 13:20:32,931 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: New container #10 got from ozone_datanode_1.ozone_default.
recon_1     | 2022-05-14 13:20:32,934 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=eea4bf28-37f5-4124-9157-cb84720170a9 not found. Cannot add container #10
recon_1     | 2022-05-14 13:20:32,935 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] WARN scm.ReconIncrementalContainerReportHandler: Container 10 not found!
scm_1       | 2022-05-14 12:59:37,954 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 1fd8b2e8-f580-4de7-855d-7a48e9feef0d, Nodes: 54b0e747-a2bb-484f-976a-c7c0770cb588{ip: 172.18.0.9, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:54b0e747-a2bb-484f-976a-c7c0770cb588, CreationTimestamp2022-05-14T12:59:26.229Z[UTC]] moved to OPEN state
scm_1       | 2022-05-14 12:59:37,959 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1       | 2022-05-14 12:59:38,168 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: ec7d4258-8caa-4f40-bc08-8aa059d6edb9, Nodes: 00910f34-9556-4f5c-8864-f93205907e3c{ip: 172.18.0.6, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:00910f34-9556-4f5c-8864-f93205907e3c, CreationTimestamp2022-05-14T12:59:26.194Z[UTC]] moved to OPEN state
scm_1       | 2022-05-14 12:59:38,180 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1       | 2022-05-14 12:59:38,742 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1       | 2022-05-14 12:59:39,412 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1       | 2022-05-14 12:59:39,748 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1       | 2022-05-14 12:59:43,181 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1       | 2022-05-14 12:59:43,342 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1       | 2022-05-14 12:59:44,500 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 503efc89-95e3-40df-aa92-c3bf6305580b, Nodes: 00910f34-9556-4f5c-8864-f93205907e3c{ip: 172.18.0.6, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}55441846-8ccc-4390-87fc-ba015dadcaaa{ip: 172.18.0.4, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}54b0e747-a2bb-484f-976a-c7c0770cb588{ip: 172.18.0.9, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:00910f34-9556-4f5c-8864-f93205907e3c, CreationTimestamp2022-05-14T12:59:26.181Z[UTC]] moved to OPEN state
scm_1       | 2022-05-14 12:59:44,504 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
scm_1       | 2022-05-14 12:59:44,506 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
scm_1       | 2022-05-14 12:59:44,507 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
scm_1       | 2022-05-14 12:59:44,507 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
scm_1       | 2022-05-14 12:59:44,507 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm_1       | 2022-05-14 12:59:44,507 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
scm_1       | 2022-05-14 12:59:44,509 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO pipeline.BackgroundPipelineCreator: Service BackgroundPipelineCreator transitions to RUNNING.
scm_1       | 2022-05-14 12:59:44,513 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO pipeline.BackgroundPipelineScrubber: Service BackgroundPipelineScrubber transitions to RUNNING.
scm_1       | 2022-05-14 12:59:44,515 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO replication.ReplicationManager: Service ReplicationManager transitions to RUNNING.
scm_1       | 2022-05-14 13:00:38,672 [IPC Server handler 30 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for containerId, change lastId from 0 to 1000.
scm_1       | 2022-05-14 13:00:38,741 [IPC Server handler 30 on default port 9863] WARN ha.SequenceIdGenerator: Failed to allocate a batch for localId, expected lastId is 0, actual lastId is 109611004723200000.
scm_1       | 2022-05-14 13:00:38,743 [IPC Server handler 30 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for localId, change lastId from 109611004723200000 to 109611004723201000.
scm_1       | 2022-05-14 13:03:45,760 [IPC Server handler 40 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for delTxnId, change lastId from 0 to 1000.
scm_1       | 2022-05-14 13:04:18,826 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm_1       | 2022-05-14 13:09:18,828 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 2 milliseconds for processing 3 containers.
scm_1       | 2022-05-14 13:14:18,829 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 4 containers.
scm_1       | 2022-05-14 13:19:18,831 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 2 milliseconds for processing 6 containers.
scm_1       | 2022-05-14 13:20:15,894 [IPC Server handler 40 on default port 9863] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: b2302968-6590-4efd-b3d4-88f98845679b, Nodes: d5e6fff5-66a9-4bee-add9-03aeb4a97c66{ip: 172.18.0.2, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}55441846-8ccc-4390-87fc-ba015dadcaaa{ip: 172.18.0.4, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}54b0e747-a2bb-484f-976a-c7c0770cb588{ip: 172.18.0.9, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}00910f34-9556-4f5c-8864-f93205907e3c{ip: 172.18.0.6, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}f3166980-8467-4e9a-9c6e-144f4303af87{ip: 172.18.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: EC/ECReplicationConfig{data=3, parity=2, ecChunkSize=1048576, codec=rs}, State:ALLOCATED, leaderId:, CreationTimestamp2022-05-14T13:20:15.873Z[UTC]].
scm_1       | 2022-05-14 13:20:15,895 [IPC Server handler 40 on default port 9863] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: b2302968-6590-4efd-b3d4-88f98845679b, Nodes: d5e6fff5-66a9-4bee-add9-03aeb4a97c66{ip: 172.18.0.2, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}55441846-8ccc-4390-87fc-ba015dadcaaa{ip: 172.18.0.4, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}54b0e747-a2bb-484f-976a-c7c0770cb588{ip: 172.18.0.9, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}00910f34-9556-4f5c-8864-f93205907e3c{ip: 172.18.0.6, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}f3166980-8467-4e9a-9c6e-144f4303af87{ip: 172.18.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: EC/ECReplicationConfig{data=3, parity=2, ecChunkSize=1048576, codec=rs}, State:ALLOCATED, leaderId:, CreationTimestamp2022-05-14T13:20:15.873Z[UTC]] moved to OPEN state
scm_1       | 2022-05-14 13:20:18,162 [IPC Server handler 36 on default port 9863] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 60ee7a26-489d-44d6-b8c5-9e342c88bb63, Nodes: f3166980-8467-4e9a-9c6e-144f4303af87{ip: 172.18.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}d5e6fff5-66a9-4bee-add9-03aeb4a97c66{ip: 172.18.0.2, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}54b0e747-a2bb-484f-976a-c7c0770cb588{ip: 172.18.0.9, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}00910f34-9556-4f5c-8864-f93205907e3c{ip: 172.18.0.6, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}55441846-8ccc-4390-87fc-ba015dadcaaa{ip: 172.18.0.4, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: EC/ECReplicationConfig{data=3, parity=2, ecChunkSize=1048576, codec=rs}, State:ALLOCATED, leaderId:, CreationTimestamp2022-05-14T13:20:18.162Z[UTC]].
scm_1       | 2022-05-14 13:20:18,168 [IPC Server handler 36 on default port 9863] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 60ee7a26-489d-44d6-b8c5-9e342c88bb63, Nodes: f3166980-8467-4e9a-9c6e-144f4303af87{ip: 172.18.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}d5e6fff5-66a9-4bee-add9-03aeb4a97c66{ip: 172.18.0.2, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}54b0e747-a2bb-484f-976a-c7c0770cb588{ip: 172.18.0.9, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}00910f34-9556-4f5c-8864-f93205907e3c{ip: 172.18.0.6, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}55441846-8ccc-4390-87fc-ba015dadcaaa{ip: 172.18.0.4, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: EC/ECReplicationConfig{data=3, parity=2, ecChunkSize=1048576, codec=rs}, State:ALLOCATED, leaderId:, CreationTimestamp2022-05-14T13:20:18.162Z[UTC]] moved to OPEN state
scm_1       | 2022-05-14 13:20:21,213 [IPC Server handler 44 on default port 9863] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 6e6105cc-e733-4e24-b11b-36605179c86d, Nodes: d5e6fff5-66a9-4bee-add9-03aeb4a97c66{ip: 172.18.0.2, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}54b0e747-a2bb-484f-976a-c7c0770cb588{ip: 172.18.0.9, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}00910f34-9556-4f5c-8864-f93205907e3c{ip: 172.18.0.6, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}55441846-8ccc-4390-87fc-ba015dadcaaa{ip: 172.18.0.4, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}f3166980-8467-4e9a-9c6e-144f4303af87{ip: 172.18.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: EC/ECReplicationConfig{data=3, parity=2, ecChunkSize=1048576, codec=rs}, State:ALLOCATED, leaderId:, CreationTimestamp2022-05-14T13:20:21.213Z[UTC]].
om_1        | 2022-05-14 13:18:29,216 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: mybucket3 of layout LEGACY in volume: spjqh
om_1        | 2022-05-14 13:18:52,657 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: mybucket4 of layout LEGACY in volume: spjqh
om_1        | 2022-05-14 13:19:00,001 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
recon_1     | 2022-05-14 13:20:33,144 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: New container #11 got from ozone_datanode_2.ozone_default.
recon_1     | 2022-05-14 13:20:33,148 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=85665b57-79bd-4721-8990-6434b89cf0f5 not found. Cannot add container #11
recon_1     | 2022-05-14 13:20:33,148 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] WARN scm.ReconIncrementalContainerReportHandler: Container 11 not found!
recon_1     | 2022-05-14 13:20:34,144 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: New container #11 got from ozone_datanode_1.ozone_default.
recon_1     | 2022-05-14 13:20:34,148 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=85665b57-79bd-4721-8990-6434b89cf0f5 not found. Cannot add container #11
recon_1     | 2022-05-14 13:20:34,148 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] WARN scm.ReconIncrementalContainerReportHandler: Container 11 not found!
recon_1     | 2022-05-14 13:20:34,155 [EventQueue-ContainerReportForReconContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=b2302968-6590-4efd-b3d4-88f98845679b not found. Cannot add container #7
recon_1     | 2022-05-14 13:20:34,156 [EventQueue-ContainerReportForReconContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=60ee7a26-489d-44d6-b8c5-9e342c88bb63 not found. Cannot add container #8
recon_1     | 2022-05-14 13:20:34,156 [EventQueue-ContainerReportForReconContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=6e6105cc-e733-4e24-b11b-36605179c86d not found. Cannot add container #9
recon_1     | 2022-05-14 13:20:34,156 [EventQueue-ContainerReportForReconContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=eea4bf28-37f5-4124-9157-cb84720170a9 not found. Cannot add container #10
recon_1     | 2022-05-14 13:20:34,156 [EventQueue-ContainerReportForReconContainerReportHandler] ERROR container.ContainerReportHandler: Received container report for an unknown container 7 from datanode 00910f34-9556-4f5c-8864-f93205907e3c{ip: 172.18.0.6, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
recon_1     | 2022-05-14 13:20:34,157 [EventQueue-ContainerReportForReconContainerReportHandler] ERROR container.ContainerReportHandler: Received container report for an unknown container 8 from datanode 00910f34-9556-4f5c-8864-f93205907e3c{ip: 172.18.0.6, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
recon_1     | 2022-05-14 13:20:34,157 [EventQueue-ContainerReportForReconContainerReportHandler] ERROR container.ContainerReportHandler: Received container report for an unknown container 9 from datanode 00910f34-9556-4f5c-8864-f93205907e3c{ip: 172.18.0.6, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
recon_1     | 2022-05-14 13:20:34,157 [EventQueue-ContainerReportForReconContainerReportHandler] ERROR container.ContainerReportHandler: Received container report for an unknown container 10 from datanode 00910f34-9556-4f5c-8864-f93205907e3c{ip: 172.18.0.6, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
recon_1     | 2022-05-14 13:20:34,157 [EventQueue-ContainerReportForReconContainerReportHandler] WARN container.ContainerReportHandler: Cannot remove container replica, container #11 not found.
recon_1     | org.apache.hadoop.hdds.scm.container.ContainerNotFoundException: ID #11
recon_1     | 	at org.apache.hadoop.hdds.scm.container.ContainerManagerImpl.lambda$getContainerReplicas$2(ContainerManagerImpl.java:314)
recon_1     | 	at java.base/java.util.Optional.orElseThrow(Optional.java:408)
recon_1     | 	at org.apache.hadoop.hdds.scm.container.ContainerManagerImpl.getContainerReplicas(ContainerManagerImpl.java:314)
recon_1     | 	at org.apache.hadoop.hdds.scm.container.ContainerReportHandler.processMissingReplicas(ContainerReportHandler.java:257)
recon_1     | 	at org.apache.hadoop.hdds.scm.container.ContainerReportHandler.onMessage(ContainerReportHandler.java:194)
recon_1     | 	at org.apache.hadoop.ozone.recon.scm.ReconContainerReportHandler.onMessage(ReconContainerReportHandler.java:53)
recon_1     | 	at org.apache.hadoop.ozone.recon.scm.ReconContainerReportHandler.onMessage(ReconContainerReportHandler.java:35)
recon_1     | 	at org.apache.hadoop.hdds.server.events.SingleThreadExecutor.lambda$onMessage$1(SingleThreadExecutor.java:85)
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1     | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1     | 2022-05-14 13:20:34,813 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: New container #8 got from ozone_datanode_4.ozone_default.
recon_1     | 2022-05-14 13:20:34,817 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=60ee7a26-489d-44d6-b8c5-9e342c88bb63 not found. Cannot add container #8
recon_1     | 2022-05-14 13:20:34,820 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] WARN scm.ReconIncrementalContainerReportHandler: Container 8 not found!
recon_1     | 2022-05-14 13:20:34,850 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: New container #8 got from ozone_datanode_2.ozone_default.
recon_1     | 2022-05-14 13:20:34,856 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=60ee7a26-489d-44d6-b8c5-9e342c88bb63 not found. Cannot add container #8
recon_1     | 2022-05-14 13:20:34,856 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] WARN scm.ReconIncrementalContainerReportHandler: Container 8 not found!
recon_1     | 2022-05-14 13:21:00,718 [EventQueue-ContainerReportForReconContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=b2302968-6590-4efd-b3d4-88f98845679b not found. Cannot add container #7
recon_1     | 2022-05-14 13:21:00,718 [EventQueue-ContainerReportForReconContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=60ee7a26-489d-44d6-b8c5-9e342c88bb63 not found. Cannot add container #8
recon_1     | 2022-05-14 13:21:00,718 [EventQueue-ContainerReportForReconContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=6e6105cc-e733-4e24-b11b-36605179c86d not found. Cannot add container #9
recon_1     | 2022-05-14 13:21:00,718 [EventQueue-ContainerReportForReconContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=eea4bf28-37f5-4124-9157-cb84720170a9 not found. Cannot add container #10
recon_1     | 2022-05-14 13:21:00,718 [EventQueue-ContainerReportForReconContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=85665b57-79bd-4721-8990-6434b89cf0f5 not found. Cannot add container #11
scm_1       | 2022-05-14 13:20:21,218 [IPC Server handler 44 on default port 9863] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 6e6105cc-e733-4e24-b11b-36605179c86d, Nodes: d5e6fff5-66a9-4bee-add9-03aeb4a97c66{ip: 172.18.0.2, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}54b0e747-a2bb-484f-976a-c7c0770cb588{ip: 172.18.0.9, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}00910f34-9556-4f5c-8864-f93205907e3c{ip: 172.18.0.6, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}55441846-8ccc-4390-87fc-ba015dadcaaa{ip: 172.18.0.4, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}f3166980-8467-4e9a-9c6e-144f4303af87{ip: 172.18.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: EC/ECReplicationConfig{data=3, parity=2, ecChunkSize=1048576, codec=rs}, State:ALLOCATED, leaderId:, CreationTimestamp2022-05-14T13:20:21.213Z[UTC]] moved to OPEN state
scm_1       | 2022-05-14 13:20:29,990 [IPC Server handler 43 on default port 9863] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: eea4bf28-37f5-4124-9157-cb84720170a9, Nodes: f3166980-8467-4e9a-9c6e-144f4303af87{ip: 172.18.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}54b0e747-a2bb-484f-976a-c7c0770cb588{ip: 172.18.0.9, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}00910f34-9556-4f5c-8864-f93205907e3c{ip: 172.18.0.6, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}d5e6fff5-66a9-4bee-add9-03aeb4a97c66{ip: 172.18.0.2, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}55441846-8ccc-4390-87fc-ba015dadcaaa{ip: 172.18.0.4, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: EC/ECReplicationConfig{data=3, parity=2, ecChunkSize=1048576, codec=rs}, State:ALLOCATED, leaderId:, CreationTimestamp2022-05-14T13:20:29.989Z[UTC]].
scm_1       | 2022-05-14 13:20:29,992 [IPC Server handler 43 on default port 9863] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: eea4bf28-37f5-4124-9157-cb84720170a9, Nodes: f3166980-8467-4e9a-9c6e-144f4303af87{ip: 172.18.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}54b0e747-a2bb-484f-976a-c7c0770cb588{ip: 172.18.0.9, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}00910f34-9556-4f5c-8864-f93205907e3c{ip: 172.18.0.6, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}d5e6fff5-66a9-4bee-add9-03aeb4a97c66{ip: 172.18.0.2, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}55441846-8ccc-4390-87fc-ba015dadcaaa{ip: 172.18.0.4, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: EC/ECReplicationConfig{data=3, parity=2, ecChunkSize=1048576, codec=rs}, State:ALLOCATED, leaderId:, CreationTimestamp2022-05-14T13:20:29.989Z[UTC]] moved to OPEN state
scm_1       | 2022-05-14 13:20:30,479 [IPC Server handler 61 on default port 9863] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 85665b57-79bd-4721-8990-6434b89cf0f5, Nodes: 55441846-8ccc-4390-87fc-ba015dadcaaa{ip: 172.18.0.4, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}54b0e747-a2bb-484f-976a-c7c0770cb588{ip: 172.18.0.9, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}00910f34-9556-4f5c-8864-f93205907e3c{ip: 172.18.0.6, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}f3166980-8467-4e9a-9c6e-144f4303af87{ip: 172.18.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}d5e6fff5-66a9-4bee-add9-03aeb4a97c66{ip: 172.18.0.2, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: EC/ECReplicationConfig{data=3, parity=2, ecChunkSize=1048576, codec=rs}, State:ALLOCATED, leaderId:, CreationTimestamp2022-05-14T13:20:30.478Z[UTC]].
s3g_1       | 	at org.apache.hadoop.ozone.s3.signature.AuthorizationV4HeaderParser.parseCredentials(AuthorizationV4HeaderParser.java:171)
s3g_1       | 	at org.apache.hadoop.ozone.s3.signature.AuthorizationV4HeaderParser.parseSignature(AuthorizationV4HeaderParser.java:91)
s3g_1       | 	at org.apache.hadoop.ozone.s3.signature.AWSSignatureProcessor.parseSignature(AWSSignatureProcessor.java:70)
s3g_1       | 	at org.apache.hadoop.ozone.s3.signature.AWSSignatureProcessor$Proxy$_$$_WeldClientProxy.parseSignature(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getSignature(OzoneClientProducer.java:80)
s3g_1       | 	... 114 more
s3g_1       | 
s3g_1       | 
s3g_1       | 2022-05-14 13:25:27,864 [qtp2096539129-21] ERROR endpoint.ObjectEndpoint: Exception occurred in PutObject
s3g_1       | 2022-05-14 13:25:55,634 [qtp2096539129-22] ERROR endpoint.ObjectEndpoint: Exception occurred in PutObject
s3g_1       | 2022-05-14 13:25:56,338 [qtp2096539129-20] ERROR endpoint.ObjectEndpoint: Exception occurred in PutObject
s3g_1       | 2022-05-14 13:26:16,402 [qtp2096539129-20] INFO rpc.RpcClient: Creating Bucket: s3v/destbucket-26720, with dlfknslnfslf as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-05-14 13:26:16,406 [qtp2096539129-20] INFO endpoint.BucketEndpoint: Location is /destbucket-26720
s3g_1       | 2022-05-14 13:26:21,339 [qtp2096539129-22] ERROR endpoint.ObjectEndpoint: Exception occurred in PutObject
s3g_1       | 2022-05-14 13:26:22,029 [qtp2096539129-20] ERROR endpoint.ObjectEndpoint: Exception occurred in PutObject
s3g_1       | 2022-05-14 13:26:23,397 [qtp2096539129-20] ERROR endpoint.ObjectEndpoint: Exception occurred in PutObject
s3g_1       | 2022-05-14 13:27:25,098 [qtp2096539129-22] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-1137339587, with dlfknslnfslf as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:19:00,003 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:19:00,004 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:20:00,001 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:20:00,002 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1     | 2022-05-14 13:21:00,719 [EventQueue-ContainerReportForReconContainerReportHandler] ERROR container.ContainerReportHandler: Received container report for an unknown container 7 from datanode f3166980-8467-4e9a-9c6e-144f4303af87{ip: 172.18.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
recon_1     | 2022-05-14 13:21:00,719 [EventQueue-ContainerReportForReconContainerReportHandler] ERROR container.ContainerReportHandler: Received container report for an unknown container 8 from datanode f3166980-8467-4e9a-9c6e-144f4303af87{ip: 172.18.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
recon_1     | 2022-05-14 13:21:00,719 [EventQueue-ContainerReportForReconContainerReportHandler] ERROR container.ContainerReportHandler: Received container report for an unknown container 9 from datanode f3166980-8467-4e9a-9c6e-144f4303af87{ip: 172.18.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
recon_1     | 2022-05-14 13:21:00,719 [EventQueue-ContainerReportForReconContainerReportHandler] ERROR container.ContainerReportHandler: Received container report for an unknown container 10 from datanode f3166980-8467-4e9a-9c6e-144f4303af87{ip: 172.18.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
recon_1     | 2022-05-14 13:21:00,719 [EventQueue-ContainerReportForReconContainerReportHandler] ERROR container.ContainerReportHandler: Received container report for an unknown container 11 from datanode f3166980-8467-4e9a-9c6e-144f4303af87{ip: 172.18.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
recon_1     | 2022-05-14 13:21:09,817 [EventQueue-ContainerReportForReconContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=b2302968-6590-4efd-b3d4-88f98845679b not found. Cannot add container #7
recon_1     | 2022-05-14 13:21:09,817 [EventQueue-ContainerReportForReconContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=60ee7a26-489d-44d6-b8c5-9e342c88bb63 not found. Cannot add container #8
recon_1     | 2022-05-14 13:21:09,817 [EventQueue-ContainerReportForReconContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=6e6105cc-e733-4e24-b11b-36605179c86d not found. Cannot add container #9
recon_1     | 2022-05-14 13:21:09,818 [EventQueue-ContainerReportForReconContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=eea4bf28-37f5-4124-9157-cb84720170a9 not found. Cannot add container #10
recon_1     | 2022-05-14 13:21:09,818 [EventQueue-ContainerReportForReconContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=85665b57-79bd-4721-8990-6434b89cf0f5 not found. Cannot add container #11
recon_1     | 2022-05-14 13:21:09,818 [EventQueue-ContainerReportForReconContainerReportHandler] ERROR container.ContainerReportHandler: Received container report for an unknown container 7 from datanode d5e6fff5-66a9-4bee-add9-03aeb4a97c66{ip: 172.18.0.2, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
recon_1     | 2022-05-14 13:21:09,818 [EventQueue-ContainerReportForReconContainerReportHandler] ERROR container.ContainerReportHandler: Received container report for an unknown container 8 from datanode d5e6fff5-66a9-4bee-add9-03aeb4a97c66{ip: 172.18.0.2, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
recon_1     | 2022-05-14 13:21:09,819 [EventQueue-ContainerReportForReconContainerReportHandler] ERROR container.ContainerReportHandler: Received container report for an unknown container 9 from datanode d5e6fff5-66a9-4bee-add9-03aeb4a97c66{ip: 172.18.0.2, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
recon_1     | 2022-05-14 13:21:09,820 [EventQueue-ContainerReportForReconContainerReportHandler] ERROR container.ContainerReportHandler: Received container report for an unknown container 10 from datanode d5e6fff5-66a9-4bee-add9-03aeb4a97c66{ip: 172.18.0.2, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
recon_1     | 2022-05-14 13:21:09,820 [EventQueue-ContainerReportForReconContainerReportHandler] ERROR container.ContainerReportHandler: Received container report for an unknown container 11 from datanode d5e6fff5-66a9-4bee-add9-03aeb4a97c66{ip: 172.18.0.2, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
recon_1     | 2022-05-14 13:21:27,592 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2022-05-14 13:21:27,593 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2022-05-14 13:21:27,593 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 1055 
recon_1     | 2022-05-14 13:21:27,664 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 69, SequenceNumber diff: 188, SequenceNumber Lag from OM 0.
recon_1     | 2022-05-14 13:21:27,664 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 188 records
recon_1     | 2022-05-14 13:21:27,671 [pool-17-thread-1] INFO tasks.NSSummaryTask: Completed a process run of NSSummaryTask
recon_1     | 2022-05-14 13:21:27,739 [pool-17-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
recon_1     | 2022-05-14 13:21:27,759 [pool-17-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 10 OM DB update event(s).
recon_1     | 2022-05-14 13:21:27,776 [pool-17-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2022-05-14 13:21:29,852 [EventQueue-ContainerReportForReconContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=b2302968-6590-4efd-b3d4-88f98845679b not found. Cannot add container #7
recon_1     | 2022-05-14 13:21:29,853 [EventQueue-ContainerReportForReconContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=60ee7a26-489d-44d6-b8c5-9e342c88bb63 not found. Cannot add container #8
recon_1     | 2022-05-14 13:21:29,853 [EventQueue-ContainerReportForReconContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=6e6105cc-e733-4e24-b11b-36605179c86d not found. Cannot add container #9
recon_1     | 2022-05-14 13:21:29,853 [EventQueue-ContainerReportForReconContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=eea4bf28-37f5-4124-9157-cb84720170a9 not found. Cannot add container #10
scm_1       | 2022-05-14 13:20:30,483 [IPC Server handler 61 on default port 9863] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 85665b57-79bd-4721-8990-6434b89cf0f5, Nodes: 55441846-8ccc-4390-87fc-ba015dadcaaa{ip: 172.18.0.4, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}54b0e747-a2bb-484f-976a-c7c0770cb588{ip: 172.18.0.9, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}00910f34-9556-4f5c-8864-f93205907e3c{ip: 172.18.0.6, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}f3166980-8467-4e9a-9c6e-144f4303af87{ip: 172.18.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}d5e6fff5-66a9-4bee-add9-03aeb4a97c66{ip: 172.18.0.2, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: EC/ECReplicationConfig{data=3, parity=2, ecChunkSize=1048576, codec=rs}, State:ALLOCATED, leaderId:, CreationTimestamp2022-05-14T13:20:30.478Z[UTC]] moved to OPEN state
scm_1       | 2022-05-14 13:24:18,832 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 11 containers.
scm_1       | 2022-05-14 13:29:18,834 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 11 containers.
scm_1       | 2022-05-14 13:32:18,775 [IPC Server handler 69 on default port 9860] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 3e1eead8-02b1-4fcc-a721-2a339903bedb, Nodes: 55441846-8ccc-4390-87fc-ba015dadcaaa{ip: 172.18.0.4, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: STANDALONE/ONE, State:OPEN, leaderId:, CreationTimestamp2022-05-14T13:32:18.774Z[UTC]].
scm_1       | 2022-05-14 13:32:56,174 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #1
scm_1       | 2022-05-14 13:33:00,261 [FixedThreadPoolWithAffinityExecutor-0-0] INFO container.IncrementalContainerReportHandler: Moving container #1 to CLOSED state, datanode 00910f34-9556-4f5c-8864-f93205907e3c{ip: 172.18.0.6, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} reported CLOSED replica.
scm_1       | 2022-05-14 13:33:22,341 [SCMBlockDeletingService#0] INFO block.SCMBlockDeletingService: Totally added 366 blocks to be deleted for 3 datanodes, task elapsed time: 2ms
scm_1       | 2022-05-14 13:33:47,789 [IPC Server handler 69 on default port 9860] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 9c3004e6-d8aa-4a5a-9e90-d38b38ce6139, Nodes: 00910f34-9556-4f5c-8864-f93205907e3c{ip: 172.18.0.6, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: STANDALONE/ONE, State:OPEN, leaderId:, CreationTimestamp2022-05-14T13:33:47.788Z[UTC]].
scm_1       | 2022-05-14 13:34:15,133 [IPC Server handler 67 on default port 9860] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 9c3004e6-d8aa-4a5a-9e90-d38b38ce6139, Nodes: 00910f34-9556-4f5c-8864-f93205907e3c{ip: 172.18.0.6, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: STANDALONE/ONE, State:OPEN, leaderId:, CreationTimestamp2022-05-14T13:33:47.788Z[UTC]] moved to CLOSED state
scm_1       | 2022-05-14 13:34:18,605 [PipelineScrubberThread] INFO pipeline.PipelineManagerImpl: Scrubbing pipeline: id: PipelineID=9c3004e6-d8aa-4a5a-9e90-d38b38ce6139 since it stays at CLOSED stage.
scm_1       | 2022-05-14 13:34:18,606 [PipelineScrubberThread] INFO pipeline.PipelineStateManagerImpl: Pipeline Pipeline[ Id: 9c3004e6-d8aa-4a5a-9e90-d38b38ce6139, Nodes: 00910f34-9556-4f5c-8864-f93205907e3c{ip: 172.18.0.6, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: STANDALONE/ONE, State:CLOSED, leaderId:, CreationTimestamp2022-05-14T13:33:47.788Z[UTC]] removed.
scm_1       | 2022-05-14 13:34:18,849 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 14 milliseconds for processing 12 containers.
scm_1       | 2022-05-14 13:34:33,378 [IPC Server handler 65 on default port 9860] INFO replication.ReplicationManager: Stopping Replication Monitor Thread.
scm_1       | 2022-05-14 13:34:33,384 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread is stopped
scm_1       | 2022-05-14 13:34:41,016 [IPC Server handler 48 on default port 9860] INFO replication.ReplicationManager: Starting Replication Monitor Thread.
scm_1       | 2022-05-14 13:34:41,025 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 12 containers.
s3g_1       | 2022-05-14 13:27:25,103 [qtp2096539129-22] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-1137339587
s3g_1       | 2022-05-14 13:27:28,743 [qtp2096539129-20] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-0490355251, with dlfknslnfslf as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-05-14 13:27:28,750 [qtp2096539129-20] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-0490355251
s3g_1       | 2022-05-14 13:27:37,252 [qtp2096539129-20] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-6708269095, with dlfknslnfslf as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-05-14 13:27:37,255 [qtp2096539129-20] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-6708269095
s3g_1       | 2022-05-14 13:27:37,816 [qtp2096539129-22] INFO rpc.RpcClient: Creating Bucket: s3v/ozone-test-glvxbjswpp, with dlfknslnfslf as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-05-14 13:27:37,820 [qtp2096539129-22] INFO endpoint.BucketEndpoint: Location is /ozone-test-glvxbjswpp
s3g_1       | 2022-05-14 13:27:39,488 [qtp2096539129-17] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-axqfazusng, with dlfknslnfslf as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-05-14 13:27:39,497 [qtp2096539129-17] INFO endpoint.BucketEndpoint: Location is /bucket-axqfazusng
s3g_1       | 2022-05-14 13:27:47,121 [qtp2096539129-24] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-2365003728, with dlfknslnfslf as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-05-14 13:27:47,126 [qtp2096539129-24] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-2365003728
s3g_1       | 2022-05-14 13:27:47,822 [qtp2096539129-23] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-8969484327, with dlfknslnfslf as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-05-14 13:27:47,825 [qtp2096539129-23] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-8969484327
s3g_1       | 2022-05-14 13:27:52,185 [qtp2096539129-23] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-8155355461, with dlfknslnfslf as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-05-14 13:27:52,188 [qtp2096539129-23] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-8155355461
s3g_1       | 2022-05-14 13:27:56,495 [qtp2096539129-24] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-3998480116, with dlfknslnfslf as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-05-14 13:27:56,499 [qtp2096539129-24] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-3998480116
s3g_1       | 2022-05-14 13:27:58,411 [qtp2096539129-24] ERROR signature.AuthorizationV4HeaderParser: AWS access id shouldn't be empty. credential:/20220514/us-west-1/s3/aws4_request
s3g_1       | May 14, 2022 1:27:58 PM org.glassfish.jersey.internal.Errors logErrors
s3g_1       | WARNING: The following warnings have been detected: WARNING: Unknown HK2 failure detected:
s3g_1       | MultiException stack 1 of 1
s3g_1       | javax.ws.rs.WebApplicationException: The authorization header you provided is invalid.
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.wrapOS3Exception(OzoneClientProducer.java:138)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getSignature(OzoneClientProducer.java:99)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor20.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:874)
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:127)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:69)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:103)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:46)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:53)
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:129)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:463)
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:46)
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2102)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:758)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:721)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:691)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:160)
om_1        | 2022-05-14 13:20:00,002 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
recon_1     | 2022-05-14 13:21:29,853 [EventQueue-ContainerReportForReconContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=85665b57-79bd-4721-8990-6434b89cf0f5 not found. Cannot add container #11
recon_1     | 2022-05-14 13:21:29,854 [EventQueue-ContainerReportForReconContainerReportHandler] ERROR container.ContainerReportHandler: Received container report for an unknown container 7 from datanode 54b0e747-a2bb-484f-976a-c7c0770cb588{ip: 172.18.0.9, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
recon_1     | 2022-05-14 13:21:29,854 [EventQueue-ContainerReportForReconContainerReportHandler] ERROR container.ContainerReportHandler: Received container report for an unknown container 8 from datanode 54b0e747-a2bb-484f-976a-c7c0770cb588{ip: 172.18.0.9, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
recon_1     | 2022-05-14 13:21:29,854 [EventQueue-ContainerReportForReconContainerReportHandler] ERROR container.ContainerReportHandler: Received container report for an unknown container 9 from datanode 54b0e747-a2bb-484f-976a-c7c0770cb588{ip: 172.18.0.9, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
recon_1     | 2022-05-14 13:21:29,854 [EventQueue-ContainerReportForReconContainerReportHandler] ERROR container.ContainerReportHandler: Received container report for an unknown container 10 from datanode 54b0e747-a2bb-484f-976a-c7c0770cb588{ip: 172.18.0.9, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
recon_1     | 2022-05-14 13:21:29,854 [EventQueue-ContainerReportForReconContainerReportHandler] ERROR container.ContainerReportHandler: Received container report for an unknown container 11 from datanode 54b0e747-a2bb-484f-976a-c7c0770cb588{ip: 172.18.0.9, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
recon_1     | 2022-05-14 13:21:31,911 [EventQueue-ContainerReportForReconContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=b2302968-6590-4efd-b3d4-88f98845679b not found. Cannot add container #7
recon_1     | 2022-05-14 13:21:31,912 [EventQueue-ContainerReportForReconContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=60ee7a26-489d-44d6-b8c5-9e342c88bb63 not found. Cannot add container #8
recon_1     | 2022-05-14 13:21:31,913 [EventQueue-ContainerReportForReconContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=6e6105cc-e733-4e24-b11b-36605179c86d not found. Cannot add container #9
recon_1     | 2022-05-14 13:21:31,913 [EventQueue-ContainerReportForReconContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=eea4bf28-37f5-4124-9157-cb84720170a9 not found. Cannot add container #10
recon_1     | 2022-05-14 13:21:31,914 [EventQueue-ContainerReportForReconContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=85665b57-79bd-4721-8990-6434b89cf0f5 not found. Cannot add container #11
recon_1     | 2022-05-14 13:21:31,914 [EventQueue-ContainerReportForReconContainerReportHandler] ERROR container.ContainerReportHandler: Received container report for an unknown container 7 from datanode 55441846-8ccc-4390-87fc-ba015dadcaaa{ip: 172.18.0.4, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
recon_1     | 2022-05-14 13:21:31,915 [EventQueue-ContainerReportForReconContainerReportHandler] ERROR container.ContainerReportHandler: Received container report for an unknown container 8 from datanode 55441846-8ccc-4390-87fc-ba015dadcaaa{ip: 172.18.0.4, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
recon_1     | 2022-05-14 13:21:31,915 [EventQueue-ContainerReportForReconContainerReportHandler] ERROR container.ContainerReportHandler: Received container report for an unknown container 9 from datanode 55441846-8ccc-4390-87fc-ba015dadcaaa{ip: 172.18.0.4, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
recon_1     | 2022-05-14 13:21:31,915 [EventQueue-ContainerReportForReconContainerReportHandler] ERROR container.ContainerReportHandler: Received container report for an unknown container 10 from datanode 55441846-8ccc-4390-87fc-ba015dadcaaa{ip: 172.18.0.4, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
recon_1     | 2022-05-14 13:21:31,916 [EventQueue-ContainerReportForReconContainerReportHandler] ERROR container.ContainerReportHandler: Received container report for an unknown container 11 from datanode 55441846-8ccc-4390-87fc-ba015dadcaaa{ip: 172.18.0.4, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
recon_1     | 2022-05-14 13:22:19,159 [EventQueue-ContainerReportForReconContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=b2302968-6590-4efd-b3d4-88f98845679b not found. Cannot add container #7
recon_1     | 2022-05-14 13:22:19,160 [EventQueue-ContainerReportForReconContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=60ee7a26-489d-44d6-b8c5-9e342c88bb63 not found. Cannot add container #8
recon_1     | 2022-05-14 13:22:19,161 [EventQueue-ContainerReportForReconContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=6e6105cc-e733-4e24-b11b-36605179c86d not found. Cannot add container #9
recon_1     | 2022-05-14 13:22:19,161 [EventQueue-ContainerReportForReconContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=eea4bf28-37f5-4124-9157-cb84720170a9 not found. Cannot add container #10
recon_1     | 2022-05-14 13:22:19,161 [EventQueue-ContainerReportForReconContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=85665b57-79bd-4721-8990-6434b89cf0f5 not found. Cannot add container #11
recon_1     | 2022-05-14 13:22:19,161 [EventQueue-ContainerReportForReconContainerReportHandler] ERROR container.ContainerReportHandler: Received container report for an unknown container 7 from datanode 00910f34-9556-4f5c-8864-f93205907e3c{ip: 172.18.0.6, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
recon_1     | 2022-05-14 13:22:19,162 [EventQueue-ContainerReportForReconContainerReportHandler] ERROR container.ContainerReportHandler: Received container report for an unknown container 8 from datanode 00910f34-9556-4f5c-8864-f93205907e3c{ip: 172.18.0.6, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
recon_1     | 2022-05-14 13:22:19,162 [EventQueue-ContainerReportForReconContainerReportHandler] ERROR container.ContainerReportHandler: Received container report for an unknown container 9 from datanode 00910f34-9556-4f5c-8864-f93205907e3c{ip: 172.18.0.6, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
recon_1     | 2022-05-14 13:22:19,162 [EventQueue-ContainerReportForReconContainerReportHandler] ERROR container.ContainerReportHandler: Received container report for an unknown container 10 from datanode 00910f34-9556-4f5c-8864-f93205907e3c{ip: 172.18.0.6, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
recon_1     | 2022-05-14 13:22:19,162 [EventQueue-ContainerReportForReconContainerReportHandler] ERROR container.ContainerReportHandler: Received container report for an unknown container 11 from datanode 00910f34-9556-4f5c-8864-f93205907e3c{ip: 172.18.0.6, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
recon_1     | 2022-05-14 13:22:20,721 [EventQueue-ContainerReportForReconContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=b2302968-6590-4efd-b3d4-88f98845679b not found. Cannot add container #7
recon_1     | 2022-05-14 13:22:20,722 [EventQueue-ContainerReportForReconContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=60ee7a26-489d-44d6-b8c5-9e342c88bb63 not found. Cannot add container #8
recon_1     | 2022-05-14 13:22:20,723 [EventQueue-ContainerReportForReconContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=6e6105cc-e733-4e24-b11b-36605179c86d not found. Cannot add container #9
recon_1     | 2022-05-14 13:22:20,723 [EventQueue-ContainerReportForReconContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=eea4bf28-37f5-4124-9157-cb84720170a9 not found. Cannot add container #10
recon_1     | 2022-05-14 13:22:20,723 [EventQueue-ContainerReportForReconContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=85665b57-79bd-4721-8990-6434b89cf0f5 not found. Cannot add container #11
recon_1     | 2022-05-14 13:22:20,724 [EventQueue-ContainerReportForReconContainerReportHandler] ERROR container.ContainerReportHandler: Received container report for an unknown container 7 from datanode f3166980-8467-4e9a-9c6e-144f4303af87{ip: 172.18.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
recon_1     | 2022-05-14 13:22:20,725 [EventQueue-ContainerReportForReconContainerReportHandler] ERROR container.ContainerReportHandler: Received container report for an unknown container 8 from datanode f3166980-8467-4e9a-9c6e-144f4303af87{ip: 172.18.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
recon_1     | 2022-05-14 13:22:20,725 [EventQueue-ContainerReportForReconContainerReportHandler] ERROR container.ContainerReportHandler: Received container report for an unknown container 9 from datanode f3166980-8467-4e9a-9c6e-144f4303af87{ip: 172.18.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
recon_1     | 2022-05-14 13:22:20,726 [EventQueue-ContainerReportForReconContainerReportHandler] ERROR container.ContainerReportHandler: Received container report for an unknown container 10 from datanode f3166980-8467-4e9a-9c6e-144f4303af87{ip: 172.18.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
recon_1     | 2022-05-14 13:22:20,726 [EventQueue-ContainerReportForReconContainerReportHandler] ERROR container.ContainerReportHandler: Received container report for an unknown container 11 from datanode f3166980-8467-4e9a-9c6e-144f4303af87{ip: 172.18.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
recon_1     | 2022-05-14 13:22:27,788 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2022-05-14 13:22:27,789 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2022-05-14 13:22:27,789 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 1243 
recon_1     | 2022-05-14 13:22:27,879 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 116, SequenceNumber diff: 309, SequenceNumber Lag from OM 0.
recon_1     | 2022-05-14 13:22:27,879 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 309 records
recon_1     | 2022-05-14 13:22:27,887 [pool-17-thread-1] INFO tasks.NSSummaryTask: Completed a process run of NSSummaryTask
recon_1     | 2022-05-14 13:22:27,998 [pool-17-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
recon_1     | 2022-05-14 13:22:28,003 [pool-17-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 10 OM DB update event(s).
recon_1     | 2022-05-14 13:22:28,018 [pool-17-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2022-05-14 13:22:56,911 [EventQueue-ContainerReportForReconContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=b2302968-6590-4efd-b3d4-88f98845679b not found. Cannot add container #7
recon_1     | 2022-05-14 13:22:56,912 [EventQueue-ContainerReportForReconContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=60ee7a26-489d-44d6-b8c5-9e342c88bb63 not found. Cannot add container #8
recon_1     | 2022-05-14 13:22:56,914 [EventQueue-ContainerReportForReconContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=6e6105cc-e733-4e24-b11b-36605179c86d not found. Cannot add container #9
recon_1     | 2022-05-14 13:22:56,914 [EventQueue-ContainerReportForReconContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=eea4bf28-37f5-4124-9157-cb84720170a9 not found. Cannot add container #10
recon_1     | 2022-05-14 13:22:56,914 [EventQueue-ContainerReportForReconContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=85665b57-79bd-4721-8990-6434b89cf0f5 not found. Cannot add container #11
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:30)
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:105)
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:260)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:51)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:86)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:89)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:89)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:89)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:69)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:38)
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:173)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:247)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1679)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
recon_1     | 2022-05-14 13:22:56,914 [EventQueue-ContainerReportForReconContainerReportHandler] ERROR container.ContainerReportHandler: Received container report for an unknown container 7 from datanode 55441846-8ccc-4390-87fc-ba015dadcaaa{ip: 172.18.0.4, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
recon_1     | 2022-05-14 13:22:56,915 [EventQueue-ContainerReportForReconContainerReportHandler] ERROR container.ContainerReportHandler: Received container report for an unknown container 8 from datanode 55441846-8ccc-4390-87fc-ba015dadcaaa{ip: 172.18.0.4, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
recon_1     | 2022-05-14 13:22:56,915 [EventQueue-ContainerReportForReconContainerReportHandler] ERROR container.ContainerReportHandler: Received container report for an unknown container 9 from datanode 55441846-8ccc-4390-87fc-ba015dadcaaa{ip: 172.18.0.4, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
recon_1     | 2022-05-14 13:22:56,916 [EventQueue-ContainerReportForReconContainerReportHandler] ERROR container.ContainerReportHandler: Received container report for an unknown container 10 from datanode 55441846-8ccc-4390-87fc-ba015dadcaaa{ip: 172.18.0.4, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
recon_1     | 2022-05-14 13:22:56,916 [EventQueue-ContainerReportForReconContainerReportHandler] ERROR container.ContainerReportHandler: Received container report for an unknown container 11 from datanode 55441846-8ccc-4390-87fc-ba015dadcaaa{ip: 172.18.0.4, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
recon_1     | 2022-05-14 13:22:59,823 [EventQueue-ContainerReportForReconContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=b2302968-6590-4efd-b3d4-88f98845679b not found. Cannot add container #7
recon_1     | 2022-05-14 13:22:59,823 [EventQueue-ContainerReportForReconContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=60ee7a26-489d-44d6-b8c5-9e342c88bb63 not found. Cannot add container #8
recon_1     | 2022-05-14 13:22:59,823 [EventQueue-ContainerReportForReconContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=6e6105cc-e733-4e24-b11b-36605179c86d not found. Cannot add container #9
recon_1     | 2022-05-14 13:22:59,823 [EventQueue-ContainerReportForReconContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=eea4bf28-37f5-4124-9157-cb84720170a9 not found. Cannot add container #10
recon_1     | 2022-05-14 13:22:59,823 [EventQueue-ContainerReportForReconContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=85665b57-79bd-4721-8990-6434b89cf0f5 not found. Cannot add container #11
recon_1     | 2022-05-14 13:22:59,824 [EventQueue-ContainerReportForReconContainerReportHandler] ERROR container.ContainerReportHandler: Received container report for an unknown container 7 from datanode d5e6fff5-66a9-4bee-add9-03aeb4a97c66{ip: 172.18.0.2, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
recon_1     | 2022-05-14 13:22:59,824 [EventQueue-ContainerReportForReconContainerReportHandler] ERROR container.ContainerReportHandler: Received container report for an unknown container 8 from datanode d5e6fff5-66a9-4bee-add9-03aeb4a97c66{ip: 172.18.0.2, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
recon_1     | 2022-05-14 13:22:59,824 [EventQueue-ContainerReportForReconContainerReportHandler] ERROR container.ContainerReportHandler: Received container report for an unknown container 9 from datanode d5e6fff5-66a9-4bee-add9-03aeb4a97c66{ip: 172.18.0.2, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
recon_1     | 2022-05-14 13:22:59,824 [EventQueue-ContainerReportForReconContainerReportHandler] ERROR container.ContainerReportHandler: Received container report for an unknown container 10 from datanode d5e6fff5-66a9-4bee-add9-03aeb4a97c66{ip: 172.18.0.2, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
recon_1     | 2022-05-14 13:22:59,824 [EventQueue-ContainerReportForReconContainerReportHandler] ERROR container.ContainerReportHandler: Received container report for an unknown container 11 from datanode d5e6fff5-66a9-4bee-add9-03aeb4a97c66{ip: 172.18.0.2, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
recon_1     | 2022-05-14 13:23:09,863 [EventQueue-ContainerReportForReconContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=b2302968-6590-4efd-b3d4-88f98845679b not found. Cannot add container #7
recon_1     | 2022-05-14 13:23:09,863 [EventQueue-ContainerReportForReconContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=60ee7a26-489d-44d6-b8c5-9e342c88bb63 not found. Cannot add container #8
recon_1     | 2022-05-14 13:23:09,864 [EventQueue-ContainerReportForReconContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=6e6105cc-e733-4e24-b11b-36605179c86d not found. Cannot add container #9
recon_1     | 2022-05-14 13:23:09,864 [EventQueue-ContainerReportForReconContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=eea4bf28-37f5-4124-9157-cb84720170a9 not found. Cannot add container #10
recon_1     | 2022-05-14 13:23:09,864 [EventQueue-ContainerReportForReconContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=85665b57-79bd-4721-8990-6434b89cf0f5 not found. Cannot add container #11
recon_1     | 2022-05-14 13:23:09,865 [EventQueue-ContainerReportForReconContainerReportHandler] ERROR container.ContainerReportHandler: Received container report for an unknown container 7 from datanode 54b0e747-a2bb-484f-976a-c7c0770cb588{ip: 172.18.0.9, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
recon_1     | 2022-05-14 13:23:09,865 [EventQueue-ContainerReportForReconContainerReportHandler] ERROR container.ContainerReportHandler: Received container report for an unknown container 8 from datanode 54b0e747-a2bb-484f-976a-c7c0770cb588{ip: 172.18.0.9, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:20:05,883 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: erasure of layout LEGACY in volume: s3v
om_1        | 2022-05-14 13:20:29,958 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ozone-test-ccygokppjg of layout LEGACY in volume: s3v
om_1        | 2022-05-14 13:20:33,217 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-pbfxtsgvfe of layout LEGACY in volume: s3v
om_1        | 2022-05-14 13:20:44,157 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-5523706137 of layout LEGACY in volume: s3v
om_1        | 2022-05-14 13:20:44,862 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-5201943209 of layout LEGACY in volume: s3v
om_1        | 2022-05-14 13:20:45,558 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket-ozone-test-5201943209 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:204)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:254)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:524)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:319)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:20:54,284 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-3330795596 of layout LEGACY in volume: s3v
om_1        | 2022-05-14 13:20:55,635 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketDeleteRequest: Delete bucket failed for bucket:nosuchbucket-ozone-test-7658787108 in volume:s3v
om_1        | BUCKET_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Bucket not exists
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketDeleteRequest.validateAndUpdateCache(OMBucketDeleteRequest.java:123)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:254)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:524)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:319)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:21:00,001 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:21:00,002 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:21:00,003 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1       | Caused by: org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1       | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.newError(S3ErrorTable.java:139)
s3g_1       | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.newError(S3ErrorTable.java:126)
s3g_1       | 	at org.apache.hadoop.ozone.s3.signature.AuthorizationV4HeaderParser.parseCredentials(AuthorizationV4HeaderParser.java:171)
s3g_1       | 	at org.apache.hadoop.ozone.s3.signature.AuthorizationV4HeaderParser.parseSignature(AuthorizationV4HeaderParser.java:91)
s3g_1       | 	at org.apache.hadoop.ozone.s3.signature.AWSSignatureProcessor.parseSignature(AWSSignatureProcessor.java:70)
s3g_1       | 	at org.apache.hadoop.ozone.s3.signature.AWSSignatureProcessor$Proxy$_$$_WeldClientProxy.parseSignature(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getSignature(OzoneClientProducer.java:80)
s3g_1       | 	... 114 more
s3g_1       | 
s3g_1       | 
s3g_1       | 2022-05-14 13:28:02,087 [qtp2096539129-23] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-6658897623, with dlfknslnfslf as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
recon_1     | 2022-05-14 13:23:09,865 [EventQueue-ContainerReportForReconContainerReportHandler] ERROR container.ContainerReportHandler: Received container report for an unknown container 9 from datanode 54b0e747-a2bb-484f-976a-c7c0770cb588{ip: 172.18.0.9, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
recon_1     | 2022-05-14 13:23:09,865 [EventQueue-ContainerReportForReconContainerReportHandler] ERROR container.ContainerReportHandler: Received container report for an unknown container 10 from datanode 54b0e747-a2bb-484f-976a-c7c0770cb588{ip: 172.18.0.9, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
recon_1     | 2022-05-14 13:23:09,865 [EventQueue-ContainerReportForReconContainerReportHandler] ERROR container.ContainerReportHandler: Received container report for an unknown container 11 from datanode 54b0e747-a2bb-484f-976a-c7c0770cb588{ip: 172.18.0.9, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
recon_1     | 2022-05-14 13:23:28,026 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2022-05-14 13:23:28,026 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2022-05-14 13:23:28,027 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 1552 
recon_1     | 2022-05-14 13:23:28,043 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 30, SequenceNumber diff: 99, SequenceNumber Lag from OM 0.
recon_1     | 2022-05-14 13:23:28,043 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 99 records
recon_1     | 2022-05-14 13:23:28,045 [pool-17-thread-1] INFO tasks.NSSummaryTask: Completed a process run of NSSummaryTask
recon_1     | 2022-05-14 13:23:28,111 [pool-17-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
recon_1     | 2022-05-14 13:23:28,119 [pool-17-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 16 OM DB update event(s).
recon_1     | 2022-05-14 13:23:28,131 [pool-17-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2022-05-14 13:24:04,164 [EventQueue-ContainerReportForReconContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=b2302968-6590-4efd-b3d4-88f98845679b not found. Cannot add container #7
recon_1     | 2022-05-14 13:24:04,164 [EventQueue-ContainerReportForReconContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=60ee7a26-489d-44d6-b8c5-9e342c88bb63 not found. Cannot add container #8
recon_1     | 2022-05-14 13:24:04,164 [EventQueue-ContainerReportForReconContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=6e6105cc-e733-4e24-b11b-36605179c86d not found. Cannot add container #9
recon_1     | 2022-05-14 13:24:04,164 [EventQueue-ContainerReportForReconContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=eea4bf28-37f5-4124-9157-cb84720170a9 not found. Cannot add container #10
recon_1     | 2022-05-14 13:24:04,164 [EventQueue-ContainerReportForReconContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=85665b57-79bd-4721-8990-6434b89cf0f5 not found. Cannot add container #11
recon_1     | 2022-05-14 13:24:04,164 [EventQueue-ContainerReportForReconContainerReportHandler] ERROR container.ContainerReportHandler: Received container report for an unknown container 7 from datanode 00910f34-9556-4f5c-8864-f93205907e3c{ip: 172.18.0.6, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
recon_1     | 2022-05-14 13:24:04,164 [EventQueue-ContainerReportForReconContainerReportHandler] ERROR container.ContainerReportHandler: Received container report for an unknown container 8 from datanode 00910f34-9556-4f5c-8864-f93205907e3c{ip: 172.18.0.6, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
recon_1     | 2022-05-14 13:24:04,164 [EventQueue-ContainerReportForReconContainerReportHandler] ERROR container.ContainerReportHandler: Received container report for an unknown container 9 from datanode 00910f34-9556-4f5c-8864-f93205907e3c{ip: 172.18.0.6, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
recon_1     | 2022-05-14 13:24:04,164 [EventQueue-ContainerReportForReconContainerReportHandler] ERROR container.ContainerReportHandler: Received container report for an unknown container 10 from datanode 00910f34-9556-4f5c-8864-f93205907e3c{ip: 172.18.0.6, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
recon_1     | 2022-05-14 13:24:04,165 [EventQueue-ContainerReportForReconContainerReportHandler] ERROR container.ContainerReportHandler: Received container report for an unknown container 11 from datanode 00910f34-9556-4f5c-8864-f93205907e3c{ip: 172.18.0.6, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
recon_1     | 2022-05-14 13:24:05,726 [EventQueue-ContainerReportForReconContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=b2302968-6590-4efd-b3d4-88f98845679b not found. Cannot add container #7
recon_1     | 2022-05-14 13:24:05,727 [EventQueue-ContainerReportForReconContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=60ee7a26-489d-44d6-b8c5-9e342c88bb63 not found. Cannot add container #8
recon_1     | 2022-05-14 13:24:05,728 [EventQueue-ContainerReportForReconContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=6e6105cc-e733-4e24-b11b-36605179c86d not found. Cannot add container #9
recon_1     | 2022-05-14 13:24:05,729 [EventQueue-ContainerReportForReconContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=eea4bf28-37f5-4124-9157-cb84720170a9 not found. Cannot add container #10
recon_1     | 2022-05-14 13:24:05,729 [EventQueue-ContainerReportForReconContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=85665b57-79bd-4721-8990-6434b89cf0f5 not found. Cannot add container #11
recon_1     | 2022-05-14 13:24:05,729 [EventQueue-ContainerReportForReconContainerReportHandler] ERROR container.ContainerReportHandler: Received container report for an unknown container 7 from datanode f3166980-8467-4e9a-9c6e-144f4303af87{ip: 172.18.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:21:36,021 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload: /s3v/erasure/ozone-test-1552435714/multipartKey2 Part number: 1 size 6  is less than minimum part size 5242880
om_1        | 2022-05-14 13:21:36,022 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-1552435714/multipartKey2 in Volume/Bucket s3v/erasure
om_1        | ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: erasure key: ozone-test-1552435714/multipartKey2. Entity too small.
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:515)
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:197)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:254)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:524)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:319)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:21:37,506 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/erasure/ozone-test-0487796895/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 1
om_1        | partName: "etag1"
om_1        | , partNumber: 2
om_1        | partName: "etag2"
om_1        | ]
om_1        | 2022-05-14 13:21:37,507 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-0487796895/multipartKey3 in Volume/Bucket s3v/erasure
om_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: erasure key: ozone-test-0487796895/multipartKey3
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:186)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:254)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:524)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:319)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:21:38,227 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/erasure/ozone-test-0487796895/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 2
om_1        | partName: "etag1"
om_1        | , partNumber: 1
om_1        | partName: "etag2"
om_1        | ]
om_1        | 2022-05-14 13:21:38,228 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-0487796895/multipartKey3 in Volume/Bucket s3v/erasure
om_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: erasure key: ozone-test-0487796895/multipartKey3
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:186)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:254)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:524)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:319)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:21:41,964 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-0487796895/multipartKey3 in Volume/Bucket s3v/erasure
om_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: erasure key: ozone-test-0487796895/multipartKey3. Provided Part info is { etag1, 1}, whereas OM has partName /s3v/erasure/ozone-test-0487796895/multipartKey3-16183e32-a164-43b0-b95d-f822b72640e3-108300500777173142-1
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:497)
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:197)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:254)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:524)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:319)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1     | 2022-05-14 13:24:05,730 [EventQueue-ContainerReportForReconContainerReportHandler] ERROR container.ContainerReportHandler: Received container report for an unknown container 8 from datanode f3166980-8467-4e9a-9c6e-144f4303af87{ip: 172.18.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
recon_1     | 2022-05-14 13:24:05,730 [EventQueue-ContainerReportForReconContainerReportHandler] ERROR container.ContainerReportHandler: Received container report for an unknown container 9 from datanode f3166980-8467-4e9a-9c6e-144f4303af87{ip: 172.18.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
recon_1     | 2022-05-14 13:24:05,730 [EventQueue-ContainerReportForReconContainerReportHandler] ERROR container.ContainerReportHandler: Received container report for an unknown container 10 from datanode f3166980-8467-4e9a-9c6e-144f4303af87{ip: 172.18.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
recon_1     | 2022-05-14 13:24:05,731 [EventQueue-ContainerReportForReconContainerReportHandler] ERROR container.ContainerReportHandler: Received container report for an unknown container 11 from datanode f3166980-8467-4e9a-9c6e-144f4303af87{ip: 172.18.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
recon_1     | 2022-05-14 13:24:11,904 [EventQueue-ContainerReportForReconContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=b2302968-6590-4efd-b3d4-88f98845679b not found. Cannot add container #7
recon_1     | 2022-05-14 13:24:11,905 [EventQueue-ContainerReportForReconContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=60ee7a26-489d-44d6-b8c5-9e342c88bb63 not found. Cannot add container #8
recon_1     | 2022-05-14 13:24:11,905 [EventQueue-ContainerReportForReconContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=6e6105cc-e733-4e24-b11b-36605179c86d not found. Cannot add container #9
recon_1     | 2022-05-14 13:24:11,905 [EventQueue-ContainerReportForReconContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=eea4bf28-37f5-4124-9157-cb84720170a9 not found. Cannot add container #10
recon_1     | 2022-05-14 13:24:11,905 [EventQueue-ContainerReportForReconContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=85665b57-79bd-4721-8990-6434b89cf0f5 not found. Cannot add container #11
recon_1     | 2022-05-14 13:24:11,906 [EventQueue-ContainerReportForReconContainerReportHandler] ERROR container.ContainerReportHandler: Received container report for an unknown container 7 from datanode 55441846-8ccc-4390-87fc-ba015dadcaaa{ip: 172.18.0.4, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
recon_1     | 2022-05-14 13:24:11,906 [EventQueue-ContainerReportForReconContainerReportHandler] ERROR container.ContainerReportHandler: Received container report for an unknown container 8 from datanode 55441846-8ccc-4390-87fc-ba015dadcaaa{ip: 172.18.0.4, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
recon_1     | 2022-05-14 13:24:11,913 [EventQueue-ContainerReportForReconContainerReportHandler] ERROR container.ContainerReportHandler: Received container report for an unknown container 9 from datanode 55441846-8ccc-4390-87fc-ba015dadcaaa{ip: 172.18.0.4, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
recon_1     | 2022-05-14 13:24:11,913 [EventQueue-ContainerReportForReconContainerReportHandler] ERROR container.ContainerReportHandler: Received container report for an unknown container 10 from datanode 55441846-8ccc-4390-87fc-ba015dadcaaa{ip: 172.18.0.4, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
recon_1     | 2022-05-14 13:24:11,913 [EventQueue-ContainerReportForReconContainerReportHandler] ERROR container.ContainerReportHandler: Received container report for an unknown container 11 from datanode 55441846-8ccc-4390-87fc-ba015dadcaaa{ip: 172.18.0.4, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
recon_1     | 2022-05-14 13:24:19,854 [EventQueue-ContainerReportForReconContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=b2302968-6590-4efd-b3d4-88f98845679b not found. Cannot add container #7
recon_1     | 2022-05-14 13:24:19,854 [EventQueue-ContainerReportForReconContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=60ee7a26-489d-44d6-b8c5-9e342c88bb63 not found. Cannot add container #8
recon_1     | 2022-05-14 13:24:19,855 [EventQueue-ContainerReportForReconContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=6e6105cc-e733-4e24-b11b-36605179c86d not found. Cannot add container #9
recon_1     | 2022-05-14 13:24:19,855 [EventQueue-ContainerReportForReconContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=eea4bf28-37f5-4124-9157-cb84720170a9 not found. Cannot add container #10
recon_1     | 2022-05-14 13:24:19,855 [EventQueue-ContainerReportForReconContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=85665b57-79bd-4721-8990-6434b89cf0f5 not found. Cannot add container #11
recon_1     | 2022-05-14 13:24:19,855 [EventQueue-ContainerReportForReconContainerReportHandler] ERROR container.ContainerReportHandler: Received container report for an unknown container 7 from datanode 54b0e747-a2bb-484f-976a-c7c0770cb588{ip: 172.18.0.9, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
recon_1     | 2022-05-14 13:24:19,856 [EventQueue-ContainerReportForReconContainerReportHandler] ERROR container.ContainerReportHandler: Received container report for an unknown container 8 from datanode 54b0e747-a2bb-484f-976a-c7c0770cb588{ip: 172.18.0.9, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
recon_1     | 2022-05-14 13:24:19,856 [EventQueue-ContainerReportForReconContainerReportHandler] ERROR container.ContainerReportHandler: Received container report for an unknown container 9 from datanode 54b0e747-a2bb-484f-976a-c7c0770cb588{ip: 172.18.0.9, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
s3g_1       | 2022-05-14 13:28:02,092 [qtp2096539129-23] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-6658897623
s3g_1       | 2022-05-14 13:28:29,328 [qtp2096539129-24] ERROR endpoint.ObjectEndpoint: Exception occurred in PutObject
s3g_1       | 2022-05-14 13:28:55,626 [qtp2096539129-19] ERROR endpoint.ObjectEndpoint: Exception occurred in PutObject
s3g_1       | 2022-05-14 13:28:56,367 [qtp2096539129-23] ERROR endpoint.ObjectEndpoint: Exception occurred in PutObject
s3g_1       | 2022-05-14 13:29:12,638 [qtp2096539129-19] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-4051989561, with dlfknslnfslf as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-05-14 13:29:12,642 [qtp2096539129-19] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-4051989561
s3g_1       | 2022-05-14 13:29:13,325 [qtp2096539129-23] INFO rpc.RpcClient: Creating Bucket: s3v/destbucket-74018, with dlfknslnfslf as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-05-14 13:29:13,328 [qtp2096539129-23] INFO endpoint.BucketEndpoint: Location is /destbucket-74018
s3g_1       | 2022-05-14 13:29:18,366 [qtp2096539129-19] ERROR endpoint.ObjectEndpoint: Exception occurred in PutObject
s3g_1       | 2022-05-14 13:29:19,071 [qtp2096539129-23] ERROR endpoint.ObjectEndpoint: Exception occurred in PutObject
s3g_1       | 2022-05-14 13:29:20,448 [qtp2096539129-23] ERROR endpoint.ObjectEndpoint: Exception occurred in PutObject
s3g_1       | 2022-05-14 13:29:24,140 [qtp2096539129-19] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-3618246140, with dlfknslnfslf as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-05-14 13:29:24,143 [qtp2096539129-19] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-3618246140
s3g_1       | 2022-05-14 13:29:40,304 [qtp2096539129-19] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-4952112418, with dlfknslnfslf as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-05-14 13:29:40,308 [qtp2096539129-19] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-4952112418
s3g_1       | 2022-05-14 13:29:48,282 [qtp2096539129-19] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-1587444284, with dlfknslnfslf as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1       | 2022-05-14 13:29:48,287 [qtp2096539129-19] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-1587444284
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:21:42,641 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-0487796895/multipartKey3 in Volume/Bucket s3v/erasure
om_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: erasure key: ozone-test-0487796895/multipartKey3. Provided Part info is { etag2, 2}, whereas OM has partName /s3v/erasure/ozone-test-0487796895/multipartKey3-16183e32-a164-43b0-b95d-f822b72640e3-108300500777173142-2
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:497)
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:197)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:254)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:524)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:319)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:21:43,307 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: PartNumber at index 1 is 2, and its previous partNumber at index 0 is 4 for ozonekey is /s3v/erasure/ozone-test-0487796895/multipartKey3
om_1        | 2022-05-14 13:21:43,308 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-0487796895/multipartKey3 in Volume/Bucket s3v/erasure
om_1        | INVALID_PART_ORDER org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: erasure key: ozone-test-0487796895/multipartKey3 because parts are in Invalid order.
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getPartsListSize(S3MultipartUploadCompleteRequest.java:463)
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:193)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:254)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:524)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:319)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:21:47,217 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadAbortRequest: Abort Multipart request is failed for KeyName ozone-test-3846447933/multipartKey5 in VolumeName/Bucket s3v/erasure
om_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Abort Multipart Upload Failed: volume: s3vbucket: erasurekey: ozone-test-3846447933/multipartKey5
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadAbortRequest.validateAndUpdateCache(S3MultipartUploadAbortRequest.java:161)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:254)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:524)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:319)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:21:47,934 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyCreateRequest: Key creation failed. Volume:s3v, Bucket:erasure, Key:ozone-test-6927900047/multipartKey. 
om_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: No such Multipart upload is with specified uploadId random
om_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareMultipartFileInfo(OMKeyRequest.java:754)
om_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareFileInfo(OMKeyRequest.java:645)
om_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareKeyInfo(OMKeyRequest.java:622)
om_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyCreateRequest.validateAndUpdateCache(OMKeyCreateRequest.java:277)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:254)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:524)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:319)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:22:00,001 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
recon_1     | 2022-05-14 13:24:19,856 [EventQueue-ContainerReportForReconContainerReportHandler] ERROR container.ContainerReportHandler: Received container report for an unknown container 10 from datanode 54b0e747-a2bb-484f-976a-c7c0770cb588{ip: 172.18.0.9, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
recon_1     | 2022-05-14 13:24:19,856 [EventQueue-ContainerReportForReconContainerReportHandler] ERROR container.ContainerReportHandler: Received container report for an unknown container 11 from datanode 54b0e747-a2bb-484f-976a-c7c0770cb588{ip: 172.18.0.9, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
recon_1     | 2022-05-14 13:24:26,922 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 1 milliseconds to process 0 existing database records.
recon_1     | 2022-05-14 13:24:26,925 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 3 milliseconds for processing 6 containers.
recon_1     | 2022-05-14 13:24:28,143 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2022-05-14 13:24:28,143 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2022-05-14 13:24:28,143 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 1651 
recon_1     | 2022-05-14 13:24:28,187 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 85, SequenceNumber diff: 219, SequenceNumber Lag from OM 0.
recon_1     | 2022-05-14 13:24:28,187 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 219 records
recon_1     | 2022-05-14 13:24:28,190 [pool-17-thread-1] INFO tasks.NSSummaryTask: Completed a process run of NSSummaryTask
recon_1     | 2022-05-14 13:24:28,232 [pool-17-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
recon_1     | 2022-05-14 13:24:28,240 [pool-17-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 12 OM DB update event(s).
recon_1     | 2022-05-14 13:24:28,248 [pool-17-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2022-05-14 13:24:29,015 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 6 pipelines in house.
recon_1     | 2022-05-14 13:24:29,017 [PipelineSyncTask] INFO scm.ReconPipelineManager: Adding new pipeline PipelineID=85665b57-79bd-4721-8990-6434b89cf0f5 from SCM.
recon_1     | 2022-05-14 13:24:29,028 [PipelineSyncTask] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 85665b57-79bd-4721-8990-6434b89cf0f5, Nodes: 55441846-8ccc-4390-87fc-ba015dadcaaa{ip: 172.18.0.4, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}54b0e747-a2bb-484f-976a-c7c0770cb588{ip: 172.18.0.9, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}00910f34-9556-4f5c-8864-f93205907e3c{ip: 172.18.0.6, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}f3166980-8467-4e9a-9c6e-144f4303af87{ip: 172.18.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}d5e6fff5-66a9-4bee-add9-03aeb4a97c66{ip: 172.18.0.2, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: EC/ECReplicationConfig{data=3, parity=2, ecChunkSize=1048576, codec=rs}, State:OPEN, leaderId:, CreationTimestamp2022-05-14T13:20:30.478Z[UTC]].
recon_1     | 2022-05-14 13:24:29,032 [PipelineSyncTask] INFO scm.ReconPipelineManager: Adding new pipeline PipelineID=6e6105cc-e733-4e24-b11b-36605179c86d from SCM.
recon_1     | 2022-05-14 13:24:29,038 [PipelineSyncTask] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 6e6105cc-e733-4e24-b11b-36605179c86d, Nodes: d5e6fff5-66a9-4bee-add9-03aeb4a97c66{ip: 172.18.0.2, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}54b0e747-a2bb-484f-976a-c7c0770cb588{ip: 172.18.0.9, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}00910f34-9556-4f5c-8864-f93205907e3c{ip: 172.18.0.6, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}55441846-8ccc-4390-87fc-ba015dadcaaa{ip: 172.18.0.4, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}f3166980-8467-4e9a-9c6e-144f4303af87{ip: 172.18.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: EC/ECReplicationConfig{data=3, parity=2, ecChunkSize=1048576, codec=rs}, State:OPEN, leaderId:, CreationTimestamp2022-05-14T13:20:21.213Z[UTC]].
recon_1     | 2022-05-14 13:24:29,042 [PipelineSyncTask] INFO scm.ReconPipelineManager: Adding new pipeline PipelineID=b2302968-6590-4efd-b3d4-88f98845679b from SCM.
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:22:00,001 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:22:00,002 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:22:29,336 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: destbucket-51219 of layout LEGACY in volume: s3v
om_1        | 2022-05-14 13:23:00,001 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:23:00,002 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:23:00,005 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
recon_1     | 2022-05-14 13:24:29,043 [PipelineSyncTask] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: b2302968-6590-4efd-b3d4-88f98845679b, Nodes: d5e6fff5-66a9-4bee-add9-03aeb4a97c66{ip: 172.18.0.2, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}55441846-8ccc-4390-87fc-ba015dadcaaa{ip: 172.18.0.4, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}54b0e747-a2bb-484f-976a-c7c0770cb588{ip: 172.18.0.9, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}00910f34-9556-4f5c-8864-f93205907e3c{ip: 172.18.0.6, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}f3166980-8467-4e9a-9c6e-144f4303af87{ip: 172.18.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: EC/ECReplicationConfig{data=3, parity=2, ecChunkSize=1048576, codec=rs}, State:OPEN, leaderId:, CreationTimestamp2022-05-14T13:20:15.873Z[UTC]].
recon_1     | 2022-05-14 13:24:29,047 [PipelineSyncTask] INFO scm.ReconPipelineManager: Adding new pipeline PipelineID=eea4bf28-37f5-4124-9157-cb84720170a9 from SCM.
recon_1     | 2022-05-14 13:24:29,048 [PipelineSyncTask] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: eea4bf28-37f5-4124-9157-cb84720170a9, Nodes: f3166980-8467-4e9a-9c6e-144f4303af87{ip: 172.18.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}54b0e747-a2bb-484f-976a-c7c0770cb588{ip: 172.18.0.9, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}00910f34-9556-4f5c-8864-f93205907e3c{ip: 172.18.0.6, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}d5e6fff5-66a9-4bee-add9-03aeb4a97c66{ip: 172.18.0.2, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}55441846-8ccc-4390-87fc-ba015dadcaaa{ip: 172.18.0.4, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: EC/ECReplicationConfig{data=3, parity=2, ecChunkSize=1048576, codec=rs}, State:OPEN, leaderId:, CreationTimestamp2022-05-14T13:20:29.989Z[UTC]].
recon_1     | 2022-05-14 13:24:29,057 [PipelineSyncTask] INFO scm.ReconPipelineManager: Adding new pipeline PipelineID=60ee7a26-489d-44d6-b8c5-9e342c88bb63 from SCM.
recon_1     | 2022-05-14 13:24:29,058 [PipelineSyncTask] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 60ee7a26-489d-44d6-b8c5-9e342c88bb63, Nodes: f3166980-8467-4e9a-9c6e-144f4303af87{ip: 172.18.0.8, host: ozone_datanode_5.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}d5e6fff5-66a9-4bee-add9-03aeb4a97c66{ip: 172.18.0.2, host: ozone_datanode_4.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}54b0e747-a2bb-484f-976a-c7c0770cb588{ip: 172.18.0.9, host: ozone_datanode_2.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}00910f34-9556-4f5c-8864-f93205907e3c{ip: 172.18.0.6, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}55441846-8ccc-4390-87fc-ba015dadcaaa{ip: 172.18.0.4, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: EC/ECReplicationConfig{data=3, parity=2, ecChunkSize=1048576, codec=rs}, State:OPEN, leaderId:, CreationTimestamp2022-05-14T13:20:18.162Z[UTC]].
recon_1     | 2022-05-14 13:24:29,061 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 49 milliseconds.
recon_1     | 2022-05-14 13:24:49,835 [EventQueue-ContainerReportForReconContainerReportHandler] INFO scm.ReconContainerManager: Successfully added container #7 to Recon.
recon_1     | 2022-05-14 13:24:49,836 [EventQueue-ContainerReportForReconContainerReportHandler] INFO scm.ReconContainerManager: Successfully added container #8 to Recon.
recon_1     | 2022-05-14 13:24:49,842 [EventQueue-ContainerReportForReconContainerReportHandler] INFO scm.ReconContainerManager: Successfully added container #9 to Recon.
recon_1     | 2022-05-14 13:24:49,843 [EventQueue-ContainerReportForReconContainerReportHandler] INFO scm.ReconContainerManager: Successfully added container #10 to Recon.
recon_1     | 2022-05-14 13:24:49,844 [EventQueue-ContainerReportForReconContainerReportHandler] INFO scm.ReconContainerManager: Successfully added container #11 to Recon.
recon_1     | 2022-05-14 13:25:28,256 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2022-05-14 13:25:28,257 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2022-05-14 13:25:28,258 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 1870 
recon_1     | 2022-05-14 13:25:28,289 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 80, SequenceNumber diff: 193, SequenceNumber Lag from OM 0.
recon_1     | 2022-05-14 13:25:28,290 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 193 records
recon_1     | 2022-05-14 13:25:28,294 [pool-17-thread-1] INFO tasks.NSSummaryTask: Completed a process run of NSSummaryTask
recon_1     | 2022-05-14 13:25:28,343 [pool-17-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
recon_1     | 2022-05-14 13:25:28,344 [pool-17-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 3 OM DB update event(s).
recon_1     | 2022-05-14 13:25:28,349 [pool-17-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2022-05-14 13:26:28,352 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2022-05-14 13:26:28,353 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2022-05-14 13:26:28,353 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 2063 
recon_1     | 2022-05-14 13:26:28,431 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 117, SequenceNumber diff: 304, SequenceNumber Lag from OM 0.
recon_1     | 2022-05-14 13:26:28,431 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 304 records
recon_1     | 2022-05-14 13:26:28,434 [pool-17-thread-1] INFO tasks.NSSummaryTask: Completed a process run of NSSummaryTask
recon_1     | 2022-05-14 13:26:28,520 [pool-17-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
recon_1     | 2022-05-14 13:26:28,524 [pool-17-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 11 OM DB update event(s).
recon_1     | 2022-05-14 13:26:28,558 [pool-17-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2022-05-14 13:27:28,567 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2022-05-14 13:27:28,568 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:23:07,372 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyDeleteRequest: Key delete failed. Volume:s3v, Bucket:erasure, Key:ozone-test-2511545991/multidelete/key=value/f4.
om_1        | KEY_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Key not found
om_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:146)
om_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:92)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:254)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:524)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:319)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:23:52,864 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:legacy for user:hadoop
om_1        | 2022-05-14 13:23:56,853 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: source-bucket of layout LEGACY in volume: legacy
om_1        | 2022-05-14 13:24:00,001 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:24:00,004 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:24:00,005 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:24:00,798 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link of layout LEGACY in volume: s3v
om_1        | 2022-05-14 13:24:20,602 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ozone-test-zqmnulnemk of layout LEGACY in volume: s3v
om_1        | 2022-05-14 13:24:23,083 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-xnvouwczbq of layout LEGACY in volume: s3v
om_1        | 2022-05-14 13:24:36,638 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: to-be-deleted of layout LEGACY in volume: s3v
om_1        | 2022-05-14 13:25:00,001 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
recon_1     | 2022-05-14 13:27:28,568 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 2367 
recon_1     | 2022-05-14 13:27:28,585 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 24, SequenceNumber diff: 80, SequenceNumber Lag from OM 0.
recon_1     | 2022-05-14 13:27:28,586 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 80 records
recon_1     | 2022-05-14 13:27:28,587 [pool-17-thread-1] INFO tasks.NSSummaryTask: Completed a process run of NSSummaryTask
recon_1     | 2022-05-14 13:27:28,653 [pool-17-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
recon_1     | 2022-05-14 13:27:28,659 [pool-17-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 13 OM DB update event(s).
recon_1     | 2022-05-14 13:27:28,661 [pool-17-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2022-05-14 13:28:28,665 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2022-05-14 13:28:28,665 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2022-05-14 13:28:28,666 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 2447 
recon_1     | 2022-05-14 13:28:28,704 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 166, SequenceNumber diff: 416, SequenceNumber Lag from OM 0.
recon_1     | 2022-05-14 13:28:28,704 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 416 records
recon_1     | 2022-05-14 13:28:28,705 [pool-17-thread-1] INFO tasks.NSSummaryTask: Completed a process run of NSSummaryTask
recon_1     | 2022-05-14 13:28:28,738 [pool-17-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
recon_1     | 2022-05-14 13:28:28,741 [pool-17-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 15 OM DB update event(s).
recon_1     | 2022-05-14 13:28:28,749 [pool-17-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2022-05-14 13:29:26,926 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 1 milliseconds to process 0 existing database records.
recon_1     | 2022-05-14 13:29:26,929 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 2 milliseconds for processing 11 containers.
recon_1     | 2022-05-14 13:29:28,753 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2022-05-14 13:29:28,753 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2022-05-14 13:29:28,753 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 2863 
recon_1     | 2022-05-14 13:29:28,804 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 124, SequenceNumber diff: 322, SequenceNumber Lag from OM 0.
recon_1     | 2022-05-14 13:29:28,804 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 322 records
recon_1     | 2022-05-14 13:29:28,806 [pool-17-thread-1] INFO tasks.NSSummaryTask: Completed a process run of NSSummaryTask
recon_1     | 2022-05-14 13:29:28,854 [pool-17-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
recon_1     | 2022-05-14 13:29:28,868 [pool-17-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 13 OM DB update event(s).
recon_1     | 2022-05-14 13:29:28,882 [pool-17-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2022-05-14 13:29:29,073 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 11 pipelines in house.
recon_1     | 2022-05-14 13:29:29,081 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 16 milliseconds.
recon_1     | 2022-05-14 13:30:28,886 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2022-05-14 13:30:28,886 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2022-05-14 13:30:28,886 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 3185 
recon_1     | 2022-05-14 13:30:28,898 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 44, SequenceNumber diff: 141, SequenceNumber Lag from OM 0.
recon_1     | 2022-05-14 13:30:28,899 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 141 records
recon_1     | 2022-05-14 13:30:28,901 [pool-17-thread-1] INFO tasks.NSSummaryTask: Completed a process run of NSSummaryTask
recon_1     | 2022-05-14 13:30:28,938 [pool-17-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
recon_1     | 2022-05-14 13:30:28,943 [pool-17-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 21 OM DB update event(s).
recon_1     | 2022-05-14 13:30:28,959 [pool-17-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2022-05-14 13:31:28,963 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2022-05-14 13:31:28,963 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2022-05-14 13:31:28,964 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 3326 
recon_1     | 2022-05-14 13:31:28,978 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 8, SequenceNumber diff: 25, SequenceNumber Lag from OM 0.
recon_1     | 2022-05-14 13:31:28,980 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 25 records
recon_1     | 2022-05-14 13:31:28,984 [pool-17-thread-1] INFO tasks.NSSummaryTask: Completed a process run of NSSummaryTask
recon_1     | 2022-05-14 13:31:29,040 [pool-17-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
recon_1     | 2022-05-14 13:31:29,044 [pool-17-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 4 OM DB update event(s).
recon_1     | 2022-05-14 13:31:29,047 [pool-17-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2022-05-14 13:32:20,804 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: New container #12 got from ozone_datanode_3.ozone_default.
recon_1     | 2022-05-14 13:32:20,815 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=3e1eead8-02b1-4fcc-a721-2a339903bedb not found. Cannot add container #12
recon_1     | 2022-05-14 13:32:20,817 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] WARN scm.ReconIncrementalContainerReportHandler: Container 12 not found!
recon_1     | 2022-05-14 13:32:29,051 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2022-05-14 13:32:29,052 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2022-05-14 13:32:29,052 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 3351 
recon_1     | 2022-05-14 13:32:29,059 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 5, SequenceNumber diff: 14, SequenceNumber Lag from OM 0.
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
recon_1     | 2022-05-14 13:32:29,059 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 14 records
recon_1     | 2022-05-14 13:32:29,062 [pool-17-thread-1] INFO tasks.NSSummaryTask: Completed a process run of NSSummaryTask
recon_1     | 2022-05-14 13:32:29,148 [pool-17-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
recon_1     | 2022-05-14 13:32:29,148 [pool-17-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 1 OM DB update event(s).
recon_1     | 2022-05-14 13:32:29,153 [pool-17-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2022-05-14 13:32:35,814 [EventQueue-ContainerReportForReconContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=3e1eead8-02b1-4fcc-a721-2a339903bedb not found. Cannot add container #12
recon_1     | 2022-05-14 13:32:35,815 [EventQueue-ContainerReportForReconContainerReportHandler] ERROR container.ContainerReportHandler: Received container report for an unknown container 12 from datanode 55441846-8ccc-4390-87fc-ba015dadcaaa{ip: 172.18.0.4, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
recon_1     | 2022-05-14 13:33:00,189 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: Container #1 has state OPEN, but given state is CLOSING.
recon_1     | 2022-05-14 13:33:00,254 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO container.IncrementalContainerReportHandler: Moving container #1 to CLOSED state, datanode 00910f34-9556-4f5c-8864-f93205907e3c{ip: 172.18.0.6, host: ozone_datanode_1.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} reported CLOSED replica.
recon_1     | 2022-05-14 13:33:29,156 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2022-05-14 13:33:29,157 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2022-05-14 13:33:29,157 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 3365 
recon_1     | 2022-05-14 13:33:29,169 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0.
recon_1     | 2022-05-14 13:33:29,169 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 0 records
recon_1     | 2022-05-14 13:34:05,278 [EventQueue-ContainerReportForReconContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=3e1eead8-02b1-4fcc-a721-2a339903bedb not found. Cannot add container #12
recon_1     | 2022-05-14 13:34:05,279 [EventQueue-ContainerReportForReconContainerReportHandler] ERROR container.ContainerReportHandler: Received container report for an unknown container 12 from datanode 55441846-8ccc-4390-87fc-ba015dadcaaa{ip: 172.18.0.4, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
recon_1     | 2022-05-14 13:34:26,929 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 0 milliseconds to process 0 existing database records.
recon_1     | 2022-05-14 13:34:26,932 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 3 milliseconds for processing 11 containers.
recon_1     | 2022-05-14 13:34:29,089 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 11 pipelines in house.
recon_1     | 2022-05-14 13:34:29,093 [PipelineSyncTask] INFO scm.ReconPipelineManager: Adding new pipeline PipelineID=3e1eead8-02b1-4fcc-a721-2a339903bedb from SCM.
recon_1     | 2022-05-14 13:34:29,096 [PipelineSyncTask] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 3e1eead8-02b1-4fcc-a721-2a339903bedb, Nodes: 55441846-8ccc-4390-87fc-ba015dadcaaa{ip: 172.18.0.4, host: ozone_datanode_3.ozone_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: STANDALONE/ONE, State:OPEN, leaderId:, CreationTimestamp2022-05-14T13:32:18.774Z[UTC]].
recon_1     | 2022-05-14 13:34:29,099 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 16 milliseconds.
recon_1     | 2022-05-14 13:34:29,171 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2022-05-14 13:34:29,171 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2022-05-14 13:34:29,172 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 3365 
recon_1     | 2022-05-14 13:34:29,185 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0.
recon_1     | 2022-05-14 13:34:29,185 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 0 records
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:25:00,002 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:25:00,003 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:25:16,422 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload: /legacy/source-bucket/ozone-test-6862889472/multipartKey2 Part number: 1 size 6  is less than minimum part size 5242880
om_1        | 2022-05-14 13:25:16,422 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-6862889472/multipartKey2 in Volume/Bucket legacy/source-bucket
om_1        | ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: link key: ozone-test-6862889472/multipartKey2. Entity too small.
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:515)
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:197)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:254)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:524)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:319)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:25:17,847 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /legacy/source-bucket/ozone-test-7746248615/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 1
om_1        | partName: "etag1"
om_1        | , partNumber: 2
om_1        | partName: "etag2"
om_1        | ]
om_1        | 2022-05-14 13:25:17,848 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-7746248615/multipartKey3 in Volume/Bucket legacy/source-bucket
om_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: link key: ozone-test-7746248615/multipartKey3
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:186)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:254)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:524)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:319)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:25:18,510 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /legacy/source-bucket/ozone-test-7746248615/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 2
om_1        | partName: "etag1"
om_1        | , partNumber: 1
om_1        | partName: "etag2"
om_1        | ]
om_1        | 2022-05-14 13:25:18,511 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-7746248615/multipartKey3 in Volume/Bucket legacy/source-bucket
om_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: link key: ozone-test-7746248615/multipartKey3
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:186)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:254)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:524)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:319)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:25:22,187 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-7746248615/multipartKey3 in Volume/Bucket legacy/source-bucket
om_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: link key: ozone-test-7746248615/multipartKey3. Provided Part info is { etag1, 1}, whereas OM has partName /legacy/source-bucket/ozone-test-7746248615/multipartKey3-09669212-5947-4f42-bb1d-efe9a3c893c7-108300515219996891-1
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:497)
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:197)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:254)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:524)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:319)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:25:22,867 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-7746248615/multipartKey3 in Volume/Bucket legacy/source-bucket
om_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: link key: ozone-test-7746248615/multipartKey3. Provided Part info is { etag2, 2}, whereas OM has partName /legacy/source-bucket/ozone-test-7746248615/multipartKey3-09669212-5947-4f42-bb1d-efe9a3c893c7-108300515219996891-2
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:497)
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:197)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:254)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:524)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:319)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:25:23,539 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: PartNumber at index 1 is 2, and its previous partNumber at index 0 is 4 for ozonekey is /legacy/source-bucket/ozone-test-7746248615/multipartKey3
om_1        | 2022-05-14 13:25:23,540 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-7746248615/multipartKey3 in Volume/Bucket legacy/source-bucket
om_1        | INVALID_PART_ORDER org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: link key: ozone-test-7746248615/multipartKey3 because parts are in Invalid order.
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getPartsListSize(S3MultipartUploadCompleteRequest.java:463)
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:193)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:254)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:524)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:319)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:25:27,167 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadAbortRequest: Abort Multipart request is failed for KeyName ozone-test-2519106411/multipartKey5 in VolumeName/Bucket legacy/source-bucket
om_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Abort Multipart Upload Failed: volume: s3vbucket: linkkey: ozone-test-2519106411/multipartKey5
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadAbortRequest.validateAndUpdateCache(S3MultipartUploadAbortRequest.java:161)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:254)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:524)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:319)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:25:27,863 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyCreateRequest: Key creation failed. Volume:s3v, Bucket:link, Key:ozone-test-4897562275/multipartKey. 
om_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: No such Multipart upload is with specified uploadId random
om_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareMultipartFileInfo(OMKeyRequest.java:754)
om_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareFileInfo(OMKeyRequest.java:645)
om_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareKeyInfo(OMKeyRequest.java:622)
om_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyCreateRequest.validateAndUpdateCache(OMKeyCreateRequest.java:277)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:254)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:524)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:319)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:26:00,000 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:26:00,001 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:26:00,003 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:26:16,405 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: destbucket-26720 of layout LEGACY in volume: s3v
om_1        | 2022-05-14 13:26:53,413 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyDeleteRequest: Key delete failed. Volume:legacy, Bucket:source-bucket, Key:ozone-test-9324718850/multidelete/key=value/f4.
om_1        | KEY_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Key not found
om_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:146)
om_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:92)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:254)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:524)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:319)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:27:00,001 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:27:00,001 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:27:00,002 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:27:25,101 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-1137339587 of layout LEGACY in volume: s3v
om_1        | 2022-05-14 13:27:28,748 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-0490355251 of layout LEGACY in volume: s3v
om_1        | 2022-05-14 13:27:37,255 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-6708269095 of layout LEGACY in volume: s3v
om_1        | 2022-05-14 13:27:37,818 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ozone-test-glvxbjswpp of layout LEGACY in volume: s3v
om_1        | 2022-05-14 13:27:39,496 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-axqfazusng of layout LEGACY in volume: s3v
om_1        | 2022-05-14 13:27:47,124 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-2365003728 of layout LEGACY in volume: s3v
om_1        | 2022-05-14 13:27:47,825 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-8969484327 of layout LEGACY in volume: s3v
om_1        | 2022-05-14 13:27:52,187 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-8155355461 of layout LEGACY in volume: s3v
om_1        | 2022-05-14 13:27:56,498 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-3998480116 of layout LEGACY in volume: s3v
om_1        | 2022-05-14 13:28:00,001 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:28:00,001 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:28:00,002 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:28:02,090 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-6658897623 of layout LEGACY in volume: s3v
om_1        | 2022-05-14 13:28:17,332 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload: /s3v/bucket-ozone-test-6658897623/ozone-test-2129011582/multipartKey2 Part number: 1 size 6  is less than minimum part size 5242880
om_1        | 2022-05-14 13:28:17,333 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-2129011582/multipartKey2 in Volume/Bucket s3v/bucket-ozone-test-6658897623
om_1        | ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-6658897623 key: ozone-test-2129011582/multipartKey2. Entity too small.
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:515)
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:197)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:254)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:524)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:319)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:28:18,903 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-ozone-test-6658897623/ozone-test-8407572907/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 1
om_1        | partName: "etag1"
om_1        | , partNumber: 2
om_1        | partName: "etag2"
om_1        | ]
om_1        | 2022-05-14 13:28:18,903 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-8407572907/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-6658897623
om_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-6658897623 key: ozone-test-8407572907/multipartKey3
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:186)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:254)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:524)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:319)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:28:19,577 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-ozone-test-6658897623/ozone-test-8407572907/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 2
om_1        | partName: "etag1"
om_1        | , partNumber: 1
om_1        | partName: "etag2"
om_1        | ]
om_1        | 2022-05-14 13:28:19,579 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-8407572907/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-6658897623
om_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-6658897623 key: ozone-test-8407572907/multipartKey3
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:186)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:254)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:524)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:319)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:28:23,393 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-8407572907/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-6658897623
om_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-6658897623 key: ozone-test-8407572907/multipartKey3. Provided Part info is { etag1, 1}, whereas OM has partName /s3v/bucket-ozone-test-6658897623/ozone-test-8407572907/multipartKey3-cc92677a-8991-4207-b207-49e165199c50-108300527082864928-1
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:497)
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:197)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:254)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:524)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:319)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:28:24,080 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-8407572907/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-6658897623
om_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-6658897623 key: ozone-test-8407572907/multipartKey3. Provided Part info is { etag2, 2}, whereas OM has partName /s3v/bucket-ozone-test-6658897623/ozone-test-8407572907/multipartKey3-cc92677a-8991-4207-b207-49e165199c50-108300527082864928-2
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:497)
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:197)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:254)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:524)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:319)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:28:24,784 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: PartNumber at index 1 is 2, and its previous partNumber at index 0 is 4 for ozonekey is /s3v/bucket-ozone-test-6658897623/ozone-test-8407572907/multipartKey3
om_1        | 2022-05-14 13:28:24,785 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-8407572907/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-6658897623
om_1        | INVALID_PART_ORDER org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-6658897623 key: ozone-test-8407572907/multipartKey3 because parts are in Invalid order.
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getPartsListSize(S3MultipartUploadCompleteRequest.java:463)
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:193)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:254)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:524)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:319)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:28:28,567 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadAbortRequest: Abort Multipart request is failed for KeyName ozone-test-2133336892/multipartKey5 in VolumeName/Bucket s3v/bucket-ozone-test-6658897623
om_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Abort Multipart Upload Failed: volume: s3vbucket: bucket-ozone-test-6658897623key: ozone-test-2133336892/multipartKey5
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadAbortRequest.validateAndUpdateCache(S3MultipartUploadAbortRequest.java:161)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:254)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:524)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:319)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:28:29,324 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyCreateRequest: Key creation failed. Volume:s3v, Bucket:bucket-ozone-test-6658897623, Key:ozone-test-9941473318/multipartKey. 
om_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: No such Multipart upload is with specified uploadId random
om_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareMultipartFileInfo(OMKeyRequest.java:754)
om_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareFileInfo(OMKeyRequest.java:645)
om_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareKeyInfo(OMKeyRequest.java:622)
om_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyCreateRequest.validateAndUpdateCache(OMKeyCreateRequest.java:277)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:254)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:524)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:319)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:29:00,002 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:29:00,002 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:29:00,002 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:29:12,641 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-4051989561 of layout LEGACY in volume: s3v
om_1        | 2022-05-14 13:29:13,327 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: destbucket-74018 of layout LEGACY in volume: s3v
om_1        | 2022-05-14 13:29:24,142 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-3618246140 of layout LEGACY in volume: s3v
om_1        | 2022-05-14 13:29:40,307 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-4952112418 of layout LEGACY in volume: s3v
om_1        | 2022-05-14 13:29:43,868 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyDeleteRequest: Key delete failed. Volume:s3v, Bucket:bucket-ozone-test-4952112418, Key:ozone-test-4272130533/multidelete/key=value/f4.
om_1        | KEY_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Key not found
om_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:146)
om_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:92)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:254)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:524)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:319)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:29:48,284 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-1587444284 of layout LEGACY in volume: s3v
om_1        | 2022-05-14 13:30:00,000 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:30:00,002 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:30:00,003 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:30:12,305 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:recon for user:hadoop
om_1        | 2022-05-14 13:30:12,357 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: api of layout LEGACY in volume: recon
om_1        | 2022-05-14 13:31:00,001 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:31:00,002 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:31:00,002 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:31:07,637 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ombg0 of layout LEGACY in volume: vol1
om_1        | 2022-05-14 13:31:32,937 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ombr0 of layout LEGACY in volume: vol1
om_1        | 2022-05-14 13:32:00,002 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:32:00,006 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:32:00,006 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:33:00,001 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:33:00,001 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:33:00,003 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:34:00,001 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:34:00,002 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:34:00,002 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:35:00,000 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:35:00,001 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2022-05-14 13:35:00,001 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 87193-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1235)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1210)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1185)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:276)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:332)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:312)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:214)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
