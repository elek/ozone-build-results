Attaching to ozonesecure-ha_datanode3_1, ozonesecure-ha_datanode2_1, ozonesecure-ha_scm2.org_1, ozonesecure-ha_recon_1, ozonesecure-ha_scm1.org_1, ozonesecure-ha_s3g_1, ozonesecure-ha_kdc_1, ozonesecure-ha_om3_1, ozonesecure-ha_kms_1, ozonesecure-ha_om1_1, ozonesecure-ha_datanode1_1, ozonesecure-ha_om2_1, ozonesecure-ha_scm3.org_1
datanode1_1  | Sleeping for 5 seconds
datanode1_1  | Waiting for the service scm3.org:9894
datanode1_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
datanode1_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode1_1  | 2022-07-10 13:10:12,350 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode1_1  | /************************************************************
datanode1_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode1_1  | STARTUP_MSG:   host = 129fc2057256/172.25.0.102
datanode1_1  | STARTUP_MSG:   args = []
datanode1_1  | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
datanode1_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.3.0-SNAPSHOT.jar
datanode1_1  | STARTUP_MSG:   build = https://github.com/apache/ozone/d088d199bf506d76f7046a4b19b690e2a9e6915e ; compiled by 'runner' on 2022-07-10T12:45Z
datanode1_1  | STARTUP_MSG:   java = 11.0.14.1
datanode1_1  | ************************************************************/
datanode1_1  | 2022-07-10 13:10:12,457 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode1_1  | 2022-07-10 13:10:12,808 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode1_1  | 2022-07-10 13:10:13,470 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode1_1  | 2022-07-10 13:10:14,270 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode1_1  | 2022-07-10 13:10:14,270 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode1_1  | 2022-07-10 13:10:14,954 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:129fc2057256 ip:172.25.0.102
datanode1_1  | 2022-07-10 13:10:17,734 [main] INFO ozone.HddsDatanodeService: Ozone security is enabled. Attempting login for Hdds Datanode user. Principal: dn/dn@EXAMPLE.COM,keytab: /etc/security/keytabs/dn.keytab
datanode1_1  | 2022-07-10 13:10:18,633 [main] INFO security.UserGroupInformation: Login successful for user dn/dn@EXAMPLE.COM using keytab file dn.keytab. Keytab auto renewal enabled : false
datanode1_1  | 2022-07-10 13:10:18,635 [main] INFO ozone.HddsDatanodeService: Hdds Datanode login successful.
datanode1_1  | 2022-07-10 13:10:20,360 [main] INFO ozone.HddsDatanodeService: Initializing secure Datanode.
datanode1_1  | 2022-07-10 13:10:20,367 [main] ERROR client.DNCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
datanode1_1  | 2022-07-10 13:10:20,367 [main] INFO client.DNCertificateClient: Certificate client init case: 0
datanode1_1  | 2022-07-10 13:10:20,372 [main] INFO client.DNCertificateClient: Creating keypair for client as keypair and certificate not found.
datanode1_1  | 2022-07-10 13:10:27,618 [main] INFO ozone.HddsDatanodeService: Init response: GETCERT
datanode1_1  | 2022-07-10 13:10:27,704 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.102,host:129fc2057256
datanode1_1  | 2022-07-10 13:10:27,711 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
datanode1_1  | 2022-07-10 13:10:27,716 [main] ERROR client.DNCertificateClient: Invalid domain 129fc2057256
datanode1_1  | 2022-07-10 13:10:27,754 [main] INFO ozone.HddsDatanodeService: Creating csr for DN-> subject:dn@129fc2057256
datanode1_1  | 2022-07-10 13:10:33,065 [main] INFO client.DNCertificateClient: Loading certificate from location:/data/metadata/dn/certs.
datanode1_1  | 2022-07-10 13:10:33,123 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/935900506483.crt.
datanode1_1  | 2022-07-10 13:10:33,130 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/ROOTCA-1.crt.
datanode1_1  | 2022-07-10 13:10:33,171 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/CA-844577728582.crt.
datanode1_1  | 2022-07-10 13:10:33,172 [main] INFO ozone.HddsDatanodeService: Successfully stored SCM signed certificate, case:GETCERT.
datanode1_1  | 2022-07-10 13:10:33,281 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
datanode1_1  | 2022-07-10 13:10:34,080 [main] INFO reflections.Reflections: Reflections took 640 ms to scan 2 urls, producing 89 keys and 195 values 
datanode1_1  | 2022-07-10 13:10:34,494 [main] INFO statemachine.DatanodeStateMachine: Datanode State Machine Task Thread Pool size 4
datanode1_1  | 2022-07-10 13:10:35,563 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode1_1  | 2022-07-10 13:10:35,642 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89311358976
datanode1_1  | 2022-07-10 13:10:35,646 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode1_1  | 2022-07-10 13:10:35,668 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode1_1  | 2022-07-10 13:10:35,887 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode1_1  | 2022-07-10 13:10:35,962 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode1_1  | 2022-07-10 13:10:35,965 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/metadata/ratis/scmUsed not found
datanode1_1  | 2022-07-10 13:10:35,966 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
datanode1_1  | 2022-07-10 13:10:35,966 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/metadata/ratis
datanode1_1  | 2022-07-10 13:10:35,967 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/metadata/ratis
datanode1_1  | 2022-07-10 13:10:36,210 [Thread-8] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode1_1  | 2022-07-10 13:10:36,243 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode1_1  | 2022-07-10 13:10:41,396 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for DNAudit to [].
datanode1_1  | 2022-07-10 13:10:42,963 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode1_1  | 2022-07-10 13:10:43,552 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
datanode1_1  | 2022-07-10 13:10:44,300 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
datanode1_1  | 2022-07-10 13:10:44,301 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
datanode1_1  | 2022-07-10 13:10:44,301 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
datanode1_1  | 2022-07-10 13:10:44,308 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode1_1  | 2022-07-10 13:10:44,311 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode1_1  | 2022-07-10 13:10:44,312 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode1_1  | 2022-07-10 13:10:44,312 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode1_1  | 2022-07-10 13:10:44,424 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
datanode1_1  | 2022-07-10 13:10:44,442 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
datanode1_1  | 2022-07-10 13:10:50,311 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
datanode1_1  | 2022-07-10 13:10:50,333 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
datanode1_1  | 2022-07-10 13:10:50,342 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
datanode1_1  | 2022-07-10 13:10:50,347 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode1_1  | 2022-07-10 13:10:50,347 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode1_1  | 2022-07-10 13:10:50,368 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode1_1  | 2022-07-10 13:10:50,835 [main] INFO server.XceiverServerGrpc: GrpcServer channel type EpollServerSocketChannel
datanode1_1  | 2022-07-10 13:10:51,915 [main] INFO token.OzoneBlockTokenSecretManager: Updating the current master key for generating tokens
datanode1_1  | 2022-07-10 13:10:51,920 [main] INFO token.ContainerTokenSecretManager: Updating the current master key for generating tokens
datanode1_1  | 2022-07-10 13:10:52,204 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode1_1  | 2022-07-10 13:10:52,214 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
datanode1_1  | 2022-07-10 13:10:52,215 [main] INFO http.BaseHttpServer: HttpAuthType: hdds.datanode.http.auth.type = kerberos
datanode1_1  | 2022-07-10 13:10:52,431 [main] INFO util.log: Logging initialized @50639ms to org.eclipse.jetty.util.log.Slf4jLog
datanode1_1  | 2022-07-10 13:10:53,254 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode1_1  | 2022-07-10 13:10:53,351 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode1_1  | 2022-07-10 13:10:53,372 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
datanode1_1  | 2022-07-10 13:10:53,381 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode1_1  | 2022-07-10 13:10:53,381 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode1_1  | 2022-07-10 13:10:53,401 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.datanode.http.auth.kerberos.principal keytabKey: hdds.datanode.http.auth.kerberos.keytab
datanode1_1  | 2022-07-10 13:10:53,827 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode1_1  | 2022-07-10 13:10:53,836 [main] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
datanode1_1  | 2022-07-10 13:10:54,078 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode1_1  | 2022-07-10 13:10:54,086 [main] INFO server.session: No SessionScavenger set, using defaults
datanode1_1  | 2022-07-10 13:10:54,093 [main] INFO server.session: node0 Scavenging every 660000ms
datanode1_1  | 2022-07-10 13:10:54,330 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode1_1  | 2022-07-10 13:10:54,340 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@3ce60feb{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode1_1  | 2022-07-10 13:10:54,351 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@57573880{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode1_1  | 2022-07-10 13:10:55,129 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode1_1  | 2022-07-10 13:10:55,238 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@2c3a2935{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-16553575526241630176/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode1_1  | 2022-07-10 13:10:55,310 [main] INFO server.AbstractConnector: Started ServerConnector@3a2b1f24{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
datanode1_1  | 2022-07-10 13:10:55,310 [main] INFO server.Server: Started @53519ms
datanode1_1  | 2022-07-10 13:10:55,372 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode1_1  | 2022-07-10 13:10:55,372 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode1_1  | 2022-07-10 13:10:55,375 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode1_1  | 2022-07-10 13:10:55,389 [Datanode State Machine Daemon Thread] INFO statemachine.DatanodeStateMachine: Ozone container server started.
datanode1_1  | 2022-07-10 13:10:55,750 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@352500d4] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode1_1  | 2022-07-10 13:10:56,230 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.25.0.115:9891
datanode1_1  | 2022-07-10 13:10:56,304 [Datanode State Machine Task Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode1_1  | 2022-07-10 13:10:58,812 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO volume.HddsVolume: SchemaV3 db is created and loaded at /data/hdds/hdds/CID-f578972c-97f6-4a12-a46c-8eeea6081008/DS-b4203ae7-ab8a-4019-abe2-5e12e661a320/container.db for volume DS-b4203ae7-ab8a-4019-abe2-5e12e661a320
datanode1_1  | 2022-07-10 13:10:58,871 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO volume.HddsVolume: SchemaV3 db is stopped at /data/hdds/hdds/CID-f578972c-97f6-4a12-a46c-8eeea6081008/DS-b4203ae7-ab8a-4019-abe2-5e12e661a320/container.db for volume DS-b4203ae7-ab8a-4019-abe2-5e12e661a320
datanode1_1  | 2022-07-10 13:10:58,888 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode1_1  | 2022-07-10 13:10:58,897 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode1_1  | 2022-07-10 13:10:59,369 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 257634a0-3792-468a-a5a2-186b5a295fa1
datanode1_1  | 2022-07-10 13:10:59,562 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO server.RaftServer: 257634a0-3792-468a-a5a2-186b5a295fa1: start RPC server
datanode1_1  | 2022-07-10 13:10:59,610 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO server.GrpcService: 257634a0-3792-468a-a5a2-186b5a295fa1: GrpcService started, listening on 9856
datanode1_1  | 2022-07-10 13:10:59,620 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO server.GrpcService: 257634a0-3792-468a-a5a2-186b5a295fa1: GrpcService started, listening on 9857
datanode1_1  | 2022-07-10 13:10:59,676 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO server.GrpcService: 257634a0-3792-468a-a5a2-186b5a295fa1: GrpcService started, listening on 9858
datanode1_1  | 2022-07-10 13:10:59,688 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 257634a0-3792-468a-a5a2-186b5a295fa1 is started using port 9858 for RATIS
datanode1_1  | 2022-07-10 13:10:59,691 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 257634a0-3792-468a-a5a2-186b5a295fa1 is started using port 9857 for RATIS_ADMIN
datanode1_1  | 2022-07-10 13:10:59,691 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 257634a0-3792-468a-a5a2-186b5a295fa1 is started using port 9856 for RATIS_SERVER
datanode1_1  | 2022-07-10 13:10:59,697 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$387/0x00000008405dec40@76ec50fa] INFO util.JvmPauseMonitor: JvmPauseMonitor-257634a0-3792-468a-a5a2-186b5a295fa1: Started
datanode1_1  | 2022-07-10 13:10:59,779 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode1_1  | 2022-07-10 13:10:59,785 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode1_1  | 2022-07-10 13:11:05,021 [Command processor thread] INFO server.RaftServer: 257634a0-3792-468a-a5a2-186b5a295fa1: addNew group-6DC84A45F007:[257634a0-3792-468a-a5a2-186b5a295fa1|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1] returns group-6DC84A45F007:java.util.concurrent.CompletableFuture@2270e9cd[Not completed]
datanode1_1  | 2022-07-10 13:11:05,142 [pool-23-thread-1] INFO server.RaftServer$Division: 257634a0-3792-468a-a5a2-186b5a295fa1: new RaftServerImpl for group-6DC84A45F007:[257634a0-3792-468a-a5a2-186b5a295fa1|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1] with ContainerStateMachine:uninitialized
datanode1_1  | 2022-07-10 13:11:05,167 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode1_1  | 2022-07-10 13:11:05,168 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode1_1  | 2022-07-10 13:11:05,172 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode1_1  | 2022-07-10 13:11:05,172 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode1_1  | 2022-07-10 13:11:05,172 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode1_1  | 2022-07-10 13:11:05,175 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode1_1  | 2022-07-10 13:11:05,224 [pool-23-thread-1] INFO server.RaftServer$Division: 257634a0-3792-468a-a5a2-186b5a295fa1@group-6DC84A45F007: ConfigurationManager, init=-1: [257634a0-3792-468a-a5a2-186b5a295fa1|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1], old=null, confs=<EMPTY_MAP>
datanode1_1  | 2022-07-10 13:11:05,232 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode1_1  | 2022-07-10 13:11:05,259 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode1_1  | 2022-07-10 13:11:05,267 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode1_1  | 2022-07-10 13:11:05,286 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/8d6e1a79-b70d-40e6-a234-6dc84a45f007 does not exist. Creating ...
datanode1_1  | 2022-07-10 13:11:05,321 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/8d6e1a79-b70d-40e6-a234-6dc84a45f007/in_use.lock acquired by nodename 6@129fc2057256
datanode1_1  | 2022-07-10 13:11:05,372 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/8d6e1a79-b70d-40e6-a234-6dc84a45f007 has been successfully formatted.
datanode1_1  | 2022-07-10 13:11:05,444 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-6DC84A45F007: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode1_1  | 2022-07-10 13:11:05,456 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode1_1  | 2022-07-10 13:11:05,461 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode1_1  | 2022-07-10 13:11:05,656 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode1_1  | 2022-07-10 13:11:05,696 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode1_1  | 2022-07-10 13:11:05,697 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode1_1  | 2022-07-10 13:11:05,940 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2022-07-10 13:11:06,041 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode1_1  | 2022-07-10 13:11:06,042 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode1_1  | 2022-07-10 13:11:06,076 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 257634a0-3792-468a-a5a2-186b5a295fa1@group-6DC84A45F007-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/8d6e1a79-b70d-40e6-a234-6dc84a45f007
datanode1_1  | 2022-07-10 13:11:06,118 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode1_1  | 2022-07-10 13:11:06,122 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode1_1  | 2022-07-10 13:11:06,124 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2022-07-10 13:11:06,131 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode1_1  | 2022-07-10 13:11:06,132 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode1_1  | 2022-07-10 13:11:06,133 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode1_1  | 2022-07-10 13:11:06,133 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode1_1  | 2022-07-10 13:11:06,134 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode1_1  | 2022-07-10 13:11:06,194 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode1_1  | 2022-07-10 13:11:06,199 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode1_1  | 2022-07-10 13:11:06,199 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode1_1  | 2022-07-10 13:11:06,258 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 257634a0-3792-468a-a5a2-186b5a295fa1@group-6DC84A45F007-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode1_1  | 2022-07-10 13:11:06,258 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 257634a0-3792-468a-a5a2-186b5a295fa1@group-6DC84A45F007-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode1_1  | 2022-07-10 13:11:06,277 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode1_1  | 2022-07-10 13:11:06,299 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode1_1  | 2022-07-10 13:11:06,300 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode1_1  | 2022-07-10 13:11:06,303 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode1_1  | 2022-07-10 13:11:06,304 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode1_1  | 2022-07-10 13:11:06,308 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode1_1  | 2022-07-10 13:11:06,634 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode2_1  | Sleeping for 5 seconds
datanode2_1  | Waiting for the service scm3.org:9894
datanode2_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
datanode2_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode2_1  | 2022-07-10 13:10:12,355 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode2_1  | /************************************************************
datanode2_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode2_1  | STARTUP_MSG:   host = f001020ea054/172.25.0.103
datanode2_1  | STARTUP_MSG:   args = []
datanode2_1  | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
datanode1_1  | 2022-07-10 13:11:06,635 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode1_1  | 2022-07-10 13:11:06,636 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode1_1  | 2022-07-10 13:11:06,639 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode1_1  | 2022-07-10 13:11:06,643 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode1_1  | 2022-07-10 13:11:06,645 [pool-23-thread-1] INFO server.RaftServer$Division: 257634a0-3792-468a-a5a2-186b5a295fa1@group-6DC84A45F007: start as a follower, conf=-1: [257634a0-3792-468a-a5a2-186b5a295fa1|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1], old=null
datanode1_1  | 2022-07-10 13:11:06,655 [pool-23-thread-1] INFO server.RaftServer$Division: 257634a0-3792-468a-a5a2-186b5a295fa1@group-6DC84A45F007: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode1_1  | 2022-07-10 13:11:06,666 [pool-23-thread-1] INFO impl.RoleInfo: 257634a0-3792-468a-a5a2-186b5a295fa1: start 257634a0-3792-468a-a5a2-186b5a295fa1@group-6DC84A45F007-FollowerState
datanode1_1  | 2022-07-10 13:11:06,701 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-6DC84A45F007,id=257634a0-3792-468a-a5a2-186b5a295fa1
datanode1_1  | 2022-07-10 13:11:06,817 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=8d6e1a79-b70d-40e6-a234-6dc84a45f007
datanode1_1  | 2022-07-10 13:11:06,820 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=8d6e1a79-b70d-40e6-a234-6dc84a45f007.
datanode1_1  | 2022-07-10 13:11:06,820 [Command processor thread] INFO server.RaftServer: 257634a0-3792-468a-a5a2-186b5a295fa1: addNew group-B841D041C364:[992f3c0d-344e-4060-87f0-890ffe8b867e|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1, a1e412ee-75aa-4bf8-87bc-4e8e615b1959|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, 257634a0-3792-468a-a5a2-186b5a295fa1|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0] returns group-B841D041C364:java.util.concurrent.CompletableFuture@4f43beb7[Not completed]
datanode1_1  | 2022-07-10 13:11:06,840 [pool-23-thread-1] INFO server.RaftServer$Division: 257634a0-3792-468a-a5a2-186b5a295fa1: new RaftServerImpl for group-B841D041C364:[992f3c0d-344e-4060-87f0-890ffe8b867e|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1, a1e412ee-75aa-4bf8-87bc-4e8e615b1959|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, 257634a0-3792-468a-a5a2-186b5a295fa1|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0] with ContainerStateMachine:uninitialized
datanode1_1  | 2022-07-10 13:11:06,854 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode1_1  | 2022-07-10 13:11:06,854 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode1_1  | 2022-07-10 13:11:06,854 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode1_1  | 2022-07-10 13:11:06,854 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode1_1  | 2022-07-10 13:11:06,858 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode1_1  | 2022-07-10 13:11:06,860 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode1_1  | 2022-07-10 13:11:06,862 [pool-23-thread-1] INFO server.RaftServer$Division: 257634a0-3792-468a-a5a2-186b5a295fa1@group-B841D041C364: ConfigurationManager, init=-1: [992f3c0d-344e-4060-87f0-890ffe8b867e|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1, a1e412ee-75aa-4bf8-87bc-4e8e615b1959|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, 257634a0-3792-468a-a5a2-186b5a295fa1|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0], old=null, confs=<EMPTY_MAP>
datanode1_1  | 2022-07-10 13:11:06,863 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode1_1  | 2022-07-10 13:11:06,872 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode1_1  | 2022-07-10 13:11:06,873 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode1_1  | 2022-07-10 13:11:06,873 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/199762fc-7613-447a-a2fc-b841d041c364 does not exist. Creating ...
datanode1_1  | 2022-07-10 13:11:06,887 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/199762fc-7613-447a-a2fc-b841d041c364/in_use.lock acquired by nodename 6@129fc2057256
datanode1_1  | 2022-07-10 13:11:06,893 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/199762fc-7613-447a-a2fc-b841d041c364 has been successfully formatted.
datanode1_1  | 2022-07-10 13:11:06,895 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-B841D041C364: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode1_1  | 2022-07-10 13:11:06,900 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode1_1  | 2022-07-10 13:11:06,900 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode1_1  | 2022-07-10 13:11:06,901 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode1_1  | 2022-07-10 13:11:06,903 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode1_1  | 2022-07-10 13:11:06,903 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode1_1  | 2022-07-10 13:11:06,903 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2022-07-10 13:11:06,904 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode1_1  | 2022-07-10 13:11:06,904 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode1_1  | 2022-07-10 13:11:06,904 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 257634a0-3792-468a-a5a2-186b5a295fa1@group-B841D041C364-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/199762fc-7613-447a-a2fc-b841d041c364
datanode1_1  | 2022-07-10 13:11:06,904 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode1_1  | 2022-07-10 13:11:06,905 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode1_1  | 2022-07-10 13:11:06,920 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2022-07-10 13:11:06,921 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode1_1  | 2022-07-10 13:11:06,957 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode1_1  | 2022-07-10 13:11:06,959 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode1_1  | 2022-07-10 13:11:06,961 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode2_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.3.0-SNAPSHOT.jar
datanode2_1  | STARTUP_MSG:   build = https://github.com/apache/ozone/d088d199bf506d76f7046a4b19b690e2a9e6915e ; compiled by 'runner' on 2022-07-10T12:45Z
datanode2_1  | STARTUP_MSG:   java = 11.0.14.1
datanode2_1  | ************************************************************/
datanode2_1  | 2022-07-10 13:10:12,402 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode2_1  | 2022-07-10 13:10:12,693 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode2_1  | 2022-07-10 13:10:13,356 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode2_1  | 2022-07-10 13:10:14,325 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode2_1  | 2022-07-10 13:10:14,327 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode2_1  | 2022-07-10 13:10:15,042 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:f001020ea054 ip:172.25.0.103
datanode2_1  | 2022-07-10 13:10:17,903 [main] INFO ozone.HddsDatanodeService: Ozone security is enabled. Attempting login for Hdds Datanode user. Principal: dn/dn@EXAMPLE.COM,keytab: /etc/security/keytabs/dn.keytab
datanode2_1  | 2022-07-10 13:10:18,632 [main] INFO security.UserGroupInformation: Login successful for user dn/dn@EXAMPLE.COM using keytab file dn.keytab. Keytab auto renewal enabled : false
datanode2_1  | 2022-07-10 13:10:18,632 [main] INFO ozone.HddsDatanodeService: Hdds Datanode login successful.
datanode2_1  | 2022-07-10 13:10:20,241 [main] INFO ozone.HddsDatanodeService: Initializing secure Datanode.
datanode2_1  | 2022-07-10 13:10:20,262 [main] ERROR client.DNCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
datanode2_1  | 2022-07-10 13:10:20,263 [main] INFO client.DNCertificateClient: Certificate client init case: 0
datanode2_1  | 2022-07-10 13:10:20,276 [main] INFO client.DNCertificateClient: Creating keypair for client as keypair and certificate not found.
datanode2_1  | 2022-07-10 13:10:25,198 [main] INFO ozone.HddsDatanodeService: Init response: GETCERT
datanode2_1  | 2022-07-10 13:10:25,323 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.103,host:f001020ea054
datanode2_1  | 2022-07-10 13:10:25,323 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
datanode2_1  | 2022-07-10 13:10:25,333 [main] ERROR client.DNCertificateClient: Invalid domain f001020ea054
datanode2_1  | 2022-07-10 13:10:25,344 [main] INFO ozone.HddsDatanodeService: Creating csr for DN-> subject:dn@f001020ea054
datanode2_1  | 2022-07-10 13:10:29,998 [main] INFO client.DNCertificateClient: Loading certificate from location:/data/metadata/dn/certs.
datanode2_1  | 2022-07-10 13:10:30,094 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/ROOTCA-1.crt.
datanode2_1  | 2022-07-10 13:10:30,111 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/933105602287.crt.
datanode2_1  | 2022-07-10 13:10:30,123 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/CA-844577728582.crt.
datanode2_1  | 2022-07-10 13:10:30,126 [main] INFO ozone.HddsDatanodeService: Successfully stored SCM signed certificate, case:GETCERT.
datanode2_1  | 2022-07-10 13:10:30,286 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
datanode2_1  | 2022-07-10 13:10:31,191 [main] INFO reflections.Reflections: Reflections took 712 ms to scan 2 urls, producing 89 keys and 195 values 
datanode2_1  | 2022-07-10 13:10:31,701 [main] INFO statemachine.DatanodeStateMachine: Datanode State Machine Task Thread Pool size 4
datanode2_1  | 2022-07-10 13:10:32,611 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode2_1  | 2022-07-10 13:10:32,699 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89311358976
datanode2_1  | 2022-07-10 13:10:32,752 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode2_1  | 2022-07-10 13:10:32,754 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode2_1  | 2022-07-10 13:10:32,960 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode2_1  | 2022-07-10 13:10:33,107 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode2_1  | 2022-07-10 13:10:33,109 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/metadata/ratis/scmUsed not found
datanode2_1  | 2022-07-10 13:10:33,127 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
datanode2_1  | 2022-07-10 13:10:33,127 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/metadata/ratis
datanode2_1  | 2022-07-10 13:10:33,144 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/metadata/ratis
datanode2_1  | 2022-07-10 13:10:33,401 [Thread-8] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode2_1  | 2022-07-10 13:10:33,439 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode2_1  | 2022-07-10 13:10:38,531 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for DNAudit to [].
datanode2_1  | 2022-07-10 13:10:39,547 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode2_1  | 2022-07-10 13:10:39,813 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
datanode2_1  | 2022-07-10 13:10:40,793 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
datanode2_1  | 2022-07-10 13:10:40,816 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
datanode2_1  | 2022-07-10 13:10:40,838 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
datanode2_1  | 2022-07-10 13:10:40,853 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode2_1  | 2022-07-10 13:10:40,855 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2022-07-10 13:10:40,857 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode2_1  | 2022-07-10 13:10:40,858 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode2_1  | 2022-07-10 13:10:41,011 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
datanode2_1  | 2022-07-10 13:10:41,044 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
datanode2_1  | 2022-07-10 13:10:47,333 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
datanode2_1  | 2022-07-10 13:10:47,356 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
datanode2_1  | 2022-07-10 13:10:47,356 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
datanode2_1  | 2022-07-10 13:10:47,356 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode2_1  | 2022-07-10 13:10:47,356 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode2_1  | 2022-07-10 13:10:47,367 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode2_1  | 2022-07-10 13:10:47,897 [main] INFO server.XceiverServerGrpc: GrpcServer channel type EpollServerSocketChannel
datanode2_1  | 2022-07-10 13:10:48,854 [main] INFO token.OzoneBlockTokenSecretManager: Updating the current master key for generating tokens
datanode2_1  | 2022-07-10 13:10:48,880 [main] INFO token.ContainerTokenSecretManager: Updating the current master key for generating tokens
datanode2_1  | 2022-07-10 13:10:49,236 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode2_1  | 2022-07-10 13:10:49,237 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
datanode2_1  | 2022-07-10 13:10:49,239 [main] INFO http.BaseHttpServer: HttpAuthType: hdds.datanode.http.auth.type = kerberos
datanode2_1  | 2022-07-10 13:10:49,414 [main] INFO util.log: Logging initialized @47543ms to org.eclipse.jetty.util.log.Slf4jLog
datanode2_1  | 2022-07-10 13:10:50,230 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode2_1  | 2022-07-10 13:10:50,308 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode2_1  | 2022-07-10 13:10:50,309 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
datanode2_1  | 2022-07-10 13:10:50,309 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode2_1  | 2022-07-10 13:10:50,309 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode2_1  | 2022-07-10 13:10:50,328 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.datanode.http.auth.kerberos.principal keytabKey: hdds.datanode.http.auth.kerberos.keytab
datanode2_1  | 2022-07-10 13:10:50,638 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode2_1  | 2022-07-10 13:10:50,639 [main] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
datanode2_1  | 2022-07-10 13:10:50,849 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode2_1  | 2022-07-10 13:10:50,850 [main] INFO server.session: No SessionScavenger set, using defaults
datanode2_1  | 2022-07-10 13:10:50,851 [main] INFO server.session: node0 Scavenging every 660000ms
datanode2_1  | 2022-07-10 13:10:50,985 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode2_1  | 2022-07-10 13:10:50,992 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1cb4cad0{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode2_1  | 2022-07-10 13:10:50,993 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@4c131823{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode2_1  | 2022-07-10 13:10:51,599 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode2_1  | 2022-07-10 13:10:51,704 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@3ae5cbb9{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-12120832588016333940/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode2_1  | 2022-07-10 13:10:51,746 [main] INFO server.AbstractConnector: Started ServerConnector@7a7698f4{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
datanode2_1  | 2022-07-10 13:10:51,747 [main] INFO server.Server: Started @49876ms
datanode2_1  | 2022-07-10 13:10:51,781 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode2_1  | 2022-07-10 13:10:51,781 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode2_1  | 2022-07-10 13:10:51,783 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode2_1  | 2022-07-10 13:10:51,794 [Datanode State Machine Daemon Thread] INFO statemachine.DatanodeStateMachine: Ozone container server started.
datanode2_1  | 2022-07-10 13:10:51,887 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@737ac2cb] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode2_1  | 2022-07-10 13:10:52,313 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.25.0.115:9891
datanode2_1  | 2022-07-10 13:10:52,379 [Datanode State Machine Task Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode2_1  | 2022-07-10 13:10:55,313 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO volume.HddsVolume: SchemaV3 db is created and loaded at /data/hdds/hdds/CID-f578972c-97f6-4a12-a46c-8eeea6081008/DS-f1acef7d-dc5f-416f-bf6a-d1d65d3c3981/container.db for volume DS-f1acef7d-dc5f-416f-bf6a-d1d65d3c3981
datanode2_1  | 2022-07-10 13:10:55,388 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO volume.HddsVolume: SchemaV3 db is stopped at /data/hdds/hdds/CID-f578972c-97f6-4a12-a46c-8eeea6081008/DS-f1acef7d-dc5f-416f-bf6a-d1d65d3c3981/container.db for volume DS-f1acef7d-dc5f-416f-bf6a-d1d65d3c3981
datanode2_1  | 2022-07-10 13:10:55,396 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode2_1  | 2022-07-10 13:10:55,401 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode2_1  | 2022-07-10 13:10:55,880 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 992f3c0d-344e-4060-87f0-890ffe8b867e
datanode2_1  | 2022-07-10 13:10:56,165 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO server.RaftServer: 992f3c0d-344e-4060-87f0-890ffe8b867e: start RPC server
datanode2_1  | 2022-07-10 13:10:56,380 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO server.GrpcService: 992f3c0d-344e-4060-87f0-890ffe8b867e: GrpcService started, listening on 9856
datanode2_1  | 2022-07-10 13:10:56,428 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO server.GrpcService: 992f3c0d-344e-4060-87f0-890ffe8b867e: GrpcService started, listening on 9857
datanode2_1  | 2022-07-10 13:10:56,430 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO server.GrpcService: 992f3c0d-344e-4060-87f0-890ffe8b867e: GrpcService started, listening on 9858
datanode2_1  | 2022-07-10 13:10:56,460 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 992f3c0d-344e-4060-87f0-890ffe8b867e is started using port 9858 for RATIS
datanode2_1  | 2022-07-10 13:10:56,463 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 992f3c0d-344e-4060-87f0-890ffe8b867e is started using port 9857 for RATIS_ADMIN
datanode2_1  | 2022-07-10 13:10:56,466 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 992f3c0d-344e-4060-87f0-890ffe8b867e is started using port 9856 for RATIS_SERVER
datanode1_1  | 2022-07-10 13:11:06,961 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode1_1  | 2022-07-10 13:11:06,965 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode1_1  | 2022-07-10 13:11:06,971 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode1_1  | 2022-07-10 13:11:06,976 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode1_1  | 2022-07-10 13:11:06,979 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 257634a0-3792-468a-a5a2-186b5a295fa1@group-B841D041C364-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode1_1  | 2022-07-10 13:11:06,991 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 257634a0-3792-468a-a5a2-186b5a295fa1@group-B841D041C364-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode1_1  | 2022-07-10 13:11:07,024 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode1_1  | 2022-07-10 13:11:07,024 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode1_1  | 2022-07-10 13:11:07,024 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode1_1  | 2022-07-10 13:11:07,024 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode1_1  | 2022-07-10 13:11:07,024 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode1_1  | 2022-07-10 13:11:07,024 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode1_1  | 2022-07-10 13:11:07,025 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode1_1  | 2022-07-10 13:11:07,025 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode1_1  | 2022-07-10 13:11:07,025 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode1_1  | 2022-07-10 13:11:07,025 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode1_1  | 2022-07-10 13:11:07,025 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode1_1  | 2022-07-10 13:11:07,025 [pool-23-thread-1] INFO server.RaftServer$Division: 257634a0-3792-468a-a5a2-186b5a295fa1@group-B841D041C364: start as a follower, conf=-1: [992f3c0d-344e-4060-87f0-890ffe8b867e|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1, a1e412ee-75aa-4bf8-87bc-4e8e615b1959|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, 257634a0-3792-468a-a5a2-186b5a295fa1|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0], old=null
datanode1_1  | 2022-07-10 13:11:07,043 [pool-23-thread-1] INFO server.RaftServer$Division: 257634a0-3792-468a-a5a2-186b5a295fa1@group-B841D041C364: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode1_1  | 2022-07-10 13:11:07,051 [pool-23-thread-1] INFO impl.RoleInfo: 257634a0-3792-468a-a5a2-186b5a295fa1: start 257634a0-3792-468a-a5a2-186b5a295fa1@group-B841D041C364-FollowerState
datanode1_1  | 2022-07-10 13:11:07,064 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-B841D041C364,id=257634a0-3792-468a-a5a2-186b5a295fa1
datanode1_1  | 2022-07-10 13:11:07,074 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=199762fc-7613-447a-a2fc-b841d041c364
datanode1_1  | 2022-07-10 13:11:09,868 [grpc-default-executor-0] INFO server.RaftServer$Division: 257634a0-3792-468a-a5a2-186b5a295fa1@group-B841D041C364: receive requestVote(ELECTION, a1e412ee-75aa-4bf8-87bc-4e8e615b1959, group-B841D041C364, 1, (t:0, i:0))
datanode1_1  | 2022-07-10 13:11:09,871 [grpc-default-executor-0] INFO impl.VoteContext: 257634a0-3792-468a-a5a2-186b5a295fa1@group-B841D041C364-FOLLOWER: accept ELECTION from a1e412ee-75aa-4bf8-87bc-4e8e615b1959: our priority 0 <= candidate's priority 0
datanode1_1  | 2022-07-10 13:11:09,871 [grpc-default-executor-0] INFO server.RaftServer$Division: 257634a0-3792-468a-a5a2-186b5a295fa1@group-B841D041C364: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:a1e412ee-75aa-4bf8-87bc-4e8e615b1959
datanode1_1  | 2022-07-10 13:11:09,872 [grpc-default-executor-0] INFO impl.RoleInfo: 257634a0-3792-468a-a5a2-186b5a295fa1: shutdown 257634a0-3792-468a-a5a2-186b5a295fa1@group-B841D041C364-FollowerState
datanode1_1  | 2022-07-10 13:11:09,872 [257634a0-3792-468a-a5a2-186b5a295fa1@group-B841D041C364-FollowerState] INFO impl.FollowerState: 257634a0-3792-468a-a5a2-186b5a295fa1@group-B841D041C364-FollowerState was interrupted
datanode1_1  | 2022-07-10 13:11:09,872 [grpc-default-executor-0] INFO impl.RoleInfo: 257634a0-3792-468a-a5a2-186b5a295fa1: start 257634a0-3792-468a-a5a2-186b5a295fa1@group-B841D041C364-FollowerState
datanode1_1  | 2022-07-10 13:11:09,889 [grpc-default-executor-0] INFO server.RaftServer$Division: 257634a0-3792-468a-a5a2-186b5a295fa1@group-B841D041C364 replies to ELECTION vote request: a1e412ee-75aa-4bf8-87bc-4e8e615b1959<-257634a0-3792-468a-a5a2-186b5a295fa1#0:OK-t1. Peer's state: 257634a0-3792-468a-a5a2-186b5a295fa1@group-B841D041C364:t1, leader=null, voted=a1e412ee-75aa-4bf8-87bc-4e8e615b1959, raftlog=257634a0-3792-468a-a5a2-186b5a295fa1@group-B841D041C364-SegmentedRaftLog:OPENED:c-1, conf=-1: [992f3c0d-344e-4060-87f0-890ffe8b867e|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1, a1e412ee-75aa-4bf8-87bc-4e8e615b1959|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, 257634a0-3792-468a-a5a2-186b5a295fa1|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0], old=null
datanode1_1  | 2022-07-10 13:11:11,824 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=199762fc-7613-447a-a2fc-b841d041c364.
datanode1_1  | 2022-07-10 13:11:11,831 [pool-23-thread-1] INFO server.RaftServer$Division: 257634a0-3792-468a-a5a2-186b5a295fa1: new RaftServerImpl for group-09A40F9F1D96:[992f3c0d-344e-4060-87f0-890ffe8b867e|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, a1e412ee-75aa-4bf8-87bc-4e8e615b1959|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, 257634a0-3792-468a-a5a2-186b5a295fa1|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0] with ContainerStateMachine:uninitialized
datanode1_1  | 2022-07-10 13:11:11,833 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode1_1  | 2022-07-10 13:11:11,834 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode1_1  | 2022-07-10 13:11:11,834 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode1_1  | 2022-07-10 13:11:11,834 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode1_1  | 2022-07-10 13:11:11,835 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode1_1  | 2022-07-10 13:11:11,835 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode2_1  | 2022-07-10 13:10:56,463 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$388/0x00000008405de840@6e6f1825] INFO util.JvmPauseMonitor: JvmPauseMonitor-992f3c0d-344e-4060-87f0-890ffe8b867e: Started
datanode2_1  | 2022-07-10 13:10:56,523 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode2_1  | 2022-07-10 13:10:56,530 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode2_1  | 2022-07-10 13:11:01,096 [Command processor thread] INFO server.RaftServer: 992f3c0d-344e-4060-87f0-890ffe8b867e: addNew group-F25D482AAF22:[992f3c0d-344e-4060-87f0-890ffe8b867e|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1] returns group-F25D482AAF22:java.util.concurrent.CompletableFuture@213b1971[Not completed]
datanode2_1  | 2022-07-10 13:11:01,209 [pool-23-thread-1] INFO server.RaftServer$Division: 992f3c0d-344e-4060-87f0-890ffe8b867e: new RaftServerImpl for group-F25D482AAF22:[992f3c0d-344e-4060-87f0-890ffe8b867e|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1] with ContainerStateMachine:uninitialized
datanode2_1  | 2022-07-10 13:11:01,223 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode2_1  | 2022-07-10 13:11:01,232 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode2_1  | 2022-07-10 13:11:01,233 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode2_1  | 2022-07-10 13:11:01,239 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode2_1  | 2022-07-10 13:11:01,240 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode2_1  | 2022-07-10 13:11:01,240 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode2_1  | 2022-07-10 13:11:01,250 [pool-23-thread-1] INFO server.RaftServer$Division: 992f3c0d-344e-4060-87f0-890ffe8b867e@group-F25D482AAF22: ConfigurationManager, init=-1: [992f3c0d-344e-4060-87f0-890ffe8b867e|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1], old=null, confs=<EMPTY_MAP>
datanode2_1  | 2022-07-10 13:11:01,251 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode2_1  | 2022-07-10 13:11:01,257 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode2_1  | 2022-07-10 13:11:01,260 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode2_1  | 2022-07-10 13:11:01,261 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/b77b6ac4-c103-4125-90f3-f25d482aaf22 does not exist. Creating ...
datanode2_1  | 2022-07-10 13:11:01,295 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/b77b6ac4-c103-4125-90f3-f25d482aaf22/in_use.lock acquired by nodename 7@f001020ea054
datanode2_1  | 2022-07-10 13:11:01,318 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/b77b6ac4-c103-4125-90f3-f25d482aaf22 has been successfully formatted.
datanode2_1  | 2022-07-10 13:11:01,478 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-F25D482AAF22: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode2_1  | 2022-07-10 13:11:01,486 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode2_1  | 2022-07-10 13:11:01,505 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode2_1  | 2022-07-10 13:11:01,685 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode2_1  | 2022-07-10 13:11:01,691 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2022-07-10 13:11:01,692 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode2_1  | 2022-07-10 13:11:01,877 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2022-07-10 13:11:01,964 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode2_1  | 2022-07-10 13:11:01,964 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode2_1  | 2022-07-10 13:11:01,994 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 992f3c0d-344e-4060-87f0-890ffe8b867e@group-F25D482AAF22-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/b77b6ac4-c103-4125-90f3-f25d482aaf22
datanode2_1  | 2022-07-10 13:11:01,994 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode2_1  | 2022-07-10 13:11:02,031 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode2_1  | 2022-07-10 13:11:02,037 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2022-07-10 13:11:02,037 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode2_1  | 2022-07-10 13:11:02,038 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode2_1  | 2022-07-10 13:11:02,058 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode2_1  | 2022-07-10 13:11:02,058 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode2_1  | 2022-07-10 13:11:02,058 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode2_1  | 2022-07-10 13:11:02,145 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode2_1  | 2022-07-10 13:11:02,167 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode2_1  | 2022-07-10 13:11:02,167 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode2_1  | 2022-07-10 13:11:02,232 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 992f3c0d-344e-4060-87f0-890ffe8b867e@group-F25D482AAF22-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode2_1  | 2022-07-10 13:11:02,232 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 992f3c0d-344e-4060-87f0-890ffe8b867e@group-F25D482AAF22-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode2_1  | 2022-07-10 13:11:02,287 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode2_1  | 2022-07-10 13:11:02,287 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode2_1  | 2022-07-10 13:11:02,288 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode2_1  | 2022-07-10 13:11:02,288 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode2_1  | 2022-07-10 13:11:02,290 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode2_1  | 2022-07-10 13:11:02,290 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode2_1  | 2022-07-10 13:11:02,600 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode1_1  | 2022-07-10 13:11:11,835 [pool-23-thread-1] INFO server.RaftServer$Division: 257634a0-3792-468a-a5a2-186b5a295fa1@group-09A40F9F1D96: ConfigurationManager, init=-1: [992f3c0d-344e-4060-87f0-890ffe8b867e|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, a1e412ee-75aa-4bf8-87bc-4e8e615b1959|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, 257634a0-3792-468a-a5a2-186b5a295fa1|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0], old=null, confs=<EMPTY_MAP>
datanode1_1  | 2022-07-10 13:11:11,835 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode1_1  | 2022-07-10 13:11:11,836 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode1_1  | 2022-07-10 13:11:11,837 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode1_1  | 2022-07-10 13:11:11,838 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/79d7f9ff-9479-4fdc-a3f9-09a40f9f1d96 does not exist. Creating ...
datanode1_1  | 2022-07-10 13:11:11,838 [Command processor thread] INFO server.RaftServer: 257634a0-3792-468a-a5a2-186b5a295fa1: addNew group-09A40F9F1D96:[992f3c0d-344e-4060-87f0-890ffe8b867e|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, a1e412ee-75aa-4bf8-87bc-4e8e615b1959|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, 257634a0-3792-468a-a5a2-186b5a295fa1|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0] returns group-09A40F9F1D96:java.util.concurrent.CompletableFuture@220e4131[Not completed]
datanode1_1  | 2022-07-10 13:11:11,839 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/79d7f9ff-9479-4fdc-a3f9-09a40f9f1d96/in_use.lock acquired by nodename 6@129fc2057256
datanode1_1  | 2022-07-10 13:11:11,851 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/79d7f9ff-9479-4fdc-a3f9-09a40f9f1d96 has been successfully formatted.
datanode1_1  | 2022-07-10 13:11:11,852 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-09A40F9F1D96: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode1_1  | 2022-07-10 13:11:11,853 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode1_1  | 2022-07-10 13:11:11,853 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode1_1  | 2022-07-10 13:11:11,853 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode1_1  | 2022-07-10 13:11:11,854 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode1_1  | 2022-07-10 13:11:11,854 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode1_1  | 2022-07-10 13:11:11,868 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2022-07-10 13:11:11,894 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode1_1  | 2022-07-10 13:11:11,909 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode1_1  | 2022-07-10 13:11:11,909 [257634a0-3792-468a-a5a2-186b5a295fa1@group-6DC84A45F007-FollowerState] INFO impl.FollowerState: 257634a0-3792-468a-a5a2-186b5a295fa1@group-6DC84A45F007-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5243597653ns, electionTimeout:5200ms
datanode1_1  | 2022-07-10 13:11:11,916 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 257634a0-3792-468a-a5a2-186b5a295fa1@group-09A40F9F1D96-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/79d7f9ff-9479-4fdc-a3f9-09a40f9f1d96
datanode1_1  | 2022-07-10 13:11:11,917 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode1_1  | 2022-07-10 13:11:11,917 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode1_1  | 2022-07-10 13:11:11,917 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2022-07-10 13:11:11,918 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode1_1  | 2022-07-10 13:11:11,917 [257634a0-3792-468a-a5a2-186b5a295fa1@group-6DC84A45F007-FollowerState] INFO impl.RoleInfo: 257634a0-3792-468a-a5a2-186b5a295fa1: shutdown 257634a0-3792-468a-a5a2-186b5a295fa1@group-6DC84A45F007-FollowerState
datanode1_1  | 2022-07-10 13:11:11,923 [257634a0-3792-468a-a5a2-186b5a295fa1@group-6DC84A45F007-FollowerState] INFO server.RaftServer$Division: 257634a0-3792-468a-a5a2-186b5a295fa1@group-6DC84A45F007: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode1_1  | 2022-07-10 13:11:11,923 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode1_1  | 2022-07-10 13:11:11,924 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode1_1  | 2022-07-10 13:11:11,924 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode1_1  | 2022-07-10 13:11:11,924 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode1_1  | 2022-07-10 13:11:11,950 [257634a0-3792-468a-a5a2-186b5a295fa1@group-6DC84A45F007-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode1_1  | 2022-07-10 13:11:11,954 [257634a0-3792-468a-a5a2-186b5a295fa1@group-6DC84A45F007-FollowerState] INFO impl.RoleInfo: 257634a0-3792-468a-a5a2-186b5a295fa1: start 257634a0-3792-468a-a5a2-186b5a295fa1@group-6DC84A45F007-LeaderElection1
datanode1_1  | 2022-07-10 13:11:11,954 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode1_1  | 2022-07-10 13:11:11,956 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode1_1  | 2022-07-10 13:11:11,957 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode1_1  | 2022-07-10 13:11:11,958 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 257634a0-3792-468a-a5a2-186b5a295fa1@group-09A40F9F1D96-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode1_1  | 2022-07-10 13:11:11,960 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 257634a0-3792-468a-a5a2-186b5a295fa1@group-09A40F9F1D96-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode1_1  | 2022-07-10 13:11:11,987 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode1_1  | 2022-07-10 13:11:11,988 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode1_1  | 2022-07-10 13:11:11,988 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode1_1  | 2022-07-10 13:11:11,995 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode1_1  | 2022-07-10 13:11:12,000 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode1_1  | 2022-07-10 13:11:12,000 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode1_1  | 2022-07-10 13:11:12,015 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode1_1  | 2022-07-10 13:11:12,018 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode3_1  | Sleeping for 5 seconds
datanode3_1  | Waiting for the service scm3.org:9894
datanode3_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
datanode3_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode3_1  | 2022-07-10 13:10:11,889 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode3_1  | /************************************************************
datanode3_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode3_1  | STARTUP_MSG:   host = 377a412caf09/172.25.0.104
datanode3_1  | STARTUP_MSG:   args = []
datanode3_1  | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
datanode3_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.3.0-SNAPSHOT.jar
datanode3_1  | STARTUP_MSG:   build = https://github.com/apache/ozone/d088d199bf506d76f7046a4b19b690e2a9e6915e ; compiled by 'runner' on 2022-07-10T12:45Z
datanode3_1  | STARTUP_MSG:   java = 11.0.14.1
datanode3_1  | ************************************************************/
datanode3_1  | 2022-07-10 13:10:11,914 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode3_1  | 2022-07-10 13:10:12,315 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode3_1  | 2022-07-10 13:10:12,937 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode3_1  | 2022-07-10 13:10:13,954 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode3_1  | 2022-07-10 13:10:13,959 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode3_1  | 2022-07-10 13:10:14,718 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:377a412caf09 ip:172.25.0.104
datanode3_1  | 2022-07-10 13:10:17,686 [main] INFO ozone.HddsDatanodeService: Ozone security is enabled. Attempting login for Hdds Datanode user. Principal: dn/dn@EXAMPLE.COM,keytab: /etc/security/keytabs/dn.keytab
datanode3_1  | 2022-07-10 13:10:18,466 [main] INFO security.UserGroupInformation: Login successful for user dn/dn@EXAMPLE.COM using keytab file dn.keytab. Keytab auto renewal enabled : false
datanode3_1  | 2022-07-10 13:10:18,474 [main] INFO ozone.HddsDatanodeService: Hdds Datanode login successful.
datanode3_1  | 2022-07-10 13:10:20,204 [main] INFO ozone.HddsDatanodeService: Initializing secure Datanode.
datanode3_1  | 2022-07-10 13:10:20,210 [main] ERROR client.DNCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
datanode3_1  | 2022-07-10 13:10:20,210 [main] INFO client.DNCertificateClient: Certificate client init case: 0
datanode3_1  | 2022-07-10 13:10:20,216 [main] INFO client.DNCertificateClient: Creating keypair for client as keypair and certificate not found.
datanode3_1  | 2022-07-10 13:10:25,704 [main] INFO ozone.HddsDatanodeService: Init response: GETCERT
datanode3_1  | 2022-07-10 13:10:25,783 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.104,host:377a412caf09
datanode3_1  | 2022-07-10 13:10:25,783 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
datanode3_1  | 2022-07-10 13:10:25,794 [main] ERROR client.DNCertificateClient: Invalid domain 377a412caf09
datanode3_1  | 2022-07-10 13:10:25,803 [main] INFO ozone.HddsDatanodeService: Creating csr for DN-> subject:dn@377a412caf09
datanode3_1  | 2022-07-10 13:10:30,232 [main] INFO client.DNCertificateClient: Loading certificate from location:/data/metadata/dn/certs.
datanode3_1  | 2022-07-10 13:10:30,303 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/ROOTCA-1.crt.
datanode3_1  | 2022-07-10 13:10:30,330 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/933456427477.crt.
datanode3_1  | 2022-07-10 13:10:30,344 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/CA-844577728582.crt.
datanode3_1  | 2022-07-10 13:10:30,347 [main] INFO ozone.HddsDatanodeService: Successfully stored SCM signed certificate, case:GETCERT.
datanode3_1  | 2022-07-10 13:10:30,446 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
datanode3_1  | 2022-07-10 13:10:31,496 [main] INFO reflections.Reflections: Reflections took 844 ms to scan 2 urls, producing 89 keys and 195 values 
datanode3_1  | 2022-07-10 13:10:31,871 [main] INFO statemachine.DatanodeStateMachine: Datanode State Machine Task Thread Pool size 4
datanode3_1  | 2022-07-10 13:10:33,109 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode3_1  | 2022-07-10 13:10:33,237 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89311358976
datanode3_1  | 2022-07-10 13:10:33,240 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode3_1  | 2022-07-10 13:10:33,252 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode3_1  | 2022-07-10 13:10:33,449 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode3_1  | 2022-07-10 13:10:33,604 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode3_1  | 2022-07-10 13:10:33,609 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/metadata/ratis/scmUsed not found
datanode3_1  | 2022-07-10 13:10:33,615 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
datanode3_1  | 2022-07-10 13:10:33,617 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/metadata/ratis
datanode3_1  | 2022-07-10 13:10:33,618 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/metadata/ratis
datanode3_1  | 2022-07-10 13:10:33,830 [Thread-8] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode3_1  | 2022-07-10 13:10:33,857 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode3_1  | 2022-07-10 13:10:39,033 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for DNAudit to [].
datanode3_1  | 2022-07-10 13:10:40,580 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode3_1  | 2022-07-10 13:10:40,993 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
datanode3_1  | 2022-07-10 13:10:41,400 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
datanode3_1  | 2022-07-10 13:10:41,411 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
datanode3_1  | 2022-07-10 13:10:41,414 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
datanode3_1  | 2022-07-10 13:10:41,415 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode3_1  | 2022-07-10 13:10:41,419 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2022-07-10 13:10:41,420 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode3_1  | 2022-07-10 13:10:41,423 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode3_1  | 2022-07-10 13:10:41,502 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
datanode3_1  | 2022-07-10 13:10:41,516 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
datanode3_1  | 2022-07-10 13:10:45,948 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
datanode3_1  | 2022-07-10 13:10:45,979 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
datanode3_1  | 2022-07-10 13:10:45,981 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
datanode3_1  | 2022-07-10 13:10:45,983 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode3_1  | 2022-07-10 13:10:45,991 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode3_1  | 2022-07-10 13:10:45,994 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode3_1  | 2022-07-10 13:10:46,412 [main] INFO server.XceiverServerGrpc: GrpcServer channel type EpollServerSocketChannel
datanode3_1  | 2022-07-10 13:10:47,328 [main] INFO token.OzoneBlockTokenSecretManager: Updating the current master key for generating tokens
datanode3_1  | 2022-07-10 13:10:47,334 [main] INFO token.ContainerTokenSecretManager: Updating the current master key for generating tokens
datanode3_1  | 2022-07-10 13:10:47,735 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode3_1  | 2022-07-10 13:10:47,736 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
datanode3_1  | 2022-07-10 13:10:47,736 [main] INFO http.BaseHttpServer: HttpAuthType: hdds.datanode.http.auth.type = kerberos
datanode3_1  | 2022-07-10 13:10:47,905 [main] INFO util.log: Logging initialized @46507ms to org.eclipse.jetty.util.log.Slf4jLog
datanode3_1  | 2022-07-10 13:10:48,621 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode3_1  | 2022-07-10 13:10:48,679 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode3_1  | 2022-07-10 13:10:48,702 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
datanode3_1  | 2022-07-10 13:10:48,702 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode3_1  | 2022-07-10 13:10:48,702 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode3_1  | 2022-07-10 13:10:48,706 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.datanode.http.auth.kerberos.principal keytabKey: hdds.datanode.http.auth.kerberos.keytab
datanode3_1  | 2022-07-10 13:10:49,009 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode3_1  | 2022-07-10 13:10:49,010 [main] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
datanode3_1  | 2022-07-10 13:10:49,215 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode3_1  | 2022-07-10 13:10:49,215 [main] INFO server.session: No SessionScavenger set, using defaults
datanode3_1  | 2022-07-10 13:10:49,220 [main] INFO server.session: node0 Scavenging every 600000ms
datanode3_1  | 2022-07-10 13:10:49,291 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode3_1  | 2022-07-10 13:10:49,294 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@3ce60feb{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode3_1  | 2022-07-10 13:10:49,294 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@57573880{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode3_1  | 2022-07-10 13:10:49,953 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode3_1  | 2022-07-10 13:10:50,042 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@2c3a2935{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-2754529992776598952/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode3_1  | 2022-07-10 13:10:50,081 [main] INFO server.AbstractConnector: Started ServerConnector@3a2b1f24{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
datanode3_1  | 2022-07-10 13:10:50,095 [main] INFO server.Server: Started @48697ms
datanode3_1  | 2022-07-10 13:10:50,114 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode3_1  | 2022-07-10 13:10:50,115 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode3_1  | 2022-07-10 13:10:50,117 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode3_1  | 2022-07-10 13:10:50,135 [Datanode State Machine Daemon Thread] INFO statemachine.DatanodeStateMachine: Ozone container server started.
datanode3_1  | 2022-07-10 13:10:50,281 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4871b9dc] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode3_1  | 2022-07-10 13:10:50,767 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.25.0.115:9891
datanode3_1  | 2022-07-10 13:10:50,839 [Datanode State Machine Task Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode3_1  | 2022-07-10 13:10:55,367 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO volume.HddsVolume: SchemaV3 db is created and loaded at /data/hdds/hdds/CID-f578972c-97f6-4a12-a46c-8eeea6081008/DS-e8324732-21e2-490f-8028-364ae40b012a/container.db for volume DS-e8324732-21e2-490f-8028-364ae40b012a
datanode3_1  | 2022-07-10 13:10:55,386 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO volume.HddsVolume: SchemaV3 db is stopped at /data/hdds/hdds/CID-f578972c-97f6-4a12-a46c-8eeea6081008/DS-e8324732-21e2-490f-8028-364ae40b012a/container.db for volume DS-e8324732-21e2-490f-8028-364ae40b012a
datanode3_1  | 2022-07-10 13:10:55,420 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode3_1  | 2022-07-10 13:10:55,424 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode3_1  | 2022-07-10 13:10:56,371 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis a1e412ee-75aa-4bf8-87bc-4e8e615b1959
datanode3_1  | 2022-07-10 13:10:56,663 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO server.RaftServer: a1e412ee-75aa-4bf8-87bc-4e8e615b1959: start RPC server
datanode3_1  | 2022-07-10 13:10:56,702 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO server.GrpcService: a1e412ee-75aa-4bf8-87bc-4e8e615b1959: GrpcService started, listening on 9856
datanode3_1  | 2022-07-10 13:10:56,706 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO server.GrpcService: a1e412ee-75aa-4bf8-87bc-4e8e615b1959: GrpcService started, listening on 9857
datanode3_1  | 2022-07-10 13:10:56,712 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO server.GrpcService: a1e412ee-75aa-4bf8-87bc-4e8e615b1959: GrpcService started, listening on 9858
datanode3_1  | 2022-07-10 13:10:56,758 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$388/0x00000008405dec40@494a6507] INFO util.JvmPauseMonitor: JvmPauseMonitor-a1e412ee-75aa-4bf8-87bc-4e8e615b1959: Started
datanode3_1  | 2022-07-10 13:10:56,762 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis a1e412ee-75aa-4bf8-87bc-4e8e615b1959 is started using port 9858 for RATIS
datanode3_1  | 2022-07-10 13:10:56,762 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis a1e412ee-75aa-4bf8-87bc-4e8e615b1959 is started using port 9857 for RATIS_ADMIN
datanode3_1  | 2022-07-10 13:10:56,762 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis a1e412ee-75aa-4bf8-87bc-4e8e615b1959 is started using port 9856 for RATIS_SERVER
datanode3_1  | 2022-07-10 13:10:56,856 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode3_1  | 2022-07-10 13:10:56,856 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode2_1  | 2022-07-10 13:11:02,600 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode2_1  | 2022-07-10 13:11:02,600 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode2_1  | 2022-07-10 13:11:02,601 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode2_1  | 2022-07-10 13:11:02,601 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode2_1  | 2022-07-10 13:11:02,613 [pool-23-thread-1] INFO server.RaftServer$Division: 992f3c0d-344e-4060-87f0-890ffe8b867e@group-F25D482AAF22: start as a follower, conf=-1: [992f3c0d-344e-4060-87f0-890ffe8b867e|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1], old=null
datanode2_1  | 2022-07-10 13:11:02,613 [pool-23-thread-1] INFO server.RaftServer$Division: 992f3c0d-344e-4060-87f0-890ffe8b867e@group-F25D482AAF22: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode2_1  | 2022-07-10 13:11:02,614 [pool-23-thread-1] INFO impl.RoleInfo: 992f3c0d-344e-4060-87f0-890ffe8b867e: start 992f3c0d-344e-4060-87f0-890ffe8b867e@group-F25D482AAF22-FollowerState
datanode2_1  | 2022-07-10 13:11:02,650 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-F25D482AAF22,id=992f3c0d-344e-4060-87f0-890ffe8b867e
datanode2_1  | 2022-07-10 13:11:02,748 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=b77b6ac4-c103-4125-90f3-f25d482aaf22
datanode2_1  | 2022-07-10 13:11:02,755 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=b77b6ac4-c103-4125-90f3-f25d482aaf22.
datanode2_1  | 2022-07-10 13:11:07,643 [992f3c0d-344e-4060-87f0-890ffe8b867e@group-F25D482AAF22-FollowerState] INFO impl.FollowerState: 992f3c0d-344e-4060-87f0-890ffe8b867e@group-F25D482AAF22-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5029282054ns, electionTimeout:5005ms
datanode2_1  | 2022-07-10 13:11:07,644 [992f3c0d-344e-4060-87f0-890ffe8b867e@group-F25D482AAF22-FollowerState] INFO impl.RoleInfo: 992f3c0d-344e-4060-87f0-890ffe8b867e: shutdown 992f3c0d-344e-4060-87f0-890ffe8b867e@group-F25D482AAF22-FollowerState
datanode2_1  | 2022-07-10 13:11:07,645 [992f3c0d-344e-4060-87f0-890ffe8b867e@group-F25D482AAF22-FollowerState] INFO server.RaftServer$Division: 992f3c0d-344e-4060-87f0-890ffe8b867e@group-F25D482AAF22: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode2_1  | 2022-07-10 13:11:07,648 [992f3c0d-344e-4060-87f0-890ffe8b867e@group-F25D482AAF22-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode2_1  | 2022-07-10 13:11:07,648 [992f3c0d-344e-4060-87f0-890ffe8b867e@group-F25D482AAF22-FollowerState] INFO impl.RoleInfo: 992f3c0d-344e-4060-87f0-890ffe8b867e: start 992f3c0d-344e-4060-87f0-890ffe8b867e@group-F25D482AAF22-LeaderElection1
datanode2_1  | 2022-07-10 13:11:07,672 [992f3c0d-344e-4060-87f0-890ffe8b867e@group-F25D482AAF22-LeaderElection1] INFO impl.LeaderElection: 992f3c0d-344e-4060-87f0-890ffe8b867e@group-F25D482AAF22-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [992f3c0d-344e-4060-87f0-890ffe8b867e|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1], old=null
datanode2_1  | 2022-07-10 13:11:07,673 [992f3c0d-344e-4060-87f0-890ffe8b867e@group-F25D482AAF22-LeaderElection1] INFO impl.LeaderElection: 992f3c0d-344e-4060-87f0-890ffe8b867e@group-F25D482AAF22-LeaderElection1 ELECTION round 0: result PASSED (term=1)
datanode2_1  | 2022-07-10 13:11:07,674 [992f3c0d-344e-4060-87f0-890ffe8b867e@group-F25D482AAF22-LeaderElection1] INFO impl.RoleInfo: 992f3c0d-344e-4060-87f0-890ffe8b867e: shutdown 992f3c0d-344e-4060-87f0-890ffe8b867e@group-F25D482AAF22-LeaderElection1
datanode2_1  | 2022-07-10 13:11:07,674 [992f3c0d-344e-4060-87f0-890ffe8b867e@group-F25D482AAF22-LeaderElection1] INFO server.RaftServer$Division: 992f3c0d-344e-4060-87f0-890ffe8b867e@group-F25D482AAF22: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode2_1  | 2022-07-10 13:11:07,674 [992f3c0d-344e-4060-87f0-890ffe8b867e@group-F25D482AAF22-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-F25D482AAF22 with new leaderId: 992f3c0d-344e-4060-87f0-890ffe8b867e
datanode2_1  | 2022-07-10 13:11:07,677 [992f3c0d-344e-4060-87f0-890ffe8b867e@group-F25D482AAF22-LeaderElection1] INFO server.RaftServer$Division: 992f3c0d-344e-4060-87f0-890ffe8b867e@group-F25D482AAF22: change Leader from null to 992f3c0d-344e-4060-87f0-890ffe8b867e at term 1 for becomeLeader, leader elected after 6195ms
datanode2_1  | 2022-07-10 13:11:07,738 [992f3c0d-344e-4060-87f0-890ffe8b867e@group-F25D482AAF22-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode2_1  | 2022-07-10 13:11:07,773 [992f3c0d-344e-4060-87f0-890ffe8b867e@group-F25D482AAF22-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode2_1  | 2022-07-10 13:11:07,784 [992f3c0d-344e-4060-87f0-890ffe8b867e@group-F25D482AAF22-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode2_1  | 2022-07-10 13:11:07,817 [992f3c0d-344e-4060-87f0-890ffe8b867e@group-F25D482AAF22-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode2_1  | 2022-07-10 13:11:07,844 [992f3c0d-344e-4060-87f0-890ffe8b867e@group-F25D482AAF22-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode2_1  | 2022-07-10 13:11:07,851 [992f3c0d-344e-4060-87f0-890ffe8b867e@group-F25D482AAF22-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode2_1  | 2022-07-10 13:11:07,886 [992f3c0d-344e-4060-87f0-890ffe8b867e@group-F25D482AAF22-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode2_1  | 2022-07-10 13:11:07,906 [992f3c0d-344e-4060-87f0-890ffe8b867e@group-F25D482AAF22-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
datanode2_1  | 2022-07-10 13:11:07,920 [992f3c0d-344e-4060-87f0-890ffe8b867e@group-F25D482AAF22-LeaderElection1] INFO impl.RoleInfo: 992f3c0d-344e-4060-87f0-890ffe8b867e: start 992f3c0d-344e-4060-87f0-890ffe8b867e@group-F25D482AAF22-LeaderStateImpl
datanode2_1  | 2022-07-10 13:11:07,995 [992f3c0d-344e-4060-87f0-890ffe8b867e@group-F25D482AAF22-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 992f3c0d-344e-4060-87f0-890ffe8b867e@group-F25D482AAF22-SegmentedRaftLogWorker: Starting segment from index:0
datanode2_1  | 2022-07-10 13:11:08,257 [992f3c0d-344e-4060-87f0-890ffe8b867e@group-F25D482AAF22-LeaderElection1] INFO server.RaftServer$Division: 992f3c0d-344e-4060-87f0-890ffe8b867e@group-F25D482AAF22: set configuration 0: [992f3c0d-344e-4060-87f0-890ffe8b867e|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1], old=null
datanode2_1  | 2022-07-10 13:11:08,551 [992f3c0d-344e-4060-87f0-890ffe8b867e@group-F25D482AAF22-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 992f3c0d-344e-4060-87f0-890ffe8b867e@group-F25D482AAF22-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/b77b6ac4-c103-4125-90f3-f25d482aaf22/current/log_inprogress_0
datanode2_1  | 2022-07-10 13:11:11,379 [grpc-default-executor-2] WARN server.GrpcServerProtocolService: 992f3c0d-344e-4060-87f0-890ffe8b867e: Failed requestVote a1e412ee-75aa-4bf8-87bc-4e8e615b1959->992f3c0d-344e-4060-87f0-890ffe8b867e#0
datanode2_1  | org.apache.ratis.protocol.exceptions.GroupMismatchException: 992f3c0d-344e-4060-87f0-890ffe8b867e: group-B841D041C364 not found.
datanode2_1  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:148)
datanode1_1  | 2022-07-10 13:11:12,019 [257634a0-3792-468a-a5a2-186b5a295fa1@group-6DC84A45F007-LeaderElection1] INFO impl.LeaderElection: 257634a0-3792-468a-a5a2-186b5a295fa1@group-6DC84A45F007-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [257634a0-3792-468a-a5a2-186b5a295fa1|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1], old=null
datanode1_1  | 2022-07-10 13:11:12,020 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode1_1  | 2022-07-10 13:11:12,023 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode1_1  | 2022-07-10 13:11:12,023 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode1_1  | 2022-07-10 13:11:12,025 [pool-23-thread-1] INFO server.RaftServer$Division: 257634a0-3792-468a-a5a2-186b5a295fa1@group-09A40F9F1D96: start as a follower, conf=-1: [992f3c0d-344e-4060-87f0-890ffe8b867e|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, a1e412ee-75aa-4bf8-87bc-4e8e615b1959|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, 257634a0-3792-468a-a5a2-186b5a295fa1|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0], old=null
datanode1_1  | 2022-07-10 13:11:12,025 [pool-23-thread-1] INFO server.RaftServer$Division: 257634a0-3792-468a-a5a2-186b5a295fa1@group-09A40F9F1D96: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode1_1  | 2022-07-10 13:11:12,025 [pool-23-thread-1] INFO impl.RoleInfo: 257634a0-3792-468a-a5a2-186b5a295fa1: start 257634a0-3792-468a-a5a2-186b5a295fa1@group-09A40F9F1D96-FollowerState
datanode1_1  | 2022-07-10 13:11:12,026 [257634a0-3792-468a-a5a2-186b5a295fa1@group-6DC84A45F007-LeaderElection1] INFO impl.LeaderElection: 257634a0-3792-468a-a5a2-186b5a295fa1@group-6DC84A45F007-LeaderElection1 ELECTION round 0: result PASSED (term=1)
datanode1_1  | 2022-07-10 13:11:12,026 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-09A40F9F1D96,id=257634a0-3792-468a-a5a2-186b5a295fa1
datanode1_1  | 2022-07-10 13:11:12,029 [257634a0-3792-468a-a5a2-186b5a295fa1@group-6DC84A45F007-LeaderElection1] INFO impl.RoleInfo: 257634a0-3792-468a-a5a2-186b5a295fa1: shutdown 257634a0-3792-468a-a5a2-186b5a295fa1@group-6DC84A45F007-LeaderElection1
datanode1_1  | 2022-07-10 13:11:12,030 [257634a0-3792-468a-a5a2-186b5a295fa1@group-6DC84A45F007-LeaderElection1] INFO server.RaftServer$Division: 257634a0-3792-468a-a5a2-186b5a295fa1@group-6DC84A45F007: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode1_1  | 2022-07-10 13:11:12,030 [257634a0-3792-468a-a5a2-186b5a295fa1@group-6DC84A45F007-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-6DC84A45F007 with new leaderId: 257634a0-3792-468a-a5a2-186b5a295fa1
datanode1_1  | 2022-07-10 13:11:12,035 [257634a0-3792-468a-a5a2-186b5a295fa1@group-6DC84A45F007-LeaderElection1] INFO server.RaftServer$Division: 257634a0-3792-468a-a5a2-186b5a295fa1@group-6DC84A45F007: change Leader from null to 257634a0-3792-468a-a5a2-186b5a295fa1 at term 1 for becomeLeader, leader elected after 6577ms
datanode1_1  | 2022-07-10 13:11:12,047 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=79d7f9ff-9479-4fdc-a3f9-09a40f9f1d96
datanode1_1  | 2022-07-10 13:11:12,051 [257634a0-3792-468a-a5a2-186b5a295fa1@group-6DC84A45F007-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode1_1  | 2022-07-10 13:11:12,080 [257634a0-3792-468a-a5a2-186b5a295fa1@group-6DC84A45F007-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode1_1  | 2022-07-10 13:11:12,083 [257634a0-3792-468a-a5a2-186b5a295fa1@group-6DC84A45F007-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode1_1  | 2022-07-10 13:11:12,187 [257634a0-3792-468a-a5a2-186b5a295fa1@group-6DC84A45F007-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode1_1  | 2022-07-10 13:11:12,187 [257634a0-3792-468a-a5a2-186b5a295fa1@group-6DC84A45F007-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode1_1  | 2022-07-10 13:11:12,232 [257634a0-3792-468a-a5a2-186b5a295fa1@group-6DC84A45F007-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode1_1  | 2022-07-10 13:11:12,345 [257634a0-3792-468a-a5a2-186b5a295fa1@group-6DC84A45F007-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode1_1  | 2022-07-10 13:11:12,389 [257634a0-3792-468a-a5a2-186b5a295fa1@group-6DC84A45F007-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
datanode1_1  | 2022-07-10 13:11:12,434 [257634a0-3792-468a-a5a2-186b5a295fa1@group-6DC84A45F007-LeaderElection1] INFO impl.RoleInfo: 257634a0-3792-468a-a5a2-186b5a295fa1: start 257634a0-3792-468a-a5a2-186b5a295fa1@group-6DC84A45F007-LeaderStateImpl
datanode1_1  | 2022-07-10 13:11:12,809 [257634a0-3792-468a-a5a2-186b5a295fa1@group-6DC84A45F007-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 257634a0-3792-468a-a5a2-186b5a295fa1@group-6DC84A45F007-SegmentedRaftLogWorker: Starting segment from index:0
datanode1_1  | 2022-07-10 13:11:13,043 [257634a0-3792-468a-a5a2-186b5a295fa1-server-thread1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-B841D041C364 with new leaderId: a1e412ee-75aa-4bf8-87bc-4e8e615b1959
datanode1_1  | 2022-07-10 13:11:13,052 [257634a0-3792-468a-a5a2-186b5a295fa1-server-thread1] INFO server.RaftServer$Division: 257634a0-3792-468a-a5a2-186b5a295fa1@group-B841D041C364: change Leader from null to a1e412ee-75aa-4bf8-87bc-4e8e615b1959 at term 1 for appendEntries, leader elected after 6142ms
datanode1_1  | 2022-07-10 13:11:13,284 [257634a0-3792-468a-a5a2-186b5a295fa1-server-thread1] INFO server.RaftServer$Division: 257634a0-3792-468a-a5a2-186b5a295fa1@group-B841D041C364: set configuration 0: [992f3c0d-344e-4060-87f0-890ffe8b867e|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1, a1e412ee-75aa-4bf8-87bc-4e8e615b1959|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 257634a0-3792-468a-a5a2-186b5a295fa1|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0], old=null
datanode1_1  | 2022-07-10 13:11:13,285 [257634a0-3792-468a-a5a2-186b5a295fa1-server-thread1] INFO segmented.SegmentedRaftLogWorker: 257634a0-3792-468a-a5a2-186b5a295fa1@group-B841D041C364-SegmentedRaftLogWorker: Starting segment from index:0
datanode1_1  | 2022-07-10 13:11:13,354 [257634a0-3792-468a-a5a2-186b5a295fa1@group-6DC84A45F007-LeaderElection1] INFO server.RaftServer$Division: 257634a0-3792-468a-a5a2-186b5a295fa1@group-6DC84A45F007: set configuration 0: [257634a0-3792-468a-a5a2-186b5a295fa1|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1], old=null
datanode1_1  | 2022-07-10 13:11:13,852 [257634a0-3792-468a-a5a2-186b5a295fa1@group-B841D041C364-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 257634a0-3792-468a-a5a2-186b5a295fa1@group-B841D041C364-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/199762fc-7613-447a-a2fc-b841d041c364/current/log_inprogress_0
datanode1_1  | 2022-07-10 13:11:13,887 [257634a0-3792-468a-a5a2-186b5a295fa1@group-6DC84A45F007-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 257634a0-3792-468a-a5a2-186b5a295fa1@group-6DC84A45F007-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/8d6e1a79-b70d-40e6-a234-6dc84a45f007/current/log_inprogress_0
datanode1_1  | 2022-07-10 13:11:14,647 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=79d7f9ff-9479-4fdc-a3f9-09a40f9f1d96.
datanode3_1  | 2022-07-10 13:11:01,543 [Command processor thread] INFO server.RaftServer: a1e412ee-75aa-4bf8-87bc-4e8e615b1959: addNew group-097F02077230:[a1e412ee-75aa-4bf8-87bc-4e8e615b1959|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1] returns group-097F02077230:java.util.concurrent.CompletableFuture@a603b43[Not completed]
datanode3_1  | 2022-07-10 13:11:01,670 [pool-23-thread-1] INFO server.RaftServer$Division: a1e412ee-75aa-4bf8-87bc-4e8e615b1959: new RaftServerImpl for group-097F02077230:[a1e412ee-75aa-4bf8-87bc-4e8e615b1959|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1] with ContainerStateMachine:uninitialized
datanode3_1  | 2022-07-10 13:11:01,712 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode3_1  | 2022-07-10 13:11:01,721 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode3_1  | 2022-07-10 13:11:01,727 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode3_1  | 2022-07-10 13:11:01,728 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode3_1  | 2022-07-10 13:11:01,735 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode3_1  | 2022-07-10 13:11:01,742 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode3_1  | 2022-07-10 13:11:01,796 [pool-23-thread-1] INFO server.RaftServer$Division: a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-097F02077230: ConfigurationManager, init=-1: [a1e412ee-75aa-4bf8-87bc-4e8e615b1959|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null, confs=<EMPTY_MAP>
datanode3_1  | 2022-07-10 13:11:01,799 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode3_1  | 2022-07-10 13:11:01,851 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode3_1  | 2022-07-10 13:11:01,861 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode3_1  | 2022-07-10 13:11:01,869 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/b1d72510-c7b3-4886-b6f1-097f02077230 does not exist. Creating ...
datanode3_1  | 2022-07-10 13:11:01,926 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/b1d72510-c7b3-4886-b6f1-097f02077230/in_use.lock acquired by nodename 6@377a412caf09
datanode3_1  | 2022-07-10 13:11:01,983 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/b1d72510-c7b3-4886-b6f1-097f02077230 has been successfully formatted.
datanode3_1  | 2022-07-10 13:11:02,113 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-097F02077230: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode3_1  | 2022-07-10 13:11:02,220 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode3_1  | 2022-07-10 13:11:02,221 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode3_1  | 2022-07-10 13:11:02,334 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode3_1  | 2022-07-10 13:11:02,364 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2022-07-10 13:11:02,368 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode3_1  | 2022-07-10 13:11:02,590 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2022-07-10 13:11:02,675 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode3_1  | 2022-07-10 13:11:02,683 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode3_1  | 2022-07-10 13:11:02,763 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-097F02077230-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/b1d72510-c7b3-4886-b6f1-097f02077230
datanode3_1  | 2022-07-10 13:11:02,764 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode3_1  | 2022-07-10 13:11:02,764 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode3_1  | 2022-07-10 13:11:02,776 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2022-07-10 13:11:02,776 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode3_1  | 2022-07-10 13:11:02,777 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode3_1  | 2022-07-10 13:11:02,778 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode3_1  | 2022-07-10 13:11:02,778 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode3_1  | 2022-07-10 13:11:02,778 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode3_1  | 2022-07-10 13:11:02,901 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode3_1  | 2022-07-10 13:11:02,902 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode3_1  | 2022-07-10 13:11:02,903 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode3_1  | 2022-07-10 13:11:02,982 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-097F02077230-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode3_1  | 2022-07-10 13:11:02,982 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-097F02077230-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode3_1  | 2022-07-10 13:11:03,027 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode3_1  | 2022-07-10 13:11:03,028 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode3_1  | 2022-07-10 13:11:03,028 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode3_1  | 2022-07-10 13:11:03,029 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode3_1  | 2022-07-10 13:11:03,030 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode3_1  | 2022-07-10 13:11:03,030 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode3_1  | 2022-07-10 13:11:03,251 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode3_1  | 2022-07-10 13:11:03,267 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode3_1  | 2022-07-10 13:11:03,274 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode3_1  | 2022-07-10 13:11:03,274 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode3_1  | 2022-07-10 13:11:03,279 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode3_1  | 2022-07-10 13:11:03,280 [pool-23-thread-1] INFO server.RaftServer$Division: a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-097F02077230: start as a follower, conf=-1: [a1e412ee-75aa-4bf8-87bc-4e8e615b1959|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null
datanode2_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:347)
datanode2_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:356)
datanode2_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:351)
datanode2_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.requestVote(RaftServerProxy.java:603)
datanode2_1  | 	at org.apache.ratis.grpc.server.GrpcServerProtocolService.requestVote(GrpcServerProtocolService.java:172)
datanode2_1  | 	at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$MethodHandlers.invoke(RaftServerProtocolServiceGrpc.java:382)
datanode2_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:182)
datanode2_1  | 	at org.apache.ratis.thirdparty.io.grpc.PartialForwardingServerCallListener.onHalfClose(PartialForwardingServerCallListener.java:35)
datanode2_1  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onHalfClose(ForwardingServerCallListener.java:23)
datanode2_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:340)
datanode2_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:866)
datanode2_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode2_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
datanode2_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode2_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode2_1  | 	at java.base/java.lang.Thread.run(Thread.java:829)
datanode2_1  | 2022-07-10 13:11:11,453 [grpc-default-executor-1] INFO server.RaftServer: 992f3c0d-344e-4060-87f0-890ffe8b867e: addNew group-B841D041C364:[992f3c0d-344e-4060-87f0-890ffe8b867e|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1, a1e412ee-75aa-4bf8-87bc-4e8e615b1959|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 257634a0-3792-468a-a5a2-186b5a295fa1|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0] returns group-B841D041C364:java.util.concurrent.CompletableFuture@3b87cc8c[Not completed]
datanode2_1  | 2022-07-10 13:11:11,460 [pool-23-thread-1] INFO server.RaftServer$Division: 992f3c0d-344e-4060-87f0-890ffe8b867e: new RaftServerImpl for group-B841D041C364:[992f3c0d-344e-4060-87f0-890ffe8b867e|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1, a1e412ee-75aa-4bf8-87bc-4e8e615b1959|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 257634a0-3792-468a-a5a2-186b5a295fa1|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0] with ContainerStateMachine:uninitialized
datanode2_1  | 2022-07-10 13:11:11,462 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode2_1  | 2022-07-10 13:11:11,462 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode2_1  | 2022-07-10 13:11:11,462 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode2_1  | 2022-07-10 13:11:11,462 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode2_1  | 2022-07-10 13:11:11,462 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode2_1  | 2022-07-10 13:11:11,462 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode2_1  | 2022-07-10 13:11:11,462 [pool-23-thread-1] INFO server.RaftServer$Division: 992f3c0d-344e-4060-87f0-890ffe8b867e@group-B841D041C364: ConfigurationManager, init=-1: [992f3c0d-344e-4060-87f0-890ffe8b867e|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1, a1e412ee-75aa-4bf8-87bc-4e8e615b1959|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 257634a0-3792-468a-a5a2-186b5a295fa1|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0], old=null, confs=<EMPTY_MAP>
datanode2_1  | 2022-07-10 13:11:11,463 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode2_1  | 2022-07-10 13:11:11,463 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode2_1  | 2022-07-10 13:11:11,463 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode2_1  | 2022-07-10 13:11:11,463 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/199762fc-7613-447a-a2fc-b841d041c364 does not exist. Creating ...
datanode2_1  | 2022-07-10 13:11:11,468 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/199762fc-7613-447a-a2fc-b841d041c364/in_use.lock acquired by nodename 7@f001020ea054
datanode2_1  | 2022-07-10 13:11:11,469 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/199762fc-7613-447a-a2fc-b841d041c364 has been successfully formatted.
datanode2_1  | 2022-07-10 13:11:11,473 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-B841D041C364: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode2_1  | 2022-07-10 13:11:11,473 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode2_1  | 2022-07-10 13:11:11,475 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode2_1  | 2022-07-10 13:11:11,476 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode2_1  | 2022-07-10 13:11:11,476 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2022-07-10 13:11:11,476 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode2_1  | 2022-07-10 13:11:11,476 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2022-07-10 13:11:11,477 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode2_1  | 2022-07-10 13:11:11,477 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode2_1  | 2022-07-10 13:11:11,477 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 992f3c0d-344e-4060-87f0-890ffe8b867e@group-B841D041C364-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/199762fc-7613-447a-a2fc-b841d041c364
datanode2_1  | 2022-07-10 13:11:11,478 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode2_1  | 2022-07-10 13:11:11,478 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode2_1  | 2022-07-10 13:11:11,478 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2022-07-10 13:11:11,478 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode2_1  | 2022-07-10 13:11:11,478 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode2_1  | 2022-07-10 13:11:11,479 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode3_1  | 2022-07-10 13:11:03,284 [pool-23-thread-1] INFO server.RaftServer$Division: a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-097F02077230: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode3_1  | 2022-07-10 13:11:03,295 [pool-23-thread-1] INFO impl.RoleInfo: a1e412ee-75aa-4bf8-87bc-4e8e615b1959: start a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-097F02077230-FollowerState
datanode3_1  | 2022-07-10 13:11:03,335 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-097F02077230,id=a1e412ee-75aa-4bf8-87bc-4e8e615b1959
datanode3_1  | 2022-07-10 13:11:03,394 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=b1d72510-c7b3-4886-b6f1-097f02077230
datanode3_1  | 2022-07-10 13:11:03,395 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=b1d72510-c7b3-4886-b6f1-097f02077230.
datanode3_1  | 2022-07-10 13:11:03,397 [Command processor thread] INFO server.RaftServer: a1e412ee-75aa-4bf8-87bc-4e8e615b1959: addNew group-B841D041C364:[992f3c0d-344e-4060-87f0-890ffe8b867e|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1, a1e412ee-75aa-4bf8-87bc-4e8e615b1959|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, 257634a0-3792-468a-a5a2-186b5a295fa1|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0] returns group-B841D041C364:java.util.concurrent.CompletableFuture@c513784[Not completed]
datanode3_1  | 2022-07-10 13:11:03,404 [pool-23-thread-1] INFO server.RaftServer$Division: a1e412ee-75aa-4bf8-87bc-4e8e615b1959: new RaftServerImpl for group-B841D041C364:[992f3c0d-344e-4060-87f0-890ffe8b867e|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1, a1e412ee-75aa-4bf8-87bc-4e8e615b1959|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, 257634a0-3792-468a-a5a2-186b5a295fa1|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0] with ContainerStateMachine:uninitialized
datanode3_1  | 2022-07-10 13:11:03,410 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode3_1  | 2022-07-10 13:11:03,412 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode3_1  | 2022-07-10 13:11:03,412 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode3_1  | 2022-07-10 13:11:03,412 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode3_1  | 2022-07-10 13:11:03,413 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode3_1  | 2022-07-10 13:11:03,413 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode3_1  | 2022-07-10 13:11:03,414 [pool-23-thread-1] INFO server.RaftServer$Division: a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364: ConfigurationManager, init=-1: [992f3c0d-344e-4060-87f0-890ffe8b867e|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1, a1e412ee-75aa-4bf8-87bc-4e8e615b1959|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, 257634a0-3792-468a-a5a2-186b5a295fa1|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0], old=null, confs=<EMPTY_MAP>
datanode3_1  | 2022-07-10 13:11:03,414 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode3_1  | 2022-07-10 13:11:03,414 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode3_1  | 2022-07-10 13:11:03,416 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode3_1  | 2022-07-10 13:11:03,419 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/199762fc-7613-447a-a2fc-b841d041c364 does not exist. Creating ...
datanode3_1  | 2022-07-10 13:11:03,422 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/199762fc-7613-447a-a2fc-b841d041c364/in_use.lock acquired by nodename 6@377a412caf09
datanode3_1  | 2022-07-10 13:11:03,428 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/199762fc-7613-447a-a2fc-b841d041c364 has been successfully formatted.
datanode3_1  | 2022-07-10 13:11:03,459 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-B841D041C364: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode3_1  | 2022-07-10 13:11:03,471 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode3_1  | 2022-07-10 13:11:03,474 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode3_1  | 2022-07-10 13:11:03,477 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode3_1  | 2022-07-10 13:11:03,477 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2022-07-10 13:11:03,481 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode3_1  | 2022-07-10 13:11:03,483 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2022-07-10 13:11:03,487 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode3_1  | 2022-07-10 13:11:03,491 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode3_1  | 2022-07-10 13:11:03,495 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/199762fc-7613-447a-a2fc-b841d041c364
datanode3_1  | 2022-07-10 13:11:03,495 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode3_1  | 2022-07-10 13:11:03,495 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode3_1  | 2022-07-10 13:11:03,495 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2022-07-10 13:11:03,495 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode3_1  | 2022-07-10 13:11:03,495 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode3_1  | 2022-07-10 13:11:03,495 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode3_1  | 2022-07-10 13:11:03,496 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode3_1  | 2022-07-10 13:11:03,496 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode3_1  | 2022-07-10 13:11:03,496 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode3_1  | 2022-07-10 13:11:03,497 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode3_1  | 2022-07-10 13:11:03,502 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode3_1  | 2022-07-10 13:11:03,505 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode1_1  | 2022-07-10 13:11:17,101 [257634a0-3792-468a-a5a2-186b5a295fa1@group-09A40F9F1D96-FollowerState] INFO impl.FollowerState: 257634a0-3792-468a-a5a2-186b5a295fa1@group-09A40F9F1D96-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5076045897ns, electionTimeout:5075ms
datanode1_1  | 2022-07-10 13:11:17,102 [257634a0-3792-468a-a5a2-186b5a295fa1@group-09A40F9F1D96-FollowerState] INFO impl.RoleInfo: 257634a0-3792-468a-a5a2-186b5a295fa1: shutdown 257634a0-3792-468a-a5a2-186b5a295fa1@group-09A40F9F1D96-FollowerState
datanode1_1  | 2022-07-10 13:11:17,102 [257634a0-3792-468a-a5a2-186b5a295fa1@group-09A40F9F1D96-FollowerState] INFO server.RaftServer$Division: 257634a0-3792-468a-a5a2-186b5a295fa1@group-09A40F9F1D96: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode1_1  | 2022-07-10 13:11:17,102 [257634a0-3792-468a-a5a2-186b5a295fa1@group-09A40F9F1D96-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode1_1  | 2022-07-10 13:11:17,102 [257634a0-3792-468a-a5a2-186b5a295fa1@group-09A40F9F1D96-FollowerState] INFO impl.RoleInfo: 257634a0-3792-468a-a5a2-186b5a295fa1: start 257634a0-3792-468a-a5a2-186b5a295fa1@group-09A40F9F1D96-LeaderElection2
datanode1_1  | 2022-07-10 13:11:17,107 [257634a0-3792-468a-a5a2-186b5a295fa1@group-09A40F9F1D96-LeaderElection2] INFO impl.LeaderElection: 257634a0-3792-468a-a5a2-186b5a295fa1@group-09A40F9F1D96-LeaderElection2 ELECTION round 0: submit vote requests at term 1 for -1: [992f3c0d-344e-4060-87f0-890ffe8b867e|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, a1e412ee-75aa-4bf8-87bc-4e8e615b1959|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, 257634a0-3792-468a-a5a2-186b5a295fa1|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0], old=null
datanode1_1  | 2022-07-10 13:11:17,454 [grpc-default-executor-0] INFO server.RaftServer$Division: 257634a0-3792-468a-a5a2-186b5a295fa1@group-09A40F9F1D96: receive requestVote(ELECTION, a1e412ee-75aa-4bf8-87bc-4e8e615b1959, group-09A40F9F1D96, 1, (t:0, i:0))
datanode1_1  | 2022-07-10 13:11:17,459 [grpc-default-executor-0] INFO impl.VoteContext: 257634a0-3792-468a-a5a2-186b5a295fa1@group-09A40F9F1D96-CANDIDATE: reject ELECTION from a1e412ee-75aa-4bf8-87bc-4e8e615b1959: already has voted for 257634a0-3792-468a-a5a2-186b5a295fa1 at current term 1
datanode1_1  | 2022-07-10 13:11:17,459 [grpc-default-executor-0] INFO server.RaftServer$Division: 257634a0-3792-468a-a5a2-186b5a295fa1@group-09A40F9F1D96 replies to ELECTION vote request: a1e412ee-75aa-4bf8-87bc-4e8e615b1959<-257634a0-3792-468a-a5a2-186b5a295fa1#0:FAIL-t1. Peer's state: 257634a0-3792-468a-a5a2-186b5a295fa1@group-09A40F9F1D96:t1, leader=null, voted=257634a0-3792-468a-a5a2-186b5a295fa1, raftlog=257634a0-3792-468a-a5a2-186b5a295fa1@group-09A40F9F1D96-SegmentedRaftLog:OPENED:c-1, conf=-1: [992f3c0d-344e-4060-87f0-890ffe8b867e|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, a1e412ee-75aa-4bf8-87bc-4e8e615b1959|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, 257634a0-3792-468a-a5a2-186b5a295fa1|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0], old=null
datanode1_1  | 2022-07-10 13:11:17,585 [257634a0-3792-468a-a5a2-186b5a295fa1-server-thread1] INFO server.RaftServer$Division: 257634a0-3792-468a-a5a2-186b5a295fa1@group-09A40F9F1D96: changes role from CANDIDATE to FOLLOWER at term 1 for appendEntries
datanode1_1  | 2022-07-10 13:11:17,591 [257634a0-3792-468a-a5a2-186b5a295fa1-server-thread1] INFO impl.RoleInfo: 257634a0-3792-468a-a5a2-186b5a295fa1: shutdown 257634a0-3792-468a-a5a2-186b5a295fa1@group-09A40F9F1D96-LeaderElection2
datanode1_1  | 2022-07-10 13:11:17,591 [257634a0-3792-468a-a5a2-186b5a295fa1-server-thread1] INFO impl.RoleInfo: 257634a0-3792-468a-a5a2-186b5a295fa1: start 257634a0-3792-468a-a5a2-186b5a295fa1@group-09A40F9F1D96-FollowerState
datanode1_1  | 2022-07-10 13:11:17,596 [257634a0-3792-468a-a5a2-186b5a295fa1-server-thread1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-09A40F9F1D96 with new leaderId: a1e412ee-75aa-4bf8-87bc-4e8e615b1959
datanode1_1  | 2022-07-10 13:11:17,596 [257634a0-3792-468a-a5a2-186b5a295fa1-server-thread1] INFO server.RaftServer$Division: 257634a0-3792-468a-a5a2-186b5a295fa1@group-09A40F9F1D96: change Leader from null to a1e412ee-75aa-4bf8-87bc-4e8e615b1959 at term 1 for appendEntries, leader elected after 5743ms
datanode1_1  | 2022-07-10 13:11:17,636 [257634a0-3792-468a-a5a2-186b5a295fa1-server-thread1] INFO server.RaftServer$Division: 257634a0-3792-468a-a5a2-186b5a295fa1@group-09A40F9F1D96: set configuration 0: [992f3c0d-344e-4060-87f0-890ffe8b867e|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, a1e412ee-75aa-4bf8-87bc-4e8e615b1959|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 257634a0-3792-468a-a5a2-186b5a295fa1|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0], old=null
datanode1_1  | 2022-07-10 13:11:17,641 [257634a0-3792-468a-a5a2-186b5a295fa1-server-thread1] INFO segmented.SegmentedRaftLogWorker: 257634a0-3792-468a-a5a2-186b5a295fa1@group-09A40F9F1D96-SegmentedRaftLogWorker: Starting segment from index:0
datanode1_1  | 2022-07-10 13:11:17,645 [257634a0-3792-468a-a5a2-186b5a295fa1@group-09A40F9F1D96-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 257634a0-3792-468a-a5a2-186b5a295fa1@group-09A40F9F1D96-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/79d7f9ff-9479-4fdc-a3f9-09a40f9f1d96/current/log_inprogress_0
datanode1_1  | 2022-07-10 13:11:17,696 [257634a0-3792-468a-a5a2-186b5a295fa1@group-09A40F9F1D96-LeaderElection2] INFO impl.LeaderElection: 257634a0-3792-468a-a5a2-186b5a295fa1@group-09A40F9F1D96-LeaderElection2: ELECTION REJECTED received 2 response(s) and 0 exception(s):
datanode1_1  | 2022-07-10 13:11:17,696 [257634a0-3792-468a-a5a2-186b5a295fa1@group-09A40F9F1D96-LeaderElection2] INFO impl.LeaderElection:   Response 0: 257634a0-3792-468a-a5a2-186b5a295fa1<-992f3c0d-344e-4060-87f0-890ffe8b867e#0:FAIL-t1
datanode1_1  | 2022-07-10 13:11:17,696 [257634a0-3792-468a-a5a2-186b5a295fa1@group-09A40F9F1D96-LeaderElection2] INFO impl.LeaderElection:   Response 1: 257634a0-3792-468a-a5a2-186b5a295fa1<-a1e412ee-75aa-4bf8-87bc-4e8e615b1959#0:FAIL-t1
datanode1_1  | 2022-07-10 13:11:17,697 [257634a0-3792-468a-a5a2-186b5a295fa1@group-09A40F9F1D96-LeaderElection2] INFO impl.LeaderElection: 257634a0-3792-468a-a5a2-186b5a295fa1@group-09A40F9F1D96-LeaderElection2 ELECTION round 0: result REJECTED
datanode1_1  | 2022-07-10 13:11:18,162 [grpc-default-executor-1] INFO server.GrpcServerProtocolService: 257634a0-3792-468a-a5a2-186b5a295fa1: Completed APPEND_ENTRIES, lastRequest: a1e412ee-75aa-4bf8-87bc-4e8e615b1959->257634a0-3792-468a-a5a2-186b5a295fa1#1-t1,previous=(t:0, i:0),leaderCommit=0,initializing? true,entries: size=1, first=(t:1, i:0), CONFIGURATIONENTRY
datanode1_1  | 2022-07-10 13:11:18,828 [grpc-default-executor-1] INFO server.RaftServer$Division: 257634a0-3792-468a-a5a2-186b5a295fa1@group-B841D041C364: receive requestVote(ELECTION, 992f3c0d-344e-4060-87f0-890ffe8b867e, group-B841D041C364, 2, (t:1, i:0))
datanode1_1  | 2022-07-10 13:11:18,829 [grpc-default-executor-1] INFO impl.VoteContext: 257634a0-3792-468a-a5a2-186b5a295fa1@group-B841D041C364-FOLLOWER: accept ELECTION from 992f3c0d-344e-4060-87f0-890ffe8b867e: our priority 0 <= candidate's priority 1
datanode1_1  | 2022-07-10 13:11:18,829 [grpc-default-executor-1] INFO server.RaftServer$Division: 257634a0-3792-468a-a5a2-186b5a295fa1@group-B841D041C364: change Leader from a1e412ee-75aa-4bf8-87bc-4e8e615b1959 to null at term 2 for updateCurrentTerm
datanode1_1  | 2022-07-10 13:11:18,829 [grpc-default-executor-1] INFO server.RaftServer$Division: 257634a0-3792-468a-a5a2-186b5a295fa1@group-B841D041C364: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:992f3c0d-344e-4060-87f0-890ffe8b867e
datanode1_1  | 2022-07-10 13:11:18,829 [grpc-default-executor-1] INFO impl.RoleInfo: 257634a0-3792-468a-a5a2-186b5a295fa1: shutdown 257634a0-3792-468a-a5a2-186b5a295fa1@group-B841D041C364-FollowerState
datanode1_1  | 2022-07-10 13:11:18,829 [257634a0-3792-468a-a5a2-186b5a295fa1@group-B841D041C364-FollowerState] INFO impl.FollowerState: 257634a0-3792-468a-a5a2-186b5a295fa1@group-B841D041C364-FollowerState was interrupted
datanode1_1  | 2022-07-10 13:11:18,830 [grpc-default-executor-1] INFO impl.RoleInfo: 257634a0-3792-468a-a5a2-186b5a295fa1: start 257634a0-3792-468a-a5a2-186b5a295fa1@group-B841D041C364-FollowerState
datanode1_1  | 2022-07-10 13:11:18,833 [grpc-default-executor-1] INFO server.RaftServer$Division: 257634a0-3792-468a-a5a2-186b5a295fa1@group-B841D041C364 replies to ELECTION vote request: 992f3c0d-344e-4060-87f0-890ffe8b867e<-257634a0-3792-468a-a5a2-186b5a295fa1#0:OK-t2. Peer's state: 257634a0-3792-468a-a5a2-186b5a295fa1@group-B841D041C364:t2, leader=null, voted=992f3c0d-344e-4060-87f0-890ffe8b867e, raftlog=257634a0-3792-468a-a5a2-186b5a295fa1@group-B841D041C364-SegmentedRaftLog:OPENED:c0, conf=0: [992f3c0d-344e-4060-87f0-890ffe8b867e|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1, a1e412ee-75aa-4bf8-87bc-4e8e615b1959|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 257634a0-3792-468a-a5a2-186b5a295fa1|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0], old=null
datanode1_1  | 2022-07-10 13:11:19,152 [257634a0-3792-468a-a5a2-186b5a295fa1-server-thread2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-B841D041C364 with new leaderId: 992f3c0d-344e-4060-87f0-890ffe8b867e
datanode1_1  | 2022-07-10 13:11:19,153 [257634a0-3792-468a-a5a2-186b5a295fa1-server-thread2] INFO server.RaftServer$Division: 257634a0-3792-468a-a5a2-186b5a295fa1@group-B841D041C364: change Leader from null to 992f3c0d-344e-4060-87f0-890ffe8b867e at term 2 for appendEntries, leader elected after 323ms
datanode1_1  | 2022-07-10 13:11:19,290 [257634a0-3792-468a-a5a2-186b5a295fa1-server-thread2] INFO server.RaftServer$Division: 257634a0-3792-468a-a5a2-186b5a295fa1@group-B841D041C364: set configuration 1: [992f3c0d-344e-4060-87f0-890ffe8b867e|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1, a1e412ee-75aa-4bf8-87bc-4e8e615b1959|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 257634a0-3792-468a-a5a2-186b5a295fa1|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0], old=null
datanode1_1  | 2022-07-10 13:11:19,292 [257634a0-3792-468a-a5a2-186b5a295fa1-server-thread2] INFO segmented.SegmentedRaftLogWorker: 257634a0-3792-468a-a5a2-186b5a295fa1@group-B841D041C364-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
datanode1_1  | 2022-07-10 13:11:19,294 [257634a0-3792-468a-a5a2-186b5a295fa1@group-B841D041C364-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 257634a0-3792-468a-a5a2-186b5a295fa1@group-B841D041C364-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/ratis/199762fc-7613-447a-a2fc-b841d041c364/current/log_inprogress_0 to /data/metadata/ratis/199762fc-7613-447a-a2fc-b841d041c364/current/log_0-0
datanode1_1  | 2022-07-10 13:11:19,321 [257634a0-3792-468a-a5a2-186b5a295fa1@group-B841D041C364-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 257634a0-3792-468a-a5a2-186b5a295fa1@group-B841D041C364-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/199762fc-7613-447a-a2fc-b841d041c364/current/log_inprogress_1
datanode1_1  | 2022-07-10 13:11:58,534 [ChunkWriter-1-0] INFO client.DNCertificateClient: Getting certificate with certSerialId:941638739763.
datanode1_1  | 2022-07-10 13:22:42,379 [ContainerOp-79d7f9ff-9479-4fdc-a3f9-09a40f9f1d96-5] INFO keyvalue.KeyValueContainer: Container 1 is synced with bcsId 105.
datanode1_1  | 2022-07-10 13:22:42,382 [ContainerOp-79d7f9ff-9479-4fdc-a3f9-09a40f9f1d96-5] INFO keyvalue.KeyValueContainer: Container 1 is synced with bcsId 105.
datanode1_1  | 2022-07-10 13:22:42,445 [ContainerOp-79d7f9ff-9479-4fdc-a3f9-09a40f9f1d96-5] INFO keyvalue.KeyValueContainer: Container 1 is closed with bcsId 105.
datanode2_1  | 2022-07-10 13:11:11,479 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode2_1  | 2022-07-10 13:11:11,479 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode2_1  | 2022-07-10 13:11:11,480 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode2_1  | 2022-07-10 13:11:11,492 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode2_1  | 2022-07-10 13:11:11,493 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode2_1  | 2022-07-10 13:11:11,494 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 992f3c0d-344e-4060-87f0-890ffe8b867e@group-B841D041C364-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode2_1  | 2022-07-10 13:11:11,508 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 992f3c0d-344e-4060-87f0-890ffe8b867e@group-B841D041C364-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode2_1  | 2022-07-10 13:11:11,538 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode2_1  | 2022-07-10 13:11:11,538 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode2_1  | 2022-07-10 13:11:11,538 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode2_1  | 2022-07-10 13:11:11,538 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode2_1  | 2022-07-10 13:11:11,539 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode2_1  | 2022-07-10 13:11:11,539 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode2_1  | 2022-07-10 13:11:11,540 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode2_1  | 2022-07-10 13:11:11,541 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode2_1  | 2022-07-10 13:11:11,542 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode2_1  | 2022-07-10 13:11:11,543 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode2_1  | 2022-07-10 13:11:11,543 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode2_1  | 2022-07-10 13:11:11,543 [pool-23-thread-1] INFO server.RaftServer$Division: 992f3c0d-344e-4060-87f0-890ffe8b867e@group-B841D041C364: start as a follower, conf=-1: [992f3c0d-344e-4060-87f0-890ffe8b867e|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1, a1e412ee-75aa-4bf8-87bc-4e8e615b1959|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 257634a0-3792-468a-a5a2-186b5a295fa1|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0], old=null
datanode2_1  | 2022-07-10 13:11:11,543 [pool-23-thread-1] INFO server.RaftServer$Division: 992f3c0d-344e-4060-87f0-890ffe8b867e@group-B841D041C364: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode2_1  | 2022-07-10 13:11:11,546 [pool-23-thread-1] INFO impl.RoleInfo: 992f3c0d-344e-4060-87f0-890ffe8b867e: start 992f3c0d-344e-4060-87f0-890ffe8b867e@group-B841D041C364-FollowerState
datanode2_1  | 2022-07-10 13:11:11,556 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-B841D041C364,id=992f3c0d-344e-4060-87f0-890ffe8b867e
datanode2_1  | 2022-07-10 13:11:12,758 [992f3c0d-344e-4060-87f0-890ffe8b867e-server-thread1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-B841D041C364 with new leaderId: a1e412ee-75aa-4bf8-87bc-4e8e615b1959
datanode2_1  | 2022-07-10 13:11:12,769 [992f3c0d-344e-4060-87f0-890ffe8b867e-server-thread1] INFO server.RaftServer$Division: 992f3c0d-344e-4060-87f0-890ffe8b867e@group-B841D041C364: change Leader from null to a1e412ee-75aa-4bf8-87bc-4e8e615b1959 at term 1 for appendEntries, leader elected after 1284ms
datanode2_1  | 2022-07-10 13:11:12,996 [992f3c0d-344e-4060-87f0-890ffe8b867e-server-thread1] INFO server.RaftServer$Division: 992f3c0d-344e-4060-87f0-890ffe8b867e@group-B841D041C364: set configuration 0: [992f3c0d-344e-4060-87f0-890ffe8b867e|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1, a1e412ee-75aa-4bf8-87bc-4e8e615b1959|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 257634a0-3792-468a-a5a2-186b5a295fa1|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0], old=null
datanode2_1  | 2022-07-10 13:11:13,002 [992f3c0d-344e-4060-87f0-890ffe8b867e-server-thread1] INFO segmented.SegmentedRaftLogWorker: 992f3c0d-344e-4060-87f0-890ffe8b867e@group-B841D041C364-SegmentedRaftLogWorker: Starting segment from index:0
datanode2_1  | 2022-07-10 13:11:13,019 [992f3c0d-344e-4060-87f0-890ffe8b867e@group-B841D041C364-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 992f3c0d-344e-4060-87f0-890ffe8b867e@group-B841D041C364-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/199762fc-7613-447a-a2fc-b841d041c364/current/log_inprogress_0
datanode2_1  | 2022-07-10 13:11:14,244 [grpc-default-executor-2] INFO server.RaftServer: 992f3c0d-344e-4060-87f0-890ffe8b867e: addNew group-09A40F9F1D96:[992f3c0d-344e-4060-87f0-890ffe8b867e|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, a1e412ee-75aa-4bf8-87bc-4e8e615b1959|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 257634a0-3792-468a-a5a2-186b5a295fa1|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0] returns group-09A40F9F1D96:java.util.concurrent.CompletableFuture@33a4f20a[Not completed]
datanode2_1  | 2022-07-10 13:11:14,246 [pool-23-thread-1] INFO server.RaftServer$Division: 992f3c0d-344e-4060-87f0-890ffe8b867e: new RaftServerImpl for group-09A40F9F1D96:[992f3c0d-344e-4060-87f0-890ffe8b867e|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, a1e412ee-75aa-4bf8-87bc-4e8e615b1959|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 257634a0-3792-468a-a5a2-186b5a295fa1|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0] with ContainerStateMachine:uninitialized
datanode2_1  | 2022-07-10 13:11:14,248 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode2_1  | 2022-07-10 13:11:14,249 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode2_1  | 2022-07-10 13:11:14,249 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode2_1  | 2022-07-10 13:11:14,249 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode2_1  | 2022-07-10 13:11:14,249 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode2_1  | 2022-07-10 13:11:14,250 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
kdc_1        | Jul 10 13:08:38 kdc krb5kdc[8](info): Loaded
kdc_1        | Jul 10 13:08:38 kdc krb5kdc[8](Error): preauth spake failed to initialize: No SPAKE preauth groups configured
kdc_1        | Jul 10 13:08:38 kdc krb5kdc[8](info): setting up network...
kdc_1        | Jul 10 13:08:38 kdc krb5kdc[8](info): setsockopt(8,IPV6_V6ONLY,1) worked
kdc_1        | Jul 10 13:08:38 kdc krb5kdc[8](info): setsockopt(10,IPV6_V6ONLY,1) worked
kdc_1        | Jul 10 13:08:38 kdc krb5kdc[8](info): set up 4 sockets
kdc_1        | Jul 10 13:08:38 kdc krb5kdc[8](info): commencing operation
kdc_1        | krb5kdc: starting...
kdc_1        | Jul 10 13:08:41 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1657458521, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 10 13:08:47 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1657458527, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 10 13:08:51 kdc krb5kdc[8](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.114: ISSUE: authtime 1657458531, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, s3g/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 10 13:08:53 kdc krb5kdc[8](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.115: ISSUE: authtime 1657458533, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, recon/recon@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 10 13:09:04 kdc krb5kdc[8](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.117: ISSUE: authtime 1657458544, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 10 13:09:11 kdc krb5kdc[8](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.116: ISSUE: authtime 1657458551, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 10 13:09:15 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657458527, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jul 10 13:09:16 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: ISSUE: authtime 1657458533, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, recon/recon@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jul 10 13:09:17 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1657458544, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jul 10 13:09:25 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1657458565, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 10 13:09:31 kdc krb5kdc[8](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.117: ISSUE: authtime 1657458571, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 10 13:09:35 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657458565, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jul 10 13:09:39 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1657458579, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 10 13:09:41 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1657458571, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jul 10 13:09:45 kdc krb5kdc[8](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.118: ISSUE: authtime 1657458585, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 10 13:09:46 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.118: ISSUE: authtime 1657458585, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jul 10 13:09:49 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657458579, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
datanode2_1  | 2022-07-10 13:11:14,251 [pool-23-thread-1] INFO server.RaftServer$Division: 992f3c0d-344e-4060-87f0-890ffe8b867e@group-09A40F9F1D96: ConfigurationManager, init=-1: [992f3c0d-344e-4060-87f0-890ffe8b867e|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, a1e412ee-75aa-4bf8-87bc-4e8e615b1959|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 257634a0-3792-468a-a5a2-186b5a295fa1|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0], old=null, confs=<EMPTY_MAP>
datanode2_1  | 2022-07-10 13:11:14,252 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode2_1  | 2022-07-10 13:11:14,253 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode2_1  | 2022-07-10 13:11:14,253 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode2_1  | 2022-07-10 13:11:14,255 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/79d7f9ff-9479-4fdc-a3f9-09a40f9f1d96 does not exist. Creating ...
datanode2_1  | 2022-07-10 13:11:14,259 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/79d7f9ff-9479-4fdc-a3f9-09a40f9f1d96/in_use.lock acquired by nodename 7@f001020ea054
datanode2_1  | 2022-07-10 13:11:14,279 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/79d7f9ff-9479-4fdc-a3f9-09a40f9f1d96 has been successfully formatted.
datanode2_1  | 2022-07-10 13:11:14,287 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-09A40F9F1D96: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode2_1  | 2022-07-10 13:11:14,289 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode2_1  | 2022-07-10 13:11:14,290 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode2_1  | 2022-07-10 13:11:14,290 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode2_1  | 2022-07-10 13:11:14,290 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2022-07-10 13:11:14,290 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode2_1  | 2022-07-10 13:11:14,291 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2022-07-10 13:11:14,291 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode2_1  | 2022-07-10 13:11:14,291 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode2_1  | 2022-07-10 13:11:14,292 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 992f3c0d-344e-4060-87f0-890ffe8b867e@group-09A40F9F1D96-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/79d7f9ff-9479-4fdc-a3f9-09a40f9f1d96
datanode2_1  | 2022-07-10 13:11:14,292 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode2_1  | 2022-07-10 13:11:14,294 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode2_1  | 2022-07-10 13:11:14,297 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2022-07-10 13:11:14,297 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode2_1  | 2022-07-10 13:11:14,298 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode2_1  | 2022-07-10 13:11:14,298 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode2_1  | 2022-07-10 13:11:14,314 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode2_1  | 2022-07-10 13:11:14,314 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode2_1  | 2022-07-10 13:11:14,316 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode2_1  | 2022-07-10 13:11:14,321 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode2_1  | 2022-07-10 13:11:14,323 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode2_1  | 2022-07-10 13:11:14,328 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 992f3c0d-344e-4060-87f0-890ffe8b867e@group-09A40F9F1D96-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode2_1  | 2022-07-10 13:11:14,328 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 992f3c0d-344e-4060-87f0-890ffe8b867e@group-09A40F9F1D96-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode2_1  | 2022-07-10 13:11:14,331 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode2_1  | 2022-07-10 13:11:14,332 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode2_1  | 2022-07-10 13:11:14,333 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode2_1  | 2022-07-10 13:11:14,333 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode2_1  | 2022-07-10 13:11:14,491 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode2_1  | 2022-07-10 13:11:14,491 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode2_1  | 2022-07-10 13:11:14,554 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode2_1  | 2022-07-10 13:11:14,601 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode2_1  | 2022-07-10 13:11:14,604 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode2_1  | 2022-07-10 13:11:14,605 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode2_1  | 2022-07-10 13:11:14,605 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode2_1  | 2022-07-10 13:11:14,605 [pool-23-thread-1] INFO server.RaftServer$Division: 992f3c0d-344e-4060-87f0-890ffe8b867e@group-09A40F9F1D96: start as a follower, conf=-1: [992f3c0d-344e-4060-87f0-890ffe8b867e|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, a1e412ee-75aa-4bf8-87bc-4e8e615b1959|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 257634a0-3792-468a-a5a2-186b5a295fa1|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0], old=null
datanode2_1  | 2022-07-10 13:11:14,606 [pool-23-thread-1] INFO server.RaftServer$Division: 992f3c0d-344e-4060-87f0-890ffe8b867e@group-09A40F9F1D96: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode2_1  | 2022-07-10 13:11:14,608 [pool-23-thread-1] INFO impl.RoleInfo: 992f3c0d-344e-4060-87f0-890ffe8b867e: start 992f3c0d-344e-4060-87f0-890ffe8b867e@group-09A40F9F1D96-FollowerState
datanode2_1  | 2022-07-10 13:11:14,608 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-09A40F9F1D96,id=992f3c0d-344e-4060-87f0-890ffe8b867e
datanode2_1  | 2022-07-10 13:11:17,340 [grpc-default-executor-2] INFO server.RaftServer$Division: 992f3c0d-344e-4060-87f0-890ffe8b867e@group-09A40F9F1D96: receive requestVote(ELECTION, a1e412ee-75aa-4bf8-87bc-4e8e615b1959, group-09A40F9F1D96, 1, (t:0, i:0))
datanode3_1  | 2022-07-10 13:11:03,507 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode3_1  | 2022-07-10 13:11:03,524 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode3_1  | 2022-07-10 13:11:03,524 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode3_1  | 2022-07-10 13:11:03,525 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode3_1  | 2022-07-10 13:11:03,525 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode3_1  | 2022-07-10 13:11:03,525 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode3_1  | 2022-07-10 13:11:03,525 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode3_1  | 2022-07-10 13:11:03,526 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode3_1  | 2022-07-10 13:11:03,527 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode3_1  | 2022-07-10 13:11:03,527 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode3_1  | 2022-07-10 13:11:03,527 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode3_1  | 2022-07-10 13:11:03,527 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode3_1  | 2022-07-10 13:11:03,528 [pool-23-thread-1] INFO server.RaftServer$Division: a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364: start as a follower, conf=-1: [992f3c0d-344e-4060-87f0-890ffe8b867e|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1, a1e412ee-75aa-4bf8-87bc-4e8e615b1959|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, 257634a0-3792-468a-a5a2-186b5a295fa1|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0], old=null
datanode3_1  | 2022-07-10 13:11:03,530 [pool-23-thread-1] INFO server.RaftServer$Division: a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode3_1  | 2022-07-10 13:11:03,531 [pool-23-thread-1] INFO impl.RoleInfo: a1e412ee-75aa-4bf8-87bc-4e8e615b1959: start a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364-FollowerState
datanode3_1  | 2022-07-10 13:11:03,542 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-B841D041C364,id=a1e412ee-75aa-4bf8-87bc-4e8e615b1959
datanode3_1  | 2022-07-10 13:11:03,545 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=199762fc-7613-447a-a2fc-b841d041c364
datanode3_1  | 2022-07-10 13:11:08,403 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-097F02077230-FollowerState] INFO impl.FollowerState: a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-097F02077230-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5108232845ns, electionTimeout:5087ms
datanode3_1  | 2022-07-10 13:11:08,404 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-097F02077230-FollowerState] INFO impl.RoleInfo: a1e412ee-75aa-4bf8-87bc-4e8e615b1959: shutdown a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-097F02077230-FollowerState
datanode3_1  | 2022-07-10 13:11:08,404 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-097F02077230-FollowerState] INFO server.RaftServer$Division: a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-097F02077230: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode3_1  | 2022-07-10 13:11:08,408 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-097F02077230-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode3_1  | 2022-07-10 13:11:08,408 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-097F02077230-FollowerState] INFO impl.RoleInfo: a1e412ee-75aa-4bf8-87bc-4e8e615b1959: start a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-097F02077230-LeaderElection1
datanode3_1  | 2022-07-10 13:11:08,431 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-097F02077230-LeaderElection1] INFO impl.LeaderElection: a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-097F02077230-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [a1e412ee-75aa-4bf8-87bc-4e8e615b1959|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null
datanode3_1  | 2022-07-10 13:11:08,432 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-097F02077230-LeaderElection1] INFO impl.LeaderElection: a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-097F02077230-LeaderElection1 ELECTION round 0: result PASSED (term=1)
datanode3_1  | 2022-07-10 13:11:08,439 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-097F02077230-LeaderElection1] INFO impl.RoleInfo: a1e412ee-75aa-4bf8-87bc-4e8e615b1959: shutdown a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-097F02077230-LeaderElection1
datanode3_1  | 2022-07-10 13:11:08,443 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-097F02077230-LeaderElection1] INFO server.RaftServer$Division: a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-097F02077230: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode3_1  | 2022-07-10 13:11:08,444 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-097F02077230-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-097F02077230 with new leaderId: a1e412ee-75aa-4bf8-87bc-4e8e615b1959
datanode3_1  | 2022-07-10 13:11:08,444 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-097F02077230-LeaderElection1] INFO server.RaftServer$Division: a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-097F02077230: change Leader from null to a1e412ee-75aa-4bf8-87bc-4e8e615b1959 at term 1 for becomeLeader, leader elected after 6224ms
datanode3_1  | 2022-07-10 13:11:08,502 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-097F02077230-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode3_1  | 2022-07-10 13:11:08,528 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-097F02077230-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode3_1  | 2022-07-10 13:11:08,536 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-097F02077230-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode3_1  | 2022-07-10 13:11:08,571 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-097F02077230-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode3_1  | 2022-07-10 13:11:08,577 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-097F02077230-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode3_1  | 2022-07-10 13:11:08,581 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-097F02077230-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode3_1  | 2022-07-10 13:11:08,620 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-097F02077230-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode3_1  | 2022-07-10 13:11:08,632 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-097F02077230-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
datanode3_1  | 2022-07-10 13:11:08,667 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-097F02077230-LeaderElection1] INFO impl.RoleInfo: a1e412ee-75aa-4bf8-87bc-4e8e615b1959: start a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-097F02077230-LeaderStateImpl
kdc_1        | Jul 10 13:09:52 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1657458592, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 10 13:09:53 kdc krb5kdc[8](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.118: ISSUE: authtime 1657458593, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 10 13:09:59 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657458592, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jul 10 13:10:00 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.118: ISSUE: authtime 1657458593, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jul 10 13:10:03 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1657458603, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 10 13:10:18 kdc krb5kdc[8](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.104: ISSUE: authtime 1657458618, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 10 13:10:18 kdc krb5kdc[8](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.102: ISSUE: authtime 1657458618, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 10 13:10:18 kdc krb5kdc[8](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.103: ISSUE: authtime 1657458618, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 10 13:10:22 kdc krb5kdc[8](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.113: ISSUE: authtime 1657458622, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 10 13:10:23 kdc krb5kdc[8](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.111: ISSUE: authtime 1657458623, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 10 13:10:23 kdc krb5kdc[8](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.112: ISSUE: authtime 1657458623, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 10 13:10:25 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.113: ISSUE: authtime 1657458622, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jul 10 13:10:25 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.111: ISSUE: authtime 1657458623, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jul 10 13:10:27 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.112: ISSUE: authtime 1657458623, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jul 10 13:10:28 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.103: ISSUE: authtime 1657458618, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jul 10 13:10:28 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.104: ISSUE: authtime 1657458618, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jul 10 13:10:31 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.102: ISSUE: authtime 1657458618, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jul 10 13:10:33 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657458603, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jul 10 13:10:39 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1657458639, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 10 13:10:52 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.104: ISSUE: authtime 1657458618, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for recon/recon@EXAMPLE.COM
datanode3_1  | 2022-07-10 13:11:08,734 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364-FollowerState] INFO impl.FollowerState: a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5203170682ns, electionTimeout:5190ms
datanode3_1  | 2022-07-10 13:11:08,743 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364-FollowerState] INFO impl.RoleInfo: a1e412ee-75aa-4bf8-87bc-4e8e615b1959: shutdown a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364-FollowerState
datanode3_1  | 2022-07-10 13:11:08,750 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364-FollowerState] INFO server.RaftServer$Division: a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode3_1  | 2022-07-10 13:11:08,743 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-097F02077230-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-097F02077230-SegmentedRaftLogWorker: Starting segment from index:0
datanode3_1  | 2022-07-10 13:11:08,750 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode3_1  | 2022-07-10 13:11:08,750 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364-FollowerState] INFO impl.RoleInfo: a1e412ee-75aa-4bf8-87bc-4e8e615b1959: start a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364-LeaderElection2
datanode3_1  | 2022-07-10 13:11:08,789 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364-LeaderElection2] INFO impl.LeaderElection: a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364-LeaderElection2 ELECTION round 0: submit vote requests at term 1 for -1: [992f3c0d-344e-4060-87f0-890ffe8b867e|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1, a1e412ee-75aa-4bf8-87bc-4e8e615b1959|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, 257634a0-3792-468a-a5a2-186b5a295fa1|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0], old=null
datanode3_1  | 2022-07-10 13:11:09,104 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-097F02077230-LeaderElection1] INFO server.RaftServer$Division: a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-097F02077230: set configuration 0: [a1e412ee-75aa-4bf8-87bc-4e8e615b1959|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1], old=null
datanode3_1  | 2022-07-10 13:11:10,222 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-097F02077230-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-097F02077230-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/b1d72510-c7b3-4886-b6f1-097f02077230/current/log_inprogress_0
datanode3_1  | 2022-07-10 13:11:11,604 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364-LeaderElection2] INFO impl.LeaderElection: a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364-LeaderElection2 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: INTERNAL: 992f3c0d-344e-4060-87f0-890ffe8b867e: group-B841D041C364 not found.
datanode3_1  | 2022-07-10 13:11:11,607 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364-LeaderElection2] INFO impl.LeaderElection: a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364-LeaderElection2: ELECTION PASSED received 1 response(s) and 1 exception(s):
datanode3_1  | 2022-07-10 13:11:11,608 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364-LeaderElection2] INFO impl.LeaderElection:   Response 0: a1e412ee-75aa-4bf8-87bc-4e8e615b1959<-257634a0-3792-468a-a5a2-186b5a295fa1#0:OK-t1
datanode3_1  | 2022-07-10 13:11:11,610 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364-LeaderElection2] INFO impl.LeaderElection:   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: INTERNAL: 992f3c0d-344e-4060-87f0-890ffe8b867e: group-B841D041C364 not found.
datanode3_1  | 2022-07-10 13:11:11,617 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364-LeaderElection2] INFO impl.LeaderElection: a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364-LeaderElection2 ELECTION round 0: result PASSED
datanode3_1  | 2022-07-10 13:11:11,618 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364-LeaderElection2] INFO impl.RoleInfo: a1e412ee-75aa-4bf8-87bc-4e8e615b1959: shutdown a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364-LeaderElection2
datanode3_1  | 2022-07-10 13:11:11,618 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364-LeaderElection2] INFO server.RaftServer$Division: a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode3_1  | 2022-07-10 13:11:11,621 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-B841D041C364 with new leaderId: a1e412ee-75aa-4bf8-87bc-4e8e615b1959
datanode3_1  | 2022-07-10 13:11:11,622 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364-LeaderElection2] INFO server.RaftServer$Division: a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364: change Leader from null to a1e412ee-75aa-4bf8-87bc-4e8e615b1959 at term 1 for becomeLeader, leader elected after 8148ms
datanode3_1  | 2022-07-10 13:11:11,653 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode3_1  | 2022-07-10 13:11:11,654 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode3_1  | 2022-07-10 13:11:11,654 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode3_1  | 2022-07-10 13:11:11,655 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode3_1  | 2022-07-10 13:11:11,655 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode3_1  | 2022-07-10 13:11:11,655 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode3_1  | 2022-07-10 13:11:11,784 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode3_1  | 2022-07-10 13:11:11,785 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
datanode3_1  | 2022-07-10 13:11:11,834 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=199762fc-7613-447a-a2fc-b841d041c364.
datanode3_1  | 2022-07-10 13:11:11,839 [Command processor thread] INFO server.RaftServer: a1e412ee-75aa-4bf8-87bc-4e8e615b1959: addNew group-09A40F9F1D96:[992f3c0d-344e-4060-87f0-890ffe8b867e|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, a1e412ee-75aa-4bf8-87bc-4e8e615b1959|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, 257634a0-3792-468a-a5a2-186b5a295fa1|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0] returns group-09A40F9F1D96:java.util.concurrent.CompletableFuture@11e52de7[Not completed]
datanode3_1  | 2022-07-10 13:11:11,844 [pool-23-thread-1] INFO server.RaftServer$Division: a1e412ee-75aa-4bf8-87bc-4e8e615b1959: new RaftServerImpl for group-09A40F9F1D96:[992f3c0d-344e-4060-87f0-890ffe8b867e|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, a1e412ee-75aa-4bf8-87bc-4e8e615b1959|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, 257634a0-3792-468a-a5a2-186b5a295fa1|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0] with ContainerStateMachine:uninitialized
datanode2_1  | 2022-07-10 13:11:17,342 [grpc-default-executor-2] INFO impl.VoteContext: 992f3c0d-344e-4060-87f0-890ffe8b867e@group-09A40F9F1D96-FOLLOWER: accept ELECTION from a1e412ee-75aa-4bf8-87bc-4e8e615b1959: our priority 0 <= candidate's priority 1
datanode2_1  | 2022-07-10 13:11:17,343 [grpc-default-executor-2] INFO server.RaftServer$Division: 992f3c0d-344e-4060-87f0-890ffe8b867e@group-09A40F9F1D96: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:a1e412ee-75aa-4bf8-87bc-4e8e615b1959
datanode2_1  | 2022-07-10 13:11:17,343 [grpc-default-executor-2] INFO impl.RoleInfo: 992f3c0d-344e-4060-87f0-890ffe8b867e: shutdown 992f3c0d-344e-4060-87f0-890ffe8b867e@group-09A40F9F1D96-FollowerState
datanode2_1  | 2022-07-10 13:11:17,343 [grpc-default-executor-2] INFO impl.RoleInfo: 992f3c0d-344e-4060-87f0-890ffe8b867e: start 992f3c0d-344e-4060-87f0-890ffe8b867e@group-09A40F9F1D96-FollowerState
datanode2_1  | 2022-07-10 13:11:17,343 [992f3c0d-344e-4060-87f0-890ffe8b867e@group-09A40F9F1D96-FollowerState] INFO impl.FollowerState: 992f3c0d-344e-4060-87f0-890ffe8b867e@group-09A40F9F1D96-FollowerState was interrupted
datanode2_1  | 2022-07-10 13:11:17,358 [grpc-default-executor-2] INFO server.RaftServer$Division: 992f3c0d-344e-4060-87f0-890ffe8b867e@group-09A40F9F1D96 replies to ELECTION vote request: a1e412ee-75aa-4bf8-87bc-4e8e615b1959<-992f3c0d-344e-4060-87f0-890ffe8b867e#0:OK-t1. Peer's state: 992f3c0d-344e-4060-87f0-890ffe8b867e@group-09A40F9F1D96:t1, leader=null, voted=a1e412ee-75aa-4bf8-87bc-4e8e615b1959, raftlog=992f3c0d-344e-4060-87f0-890ffe8b867e@group-09A40F9F1D96-SegmentedRaftLog:OPENED:c-1, conf=-1: [992f3c0d-344e-4060-87f0-890ffe8b867e|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, a1e412ee-75aa-4bf8-87bc-4e8e615b1959|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 257634a0-3792-468a-a5a2-186b5a295fa1|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0], old=null
datanode2_1  | 2022-07-10 13:11:17,513 [grpc-default-executor-2] INFO server.RaftServer$Division: 992f3c0d-344e-4060-87f0-890ffe8b867e@group-09A40F9F1D96: receive requestVote(ELECTION, 257634a0-3792-468a-a5a2-186b5a295fa1, group-09A40F9F1D96, 1, (t:0, i:0))
datanode2_1  | 2022-07-10 13:11:17,513 [grpc-default-executor-2] INFO impl.VoteContext: 992f3c0d-344e-4060-87f0-890ffe8b867e@group-09A40F9F1D96-FOLLOWER: reject ELECTION from 257634a0-3792-468a-a5a2-186b5a295fa1: already has voted for a1e412ee-75aa-4bf8-87bc-4e8e615b1959 at current term 1
datanode2_1  | 2022-07-10 13:11:17,513 [grpc-default-executor-2] INFO server.RaftServer$Division: 992f3c0d-344e-4060-87f0-890ffe8b867e@group-09A40F9F1D96 replies to ELECTION vote request: 257634a0-3792-468a-a5a2-186b5a295fa1<-992f3c0d-344e-4060-87f0-890ffe8b867e#0:FAIL-t1. Peer's state: 992f3c0d-344e-4060-87f0-890ffe8b867e@group-09A40F9F1D96:t1, leader=null, voted=a1e412ee-75aa-4bf8-87bc-4e8e615b1959, raftlog=992f3c0d-344e-4060-87f0-890ffe8b867e@group-09A40F9F1D96-SegmentedRaftLog:OPENED:c-1, conf=-1: [992f3c0d-344e-4060-87f0-890ffe8b867e|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, a1e412ee-75aa-4bf8-87bc-4e8e615b1959|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 257634a0-3792-468a-a5a2-186b5a295fa1|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0], old=null
datanode2_1  | 2022-07-10 13:11:17,554 [992f3c0d-344e-4060-87f0-890ffe8b867e-server-thread1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-09A40F9F1D96 with new leaderId: a1e412ee-75aa-4bf8-87bc-4e8e615b1959
datanode2_1  | 2022-07-10 13:11:17,555 [992f3c0d-344e-4060-87f0-890ffe8b867e-server-thread1] INFO server.RaftServer$Division: 992f3c0d-344e-4060-87f0-890ffe8b867e@group-09A40F9F1D96: change Leader from null to a1e412ee-75aa-4bf8-87bc-4e8e615b1959 at term 1 for appendEntries, leader elected after 3264ms
datanode2_1  | 2022-07-10 13:11:17,618 [992f3c0d-344e-4060-87f0-890ffe8b867e-server-thread1] INFO server.RaftServer$Division: 992f3c0d-344e-4060-87f0-890ffe8b867e@group-09A40F9F1D96: set configuration 0: [992f3c0d-344e-4060-87f0-890ffe8b867e|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, a1e412ee-75aa-4bf8-87bc-4e8e615b1959|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 257634a0-3792-468a-a5a2-186b5a295fa1|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0], old=null
datanode2_1  | 2022-07-10 13:11:17,619 [992f3c0d-344e-4060-87f0-890ffe8b867e-server-thread1] INFO segmented.SegmentedRaftLogWorker: 992f3c0d-344e-4060-87f0-890ffe8b867e@group-09A40F9F1D96-SegmentedRaftLogWorker: Starting segment from index:0
datanode2_1  | 2022-07-10 13:11:17,621 [992f3c0d-344e-4060-87f0-890ffe8b867e@group-09A40F9F1D96-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 992f3c0d-344e-4060-87f0-890ffe8b867e@group-09A40F9F1D96-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/79d7f9ff-9479-4fdc-a3f9-09a40f9f1d96/current/log_inprogress_0
datanode2_1  | 2022-07-10 13:11:17,730 [grpc-default-executor-2] INFO impl.RoleInfo: 992f3c0d-344e-4060-87f0-890ffe8b867e: shutdown 992f3c0d-344e-4060-87f0-890ffe8b867e@group-B841D041C364-FollowerState
datanode2_1  | 2022-07-10 13:11:17,730 [grpc-default-executor-2] INFO server.RaftServer$Division: 992f3c0d-344e-4060-87f0-890ffe8b867e@group-B841D041C364: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
datanode2_1  | 2022-07-10 13:11:17,730 [992f3c0d-344e-4060-87f0-890ffe8b867e@group-B841D041C364-FollowerState] INFO impl.FollowerState: 992f3c0d-344e-4060-87f0-890ffe8b867e@group-B841D041C364-FollowerState was interrupted
datanode2_1  | 2022-07-10 13:11:17,730 [grpc-default-executor-2] INFO impl.RoleInfo: 992f3c0d-344e-4060-87f0-890ffe8b867e: start 992f3c0d-344e-4060-87f0-890ffe8b867e@group-B841D041C364-LeaderElection2
datanode2_1  | 2022-07-10 13:11:17,747 [992f3c0d-344e-4060-87f0-890ffe8b867e@group-B841D041C364-LeaderElection2] INFO server.RaftServer$Division: 992f3c0d-344e-4060-87f0-890ffe8b867e@group-B841D041C364: change Leader from a1e412ee-75aa-4bf8-87bc-4e8e615b1959 to null at term 1 for ELECTION
datanode2_1  | 2022-07-10 13:11:17,755 [992f3c0d-344e-4060-87f0-890ffe8b867e@group-B841D041C364-LeaderElection2] INFO impl.LeaderElection: 992f3c0d-344e-4060-87f0-890ffe8b867e@group-B841D041C364-LeaderElection2 ELECTION round 0: submit vote requests at term 2 for 0: [992f3c0d-344e-4060-87f0-890ffe8b867e|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1, a1e412ee-75aa-4bf8-87bc-4e8e615b1959|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 257634a0-3792-468a-a5a2-186b5a295fa1|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0], old=null
datanode2_1  | 2022-07-10 13:11:18,180 [grpc-default-executor-2] INFO server.GrpcServerProtocolService: 992f3c0d-344e-4060-87f0-890ffe8b867e: Completed APPEND_ENTRIES, lastRequest: a1e412ee-75aa-4bf8-87bc-4e8e615b1959->992f3c0d-344e-4060-87f0-890ffe8b867e#1-t1,previous=(t:0, i:0),leaderCommit=0,initializing? true,entries: size=1, first=(t:1, i:0), CONFIGURATIONENTRY
datanode2_1  | 2022-07-10 13:11:18,866 [992f3c0d-344e-4060-87f0-890ffe8b867e@group-B841D041C364-LeaderElection2] INFO impl.LeaderElection: 992f3c0d-344e-4060-87f0-890ffe8b867e@group-B841D041C364-LeaderElection2: ELECTION PASSED received 1 response(s) and 0 exception(s):
datanode2_1  | 2022-07-10 13:11:18,870 [992f3c0d-344e-4060-87f0-890ffe8b867e@group-B841D041C364-LeaderElection2] INFO impl.LeaderElection:   Response 0: 992f3c0d-344e-4060-87f0-890ffe8b867e<-a1e412ee-75aa-4bf8-87bc-4e8e615b1959#0:OK-t2
datanode2_1  | 2022-07-10 13:11:18,870 [992f3c0d-344e-4060-87f0-890ffe8b867e@group-B841D041C364-LeaderElection2] INFO impl.LeaderElection: 992f3c0d-344e-4060-87f0-890ffe8b867e@group-B841D041C364-LeaderElection2 ELECTION round 0: result PASSED
datanode3_1  | 2022-07-10 13:11:11,853 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode3_1  | 2022-07-10 13:11:11,853 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode3_1  | 2022-07-10 13:11:11,853 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode3_1  | 2022-07-10 13:11:11,853 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode3_1  | 2022-07-10 13:11:11,853 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode3_1  | 2022-07-10 13:11:11,853 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode3_1  | 2022-07-10 13:11:11,854 [pool-23-thread-1] INFO server.RaftServer$Division: a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-09A40F9F1D96: ConfigurationManager, init=-1: [992f3c0d-344e-4060-87f0-890ffe8b867e|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, a1e412ee-75aa-4bf8-87bc-4e8e615b1959|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, 257634a0-3792-468a-a5a2-186b5a295fa1|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0], old=null, confs=<EMPTY_MAP>
datanode3_1  | 2022-07-10 13:11:11,854 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode3_1  | 2022-07-10 13:11:11,854 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode3_1  | 2022-07-10 13:11:11,854 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode3_1  | 2022-07-10 13:11:11,855 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/79d7f9ff-9479-4fdc-a3f9-09a40f9f1d96 does not exist. Creating ...
datanode3_1  | 2022-07-10 13:11:11,865 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/79d7f9ff-9479-4fdc-a3f9-09a40f9f1d96/in_use.lock acquired by nodename 6@377a412caf09
datanode3_1  | 2022-07-10 13:11:11,884 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/79d7f9ff-9479-4fdc-a3f9-09a40f9f1d96 has been successfully formatted.
datanode3_1  | 2022-07-10 13:11:11,903 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-09A40F9F1D96: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode3_1  | 2022-07-10 13:11:11,903 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode3_1  | 2022-07-10 13:11:11,903 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode3_1  | 2022-07-10 13:11:11,904 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode3_1  | 2022-07-10 13:11:11,904 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2022-07-10 13:11:11,904 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode3_1  | 2022-07-10 13:11:11,904 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2022-07-10 13:11:11,916 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode3_1  | 2022-07-10 13:11:11,926 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode3_1  | 2022-07-10 13:11:11,968 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-09A40F9F1D96-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/79d7f9ff-9479-4fdc-a3f9-09a40f9f1d96
datanode3_1  | 2022-07-10 13:11:11,970 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode3_1  | 2022-07-10 13:11:11,971 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode3_1  | 2022-07-10 13:11:11,971 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2022-07-10 13:11:11,972 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode3_1  | 2022-07-10 13:11:11,972 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode3_1  | 2022-07-10 13:11:11,972 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode3_1  | 2022-07-10 13:11:11,972 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode3_1  | 2022-07-10 13:11:11,976 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode3_1  | 2022-07-10 13:11:11,978 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode3_1  | 2022-07-10 13:11:12,003 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode3_1  | 2022-07-10 13:11:12,007 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode3_1  | 2022-07-10 13:11:12,007 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-09A40F9F1D96-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode3_1  | 2022-07-10 13:11:12,023 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-09A40F9F1D96-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode3_1  | 2022-07-10 13:11:12,031 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode3_1  | 2022-07-10 13:11:12,031 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode3_1  | 2022-07-10 13:11:12,031 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode3_1  | 2022-07-10 13:11:12,031 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode3_1  | 2022-07-10 13:11:12,031 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode3_1  | 2022-07-10 13:11:12,036 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode3_1  | 2022-07-10 13:11:12,037 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode3_1  | 2022-07-10 13:11:12,061 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode3_1  | 2022-07-10 13:11:12,063 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode3_1  | 2022-07-10 13:11:12,063 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode3_1  | 2022-07-10 13:11:12,067 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode3_1  | 2022-07-10 13:11:12,069 [pool-23-thread-1] INFO server.RaftServer$Division: a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-09A40F9F1D96: start as a follower, conf=-1: [992f3c0d-344e-4060-87f0-890ffe8b867e|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, a1e412ee-75aa-4bf8-87bc-4e8e615b1959|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, 257634a0-3792-468a-a5a2-186b5a295fa1|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0], old=null
datanode3_1  | 2022-07-10 13:11:12,081 [pool-23-thread-1] INFO server.RaftServer$Division: a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-09A40F9F1D96: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode3_1  | 2022-07-10 13:11:12,081 [pool-23-thread-1] INFO impl.RoleInfo: a1e412ee-75aa-4bf8-87bc-4e8e615b1959: start a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-09A40F9F1D96-FollowerState
datanode3_1  | 2022-07-10 13:11:12,091 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-09A40F9F1D96,id=a1e412ee-75aa-4bf8-87bc-4e8e615b1959
datanode3_1  | 2022-07-10 13:11:12,120 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode3_1  | 2022-07-10 13:11:12,121 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2022-07-10 13:11:12,122 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode3_1  | 2022-07-10 13:11:12,120 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=79d7f9ff-9479-4fdc-a3f9-09a40f9f1d96
datanode3_1  | 2022-07-10 13:11:12,170 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode3_1  | 2022-07-10 13:11:12,193 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode3_1  | 2022-07-10 13:11:12,193 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode3_1  | 2022-07-10 13:11:12,242 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode3_1  | 2022-07-10 13:11:12,251 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2022-07-10 13:11:12,279 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode3_1  | 2022-07-10 13:11:12,286 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode3_1  | 2022-07-10 13:11:12,299 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode3_1  | 2022-07-10 13:11:12,304 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode3_1  | 2022-07-10 13:11:12,372 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364-LeaderElection2] INFO impl.RoleInfo: a1e412ee-75aa-4bf8-87bc-4e8e615b1959: start a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364-LeaderStateImpl
datanode3_1  | 2022-07-10 13:11:12,383 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364-SegmentedRaftLogWorker: Starting segment from index:0
datanode3_1  | 2022-07-10 13:11:12,399 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/199762fc-7613-447a-a2fc-b841d041c364/current/log_inprogress_0
datanode3_1  | 2022-07-10 13:11:12,509 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364-LeaderElection2] INFO server.RaftServer$Division: a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364: set configuration 0: [992f3c0d-344e-4060-87f0-890ffe8b867e|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1, a1e412ee-75aa-4bf8-87bc-4e8e615b1959|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 257634a0-3792-468a-a5a2-186b5a295fa1|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0], old=null
datanode3_1  | 2022-07-10 13:11:14,592 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=79d7f9ff-9479-4fdc-a3f9-09a40f9f1d96.
datanode3_1  | 2022-07-10 13:11:17,265 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-09A40F9F1D96-FollowerState] INFO impl.FollowerState: a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-09A40F9F1D96-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5183662034ns, electionTimeout:5173ms
datanode3_1  | 2022-07-10 13:11:17,266 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-09A40F9F1D96-FollowerState] INFO impl.RoleInfo: a1e412ee-75aa-4bf8-87bc-4e8e615b1959: shutdown a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-09A40F9F1D96-FollowerState
datanode3_1  | 2022-07-10 13:11:17,266 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-09A40F9F1D96-FollowerState] INFO server.RaftServer$Division: a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-09A40F9F1D96: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode3_1  | 2022-07-10 13:11:17,266 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-09A40F9F1D96-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode3_1  | 2022-07-10 13:11:17,266 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-09A40F9F1D96-FollowerState] INFO impl.RoleInfo: a1e412ee-75aa-4bf8-87bc-4e8e615b1959: start a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-09A40F9F1D96-LeaderElection3
datanode3_1  | 2022-07-10 13:11:17,290 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-09A40F9F1D96-LeaderElection3] INFO impl.LeaderElection: a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-09A40F9F1D96-LeaderElection3 ELECTION round 0: submit vote requests at term 1 for -1: [992f3c0d-344e-4060-87f0-890ffe8b867e|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, a1e412ee-75aa-4bf8-87bc-4e8e615b1959|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, 257634a0-3792-468a-a5a2-186b5a295fa1|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0], old=null
datanode3_1  | 2022-07-10 13:11:17,383 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-09A40F9F1D96-LeaderElection3] INFO impl.LeaderElection: a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-09A40F9F1D96-LeaderElection3: ELECTION PASSED received 1 response(s) and 0 exception(s):
datanode3_1  | 2022-07-10 13:11:17,384 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-09A40F9F1D96-LeaderElection3] INFO impl.LeaderElection:   Response 0: a1e412ee-75aa-4bf8-87bc-4e8e615b1959<-992f3c0d-344e-4060-87f0-890ffe8b867e#0:OK-t1
datanode3_1  | 2022-07-10 13:11:17,384 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-09A40F9F1D96-LeaderElection3] INFO impl.LeaderElection: a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-09A40F9F1D96-LeaderElection3 ELECTION round 0: result PASSED
datanode3_1  | 2022-07-10 13:11:17,384 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-09A40F9F1D96-LeaderElection3] INFO impl.RoleInfo: a1e412ee-75aa-4bf8-87bc-4e8e615b1959: shutdown a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-09A40F9F1D96-LeaderElection3
datanode3_1  | 2022-07-10 13:11:17,384 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-09A40F9F1D96-LeaderElection3] INFO server.RaftServer$Division: a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-09A40F9F1D96: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode3_1  | 2022-07-10 13:11:17,384 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-09A40F9F1D96-LeaderElection3] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-09A40F9F1D96 with new leaderId: a1e412ee-75aa-4bf8-87bc-4e8e615b1959
datanode3_1  | 2022-07-10 13:11:17,385 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-09A40F9F1D96-LeaderElection3] INFO server.RaftServer$Division: a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-09A40F9F1D96: change Leader from null to a1e412ee-75aa-4bf8-87bc-4e8e615b1959 at term 1 for becomeLeader, leader elected after 5481ms
datanode3_1  | 2022-07-10 13:11:17,385 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-09A40F9F1D96-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode3_1  | 2022-07-10 13:11:17,386 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-09A40F9F1D96-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode3_1  | 2022-07-10 13:11:17,388 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-09A40F9F1D96-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode3_1  | 2022-07-10 13:11:17,389 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-09A40F9F1D96-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode3_1  | 2022-07-10 13:11:17,389 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-09A40F9F1D96-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode3_1  | 2022-07-10 13:11:17,389 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-09A40F9F1D96-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode3_1  | 2022-07-10 13:11:17,389 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-09A40F9F1D96-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode3_1  | 2022-07-10 13:11:17,390 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-09A40F9F1D96-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
datanode3_1  | 2022-07-10 13:11:17,397 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-09A40F9F1D96-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode3_1  | 2022-07-10 13:11:17,397 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-09A40F9F1D96-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2022-07-10 13:11:17,400 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-09A40F9F1D96-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode3_1  | 2022-07-10 13:11:17,409 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-09A40F9F1D96-LeaderElection3] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode3_1  | 2022-07-10 13:11:17,415 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-09A40F9F1D96-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode3_1  | 2022-07-10 13:11:17,415 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-09A40F9F1D96-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode3_1  | 2022-07-10 13:11:17,418 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-09A40F9F1D96-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode3_1  | 2022-07-10 13:11:17,463 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-09A40F9F1D96-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2022-07-10 13:11:17,466 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-09A40F9F1D96-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode3_1  | 2022-07-10 13:11:17,466 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-09A40F9F1D96-LeaderElection3] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode3_1  | 2022-07-10 13:11:17,466 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-09A40F9F1D96-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode3_1  | 2022-07-10 13:11:17,466 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-09A40F9F1D96-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode3_1  | 2022-07-10 13:11:17,469 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-09A40F9F1D96-LeaderElection3] INFO impl.RoleInfo: a1e412ee-75aa-4bf8-87bc-4e8e615b1959: start a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-09A40F9F1D96-LeaderStateImpl
datanode3_1  | 2022-07-10 13:11:17,470 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-09A40F9F1D96-LeaderElection3] INFO segmented.SegmentedRaftLogWorker: a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-09A40F9F1D96-SegmentedRaftLogWorker: Starting segment from index:0
datanode3_1  | 2022-07-10 13:11:17,493 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-09A40F9F1D96-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-09A40F9F1D96-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/79d7f9ff-9479-4fdc-a3f9-09a40f9f1d96/current/log_inprogress_0
datanode3_1  | 2022-07-10 13:11:17,541 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-09A40F9F1D96-LeaderElection3] INFO server.RaftServer$Division: a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-09A40F9F1D96: set configuration 0: [992f3c0d-344e-4060-87f0-890ffe8b867e|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, a1e412ee-75aa-4bf8-87bc-4e8e615b1959|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 257634a0-3792-468a-a5a2-186b5a295fa1|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0], old=null
datanode3_1  | 2022-07-10 13:11:17,630 [grpc-default-executor-1] INFO server.RaftServer$Division: a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-09A40F9F1D96: receive requestVote(ELECTION, 257634a0-3792-468a-a5a2-186b5a295fa1, group-09A40F9F1D96, 1, (t:0, i:0))
datanode3_1  | 2022-07-10 13:11:17,648 [grpc-default-executor-1] INFO impl.VoteContext: a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-09A40F9F1D96-LEADER: reject ELECTION from 257634a0-3792-468a-a5a2-186b5a295fa1: already has voted for a1e412ee-75aa-4bf8-87bc-4e8e615b1959 at current term 1
datanode3_1  | 2022-07-10 13:11:17,653 [grpc-default-executor-1] INFO server.RaftServer$Division: a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-09A40F9F1D96 replies to ELECTION vote request: 257634a0-3792-468a-a5a2-186b5a295fa1<-a1e412ee-75aa-4bf8-87bc-4e8e615b1959#0:FAIL-t1. Peer's state: a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-09A40F9F1D96:t1, leader=a1e412ee-75aa-4bf8-87bc-4e8e615b1959, voted=a1e412ee-75aa-4bf8-87bc-4e8e615b1959, raftlog=a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-09A40F9F1D96-SegmentedRaftLog:OPENED:c0, conf=0: [992f3c0d-344e-4060-87f0-890ffe8b867e|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, a1e412ee-75aa-4bf8-87bc-4e8e615b1959|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 257634a0-3792-468a-a5a2-186b5a295fa1|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0], old=null
datanode3_1  | 2022-07-10 13:11:17,711 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364-LeaderStateImpl] INFO server.RaftServer$Division: a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364-LeaderStateImpl send StartLeaderElectionRequest to follower:992f3c0d-344e-4060-87f0-890ffe8b867e on term:1 because follower's priority:1 is higher than leader's:0 and follower's lastEntry index:0 catch up with leader's:0
kdc_1        | Jul 10 13:10:54 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.103: ISSUE: authtime 1657458618, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for recon/recon@EXAMPLE.COM
kdc_1        | Jul 10 13:10:58 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.102: ISSUE: authtime 1657458618, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for recon/recon@EXAMPLE.COM
kdc_1        | Jul 10 13:10:59 kdc krb5kdc[8](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.111: ISSUE: authtime 1657458659, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 10 13:11:00 kdc krb5kdc[8](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.112: ISSUE: authtime 1657458660, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 10 13:11:02 kdc krb5kdc[8](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.113: ISSUE: authtime 1657458662, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 10 13:11:03 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.111: ISSUE: authtime 1657458659, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jul 10 13:11:04 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.112: ISSUE: authtime 1657458660, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jul 10 13:11:05 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.113: ISSUE: authtime 1657458662, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jul 10 13:11:07 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657458639, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jul 10 13:11:13 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1657458673, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 10 13:11:28 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: ISSUE: authtime 1657458533, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, recon/recon@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 10 13:11:29 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657458673, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jul 10 13:11:31 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1657458691, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 10 13:11:38 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657458691, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 10 13:11:41 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jul 10 13:11:41 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jul 10 13:11:41 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jul 10 13:11:41 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jul 10 13:11:43 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1657458703, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
datanode3_1  | 2022-07-10 13:11:17,760 [Thread-55] INFO server.RaftServer$Division: a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364-LeaderStateImpl received success reply of StartLeaderElectionRequest from follower:992f3c0d-344e-4060-87f0-890ffe8b867e
datanode3_1  | 2022-07-10 13:11:18,140 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364-LeaderStateImpl] INFO server.RaftServer$Division: a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364: change Leader from a1e412ee-75aa-4bf8-87bc-4e8e615b1959 to null at term 2 for updateCurrentTerm
datanode3_1  | 2022-07-10 13:11:18,142 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364-LeaderStateImpl] INFO server.RaftServer$Division: a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364: changes role from    LEADER to FOLLOWER at term 2 for StepDownReason:HIGHER_TERM
datanode3_1  | 2022-07-10 13:11:18,145 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364-LeaderStateImpl] INFO impl.RoleInfo: a1e412ee-75aa-4bf8-87bc-4e8e615b1959: shutdown a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364-LeaderStateImpl
datanode3_1  | 2022-07-10 13:11:18,148 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364->992f3c0d-344e-4060-87f0-890ffe8b867e-GrpcLogAppender-LogAppenderDaemon] WARN server.GrpcLogAppender: a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364->992f3c0d-344e-4060-87f0-890ffe8b867e-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
datanode3_1  | 2022-07-10 13:11:18,148 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364->257634a0-3792-468a-a5a2-186b5a295fa1-GrpcLogAppender-LogAppenderDaemon] WARN server.GrpcLogAppender: a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364->257634a0-3792-468a-a5a2-186b5a295fa1-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
datanode3_1  | 2022-07-10 13:11:18,169 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364-LeaderStateImpl] INFO impl.PendingRequests: a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364-PendingRequests: sendNotLeaderResponses
datanode3_1  | 2022-07-10 13:11:18,182 [grpc-default-executor-1] INFO server.GrpcLogAppender: a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364->257634a0-3792-468a-a5a2-186b5a295fa1-AppendLogResponseHandler: follower responses appendEntries COMPLETED
datanode3_1  | 2022-07-10 13:11:18,195 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364-LeaderStateImpl] INFO impl.RoleInfo: a1e412ee-75aa-4bf8-87bc-4e8e615b1959: start a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364-FollowerState
datanode3_1  | 2022-07-10 13:11:18,202 [grpc-default-executor-0] INFO server.GrpcLogAppender: a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364->992f3c0d-344e-4060-87f0-890ffe8b867e-AppendLogResponseHandler: follower responses appendEntries COMPLETED
datanode3_1  | 2022-07-10 13:11:18,203 [grpc-default-executor-0] INFO leader.FollowerInfo: a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364->992f3c0d-344e-4060-87f0-890ffe8b867e: nextIndex: updateUnconditionally 1 -> 0
datanode3_1  | 2022-07-10 13:11:18,205 [grpc-default-executor-1] INFO leader.FollowerInfo: a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364->257634a0-3792-468a-a5a2-186b5a295fa1: nextIndex: updateUnconditionally 1 -> 0
datanode3_1  | 2022-07-10 13:11:18,820 [grpc-default-executor-1] INFO server.RaftServer$Division: a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364: receive requestVote(ELECTION, 992f3c0d-344e-4060-87f0-890ffe8b867e, group-B841D041C364, 2, (t:1, i:0))
datanode3_1  | 2022-07-10 13:11:18,820 [grpc-default-executor-1] INFO impl.VoteContext: a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364-FOLLOWER: accept ELECTION from 992f3c0d-344e-4060-87f0-890ffe8b867e: our priority 0 <= candidate's priority 1
datanode3_1  | 2022-07-10 13:11:18,820 [grpc-default-executor-1] INFO server.RaftServer$Division: a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:992f3c0d-344e-4060-87f0-890ffe8b867e
datanode3_1  | 2022-07-10 13:11:18,820 [grpc-default-executor-1] INFO impl.RoleInfo: a1e412ee-75aa-4bf8-87bc-4e8e615b1959: shutdown a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364-FollowerState
datanode3_1  | 2022-07-10 13:11:18,820 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364-FollowerState] INFO impl.FollowerState: a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364-FollowerState was interrupted
datanode3_1  | 2022-07-10 13:11:18,821 [grpc-default-executor-1] INFO impl.RoleInfo: a1e412ee-75aa-4bf8-87bc-4e8e615b1959: start a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364-FollowerState
datanode3_1  | 2022-07-10 13:11:18,835 [grpc-default-executor-1] INFO server.RaftServer$Division: a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364 replies to ELECTION vote request: 992f3c0d-344e-4060-87f0-890ffe8b867e<-a1e412ee-75aa-4bf8-87bc-4e8e615b1959#0:OK-t2. Peer's state: a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364:t2, leader=null, voted=992f3c0d-344e-4060-87f0-890ffe8b867e, raftlog=a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364-SegmentedRaftLog:OPENED:c0, conf=0: [992f3c0d-344e-4060-87f0-890ffe8b867e|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1, a1e412ee-75aa-4bf8-87bc-4e8e615b1959|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 257634a0-3792-468a-a5a2-186b5a295fa1|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0], old=null
datanode3_1  | 2022-07-10 13:11:19,125 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959-server-thread1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-B841D041C364 with new leaderId: 992f3c0d-344e-4060-87f0-890ffe8b867e
datanode3_1  | 2022-07-10 13:11:19,125 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959-server-thread1] INFO server.RaftServer$Division: a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364: change Leader from null to 992f3c0d-344e-4060-87f0-890ffe8b867e at term 2 for appendEntries, leader elected after 984ms
datanode3_1  | 2022-07-10 13:11:19,298 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959-server-thread1] INFO server.RaftServer$Division: a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364: set configuration 1: [992f3c0d-344e-4060-87f0-890ffe8b867e|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1, a1e412ee-75aa-4bf8-87bc-4e8e615b1959|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 257634a0-3792-468a-a5a2-186b5a295fa1|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0], old=null
datanode3_1  | 2022-07-10 13:11:19,299 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959-server-thread1] INFO segmented.SegmentedRaftLogWorker: a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
datanode3_1  | 2022-07-10 13:11:19,301 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/ratis/199762fc-7613-447a-a2fc-b841d041c364/current/log_inprogress_0 to /data/metadata/ratis/199762fc-7613-447a-a2fc-b841d041c364/current/log_0-0
datanode3_1  | 2022-07-10 13:11:19,305 [a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: a1e412ee-75aa-4bf8-87bc-4e8e615b1959@group-B841D041C364-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/199762fc-7613-447a-a2fc-b841d041c364/current/log_inprogress_1
datanode3_1  | 2022-07-10 13:11:58,374 [ChunkWriter-1-0] INFO client.DNCertificateClient: Getting certificate with certSerialId:941638739763.
datanode3_1  | 2022-07-10 13:19:45,155 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$388/0x00000008405dec40@494a6507] WARN util.JvmPauseMonitor: JvmPauseMonitor-a1e412ee-75aa-4bf8-87bc-4e8e615b1959: Detected pause in JVM or host machine (eg GC): pause of approximately 136874266ns.
datanode3_1  | GC pool 'ParNew' had collection(s): count=1 time=56ms
datanode2_1  | 2022-07-10 13:11:18,870 [992f3c0d-344e-4060-87f0-890ffe8b867e@group-B841D041C364-LeaderElection2] INFO impl.RoleInfo: 992f3c0d-344e-4060-87f0-890ffe8b867e: shutdown 992f3c0d-344e-4060-87f0-890ffe8b867e@group-B841D041C364-LeaderElection2
datanode2_1  | 2022-07-10 13:11:18,870 [992f3c0d-344e-4060-87f0-890ffe8b867e@group-B841D041C364-LeaderElection2] INFO server.RaftServer$Division: 992f3c0d-344e-4060-87f0-890ffe8b867e@group-B841D041C364: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
datanode2_1  | 2022-07-10 13:11:18,870 [992f3c0d-344e-4060-87f0-890ffe8b867e@group-B841D041C364-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-B841D041C364 with new leaderId: 992f3c0d-344e-4060-87f0-890ffe8b867e
datanode2_1  | 2022-07-10 13:11:18,871 [992f3c0d-344e-4060-87f0-890ffe8b867e@group-B841D041C364-LeaderElection2] INFO server.RaftServer$Division: 992f3c0d-344e-4060-87f0-890ffe8b867e@group-B841D041C364: change Leader from null to 992f3c0d-344e-4060-87f0-890ffe8b867e at term 2 for becomeLeader, leader elected after 1123ms
datanode2_1  | 2022-07-10 13:11:18,874 [992f3c0d-344e-4060-87f0-890ffe8b867e@group-B841D041C364-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode2_1  | 2022-07-10 13:11:18,876 [992f3c0d-344e-4060-87f0-890ffe8b867e@group-B841D041C364-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode2_1  | 2022-07-10 13:11:18,888 [992f3c0d-344e-4060-87f0-890ffe8b867e@group-B841D041C364-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode2_1  | 2022-07-10 13:11:18,889 [992f3c0d-344e-4060-87f0-890ffe8b867e@group-B841D041C364-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode2_1  | 2022-07-10 13:11:18,894 [992f3c0d-344e-4060-87f0-890ffe8b867e@group-B841D041C364-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode2_1  | 2022-07-10 13:11:18,895 [992f3c0d-344e-4060-87f0-890ffe8b867e@group-B841D041C364-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode2_1  | 2022-07-10 13:11:18,895 [992f3c0d-344e-4060-87f0-890ffe8b867e@group-B841D041C364-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode2_1  | 2022-07-10 13:11:18,897 [992f3c0d-344e-4060-87f0-890ffe8b867e@group-B841D041C364-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
datanode2_1  | 2022-07-10 13:11:18,929 [992f3c0d-344e-4060-87f0-890ffe8b867e@group-B841D041C364-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode2_1  | 2022-07-10 13:11:18,929 [992f3c0d-344e-4060-87f0-890ffe8b867e@group-B841D041C364-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2022-07-10 13:11:18,930 [992f3c0d-344e-4060-87f0-890ffe8b867e@group-B841D041C364-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode2_1  | 2022-07-10 13:11:18,950 [992f3c0d-344e-4060-87f0-890ffe8b867e@group-B841D041C364-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode2_1  | 2022-07-10 13:11:18,954 [992f3c0d-344e-4060-87f0-890ffe8b867e@group-B841D041C364-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode2_1  | 2022-07-10 13:11:18,955 [992f3c0d-344e-4060-87f0-890ffe8b867e@group-B841D041C364-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode2_1  | 2022-07-10 13:11:18,967 [992f3c0d-344e-4060-87f0-890ffe8b867e@group-B841D041C364-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode2_1  | 2022-07-10 13:11:18,971 [992f3c0d-344e-4060-87f0-890ffe8b867e@group-B841D041C364-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2022-07-10 13:11:18,971 [992f3c0d-344e-4060-87f0-890ffe8b867e@group-B841D041C364-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode2_1  | 2022-07-10 13:11:18,972 [992f3c0d-344e-4060-87f0-890ffe8b867e@group-B841D041C364-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode2_1  | 2022-07-10 13:11:18,979 [992f3c0d-344e-4060-87f0-890ffe8b867e@group-B841D041C364-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode2_1  | 2022-07-10 13:11:18,980 [992f3c0d-344e-4060-87f0-890ffe8b867e@group-B841D041C364-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode2_1  | 2022-07-10 13:11:18,995 [992f3c0d-344e-4060-87f0-890ffe8b867e@group-B841D041C364-LeaderElection2] INFO impl.RoleInfo: 992f3c0d-344e-4060-87f0-890ffe8b867e: start 992f3c0d-344e-4060-87f0-890ffe8b867e@group-B841D041C364-LeaderStateImpl
datanode2_1  | 2022-07-10 13:11:19,002 [992f3c0d-344e-4060-87f0-890ffe8b867e@group-B841D041C364-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: 992f3c0d-344e-4060-87f0-890ffe8b867e@group-B841D041C364-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
datanode2_1  | 2022-07-10 13:11:19,016 [992f3c0d-344e-4060-87f0-890ffe8b867e@group-B841D041C364-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 992f3c0d-344e-4060-87f0-890ffe8b867e@group-B841D041C364-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/ratis/199762fc-7613-447a-a2fc-b841d041c364/current/log_inprogress_0 to /data/metadata/ratis/199762fc-7613-447a-a2fc-b841d041c364/current/log_0-0
datanode2_1  | 2022-07-10 13:11:19,022 [992f3c0d-344e-4060-87f0-890ffe8b867e@group-B841D041C364-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 992f3c0d-344e-4060-87f0-890ffe8b867e@group-B841D041C364-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/199762fc-7613-447a-a2fc-b841d041c364/current/log_inprogress_1
datanode2_1  | 2022-07-10 13:11:19,042 [992f3c0d-344e-4060-87f0-890ffe8b867e@group-B841D041C364-LeaderElection2] INFO server.RaftServer$Division: 992f3c0d-344e-4060-87f0-890ffe8b867e@group-B841D041C364: set configuration 1: [992f3c0d-344e-4060-87f0-890ffe8b867e|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1, a1e412ee-75aa-4bf8-87bc-4e8e615b1959|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 257634a0-3792-468a-a5a2-186b5a295fa1|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0], old=null
datanode2_1  | 2022-07-10 13:11:58,628 [ChunkWriter-1-0] INFO client.DNCertificateClient: Getting certificate with certSerialId:941638739763.
datanode2_1  | 2022-07-10 13:22:42,303 [ContainerOp-79d7f9ff-9479-4fdc-a3f9-09a40f9f1d96-5] INFO keyvalue.KeyValueContainer: Container 1 is synced with bcsId 105.
datanode2_1  | 2022-07-10 13:22:42,329 [ContainerOp-79d7f9ff-9479-4fdc-a3f9-09a40f9f1d96-5] INFO keyvalue.KeyValueContainer: Container 1 is synced with bcsId 105.
datanode2_1  | 2022-07-10 13:22:42,393 [ContainerOp-79d7f9ff-9479-4fdc-a3f9-09a40f9f1d96-5] INFO keyvalue.KeyValueContainer: Container 1 is closed with bcsId 105.
kdc_1        | Jul 10 13:11:54 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657458703, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 10 13:12:04 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657458703, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 10 13:12:10 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657458703, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 10 13:12:15 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657458703, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 10 13:12:23 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657458703, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 10 13:12:30 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657458703, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 10 13:12:35 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657458703, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 10 13:12:40 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657458703, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 10 13:12:41 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jul 10 13:12:41 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jul 10 13:12:55 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657458703, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 10 13:12:59 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657458703, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 10 13:13:03 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657458703, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 10 13:13:08 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657458703, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 10 13:13:15 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657458703, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 10 13:13:19 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657458703, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 10 13:13:23 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657458703, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 10 13:13:28 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657458703, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 10 13:13:32 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657458703, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 10 13:13:36 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657458703, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 10 13:13:41 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657458703, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 10 13:13:41 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jul 10 13:13:41 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jul 10 13:13:45 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657458703, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 10 13:13:49 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657458703, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 10 13:13:50 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1657458830, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 10 13:13:53 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657458830, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 10 13:13:58 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657458830, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 10 13:13:58 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1657458838, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 10 13:14:02 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657458838, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 10 13:14:06 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657458838, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 10 13:14:11 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657458838, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 10 13:14:18 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657458838, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 10 13:14:21 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1657458861, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 10 13:14:24 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657458861, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 10 13:14:31 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657458861, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 10 13:14:35 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1657458875, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 10 13:14:38 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657458875, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 10 13:14:41 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jul 10 13:14:41 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jul 10 13:14:43 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657458875, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 10 13:14:44 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1657458884, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 10 13:14:47 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657458884, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 10 13:14:51 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657458884, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 10 13:14:52 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1657458892, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 10 13:14:56 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657458892, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 10 13:14:57 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1657458897, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 10 13:15:00 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657458897, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 10 13:15:01 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1657458901, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 10 13:15:05 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657458901, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 10 13:15:08 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657458901, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 10 13:15:13 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657458901, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 10 13:15:17 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657458901, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 10 13:15:21 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657458901, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 10 13:15:26 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657458901, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 10 13:15:27 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1657458927, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 10 13:15:30 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657458927, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 10 13:15:35 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657458927, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 10 13:15:39 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657458927, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 10 13:15:42 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jul 10 13:15:42 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jul 10 13:15:43 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657458927, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 10 13:15:44 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1657458944, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 10 13:15:44 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1657458944, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 10 13:15:48 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657458944, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 10 13:15:49 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1657458949, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 10 13:15:49 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1657458949, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 10 13:15:53 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657458949, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 10 13:15:53 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1657458953, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 10 13:15:53 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1657458953, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 10 13:15:57 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657458953, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 10 13:16:01 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657458953, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 10 13:16:02 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1657458962, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 10 13:16:05 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657458962, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 10 13:16:09 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657458962, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 10 13:16:14 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657458962, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 10 13:16:18 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657458962, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 10 13:16:19 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1657458979, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 10 13:16:22 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657458979, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 10 13:16:26 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657458979, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 10 13:16:33 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657458979, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 10 13:16:36 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1657458996, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 10 13:16:40 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657458996, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 10 13:16:42 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jul 10 13:16:42 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jul 10 13:16:44 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657458996, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 10 13:16:48 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657458996, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 10 13:16:49 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1657459009, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
datanode3_1  | 2022-07-10 13:22:42,275 [ContainerOp-79d7f9ff-9479-4fdc-a3f9-09a40f9f1d96-6] INFO keyvalue.KeyValueContainer: Container 1 is synced with bcsId 105.
datanode3_1  | 2022-07-10 13:22:42,275 [ContainerOp-79d7f9ff-9479-4fdc-a3f9-09a40f9f1d96-6] INFO keyvalue.KeyValueContainer: Container 1 is synced with bcsId 105.
datanode3_1  | 2022-07-10 13:22:42,285 [ContainerOp-79d7f9ff-9479-4fdc-a3f9-09a40f9f1d96-6] INFO keyvalue.KeyValueContainer: Container 1 is closed with bcsId 105.
kms_1        | Sleeping for 5 seconds
kms_1        | WARNING: /opt/hadoop/temp does not exist. Creating.
kdc_1        | Jul 10 13:16:53 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657459009, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 10 13:16:57 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657459009, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 10 13:17:01 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657459009, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 10 13:17:33 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1657459053, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 10 13:17:36 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657459053, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 10 13:17:42 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.114: ISSUE: authtime 1657458531, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, s3g/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 10 13:17:42 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jul 10 13:17:42 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jul 10 13:17:43 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1657459063, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 10 13:17:46 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657459063, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 10 13:17:58 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1657459078, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 10 13:18:01 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657459078, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 10 13:18:13 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1657459093, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 10 13:18:16 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657459093, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 10 13:18:27 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657459093, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 10 13:18:29 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1657459109, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 10 13:18:32 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657459109, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 10 13:18:38 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1657459118, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 10 13:18:41 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657459118, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 10 13:18:42 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jul 10 13:18:42 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jul 10 13:18:47 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1657459127, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 10 13:18:49 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657459127, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 10 13:18:57 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657459127, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 10 13:19:00 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1657459140, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 10 13:19:03 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657459140, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 10 13:19:42 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jul 10 13:19:42 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jul 10 13:20:10 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1657459210, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 10 13:20:14 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657459210, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 10 13:20:26 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1657459226, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 10 13:20:29 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657459226, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 10 13:20:42 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jul 10 13:20:42 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jul 10 13:20:45 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1657459245, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 10 13:20:48 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657459245, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 10 13:20:57 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1657459257, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 10 13:21:00 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657459257, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 10 13:21:17 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1657459277, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 10 13:21:20 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657459277, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 10 13:21:24 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1657459284, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 10 13:21:24 kdc krb5kdc[8](info): TGS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1657459284, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for HTTP/s3g@EXAMPLE.COM
kdc_1        | Jul 10 13:21:34 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1657459294, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 10 13:21:38 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657459294, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 10 13:21:42 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jul 10 13:21:42 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jul 10 13:21:47 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657459294, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jul 10 13:21:53 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657459294, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jul 10 13:21:57 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657459294, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jul 10 13:22:02 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657459294, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jul 10 13:22:06 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657459294, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jul 10 13:22:10 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657459294, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jul 10 13:22:14 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657459294, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jul 10 13:22:18 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657459294, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jul 10 13:22:22 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657459294, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jul 10 13:22:26 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657459294, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jul 10 13:22:31 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657459294, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jul 10 13:22:35 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657459294, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jul 10 13:22:42 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jul 10 13:22:42 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jul 10 13:22:49 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657459294, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jul 10 13:22:52 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1657459372, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 10 13:22:56 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657459372, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jul 10 13:22:56 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1657459376, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 10 13:23:00 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657459376, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jul 10 13:23:04 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657459376, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jul 10 13:23:08 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657459376, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jul 10 13:23:12 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657459376, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jul 10 13:23:16 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657459376, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jul 10 13:23:20 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657459376, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jul 10 13:23:24 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657459376, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
om1_1        | Sleeping for 5 seconds
om1_1        | Waiting for the service scm3.org:9894
om1_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om1_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om1_1        | 2022-07-10 13:10:11,741 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om1_1        | /************************************************************
om1_1        | STARTUP_MSG: Starting OzoneManager
om1_1        | STARTUP_MSG:   host = om1/172.25.0.111
om1_1        | STARTUP_MSG:   args = [--init]
om1_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
om1_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jna-platform-5.2.0.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/solr-solrj-8.11.2.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.44.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/orc-core-1.5.8.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.44.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/httpasyncclient-4.1.4.jar:/opt/hadoop/share/ozone/lib/httpcore-nio-4.4.14.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-audit-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.23.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/ranger-intg-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.44.0.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.19.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang-2.6.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jna-5.2.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/hppc-0.8.0.jar:/opt/hadoop/share/ozone/lib/aws-java-sdk-bundle-1.12.125.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.44.0.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.44.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jetty-client-9.4.44.v20210927.jar:/opt/hadoop/share/ozone/lib/jersey-client-1.19.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/zstd-jni-1.4.9-1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.44.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ranger-plugin-classloader-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/hive-storage-api-2.7.2.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/gethostname4j-0.0.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-common-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.44.0.jar:/opt/hadoop/share/ozone/lib/kafka-clients-2.8.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/httpmime-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-cred-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-2.0.48.Final.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar
om1_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/d088d199bf506d76f7046a4b19b690e2a9e6915e ; compiled by 'runner' on 2022-07-10T12:46Z
om1_1        | STARTUP_MSG:   java = 11.0.14.1
om1_1        | ************************************************************/
om1_1        | 2022-07-10 13:10:11,795 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om1_1        | 2022-07-10 13:10:19,246 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for OMAudit to [].
om1_1        | 2022-07-10 13:10:21,611 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om1_1        | 2022-07-10 13:10:22,210 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om1, RPC Address: om1:9862 and Ratis port: 9872
om1_1        | 2022-07-10 13:10:22,211 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om1: om1
om1_1        | 2022-07-10 13:10:22,215 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om1: om1
om1_1        | 2022-07-10 13:10:23,414 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om1_1        | 2022-07-10 13:10:23,414 [main] INFO om.OzoneManager: Ozone Manager login successful.
om1_1        | 2022-07-10 13:10:23,501 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1        | 2022-07-10 13:10:24,246 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 3 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
om1_1        | 2022-07-10 13:10:26,529 [main] INFO om.OzoneManager: Initializing secure OzoneManager.
om1_1        | 2022-07-10 13:10:29,877 [main] ERROR client.OMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
om1_1        | 2022-07-10 13:10:29,883 [main] INFO client.OMCertificateClient: Certificate client init case: 0
om1_1        | 2022-07-10 13:10:29,888 [main] INFO client.OMCertificateClient: Creating keypair for client as keypair and certificate not found.
om1_1        | 2022-07-10 13:10:34,328 [main] INFO om.OzoneManager: Init response: GETCERT
om1_1        | 2022-07-10 13:10:34,698 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.111,host:om1
om1_1        | 2022-07-10 13:10:34,707 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
om1_1        | 2022-07-10 13:10:34,725 [main] ERROR client.OMCertificateClient: Invalid domain om1
om1_1        | 2022-07-10 13:10:34,730 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om1_1        | 2022-07-10 13:10:34,750 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om1, RPC Address: om1:9862 and Ratis port: 9872
om1_1        | 2022-07-10 13:10:34,755 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om1: om1
om1_1        | 2022-07-10 13:10:34,756 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om1: om1
om1_1        | 2022-07-10 13:10:34,764 [main] INFO om.OzoneManager: Creating csr for OM->dns:om1,ip:172.25.0.111,scmId:988d83fb-8298-4167-8ff5-9318a8e0d8d4,clusterId:CID-f578972c-97f6-4a12-a46c-8eeea6081008,subject:om1
om1_1        | 2022-07-10 13:10:35,706 [main] INFO om.OzoneManager: OzoneManager ports added:[name: "RPC"
om1_1        | value: 9862
om1_1        | ]
om1_1        | 2022-07-10 13:10:37,282 [main] INFO om.OzoneManager: Successfully stored SCM signed certificate.
om1_1        | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-f578972c-97f6-4a12-a46c-8eeea6081008;layoutVersion=3
om1_1        | 2022-07-10 13:10:37,426 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
om1_1        | /************************************************************
om1_1        | SHUTDOWN_MSG: Shutting down OzoneManager at om1/172.25.0.111
om1_1        | ************************************************************/
om1_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om1_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om1_1        | 2022-07-10 13:10:47,967 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om1_1        | /************************************************************
om2_1        | Sleeping for 5 seconds
om2_1        | Waiting for the service scm3.org:9894
om2_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om2_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om2_1        | 2022-07-10 13:10:12,514 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om2_1        | /************************************************************
om2_1        | STARTUP_MSG: Starting OzoneManager
om2_1        | STARTUP_MSG:   host = om2/172.25.0.112
om2_1        | STARTUP_MSG:   args = [--init]
om2_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
om2_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jna-platform-5.2.0.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/solr-solrj-8.11.2.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.44.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/orc-core-1.5.8.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.44.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/httpasyncclient-4.1.4.jar:/opt/hadoop/share/ozone/lib/httpcore-nio-4.4.14.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-audit-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.23.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/ranger-intg-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.44.0.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.19.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang-2.6.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jna-5.2.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/hppc-0.8.0.jar:/opt/hadoop/share/ozone/lib/aws-java-sdk-bundle-1.12.125.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.44.0.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.44.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jetty-client-9.4.44.v20210927.jar:/opt/hadoop/share/ozone/lib/jersey-client-1.19.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/zstd-jni-1.4.9-1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.44.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ranger-plugin-classloader-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/hive-storage-api-2.7.2.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/gethostname4j-0.0.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-common-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.44.0.jar:/opt/hadoop/share/ozone/lib/kafka-clients-2.8.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/httpmime-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-cred-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-2.0.48.Final.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar
om2_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/d088d199bf506d76f7046a4b19b690e2a9e6915e ; compiled by 'runner' on 2022-07-10T12:46Z
om2_1        | STARTUP_MSG:   java = 11.0.14.1
om2_1        | ************************************************************/
om2_1        | 2022-07-10 13:10:12,625 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om2_1        | 2022-07-10 13:10:19,599 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for OMAudit to [].
om2_1        | 2022-07-10 13:10:21,837 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om2_1        | 2022-07-10 13:10:22,552 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om2, RPC Address: om2:9862 and Ratis port: 9872
om2_1        | 2022-07-10 13:10:22,553 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om2: om2
om2_1        | 2022-07-10 13:10:22,553 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om2: om2
om2_1        | 2022-07-10 13:10:23,837 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om2_1        | 2022-07-10 13:10:23,837 [main] INFO om.OzoneManager: Ozone Manager login successful.
om2_1        | 2022-07-10 13:10:23,914 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1        | 2022-07-10 13:10:24,812 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 3 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
om2_1        | 2022-07-10 13:10:27,790 [main] INFO om.OzoneManager: Initializing secure OzoneManager.
om2_1        | 2022-07-10 13:10:30,590 [main] ERROR client.OMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
om2_1        | 2022-07-10 13:10:30,595 [main] INFO client.OMCertificateClient: Certificate client init case: 0
om2_1        | 2022-07-10 13:10:30,607 [main] INFO client.OMCertificateClient: Creating keypair for client as keypair and certificate not found.
om2_1        | 2022-07-10 13:10:35,659 [main] INFO om.OzoneManager: Init response: GETCERT
om2_1        | 2022-07-10 13:10:35,904 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.112,host:om2
om2_1        | 2022-07-10 13:10:35,904 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
om2_1        | 2022-07-10 13:10:35,917 [main] ERROR client.OMCertificateClient: Invalid domain om2
om2_1        | 2022-07-10 13:10:35,918 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om2_1        | 2022-07-10 13:10:35,918 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om2, RPC Address: om2:9862 and Ratis port: 9872
om2_1        | 2022-07-10 13:10:35,918 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om2: om2
om2_1        | 2022-07-10 13:10:35,919 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om2: om2
om2_1        | 2022-07-10 13:10:35,934 [main] INFO om.OzoneManager: Creating csr for OM->dns:om2,ip:172.25.0.112,scmId:988d83fb-8298-4167-8ff5-9318a8e0d8d4,clusterId:CID-f578972c-97f6-4a12-a46c-8eeea6081008,subject:om2
om2_1        | 2022-07-10 13:10:36,742 [main] INFO om.OzoneManager: OzoneManager ports added:[name: "RPC"
om2_1        | value: 9862
om2_1        | ]
om2_1        | 2022-07-10 13:10:37,904 [main] INFO om.OzoneManager: Successfully stored SCM signed certificate.
om2_1        | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-f578972c-97f6-4a12-a46c-8eeea6081008;layoutVersion=3
om2_1        | 2022-07-10 13:10:38,108 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
om2_1        | /************************************************************
om2_1        | SHUTDOWN_MSG: Shutting down OzoneManager at om2/172.25.0.112
om2_1        | ************************************************************/
om2_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om2_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om2_1        | 2022-07-10 13:10:48,016 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om2_1        | /************************************************************
om3_1        | Sleeping for 5 seconds
om3_1        | Waiting for the service scm3.org:9894
om3_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om3_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om3_1        | 2022-07-10 13:10:12,001 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om3_1        | /************************************************************
om3_1        | STARTUP_MSG: Starting OzoneManager
om3_1        | STARTUP_MSG:   host = om3/172.25.0.113
om3_1        | STARTUP_MSG:   args = [--init]
om3_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
om3_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jna-platform-5.2.0.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/solr-solrj-8.11.2.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.44.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/orc-core-1.5.8.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.44.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/httpasyncclient-4.1.4.jar:/opt/hadoop/share/ozone/lib/httpcore-nio-4.4.14.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-audit-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.23.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/ranger-intg-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.44.0.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.19.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang-2.6.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jna-5.2.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/hppc-0.8.0.jar:/opt/hadoop/share/ozone/lib/aws-java-sdk-bundle-1.12.125.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.44.0.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.44.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jetty-client-9.4.44.v20210927.jar:/opt/hadoop/share/ozone/lib/jersey-client-1.19.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/zstd-jni-1.4.9-1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.44.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ranger-plugin-classloader-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/hive-storage-api-2.7.2.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/gethostname4j-0.0.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-common-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.44.0.jar:/opt/hadoop/share/ozone/lib/kafka-clients-2.8.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/httpmime-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-cred-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-2.0.48.Final.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar
om3_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/d088d199bf506d76f7046a4b19b690e2a9e6915e ; compiled by 'runner' on 2022-07-10T12:46Z
om3_1        | STARTUP_MSG:   java = 11.0.14.1
om3_1        | ************************************************************/
om3_1        | 2022-07-10 13:10:12,062 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om3_1        | 2022-07-10 13:10:18,846 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for OMAudit to [].
om3_1        | 2022-07-10 13:10:21,105 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om3_1        | 2022-07-10 13:10:21,618 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om3, RPC Address: om3:9862 and Ratis port: 9872
om3_1        | 2022-07-10 13:10:21,629 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om3: om3
om3_1        | 2022-07-10 13:10:21,632 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om3: om3
om3_1        | 2022-07-10 13:10:22,726 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om3_1        | 2022-07-10 13:10:22,772 [main] INFO om.OzoneManager: Ozone Manager login successful.
om3_1        | 2022-07-10 13:10:22,810 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1        | 2022-07-10 13:10:23,472 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 3 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
om3_1        | 2022-07-10 13:10:25,861 [main] INFO om.OzoneManager: Initializing secure OzoneManager.
om3_1        | 2022-07-10 13:10:29,004 [main] ERROR client.OMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
om3_1        | 2022-07-10 13:10:29,005 [main] INFO client.OMCertificateClient: Certificate client init case: 0
om3_1        | 2022-07-10 13:10:29,026 [main] INFO client.OMCertificateClient: Creating keypair for client as keypair and certificate not found.
om3_1        | 2022-07-10 13:10:36,276 [main] INFO om.OzoneManager: Init response: GETCERT
om3_1        | 2022-07-10 13:10:36,435 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.113,host:om3
om3_1        | 2022-07-10 13:10:36,440 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
om3_1        | 2022-07-10 13:10:36,460 [main] ERROR client.OMCertificateClient: Invalid domain om3
om3_1        | 2022-07-10 13:10:36,462 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om3_1        | 2022-07-10 13:10:36,463 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om3, RPC Address: om3:9862 and Ratis port: 9872
om3_1        | 2022-07-10 13:10:36,466 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om3: om3
om3_1        | 2022-07-10 13:10:36,467 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om3: om3
om3_1        | 2022-07-10 13:10:36,481 [main] INFO om.OzoneManager: Creating csr for OM->dns:om3,ip:172.25.0.113,scmId:988d83fb-8298-4167-8ff5-9318a8e0d8d4,clusterId:CID-f578972c-97f6-4a12-a46c-8eeea6081008,subject:om3
om3_1        | 2022-07-10 13:10:37,317 [main] INFO om.OzoneManager: OzoneManager ports added:[name: "RPC"
om3_1        | value: 9862
om3_1        | ]
om3_1        | 2022-07-10 13:10:39,002 [main] INFO om.OzoneManager: Successfully stored SCM signed certificate.
om3_1        | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-f578972c-97f6-4a12-a46c-8eeea6081008;layoutVersion=3
om3_1        | 2022-07-10 13:10:39,176 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
om3_1        | /************************************************************
om3_1        | SHUTDOWN_MSG: Shutting down OzoneManager at om3/172.25.0.113
om3_1        | ************************************************************/
om3_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om3_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om3_1        | 2022-07-10 13:10:49,020 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om3_1        | /************************************************************
om3_1        | STARTUP_MSG: Starting OzoneManager
om3_1        | STARTUP_MSG:   host = om3/172.25.0.113
om3_1        | STARTUP_MSG:   args = []
om3_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
kdc_1        | Jul 10 13:23:28 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657459376, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jul 10 13:23:32 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657459376, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jul 10 13:23:36 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657459376, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jul 10 13:23:40 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1657459420, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 10 13:23:42 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jul 10 13:23:42 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jul 10 13:23:44 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657459420, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jul 10 13:23:48 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657459420, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jul 10 13:23:52 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657459420, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jul 10 13:23:56 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657459420, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jul 10 13:24:00 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657459420, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jul 10 13:24:04 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657459420, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jul 10 13:24:08 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657459420, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jul 10 13:24:12 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657459420, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jul 10 13:24:17 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657459420, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jul 10 13:24:20 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1657459460, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 10 13:24:24 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657459460, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jul 10 13:24:28 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657459460, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jul 10 13:24:31 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657459460, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jul 10 13:24:36 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657459460, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jul 10 13:24:40 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657459460, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jul 10 13:24:42 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jul 10 13:24:42 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jul 10 13:24:44 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657459460, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jul 10 13:24:51 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657459460, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jul 10 13:24:55 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657459460, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jul 10 13:24:59 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657459460, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jul 10 13:25:05 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1657459460, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
om1_1        | STARTUP_MSG: Starting OzoneManager
om1_1        | STARTUP_MSG:   host = om1/172.25.0.111
om1_1        | STARTUP_MSG:   args = []
om1_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
om2_1        | STARTUP_MSG: Starting OzoneManager
om2_1        | STARTUP_MSG:   host = om2/172.25.0.112
om2_1        | STARTUP_MSG:   args = []
om2_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
om1_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jna-platform-5.2.0.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/solr-solrj-8.11.2.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.44.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/orc-core-1.5.8.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.44.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/httpasyncclient-4.1.4.jar:/opt/hadoop/share/ozone/lib/httpcore-nio-4.4.14.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-audit-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.23.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/ranger-intg-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.44.0.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.19.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang-2.6.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jna-5.2.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/hppc-0.8.0.jar:/opt/hadoop/share/ozone/lib/aws-java-sdk-bundle-1.12.125.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.44.0.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.44.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jetty-client-9.4.44.v20210927.jar:/opt/hadoop/share/ozone/lib/jersey-client-1.19.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/zstd-jni-1.4.9-1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.44.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ranger-plugin-classloader-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/hive-storage-api-2.7.2.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/gethostname4j-0.0.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-common-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.44.0.jar:/opt/hadoop/share/ozone/lib/kafka-clients-2.8.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/httpmime-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-cred-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-2.0.48.Final.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar
om1_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/d088d199bf506d76f7046a4b19b690e2a9e6915e ; compiled by 'runner' on 2022-07-10T12:46Z
om1_1        | STARTUP_MSG:   java = 11.0.14.1
om1_1        | ************************************************************/
om1_1        | 2022-07-10 13:10:48,014 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om1_1        | 2022-07-10 13:10:54,580 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for OMAudit to [].
om1_1        | 2022-07-10 13:10:57,213 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om1_1        | 2022-07-10 13:10:57,523 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om1, RPC Address: om1:9862 and Ratis port: 9872
om1_1        | 2022-07-10 13:10:57,524 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om1: om1
om1_1        | 2022-07-10 13:10:57,524 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om1: om1
om1_1        | 2022-07-10 13:10:57,546 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1        | 2022-07-10 13:10:57,773 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = MULTITENANCY_SCHEMA (version = 3), software layout = MULTITENANCY_SCHEMA (version = 3)
om1_1        | 2022-07-10 13:10:59,023 [main] INFO reflections.Reflections: Reflections took 1072 ms to scan 1 urls, producing 113 keys and 337 values [using 2 cores]
om1_1        | 2022-07-10 13:11:00,161 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om1_1        | 2022-07-10 13:11:00,162 [main] INFO om.OzoneManager: Ozone Manager login successful.
om1_1        | 2022-07-10 13:11:00,162 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1        | 2022-07-10 13:11:02,297 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 3 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
om1_1        | 2022-07-10 13:11:02,642 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 3 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
om1_1        | 2022-07-10 13:11:06,667 [main] INFO client.OMCertificateClient: Loading certificate from location:/data/metadata/om/certs.
om1_1        | 2022-07-10 13:11:07,294 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/941001850565.crt.
om1_1        | 2022-07-10 13:11:07,329 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/ROOTCA-1.crt.
om1_1        | 2022-07-10 13:11:07,342 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/CA-844577728582.crt.
om1_1        | 2022-07-10 13:11:07,517 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1        | 2022-07-10 13:11:08,318 [main] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
om1_1        | 2022-07-10 13:11:08,322 [main] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
om1_1        | 2022-07-10 13:11:09,856 [main] INFO om.OzoneManager: S3 Multi-Tenancy is disabled
om1_1        | 2022-07-10 13:11:09,917 [main] INFO security.OzoneSecretStore: Loaded 0 tokens
om1_1        | 2022-07-10 13:11:09,918 [main] INFO security.OzoneDelegationTokenSecretManager: Loading token state into token manager.
om1_1        | 2022-07-10 13:11:10,624 [main] INFO om.OzoneManager: Created Volume s3v With Owner om required for S3Gateway operations.
om1_1        | 2022-07-10 13:11:11,335 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om1_1        | 2022-07-10 13:11:11,336 [main] WARN utils.OzoneManagerRatisUtils: ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
om1_1        | 2022-07-10 13:11:11,445 [main] INFO snapshot.OzoneManagerSnapshotProvider: Initializing OM Snapshot Provider
om1_1        | 2022-07-10 13:11:12,589 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
om1_1        | 2022-07-10 13:11:12,736 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om1_1        | 2022-07-10 13:11:13,319 [main] INFO ratis.OzoneManagerRatisServer: Instantiating OM Ratis server with groupID: id1 and peers: om1:9872, om3:9872, om2:9872
om1_1        | 2022-07-10 13:11:13,447 [main] INFO ratis.OzoneManagerStateMachine: LastAppliedIndex is set from TransactionInfo from OM DB as (t:0, i:~)
om1_1        | 2022-07-10 13:11:15,131 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
om1_1        | 2022-07-10 13:11:15,492 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
om1_1        | 2022-07-10 13:11:15,494 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om2_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jna-platform-5.2.0.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/solr-solrj-8.11.2.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.44.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/orc-core-1.5.8.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.44.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/httpasyncclient-4.1.4.jar:/opt/hadoop/share/ozone/lib/httpcore-nio-4.4.14.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-audit-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.23.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/ranger-intg-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.44.0.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.19.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang-2.6.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jna-5.2.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/hppc-0.8.0.jar:/opt/hadoop/share/ozone/lib/aws-java-sdk-bundle-1.12.125.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.44.0.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.44.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jetty-client-9.4.44.v20210927.jar:/opt/hadoop/share/ozone/lib/jersey-client-1.19.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/zstd-jni-1.4.9-1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.44.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ranger-plugin-classloader-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/hive-storage-api-2.7.2.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/gethostname4j-0.0.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-common-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.44.0.jar:/opt/hadoop/share/ozone/lib/kafka-clients-2.8.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/httpmime-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-cred-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-2.0.48.Final.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar
om2_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/d088d199bf506d76f7046a4b19b690e2a9e6915e ; compiled by 'runner' on 2022-07-10T12:46Z
om2_1        | STARTUP_MSG:   java = 11.0.14.1
om2_1        | ************************************************************/
om2_1        | 2022-07-10 13:10:48,078 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om2_1        | 2022-07-10 13:10:54,872 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for OMAudit to [].
om2_1        | 2022-07-10 13:10:57,505 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om2_1        | 2022-07-10 13:10:57,750 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om2, RPC Address: om2:9862 and Ratis port: 9872
om2_1        | 2022-07-10 13:10:57,755 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om2: om2
om2_1        | 2022-07-10 13:10:57,755 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om2: om2
om2_1        | 2022-07-10 13:10:57,805 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1        | 2022-07-10 13:10:58,025 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = MULTITENANCY_SCHEMA (version = 3), software layout = MULTITENANCY_SCHEMA (version = 3)
om2_1        | 2022-07-10 13:10:59,750 [main] INFO reflections.Reflections: Reflections took 1250 ms to scan 1 urls, producing 113 keys and 337 values [using 2 cores]
om2_1        | 2022-07-10 13:11:00,684 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om2_1        | 2022-07-10 13:11:00,693 [main] INFO om.OzoneManager: Ozone Manager login successful.
om2_1        | 2022-07-10 13:11:00,693 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1        | 2022-07-10 13:11:03,188 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 3 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
om2_1        | 2022-07-10 13:11:03,418 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 3 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
om2_1        | 2022-07-10 13:11:07,378 [main] INFO client.OMCertificateClient: Loading certificate from location:/data/metadata/om/certs.
om2_1        | 2022-07-10 13:11:08,014 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/941638739763.crt.
om2_1        | 2022-07-10 13:11:08,059 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/ROOTCA-1.crt.
om2_1        | 2022-07-10 13:11:08,087 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/CA-844577728582.crt.
om2_1        | 2022-07-10 13:11:08,315 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1        | 2022-07-10 13:11:09,983 [main] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
om2_1        | 2022-07-10 13:11:09,986 [main] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
om2_1        | 2022-07-10 13:11:11,356 [main] INFO om.OzoneManager: S3 Multi-Tenancy is disabled
om2_1        | 2022-07-10 13:11:11,397 [main] INFO security.OzoneSecretStore: Loaded 0 tokens
om2_1        | 2022-07-10 13:11:11,397 [main] INFO security.OzoneDelegationTokenSecretManager: Loading token state into token manager.
om2_1        | 2022-07-10 13:11:12,174 [main] INFO om.OzoneManager: Created Volume s3v With Owner om required for S3Gateway operations.
om2_1        | 2022-07-10 13:11:13,163 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om2_1        | 2022-07-10 13:11:13,167 [main] WARN utils.OzoneManagerRatisUtils: ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
om2_1        | 2022-07-10 13:11:13,286 [main] INFO snapshot.OzoneManagerSnapshotProvider: Initializing OM Snapshot Provider
om2_1        | 2022-07-10 13:11:13,950 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
om2_1        | 2022-07-10 13:11:14,023 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om2_1        | 2022-07-10 13:11:14,209 [main] INFO ratis.OzoneManagerRatisServer: Instantiating OM Ratis server with groupID: id1 and peers: om2:9872, om1:9872, om3:9872
om2_1        | 2022-07-10 13:11:14,312 [main] INFO ratis.OzoneManagerStateMachine: LastAppliedIndex is set from TransactionInfo from OM DB as (t:0, i:~)
om2_1        | 2022-07-10 13:11:15,393 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
om2_1        | 2022-07-10 13:11:15,743 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
om2_1        | 2022-07-10 13:11:15,749 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om1_1        | 2022-07-10 13:11:15,496 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
om1_1        | 2022-07-10 13:11:15,500 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om1_1        | 2022-07-10 13:11:15,501 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om1_1        | 2022-07-10 13:11:15,503 [main] INFO server.GrpcService: raft.grpc.message.size.max = 33554432 (custom)
om1_1        | 2022-07-10 13:11:15,520 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om1_1        | 2022-07-10 13:11:15,521 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
om1_1        | 2022-07-10 13:11:15,524 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om1_1        | 2022-07-10 13:11:15,624 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
om1_1        | 2022-07-10 13:11:15,626 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
om1_1        | 2022-07-10 13:11:18,037 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
om1_1        | 2022-07-10 13:11:18,059 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
om1_1        | 2022-07-10 13:11:18,067 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
om1_1        | 2022-07-10 13:11:18,070 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om1_1        | 2022-07-10 13:11:18,071 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om1_1        | 2022-07-10 13:11:18,093 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om1_1        | 2022-07-10 13:11:18,190 [main] INFO server.RaftServer: om1: addNew group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] returns group-562213E44849:java.util.concurrent.CompletableFuture@49d5b651[Not completed]
om1_1        | 2022-07-10 13:11:18,190 [main] INFO om.OzoneManager: OzoneManager Ratis server initialized at port 9872
om1_1        | 2022-07-10 13:11:18,335 [pool-27-thread-1] INFO server.RaftServer$Division: om1: new RaftServerImpl for group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] with OzoneManagerStateMachine:uninitialized
om1_1        | 2022-07-10 13:11:18,354 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
om1_1        | 2022-07-10 13:11:18,364 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
om1_1        | 2022-07-10 13:11:18,364 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
om1_1        | 2022-07-10 13:11:18,364 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om1_1        | 2022-07-10 13:11:18,364 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om1_1        | 2022-07-10 13:11:18,364 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
om1_1        | 2022-07-10 13:11:18,406 [main] INFO om.OzoneManager: Creating RPC Server
om1_1        | 2022-07-10 13:11:18,425 [pool-27-thread-1] INFO server.RaftServer$Division: om1@group-562213E44849: ConfigurationManager, init=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null, confs=<EMPTY_MAP>
om1_1        | 2022-07-10 13:11:18,439 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om1_1        | 2022-07-10 13:11:18,471 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om1_1        | 2022-07-10 13:11:18,483 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
om1_1        | 2022-07-10 13:11:18,488 [pool-27-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 does not exist. Creating ...
om1_1        | 2022-07-10 13:11:18,576 [pool-27-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/in_use.lock acquired by nodename 7@om1
om1_1        | 2022-07-10 13:11:18,781 [pool-27-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 has been successfully formatted.
om1_1        | 2022-07-10 13:11:18,796 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
om1_1        | 2022-07-10 13:11:18,812 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
om1_1        | 2022-07-10 13:11:18,931 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om1_1        | 2022-07-10 13:11:18,934 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om1_1        | 2022-07-10 13:11:18,942 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
om1_1        | 2022-07-10 13:11:19,179 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om1_1        | 2022-07-10 13:11:19,267 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
om1_1        | 2022-07-10 13:11:19,267 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
om1_1        | 2022-07-10 13:11:19,356 [pool-27-thread-1] INFO segmented.SegmentedRaftLogWorker: new om1@group-562213E44849-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849
om1_1        | 2022-07-10 13:11:19,419 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
om1_1        | 2022-07-10 13:11:19,426 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
om1_1        | 2022-07-10 13:11:19,432 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om1_1        | 2022-07-10 13:11:19,544 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
om1_1        | 2022-07-10 13:11:19,545 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
om1_1        | 2022-07-10 13:11:19,561 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
om1_1        | 2022-07-10 13:11:19,563 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om1_1        | 2022-07-10 13:11:19,569 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
om1_1        | 2022-07-10 13:11:19,712 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
om1_1        | 2022-07-10 13:11:19,723 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
om1_1        | 2022-07-10 13:11:19,742 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
om1_1        | 2022-07-10 13:11:19,836 [pool-27-thread-1] INFO segmented.SegmentedRaftLogWorker: om1@group-562213E44849-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
om1_1        | 2022-07-10 13:11:19,853 [pool-27-thread-1] INFO segmented.SegmentedRaftLogWorker: om1@group-562213E44849-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
om1_1        | 2022-07-10 13:11:19,886 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
om1_1        | 2022-07-10 13:11:19,894 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 400000 (default)
om1_1        | 2022-07-10 13:11:19,895 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
om1_1        | 2022-07-10 13:11:19,903 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = true (custom)
om1_1        | 2022-07-10 13:11:19,914 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 300s (custom)
om1_1        | 2022-07-10 13:11:19,922 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
om1_1        | 2022-07-10 13:11:20,269 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om1_1        | 2022-07-10 13:11:20,322 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
om1_1        | 2022-07-10 13:11:20,323 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
om1_1        | 2022-07-10 13:11:20,324 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
om1_1        | 2022-07-10 13:11:20,330 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
om1_1        | 2022-07-10 13:11:20,994 [main] INFO reflections.Reflections: Reflections took 2092 ms to scan 8 urls, producing 23 keys and 512 values [using 2 cores]
om1_1        | 2022-07-10 13:11:21,973 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om1_1        | 2022-07-10 13:11:22,031 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om1_1        | 2022-07-10 13:11:26,029 [Listener at om1/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om1_1        | 2022-07-10 13:11:26,091 [Listener at om1/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om1_1        | 2022-07-10 13:11:26,091 [Listener at om1/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om1_1        | 2022-07-10 13:11:26,298 [Listener at om1/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om1/172.25.0.111:9862
om1_1        | 2022-07-10 13:11:26,299 [Listener at om1/9862] INFO ratis.OzoneManagerRatisServer: Starting OzoneManagerRatisServer om1 at port 9872
om1_1        | 2022-07-10 13:11:26,301 [om1-impl-thread1] INFO server.RaftServer$Division: om1@group-562213E44849: start as a follower, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om1_1        | 2022-07-10 13:11:26,307 [om1-impl-thread1] INFO server.RaftServer$Division: om1@group-562213E44849: changes role from      null to FOLLOWER at term 0 for startAsFollower
om1_1        | 2022-07-10 13:11:26,310 [om1-impl-thread1] INFO impl.RoleInfo: om1: start om1@group-562213E44849-FollowerState
om1_1        | 2022-07-10 13:11:26,323 [om1-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-562213E44849,id=om1
om1_1        | 2022-07-10 13:11:26,341 [Listener at om1/9862] INFO server.RaftServer: om1: start RPC server
om1_1        | 2022-07-10 13:11:26,510 [Listener at om1/9862] INFO server.GrpcService: om1: GrpcService started, listening on 9872
om1_1        | 2022-07-10 13:11:26,513 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$449/0x00000008405cac40@5aecf9b5] INFO util.JvmPauseMonitor: JvmPauseMonitor-om1: Started
om1_1        | 2022-07-10 13:11:26,515 [Listener at om1/9862] INFO om.OzoneManager: Starting OM block token secret manager
om1_1        | 2022-07-10 13:11:26,525 [Listener at om1/9862] INFO token.OzoneBlockTokenSecretManager: Updating the current master key for generating tokens
om1_1        | 2022-07-10 13:11:26,526 [Listener at om1/9862] INFO om.OzoneManager: Starting OM delegation token secret manager
om1_1        | 2022-07-10 13:11:26,526 [Listener at om1/9862] INFO security.OzoneDelegationTokenSecretManager: Updating the current master key for generating tokens
om1_1        | 2022-07-10 13:11:26,540 [Listener at om1/9862] INFO om.OzoneManager: Version File has different layout version (3) than OM DB (null). That is expected if this OM has never been finalized to a newer layout version.
om1_1        | 2022-07-10 13:11:26,535 [Thread[Thread-18,5,main]] INFO security.OzoneDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
om1_1        | 2022-07-10 13:11:26,724 [Listener at om1/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om1_1        | 2022-07-10 13:11:26,727 [Listener at om1/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
om1_1        | 2022-07-10 13:11:26,727 [Listener at om1/9862] INFO http.BaseHttpServer: HttpAuthType: ozone.om.http.auth.type = kerberos
om2_1        | 2022-07-10 13:11:15,749 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
om2_1        | 2022-07-10 13:11:15,749 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om2_1        | 2022-07-10 13:11:15,750 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om2_1        | 2022-07-10 13:11:15,750 [main] INFO server.GrpcService: raft.grpc.message.size.max = 33554432 (custom)
om2_1        | 2022-07-10 13:11:15,757 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om2_1        | 2022-07-10 13:11:15,759 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
om2_1        | 2022-07-10 13:11:15,762 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om2_1        | 2022-07-10 13:11:15,806 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
om2_1        | 2022-07-10 13:11:15,810 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
om2_1        | 2022-07-10 13:11:17,990 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
om2_1        | 2022-07-10 13:11:18,007 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
om2_1        | 2022-07-10 13:11:18,021 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
om2_1        | 2022-07-10 13:11:18,022 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om2_1        | 2022-07-10 13:11:18,022 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om2_1        | 2022-07-10 13:11:18,047 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om2_1        | 2022-07-10 13:11:18,126 [main] INFO server.RaftServer: om2: addNew group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] returns group-562213E44849:java.util.concurrent.CompletableFuture@61fb3dae[Not completed]
om2_1        | 2022-07-10 13:11:18,126 [main] INFO om.OzoneManager: OzoneManager Ratis server initialized at port 9872
om2_1        | 2022-07-10 13:11:18,329 [main] INFO om.OzoneManager: Creating RPC Server
om2_1        | 2022-07-10 13:11:18,328 [pool-27-thread-1] INFO server.RaftServer$Division: om2: new RaftServerImpl for group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] with OzoneManagerStateMachine:uninitialized
om2_1        | 2022-07-10 13:11:18,397 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
om2_1        | 2022-07-10 13:11:18,415 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
om2_1        | 2022-07-10 13:11:18,416 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
om2_1        | 2022-07-10 13:11:18,416 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om2_1        | 2022-07-10 13:11:18,416 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om2_1        | 2022-07-10 13:11:18,423 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
om2_1        | 2022-07-10 13:11:18,448 [pool-27-thread-1] INFO server.RaftServer$Division: om2@group-562213E44849: ConfigurationManager, init=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null, confs=<EMPTY_MAP>
om2_1        | 2022-07-10 13:11:18,471 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om2_1        | 2022-07-10 13:11:18,535 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om2_1        | 2022-07-10 13:11:18,536 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
om2_1        | 2022-07-10 13:11:18,571 [pool-27-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 does not exist. Creating ...
om2_1        | 2022-07-10 13:11:18,706 [pool-27-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/in_use.lock acquired by nodename 7@om2
om2_1        | 2022-07-10 13:11:18,851 [pool-27-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 has been successfully formatted.
om2_1        | 2022-07-10 13:11:18,867 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
om2_1        | 2022-07-10 13:11:18,894 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
om2_1        | 2022-07-10 13:11:18,998 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om2_1        | 2022-07-10 13:11:19,022 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om2_1        | 2022-07-10 13:11:19,071 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
om2_1        | 2022-07-10 13:11:19,398 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om2_1        | 2022-07-10 13:11:19,548 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
om2_1        | 2022-07-10 13:11:19,563 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
om2_1        | 2022-07-10 13:11:19,604 [pool-27-thread-1] INFO segmented.SegmentedRaftLogWorker: new om2@group-562213E44849-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849
om2_1        | 2022-07-10 13:11:19,632 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
om2_1        | 2022-07-10 13:11:19,632 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
om2_1        | 2022-07-10 13:11:19,643 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om2_1        | 2022-07-10 13:11:19,652 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
om2_1        | 2022-07-10 13:11:19,654 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
om2_1        | 2022-07-10 13:11:19,655 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
om2_1        | 2022-07-10 13:11:19,661 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om2_1        | 2022-07-10 13:11:19,664 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
om2_1        | 2022-07-10 13:11:19,837 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
om2_1        | 2022-07-10 13:11:19,851 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
om2_1        | 2022-07-10 13:11:19,853 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
om2_1        | 2022-07-10 13:11:19,926 [pool-27-thread-1] INFO segmented.SegmentedRaftLogWorker: om2@group-562213E44849-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
om1_1        | 2022-07-10 13:11:26,851 [Listener at om1/9862] INFO util.log: Logging initialized @48139ms to org.eclipse.jetty.util.log.Slf4jLog
om1_1        | 2022-07-10 13:11:27,315 [Listener at om1/9862] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
om1_1        | 2022-07-10 13:11:27,345 [Listener at om1/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om1_1        | 2022-07-10 13:11:27,352 [Listener at om1/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context ozoneManager
om1_1        | 2022-07-10 13:11:27,360 [Listener at om1/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
om1_1        | 2022-07-10 13:11:27,361 [Listener at om1/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
om1_1        | 2022-07-10 13:11:27,364 [Listener at om1/9862] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.om.http.auth.kerberos.principal keytabKey: ozone.om.http.auth.kerberos.keytab
om1_1        | 2022-07-10 13:11:27,572 [Listener at om1/9862] INFO http.HttpServer2: Jetty bound to port 9874
om1_1        | 2022-07-10 13:11:27,574 [Listener at om1/9862] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
om1_1        | 2022-07-10 13:11:27,752 [Listener at om1/9862] INFO server.session: DefaultSessionIdManager workerName=node0
om1_1        | 2022-07-10 13:11:27,760 [Listener at om1/9862] INFO server.session: No SessionScavenger set, using defaults
om1_1        | 2022-07-10 13:11:27,773 [Listener at om1/9862] INFO server.session: node0 Scavenging every 600000ms
om1_1        | 2022-07-10 13:11:27,829 [Listener at om1/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om1_1        | 2022-07-10 13:11:27,840 [Listener at om1/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1ce27871{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om1_1        | 2022-07-10 13:11:27,843 [Listener at om1/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@4257255f{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om2_1        | 2022-07-10 13:11:19,931 [pool-27-thread-1] INFO segmented.SegmentedRaftLogWorker: om2@group-562213E44849-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
om2_1        | 2022-07-10 13:11:19,995 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
om2_1        | 2022-07-10 13:11:19,997 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 400000 (default)
om2_1        | 2022-07-10 13:11:19,999 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
om2_1        | 2022-07-10 13:11:20,002 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = true (custom)
om2_1        | 2022-07-10 13:11:20,033 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 300s (custom)
om2_1        | 2022-07-10 13:11:20,035 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
om2_1        | 2022-07-10 13:11:20,393 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om2_1        | 2022-07-10 13:11:20,403 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
om2_1        | 2022-07-10 13:11:20,408 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
om2_1        | 2022-07-10 13:11:20,409 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
om2_1        | 2022-07-10 13:11:20,411 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
om2_1        | 2022-07-10 13:11:20,975 [main] INFO reflections.Reflections: Reflections took 2085 ms to scan 8 urls, producing 23 keys and 512 values [using 2 cores]
om2_1        | 2022-07-10 13:11:21,937 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om2_1        | 2022-07-10 13:11:21,976 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om2_1        | 2022-07-10 13:11:25,762 [Listener at om2/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om2_1        | 2022-07-10 13:11:25,825 [Listener at om2/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om2_1        | 2022-07-10 13:11:25,825 [Listener at om2/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om2_1        | 2022-07-10 13:11:26,260 [Listener at om2/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om2/172.25.0.112:9862
om2_1        | 2022-07-10 13:11:26,260 [Listener at om2/9862] INFO ratis.OzoneManagerRatisServer: Starting OzoneManagerRatisServer om2 at port 9872
om2_1        | 2022-07-10 13:11:26,286 [om2-impl-thread1] INFO server.RaftServer$Division: om2@group-562213E44849: start as a follower, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om2_1        | 2022-07-10 13:11:26,296 [om2-impl-thread1] INFO server.RaftServer$Division: om2@group-562213E44849: changes role from      null to FOLLOWER at term 0 for startAsFollower
om2_1        | 2022-07-10 13:11:26,309 [om2-impl-thread1] INFO impl.RoleInfo: om2: start om2@group-562213E44849-FollowerState
om2_1        | 2022-07-10 13:11:26,328 [om2-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-562213E44849,id=om2
om2_1        | 2022-07-10 13:11:26,363 [Listener at om2/9862] INFO server.RaftServer: om2: start RPC server
om2_1        | 2022-07-10 13:11:26,645 [Listener at om2/9862] INFO server.GrpcService: om2: GrpcService started, listening on 9872
om2_1        | 2022-07-10 13:11:26,653 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$449/0x00000008405cac40@2a0b4810] INFO util.JvmPauseMonitor: JvmPauseMonitor-om2: Started
om2_1        | 2022-07-10 13:11:26,654 [Listener at om2/9862] INFO om.OzoneManager: Starting OM block token secret manager
om2_1        | 2022-07-10 13:11:26,655 [Listener at om2/9862] INFO token.OzoneBlockTokenSecretManager: Updating the current master key for generating tokens
om2_1        | 2022-07-10 13:11:26,660 [Listener at om2/9862] INFO om.OzoneManager: Starting OM delegation token secret manager
om2_1        | 2022-07-10 13:11:26,660 [Listener at om2/9862] INFO security.OzoneDelegationTokenSecretManager: Updating the current master key for generating tokens
om2_1        | 2022-07-10 13:11:26,674 [Listener at om2/9862] INFO om.OzoneManager: Version File has different layout version (3) than OM DB (null). That is expected if this OM has never been finalized to a newer layout version.
om2_1        | 2022-07-10 13:11:26,695 [Thread[Thread-18,5,main]] INFO security.OzoneDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
om2_1        | 2022-07-10 13:11:26,872 [Listener at om2/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om2_1        | 2022-07-10 13:11:26,872 [Listener at om2/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
om2_1        | 2022-07-10 13:11:26,872 [Listener at om2/9862] INFO http.BaseHttpServer: HttpAuthType: ozone.om.http.auth.type = kerberos
om2_1        | 2022-07-10 13:11:27,205 [Listener at om2/9862] INFO util.log: Logging initialized @47793ms to org.eclipse.jetty.util.log.Slf4jLog
om2_1        | 2022-07-10 13:11:27,648 [Listener at om2/9862] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
om2_1        | 2022-07-10 13:11:27,679 [Listener at om2/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om2_1        | 2022-07-10 13:11:27,691 [Listener at om2/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context ozoneManager
om2_1        | 2022-07-10 13:11:27,691 [Listener at om2/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
om2_1        | 2022-07-10 13:11:27,691 [Listener at om2/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
om2_1        | 2022-07-10 13:11:27,694 [Listener at om2/9862] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.om.http.auth.kerberos.principal keytabKey: ozone.om.http.auth.kerberos.keytab
om2_1        | 2022-07-10 13:11:27,999 [Listener at om2/9862] INFO http.HttpServer2: Jetty bound to port 9874
om2_1        | 2022-07-10 13:11:28,003 [Listener at om2/9862] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
om2_1        | 2022-07-10 13:11:28,145 [Listener at om2/9862] INFO server.session: DefaultSessionIdManager workerName=node0
om2_1        | 2022-07-10 13:11:28,145 [Listener at om2/9862] INFO server.session: No SessionScavenger set, using defaults
om2_1        | 2022-07-10 13:11:28,161 [Listener at om2/9862] INFO server.session: node0 Scavenging every 600000ms
om2_1        | 2022-07-10 13:11:28,261 [Listener at om2/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om2_1        | 2022-07-10 13:11:28,271 [Listener at om2/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@45e4debe{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om2_1        | 2022-07-10 13:11:28,273 [Listener at om2/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@3073c879{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om3_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jna-platform-5.2.0.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/solr-solrj-8.11.2.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.44.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/orc-core-1.5.8.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.44.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/httpasyncclient-4.1.4.jar:/opt/hadoop/share/ozone/lib/httpcore-nio-4.4.14.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-audit-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.23.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/ranger-intg-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.44.0.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.19.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang-2.6.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jna-5.2.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/hppc-0.8.0.jar:/opt/hadoop/share/ozone/lib/aws-java-sdk-bundle-1.12.125.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.44.0.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.44.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jetty-client-9.4.44.v20210927.jar:/opt/hadoop/share/ozone/lib/jersey-client-1.19.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/zstd-jni-1.4.9-1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.44.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ranger-plugin-classloader-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/hive-storage-api-2.7.2.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/gethostname4j-0.0.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-common-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.44.0.jar:/opt/hadoop/share/ozone/lib/kafka-clients-2.8.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/httpmime-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-cred-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-2.0.48.Final.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar
om3_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/d088d199bf506d76f7046a4b19b690e2a9e6915e ; compiled by 'runner' on 2022-07-10T12:46Z
om3_1        | STARTUP_MSG:   java = 11.0.14.1
om3_1        | ************************************************************/
om3_1        | 2022-07-10 13:10:49,101 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om3_1        | 2022-07-10 13:10:56,717 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for OMAudit to [].
om3_1        | 2022-07-10 13:10:58,738 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om3_1        | 2022-07-10 13:10:59,521 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om3, RPC Address: om3:9862 and Ratis port: 9872
om3_1        | 2022-07-10 13:10:59,521 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om3: om3
om3_1        | 2022-07-10 13:10:59,524 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om3: om3
om3_1        | 2022-07-10 13:10:59,653 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1        | 2022-07-10 13:10:59,947 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = MULTITENANCY_SCHEMA (version = 3), software layout = MULTITENANCY_SCHEMA (version = 3)
om3_1        | 2022-07-10 13:11:01,240 [main] INFO reflections.Reflections: Reflections took 864 ms to scan 1 urls, producing 113 keys and 337 values [using 2 cores]
om3_1        | 2022-07-10 13:11:02,736 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om3_1        | 2022-07-10 13:11:02,736 [main] INFO om.OzoneManager: Ozone Manager login successful.
om3_1        | 2022-07-10 13:11:02,739 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1        | 2022-07-10 13:11:04,834 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 3 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
om3_1        | 2022-07-10 13:11:05,037 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 3 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
om3_1        | 2022-07-10 13:11:09,352 [main] INFO client.OMCertificateClient: Loading certificate from location:/data/metadata/om/certs.
om3_1        | 2022-07-10 13:11:09,892 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/ROOTCA-1.crt.
om3_1        | 2022-07-10 13:11:09,910 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/CA-844577728582.crt.
om3_1        | 2022-07-10 13:11:09,958 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/942462550383.crt.
om3_1        | 2022-07-10 13:11:10,221 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1        | 2022-07-10 13:11:10,982 [main] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
om3_1        | 2022-07-10 13:11:10,984 [main] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
om3_1        | 2022-07-10 13:11:11,905 [main] INFO om.OzoneManager: S3 Multi-Tenancy is disabled
om3_1        | 2022-07-10 13:11:11,971 [main] INFO security.OzoneSecretStore: Loaded 0 tokens
om3_1        | 2022-07-10 13:11:11,971 [main] INFO security.OzoneDelegationTokenSecretManager: Loading token state into token manager.
om3_1        | 2022-07-10 13:11:12,614 [main] INFO om.OzoneManager: Created Volume s3v With Owner om required for S3Gateway operations.
om3_1        | 2022-07-10 13:11:13,390 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om3_1        | 2022-07-10 13:11:13,395 [main] WARN utils.OzoneManagerRatisUtils: ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
om3_1        | 2022-07-10 13:11:13,481 [main] INFO snapshot.OzoneManagerSnapshotProvider: Initializing OM Snapshot Provider
om3_1        | 2022-07-10 13:11:14,252 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
om3_1        | 2022-07-10 13:11:14,417 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om3_1        | 2022-07-10 13:11:14,906 [main] INFO ratis.OzoneManagerRatisServer: Instantiating OM Ratis server with groupID: id1 and peers: om3:9872, om1:9872, om2:9872
om3_1        | 2022-07-10 13:11:14,966 [main] INFO ratis.OzoneManagerStateMachine: LastAppliedIndex is set from TransactionInfo from OM DB as (t:0, i:~)
om3_1        | 2022-07-10 13:11:15,964 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
om3_1        | 2022-07-10 13:11:16,426 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
om3_1        | 2022-07-10 13:11:16,451 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om3_1        | 2022-07-10 13:11:16,451 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
om3_1        | 2022-07-10 13:11:16,456 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om3_1        | 2022-07-10 13:11:16,457 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om3_1        | 2022-07-10 13:11:16,461 [main] INFO server.GrpcService: raft.grpc.message.size.max = 33554432 (custom)
om3_1        | 2022-07-10 13:11:16,481 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om3_1        | 2022-07-10 13:11:16,488 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
om3_1        | 2022-07-10 13:11:16,490 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om3_1        | 2022-07-10 13:11:16,553 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
om3_1        | 2022-07-10 13:11:16,559 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
om3_1        | 2022-07-10 13:11:19,225 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
om3_1        | 2022-07-10 13:11:19,233 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
om3_1        | 2022-07-10 13:11:19,238 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
om3_1        | 2022-07-10 13:11:19,243 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om3_1        | 2022-07-10 13:11:19,244 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om3_1        | 2022-07-10 13:11:19,255 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om3_1        | 2022-07-10 13:11:19,350 [main] INFO server.RaftServer: om3: addNew group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] returns group-562213E44849:java.util.concurrent.CompletableFuture@49d5b651[Not completed]
om3_1        | 2022-07-10 13:11:19,352 [main] INFO om.OzoneManager: OzoneManager Ratis server initialized at port 9872
om3_1        | 2022-07-10 13:11:19,427 [pool-27-thread-1] INFO server.RaftServer$Division: om3: new RaftServerImpl for group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] with OzoneManagerStateMachine:uninitialized
om3_1        | 2022-07-10 13:11:19,429 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
om3_1        | 2022-07-10 13:11:19,435 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
om3_1        | 2022-07-10 13:11:19,436 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
om3_1        | 2022-07-10 13:11:19,437 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om3_1        | 2022-07-10 13:11:19,438 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om3_1        | 2022-07-10 13:11:19,438 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
om3_1        | 2022-07-10 13:11:19,489 [main] INFO om.OzoneManager: Creating RPC Server
om3_1        | 2022-07-10 13:11:19,541 [pool-27-thread-1] INFO server.RaftServer$Division: om3@group-562213E44849: ConfigurationManager, init=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null, confs=<EMPTY_MAP>
om3_1        | 2022-07-10 13:11:19,544 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om3_1        | 2022-07-10 13:11:19,572 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om3_1        | 2022-07-10 13:11:19,580 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
om3_1        | 2022-07-10 13:11:19,586 [pool-27-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 does not exist. Creating ...
om3_1        | 2022-07-10 13:11:19,655 [pool-27-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/in_use.lock acquired by nodename 6@om3
om3_1        | 2022-07-10 13:11:19,896 [pool-27-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 has been successfully formatted.
om3_1        | 2022-07-10 13:11:19,934 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
om3_1        | 2022-07-10 13:11:19,950 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
om3_1        | 2022-07-10 13:11:20,030 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om3_1        | 2022-07-10 13:11:20,030 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om3_1        | 2022-07-10 13:11:20,060 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
om3_1        | 2022-07-10 13:11:20,269 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om3_1        | 2022-07-10 13:11:20,452 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
om3_1        | 2022-07-10 13:11:20,453 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
om3_1        | 2022-07-10 13:11:20,505 [pool-27-thread-1] INFO segmented.SegmentedRaftLogWorker: new om3@group-562213E44849-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849
om3_1        | 2022-07-10 13:11:20,517 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
om3_1        | 2022-07-10 13:11:20,523 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
om3_1        | 2022-07-10 13:11:20,527 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om3_1        | 2022-07-10 13:11:20,534 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
om3_1        | 2022-07-10 13:11:20,536 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
om3_1        | 2022-07-10 13:11:20,547 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
om3_1        | 2022-07-10 13:11:20,547 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om3_1        | 2022-07-10 13:11:20,548 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
om3_1        | 2022-07-10 13:11:20,623 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
om3_1        | 2022-07-10 13:11:20,635 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
om3_1        | 2022-07-10 13:11:20,644 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
om3_1        | 2022-07-10 13:11:20,730 [pool-27-thread-1] INFO segmented.SegmentedRaftLogWorker: om3@group-562213E44849-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
om2_1        | 2022-07-10 13:11:28,646 [Listener at om2/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om2_1        | 2022-07-10 13:11:28,683 [Listener at om2/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@510a5fe1{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-ozone-manager-1_3_0-SNAPSHOT_jar-_-any-9707071660824963880/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/ozoneManager}
om2_1        | 2022-07-10 13:11:28,717 [Listener at om2/9862] INFO server.AbstractConnector: Started ServerConnector@22395d00{HTTP/1.1, (http/1.1)}{0.0.0.0:9874}
om2_1        | 2022-07-10 13:11:28,717 [Listener at om2/9862] INFO server.Server: Started @49305ms
om2_1        | 2022-07-10 13:11:28,719 [Listener at om2/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
om2_1        | 2022-07-10 13:11:28,719 [Listener at om2/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
om2_1        | 2022-07-10 13:11:28,727 [Listener at om2/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
om2_1        | 2022-07-10 13:11:28,738 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om2_1        | 2022-07-10 13:11:28,762 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om2_1        | 2022-07-10 13:11:28,846 [Listener at om2/9862] INFO om.OzoneManager: Trash Interval set to 0. Files deleted won't move to trash
om2_1        | 2022-07-10 13:11:29,087 [Listener at om2/9862] INFO om.GrpcOzoneManagerServer: GrpcOzoneManagerServer is started using port 8981
om2_1        | 2022-07-10 13:11:29,119 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6dd3a1a1] INFO util.JvmPauseMonitor: Starting JVM pause monitor
om2_1        | 2022-07-10 13:11:29,783 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:42327
om2_1        | 2022-07-10 13:11:29,799 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:11:31,422 [om2@group-562213E44849-FollowerState] INFO impl.FollowerState: om2@group-562213E44849-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5113412453ns, electionTimeout:5108ms
om2_1        | 2022-07-10 13:11:31,424 [om2@group-562213E44849-FollowerState] INFO impl.RoleInfo: om2: shutdown om2@group-562213E44849-FollowerState
om2_1        | 2022-07-10 13:11:31,424 [om2@group-562213E44849-FollowerState] INFO server.RaftServer$Division: om2@group-562213E44849: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
om2_1        | 2022-07-10 13:11:31,429 [om2@group-562213E44849-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
om2_1        | 2022-07-10 13:11:31,429 [om2@group-562213E44849-FollowerState] INFO impl.RoleInfo: om2: start om2@group-562213E44849-LeaderElection1
om2_1        | 2022-07-10 13:11:31,448 [om2@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om2@group-562213E44849-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om2_1        | 2022-07-10 13:11:33,655 [grpc-default-executor-1] INFO server.RaftServer$Division: om2@group-562213E44849: receive requestVote(ELECTION, om1, group-562213E44849, 1, (t:0, i:~))
om2_1        | 2022-07-10 13:11:33,666 [grpc-default-executor-1] INFO impl.VoteContext: om2@group-562213E44849-CANDIDATE: reject ELECTION from om1: already has voted for om2 at current term 1
om2_1        | 2022-07-10 13:11:33,674 [grpc-default-executor-1] INFO server.RaftServer$Division: om2@group-562213E44849 replies to ELECTION vote request: om1<-om2#0:FAIL-t1. Peer's state: om2@group-562213E44849:t1, leader=null, voted=om2, raftlog=om2@group-562213E44849-SegmentedRaftLog:OPENED:c-1, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om2_1        | 2022-07-10 13:11:34,408 [om2@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om2@group-562213E44849-LeaderElection1: ELECTION REJECTED received 2 response(s) and 0 exception(s):
om2_1        | 2022-07-10 13:11:34,408 [om2@group-562213E44849-LeaderElection1] INFO impl.LeaderElection:   Response 0: om2<-om1#0:FAIL-t1
om2_1        | 2022-07-10 13:11:34,408 [om2@group-562213E44849-LeaderElection1] INFO impl.LeaderElection:   Response 1: om2<-om3#0:FAIL-t1
om2_1        | 2022-07-10 13:11:34,409 [om2@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om2@group-562213E44849-LeaderElection1 ELECTION round 0: result REJECTED
om2_1        | 2022-07-10 13:11:34,424 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServer$Division: om2@group-562213E44849: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
om2_1        | 2022-07-10 13:11:34,424 [om2@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om2: shutdown om2@group-562213E44849-LeaderElection1
om2_1        | 2022-07-10 13:11:34,424 [om2@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om2: start om2@group-562213E44849-FollowerState
om2_1        | 2022-07-10 13:11:34,564 [grpc-default-executor-1] INFO server.RaftServer$Division: om2@group-562213E44849: receive requestVote(ELECTION, om3, group-562213E44849, 1, (t:0, i:~))
om2_1        | 2022-07-10 13:11:34,564 [grpc-default-executor-1] INFO impl.VoteContext: om2@group-562213E44849-FOLLOWER: reject ELECTION from om3: already has voted for om2 at current term 1
om2_1        | 2022-07-10 13:11:34,564 [grpc-default-executor-1] INFO server.RaftServer$Division: om2@group-562213E44849 replies to ELECTION vote request: om3<-om2#0:FAIL-t1. Peer's state: om2@group-562213E44849:t1, leader=null, voted=om2, raftlog=om2@group-562213E44849-SegmentedRaftLog:OPENED:c-1, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om2_1        | 2022-07-10 13:11:38,196 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41900
om2_1        | 2022-07-10 13:11:38,202 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:11:39,523 [om2@group-562213E44849-FollowerState] INFO impl.FollowerState: om2@group-562213E44849-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5098770988ns, electionTimeout:5095ms
om2_1        | 2022-07-10 13:11:39,524 [om2@group-562213E44849-FollowerState] INFO impl.RoleInfo: om2: shutdown om2@group-562213E44849-FollowerState
om2_1        | 2022-07-10 13:11:39,524 [om2@group-562213E44849-FollowerState] INFO server.RaftServer$Division: om2@group-562213E44849: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
om2_1        | 2022-07-10 13:11:39,524 [om2@group-562213E44849-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
om2_1        | 2022-07-10 13:11:39,524 [om2@group-562213E44849-FollowerState] INFO impl.RoleInfo: om2: start om2@group-562213E44849-LeaderElection2
om2_1        | 2022-07-10 13:11:39,526 [om2@group-562213E44849-LeaderElection2] INFO impl.LeaderElection: om2@group-562213E44849-LeaderElection2 ELECTION round 0: submit vote requests at term 2 for -1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om2_1        | 2022-07-10 13:11:39,565 [om2@group-562213E44849-LeaderElection2] INFO impl.LeaderElection: om2@group-562213E44849-LeaderElection2: ELECTION PASSED received 1 response(s) and 0 exception(s):
om2_1        | 2022-07-10 13:11:39,565 [om2@group-562213E44849-LeaderElection2] INFO impl.LeaderElection:   Response 0: om2<-om1#0:OK-t2
om1_1        | 2022-07-10 13:11:28,255 [Listener at om1/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om1_1        | 2022-07-10 13:11:28,299 [Listener at om1/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@3d8141b4{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-ozone-manager-1_3_0-SNAPSHOT_jar-_-any-7171406699205167807/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/ozoneManager}
om1_1        | 2022-07-10 13:11:28,333 [Listener at om1/9862] INFO server.AbstractConnector: Started ServerConnector@18690d13{HTTP/1.1, (http/1.1)}{0.0.0.0:9874}
om1_1        | 2022-07-10 13:11:28,333 [Listener at om1/9862] INFO server.Server: Started @49621ms
om1_1        | 2022-07-10 13:11:28,347 [Listener at om1/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
om1_1        | 2022-07-10 13:11:28,347 [Listener at om1/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
om1_1        | 2022-07-10 13:11:28,349 [Listener at om1/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
om1_1        | 2022-07-10 13:11:28,361 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om1_1        | 2022-07-10 13:11:28,364 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om1_1        | 2022-07-10 13:11:28,649 [Listener at om1/9862] INFO om.OzoneManager: Trash Interval set to 0. Files deleted won't move to trash
om1_1        | 2022-07-10 13:11:28,842 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:39163
om1_1        | 2022-07-10 13:11:28,859 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-07-10 13:11:29,061 [Listener at om1/9862] INFO om.GrpcOzoneManagerServer: GrpcOzoneManagerServer is started using port 8981
om1_1        | 2022-07-10 13:11:29,106 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@10e3a63a] INFO util.JvmPauseMonitor: Starting JVM pause monitor
om1_1        | 2022-07-10 13:11:31,476 [om1@group-562213E44849-FollowerState] INFO impl.FollowerState: om1@group-562213E44849-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5166700862ns, electionTimeout:5118ms
om1_1        | 2022-07-10 13:11:31,477 [om1@group-562213E44849-FollowerState] INFO impl.RoleInfo: om1: shutdown om1@group-562213E44849-FollowerState
om1_1        | 2022-07-10 13:11:31,479 [om1@group-562213E44849-FollowerState] INFO server.RaftServer$Division: om1@group-562213E44849: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
om1_1        | 2022-07-10 13:11:31,499 [om1@group-562213E44849-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
om1_1        | 2022-07-10 13:11:31,499 [om1@group-562213E44849-FollowerState] INFO impl.RoleInfo: om1: start om1@group-562213E44849-LeaderElection1
om1_1        | 2022-07-10 13:11:31,529 [om1@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om1@group-562213E44849-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om1_1        | 2022-07-10 13:11:33,679 [grpc-default-executor-0] INFO server.RaftServer$Division: om1@group-562213E44849: receive requestVote(ELECTION, om2, group-562213E44849, 1, (t:0, i:~))
om1_1        | 2022-07-10 13:11:33,686 [grpc-default-executor-0] INFO impl.VoteContext: om1@group-562213E44849-CANDIDATE: reject ELECTION from om2: already has voted for om1 at current term 1
om1_1        | 2022-07-10 13:11:33,700 [grpc-default-executor-0] INFO server.RaftServer$Division: om1@group-562213E44849 replies to ELECTION vote request: om2<-om1#0:FAIL-t1. Peer's state: om1@group-562213E44849:t1, leader=null, voted=om1, raftlog=om1@group-562213E44849-SegmentedRaftLog:OPENED:c-1, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om1_1        | 2022-07-10 13:11:34,445 [om1@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om1@group-562213E44849-LeaderElection1: ELECTION REJECTED received 2 response(s) and 0 exception(s):
om1_1        | 2022-07-10 13:11:34,445 [om1@group-562213E44849-LeaderElection1] INFO impl.LeaderElection:   Response 0: om1<-om3#0:FAIL-t1
om1_1        | 2022-07-10 13:11:34,445 [om1@group-562213E44849-LeaderElection1] INFO impl.LeaderElection:   Response 1: om1<-om2#0:FAIL-t1
om1_1        | 2022-07-10 13:11:34,449 [om1@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om1@group-562213E44849-LeaderElection1 ELECTION round 0: result REJECTED
om1_1        | 2022-07-10 13:11:34,450 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServer$Division: om1@group-562213E44849: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
om1_1        | 2022-07-10 13:11:34,450 [om1@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om1: shutdown om1@group-562213E44849-LeaderElection1
om1_1        | 2022-07-10 13:11:34,451 [om1@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om1: start om1@group-562213E44849-FollowerState
om1_1        | 2022-07-10 13:11:34,561 [grpc-default-executor-0] INFO server.RaftServer$Division: om1@group-562213E44849: receive requestVote(ELECTION, om3, group-562213E44849, 1, (t:0, i:~))
om1_1        | 2022-07-10 13:11:34,561 [grpc-default-executor-0] INFO impl.VoteContext: om1@group-562213E44849-FOLLOWER: reject ELECTION from om3: already has voted for om1 at current term 1
om1_1        | 2022-07-10 13:11:34,561 [grpc-default-executor-0] INFO server.RaftServer$Division: om1@group-562213E44849 replies to ELECTION vote request: om3<-om1#0:FAIL-t1. Peer's state: om1@group-562213E44849:t1, leader=null, voted=om1, raftlog=om1@group-562213E44849-SegmentedRaftLog:OPENED:c-1, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om1_1        | 2022-07-10 13:11:38,148 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33598
om1_1        | 2022-07-10 13:11:38,169 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-07-10 13:11:39,551 [grpc-default-executor-0] INFO server.RaftServer$Division: om1@group-562213E44849: receive requestVote(ELECTION, om2, group-562213E44849, 2, (t:0, i:~))
om1_1        | 2022-07-10 13:11:39,552 [grpc-default-executor-0] INFO impl.VoteContext: om1@group-562213E44849-FOLLOWER: accept ELECTION from om2: our priority 0 <= candidate's priority 0
om1_1        | 2022-07-10 13:11:39,552 [grpc-default-executor-0] INFO server.RaftServer$Division: om1@group-562213E44849: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:om2
om1_1        | 2022-07-10 13:11:39,552 [grpc-default-executor-0] INFO impl.RoleInfo: om1: shutdown om1@group-562213E44849-FollowerState
om1_1        | 2022-07-10 13:11:39,552 [om1@group-562213E44849-FollowerState] INFO impl.FollowerState: om1@group-562213E44849-FollowerState was interrupted
om1_1        | 2022-07-10 13:11:39,553 [grpc-default-executor-0] INFO impl.RoleInfo: om1: start om1@group-562213E44849-FollowerState
om1_1        | 2022-07-10 13:11:39,561 [grpc-default-executor-0] INFO server.RaftServer$Division: om1@group-562213E44849 replies to ELECTION vote request: om2<-om1#0:OK-t2. Peer's state: om1@group-562213E44849:t2, leader=null, voted=om2, raftlog=om1@group-562213E44849-SegmentedRaftLog:OPENED:c-1, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om1_1        | 2022-07-10 13:11:39,768 [om1-server-thread1] INFO server.RaftServer$Division: om1@group-562213E44849: change Leader from null to om2 at term 2 for appendEntries, leader elected after 20972ms
om2_1        | 2022-07-10 13:11:39,565 [om2@group-562213E44849-LeaderElection2] INFO impl.LeaderElection: om2@group-562213E44849-LeaderElection2 ELECTION round 0: result PASSED
om2_1        | 2022-07-10 13:11:39,566 [om2@group-562213E44849-LeaderElection2] INFO impl.RoleInfo: om2: shutdown om2@group-562213E44849-LeaderElection2
om2_1        | 2022-07-10 13:11:39,567 [om2@group-562213E44849-LeaderElection2] INFO server.RaftServer$Division: om2@group-562213E44849: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
om2_1        | 2022-07-10 13:11:39,567 [om2@group-562213E44849-LeaderElection2] INFO server.RaftServer$Division: om2@group-562213E44849: change Leader from null to om2 at term 2 for becomeLeader, leader elected after 20699ms
om2_1        | 2022-07-10 13:11:39,581 [om2@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
om2_1        | 2022-07-10 13:11:39,586 [om2@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
om2_1        | 2022-07-10 13:11:39,586 [om2@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
om2_1        | 2022-07-10 13:11:39,592 [om2@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
om2_1        | 2022-07-10 13:11:39,593 [om2@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
om2_1        | 2022-07-10 13:11:39,593 [om2@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
om2_1        | 2022-07-10 13:11:39,598 [om2@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
om2_1        | 2022-07-10 13:11:39,600 [om2@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
om2_1        | 2022-07-10 13:11:39,612 [om2@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
om2_1        | 2022-07-10 13:11:39,612 [om2@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om2_1        | 2022-07-10 13:11:39,612 [om2@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1024 (custom)
om2_1        | 2022-07-10 13:11:39,615 [om2@group-562213E44849-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
om2_1        | 2022-07-10 13:11:39,615 [om2@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om2_1        | 2022-07-10 13:11:39,615 [om2@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om2_1        | 2022-07-10 13:11:39,625 [om2@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
om2_1        | 2022-07-10 13:11:39,625 [om2@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om2_1        | 2022-07-10 13:11:39,627 [om2@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1024 (custom)
om2_1        | 2022-07-10 13:11:39,627 [om2@group-562213E44849-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
om2_1        | 2022-07-10 13:11:39,630 [om2@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om2_1        | 2022-07-10 13:11:39,630 [om2@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om2_1        | 2022-07-10 13:11:39,633 [om2@group-562213E44849-LeaderElection2] INFO impl.RoleInfo: om2: start om2@group-562213E44849-LeaderStateImpl
om2_1        | 2022-07-10 13:11:39,685 [om2@group-562213E44849-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: om2@group-562213E44849-SegmentedRaftLogWorker: Starting segment from index:0
om2_1        | 2022-07-10 13:11:39,704 [om2@group-562213E44849-LeaderElection2] INFO server.RaftServer$Division: om2@group-562213E44849: set configuration 0: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om2_1        | 2022-07-10 13:11:39,926 [om2@group-562213E44849-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: om2@group-562213E44849-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/current/log_inprogress_0
om2_1        | 2022-07-10 13:11:40,056 [om2@group-562213E44849-StateMachineUpdater] INFO ratis.OzoneManagerStateMachine: Received Configuration change notification from Ratis. New Peer list:
om2_1        | [id: "om1"
om2_1        | address: "om1:9872"
om2_1        | , id: "om3"
om2_1        | address: "om3:9872"
om2_1        | , id: "om2"
om2_1        | address: "om2:9872"
om2_1        | ]
om2_1        | 2022-07-10 13:11:54,363 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41958
om2_1        | 2022-07-10 13:11:54,372 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:11:55,116 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:vol1 for user:testuser
om2_1        | 2022-07-10 13:11:55,365 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket1 of layout LEGACY in volume: vol1
om2_1        | 2022-07-10 13:12:04,777 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42014
om2_1        | 2022-07-10 13:12:04,788 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:12:05,445 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42018
om2_1        | 2022-07-10 13:12:05,449 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:12:10,448 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42042
om2_1        | 2022-07-10 13:12:10,456 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:12:10,938 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42046
om2_1        | 2022-07-10 13:12:10,942 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:12:10,960 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ombg0 of layout LEGACY in volume: vol1
om3_1        | 2022-07-10 13:11:20,747 [pool-27-thread-1] INFO segmented.SegmentedRaftLogWorker: om3@group-562213E44849-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
om3_1        | 2022-07-10 13:11:20,758 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
om3_1        | 2022-07-10 13:11:20,788 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 400000 (default)
om3_1        | 2022-07-10 13:11:20,793 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
om3_1        | 2022-07-10 13:11:20,845 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = true (custom)
om3_1        | 2022-07-10 13:11:20,865 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 300s (custom)
om3_1        | 2022-07-10 13:11:20,868 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
om3_1        | 2022-07-10 13:11:21,279 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om3_1        | 2022-07-10 13:11:21,290 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
om3_1        | 2022-07-10 13:11:21,297 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
om3_1        | 2022-07-10 13:11:21,299 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
om3_1        | 2022-07-10 13:11:21,300 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
om3_1        | 2022-07-10 13:11:21,948 [main] INFO reflections.Reflections: Reflections took 2011 ms to scan 8 urls, producing 23 keys and 512 values [using 2 cores]
om3_1        | 2022-07-10 13:11:22,872 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om3_1        | 2022-07-10 13:11:22,908 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om3_1        | 2022-07-10 13:11:26,982 [Listener at om3/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om3_1        | 2022-07-10 13:11:27,059 [Listener at om3/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om3_1        | 2022-07-10 13:11:27,059 [Listener at om3/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om3_1        | 2022-07-10 13:11:27,284 [Listener at om3/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om3/172.25.0.113:9862
om3_1        | 2022-07-10 13:11:27,288 [Listener at om3/9862] INFO ratis.OzoneManagerRatisServer: Starting OzoneManagerRatisServer om3 at port 9872
om3_1        | 2022-07-10 13:11:27,299 [om3-impl-thread1] INFO server.RaftServer$Division: om3@group-562213E44849: start as a follower, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om3_1        | 2022-07-10 13:11:27,303 [om3-impl-thread1] INFO server.RaftServer$Division: om3@group-562213E44849: changes role from      null to FOLLOWER at term 0 for startAsFollower
om3_1        | 2022-07-10 13:11:27,304 [om3-impl-thread1] INFO impl.RoleInfo: om3: start om3@group-562213E44849-FollowerState
om3_1        | 2022-07-10 13:11:27,332 [om3-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-562213E44849,id=om3
om3_1        | 2022-07-10 13:11:27,346 [Listener at om3/9862] INFO server.RaftServer: om3: start RPC server
om3_1        | 2022-07-10 13:11:27,569 [Listener at om3/9862] INFO server.GrpcService: om3: GrpcService started, listening on 9872
om3_1        | 2022-07-10 13:11:27,581 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$449/0x00000008405cac40@5982f78] INFO util.JvmPauseMonitor: JvmPauseMonitor-om3: Started
om3_1        | 2022-07-10 13:11:27,582 [Listener at om3/9862] INFO om.OzoneManager: Starting OM block token secret manager
om3_1        | 2022-07-10 13:11:27,582 [Listener at om3/9862] INFO token.OzoneBlockTokenSecretManager: Updating the current master key for generating tokens
om3_1        | 2022-07-10 13:11:27,585 [Listener at om3/9862] INFO om.OzoneManager: Starting OM delegation token secret manager
om3_1        | 2022-07-10 13:11:27,588 [Listener at om3/9862] INFO security.OzoneDelegationTokenSecretManager: Updating the current master key for generating tokens
om3_1        | 2022-07-10 13:11:27,603 [Listener at om3/9862] INFO om.OzoneManager: Version File has different layout version (3) than OM DB (null). That is expected if this OM has never been finalized to a newer layout version.
om3_1        | 2022-07-10 13:11:27,611 [Thread[Thread-18,5,main]] INFO security.OzoneDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
om3_1        | 2022-07-10 13:11:27,841 [Listener at om3/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om3_1        | 2022-07-10 13:11:27,843 [Listener at om3/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
om3_1        | 2022-07-10 13:11:27,843 [Listener at om3/9862] INFO http.BaseHttpServer: HttpAuthType: ozone.om.http.auth.type = kerberos
om3_1        | 2022-07-10 13:11:27,939 [Listener at om3/9862] INFO util.log: Logging initialized @47623ms to org.eclipse.jetty.util.log.Slf4jLog
om3_1        | 2022-07-10 13:11:28,420 [Listener at om3/9862] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
om3_1        | 2022-07-10 13:11:28,454 [Listener at om3/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om3_1        | 2022-07-10 13:11:28,455 [Listener at om3/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context ozoneManager
om3_1        | 2022-07-10 13:11:28,459 [Listener at om3/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
om3_1        | 2022-07-10 13:11:28,459 [Listener at om3/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
om3_1        | 2022-07-10 13:11:28,472 [Listener at om3/9862] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.om.http.auth.kerberos.principal keytabKey: ozone.om.http.auth.kerberos.keytab
om3_1        | 2022-07-10 13:11:28,663 [Listener at om3/9862] INFO http.HttpServer2: Jetty bound to port 9874
om3_1        | 2022-07-10 13:11:28,664 [Listener at om3/9862] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
om3_1        | 2022-07-10 13:11:28,822 [Listener at om3/9862] INFO server.session: DefaultSessionIdManager workerName=node0
om3_1        | 2022-07-10 13:11:28,822 [Listener at om3/9862] INFO server.session: No SessionScavenger set, using defaults
om3_1        | 2022-07-10 13:11:28,833 [Listener at om3/9862] INFO server.session: node0 Scavenging every 600000ms
om3_1        | 2022-07-10 13:11:28,930 [Listener at om3/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om3_1        | 2022-07-10 13:11:28,934 [Listener at om3/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@14d428d8{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om3_1        | 2022-07-10 13:11:28,939 [Listener at om3/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7a9e618e{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om2_1        | 2022-07-10 13:12:15,839 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42052
om2_1        | 2022-07-10 13:12:15,855 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:12:23,848 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42080
om2_1        | 2022-07-10 13:12:23,856 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:12:30,151 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42120
om2_1        | 2022-07-10 13:12:30,159 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:12:30,736 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42124
om2_1        | 2022-07-10 13:12:30,744 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:12:30,758 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ombr0 of layout LEGACY in volume: vol1
om2_1        | 2022-07-10 13:12:35,749 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42138
om2_1        | 2022-07-10 13:12:35,758 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:12:40,509 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42152
om2_1        | 2022-07-10 13:12:40,511 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:12:41,828 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:39497
om2_1        | 2022-07-10 13:12:41,842 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:12:55,280 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42180
om2_1        | 2022-07-10 13:12:55,285 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:12:55,808 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:53449-source for user:testuser
om2_1        | 2022-07-10 13:12:59,692 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42218
om2_1        | 2022-07-10 13:12:59,695 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:13:00,308 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:53449-target for user:testuser
om2_1        | 2022-07-10 13:13:03,864 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42224
om2_1        | 2022-07-10 13:13:03,877 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:13:04,495 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: readable-bucket of layout LEGACY in volume: 53449-source
om2_1        | 2022-07-10 13:13:08,291 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42238
om2_1        | 2022-07-10 13:13:08,298 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:13:15,550 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42290
om2_1        | 2022-07-10 13:13:15,555 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:13:16,085 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: unreadable-bucket of layout LEGACY in volume: 53449-source
om2_1        | 2022-07-10 13:13:19,748 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42306
om2_1        | 2022-07-10 13:13:19,758 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:13:20,343 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: readable-link of layout LEGACY in volume: 53449-target
om2_1        | 2022-07-10 13:13:24,019 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42320
om2_1        | 2022-07-10 13:13:24,030 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:13:24,634 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: unreadable-link of layout LEGACY in volume: 53449-target
om2_1        | 2022-07-10 13:13:28,375 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42326
om2_1        | 2022-07-10 13:13:28,380 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:13:29,048 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link-to-unreadable-bucket of layout LEGACY in volume: 53449-target
om2_1        | 2022-07-10 13:13:32,580 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42340
om1_1        | 2022-07-10 13:11:39,840 [om1-server-thread1] INFO server.RaftServer$Division: om1@group-562213E44849: set configuration 0: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om1_1        | 2022-07-10 13:11:39,857 [om1-server-thread1] INFO segmented.SegmentedRaftLogWorker: om1@group-562213E44849-SegmentedRaftLogWorker: Starting segment from index:0
om1_1        | 2022-07-10 13:11:40,017 [om1@group-562213E44849-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: om1@group-562213E44849-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/current/log_inprogress_0
om1_1        | 2022-07-10 13:11:42,856 [om1@group-562213E44849-StateMachineUpdater] INFO ratis.OzoneManagerStateMachine: Received Configuration change notification from Ratis. New Peer list:
om1_1        | [id: "om1"
om1_1        | address: "om1:9872"
om1_1        | , id: "om3"
om1_1        | address: "om3:9872"
om1_1        | , id: "om2"
om1_1        | address: "om2:9872"
om1_1        | ]
om1_1        | 2022-07-10 13:11:54,287 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33656
om1_1        | 2022-07-10 13:11:54,316 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-07-10 13:11:55,236 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:vol1 for user:testuser
om1_1        | 2022-07-10 13:11:55,443 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket1 of layout LEGACY in volume: vol1
om1_1        | 2022-07-10 13:12:04,696 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33712
om1_1        | 2022-07-10 13:12:04,728 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-07-10 13:12:05,422 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33716
om1_1        | 2022-07-10 13:12:05,427 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-07-10 13:12:10,381 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33740
om1_1        | 2022-07-10 13:12:10,404 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-07-10 13:12:10,915 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33744
om1_1        | 2022-07-10 13:12:10,923 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-07-10 13:12:10,969 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ombg0 of layout LEGACY in volume: vol1
om1_1        | 2022-07-10 13:12:15,760 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33750
om1_1        | 2022-07-10 13:12:15,791 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-07-10 13:12:23,788 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33778
om1_1        | 2022-07-10 13:12:23,808 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-07-10 13:12:30,070 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33818
om1_1        | 2022-07-10 13:12:30,087 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-07-10 13:12:30,717 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33822
om1_1        | 2022-07-10 13:12:30,719 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-07-10 13:12:30,768 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ombr0 of layout LEGACY in volume: vol1
om1_1        | 2022-07-10 13:12:35,709 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33836
om1_1        | 2022-07-10 13:12:35,727 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-07-10 13:12:40,449 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33850
om1_1        | 2022-07-10 13:12:40,472 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-07-10 13:12:55,221 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33878
om1_1        | 2022-07-10 13:12:55,240 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-07-10 13:12:55,819 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:53449-source for user:testuser
om1_1        | 2022-07-10 13:12:59,610 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33916
om1_1        | 2022-07-10 13:12:59,654 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-07-10 13:13:00,316 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:53449-target for user:testuser
om1_1        | 2022-07-10 13:13:03,805 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33922
om2_1        | 2022-07-10 13:13:32,587 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:13:37,055 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42354
om2_1        | 2022-07-10 13:13:37,067 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:13:41,493 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42392
om2_1        | 2022-07-10 13:13:41,504 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:13:41,895 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:40899
om2_1        | 2022-07-10 13:13:41,901 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:13:45,783 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42400
om2_1        | 2022-07-10 13:13:45,793 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:13:49,934 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42414
om2_1        | 2022-07-10 13:13:49,942 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:13:53,885 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42428
om2_1        | 2022-07-10 13:13:53,890 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:13:54,512 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: dangling-link of layout LEGACY in volume: 53449-target
om2_1        | 2022-07-10 13:13:58,162 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42434
om2_1        | 2022-07-10 13:13:58,166 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:14:02,478 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42452
om2_1        | 2022-07-10 13:14:02,484 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:14:03,066 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link1 of layout LEGACY in volume: 53449-target
om2_1        | 2022-07-10 13:14:06,949 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42466
om2_1        | 2022-07-10 13:14:06,968 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:14:07,593 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket1 of layout LEGACY in volume: 53449-source
om2_1        | 2022-07-10 13:14:11,662 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42514
om2_1        | 2022-07-10 13:14:11,670 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:14:18,703 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42534
om2_1        | 2022-07-10 13:14:18,711 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:14:24,980 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42552
om2_1        | 2022-07-10 13:14:24,990 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:14:31,924 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42570
om2_1        | 2022-07-10 13:14:31,939 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:14:38,566 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42588
om2_1        | 2022-07-10 13:14:38,574 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:14:41,953 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:40837
om2_1        | 2022-07-10 13:14:41,959 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:14:43,141 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42628
om2_1        | 2022-07-10 13:14:43,146 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:14:47,551 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42642
om2_1        | 2022-07-10 13:14:47,563 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:14:51,664 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42648
om2_1        | 2022-07-10 13:14:51,667 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:14:56,165 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42662
om2_1        | 2022-07-10 13:14:56,177 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:15:00,718 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42676
om2_1        | 2022-07-10 13:15:00,727 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:15:05,109 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42690
om2_1        | 2022-07-10 13:15:05,118 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:15:08,965 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42696
om2_1        | 2022-07-10 13:15:08,973 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:15:13,223 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42744
om2_1        | 2022-07-10 13:15:13,227 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:15:17,902 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42762
om2_1        | 2022-07-10 13:15:17,906 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:15:22,045 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42768
om2_1        | 2022-07-10 13:15:22,053 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:15:26,521 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42782
om2_1        | 2022-07-10 13:15:26,527 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:15:30,772 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42798
om2_1        | 2022-07-10 13:15:30,782 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:15:31,403 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link2 of layout LEGACY in volume: 53449-target
om2_1        | 2022-07-10 13:15:35,255 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42812
om2_1        | 2022-07-10 13:15:35,262 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:15:35,814 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:link2 in volume:53449-target
om2_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om2_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-07-10 13:15:39,531 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42818
om2_1        | 2022-07-10 13:15:39,536 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:15:40,073 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket3 of layout LEGACY in volume: 53449-target
om2_1        | 2022-07-10 13:15:42,021 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:37815
om2_1        | 2022-07-10 13:15:42,039 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:15:43,840 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42858
om2_1        | 2022-07-10 13:15:43,844 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:15:44,565 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket3 in volume:53449-target
om2_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om2_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om1_1        | 2022-07-10 13:13:03,823 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-07-10 13:13:04,519 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: readable-bucket of layout LEGACY in volume: 53449-source
om1_1        | 2022-07-10 13:13:08,191 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33936
om1_1        | 2022-07-10 13:13:08,239 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-07-10 13:13:15,497 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33988
om1_1        | 2022-07-10 13:13:15,514 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-07-10 13:13:16,108 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: unreadable-bucket of layout LEGACY in volume: 53449-source
om1_1        | 2022-07-10 13:13:19,678 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34004
om1_1        | 2022-07-10 13:13:19,706 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-07-10 13:13:20,357 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: readable-link of layout LEGACY in volume: 53449-target
om1_1        | 2022-07-10 13:13:23,948 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34018
om1_1        | 2022-07-10 13:13:23,975 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-07-10 13:13:24,649 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: unreadable-link of layout LEGACY in volume: 53449-target
om1_1        | 2022-07-10 13:13:28,325 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34024
om1_1        | 2022-07-10 13:13:28,337 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-07-10 13:13:29,048 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link-to-unreadable-bucket of layout LEGACY in volume: 53449-target
om1_1        | 2022-07-10 13:13:32,521 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34038
om1_1        | 2022-07-10 13:13:32,536 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-07-10 13:13:37,013 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34052
om1_1        | 2022-07-10 13:13:37,027 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-07-10 13:13:41,426 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34066
om1_1        | 2022-07-10 13:13:41,444 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-07-10 13:13:45,724 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34098
om1_1        | 2022-07-10 13:13:45,746 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-07-10 13:13:49,885 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34112
om1_1        | 2022-07-10 13:13:49,906 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-07-10 13:13:53,842 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34126
om1_1        | 2022-07-10 13:13:53,859 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-07-10 13:13:54,522 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: dangling-link of layout LEGACY in volume: 53449-target
om1_1        | 2022-07-10 13:13:58,098 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34132
om1_1        | 2022-07-10 13:13:58,118 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-07-10 13:14:02,420 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34150
om1_1        | 2022-07-10 13:14:02,442 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-07-10 13:14:03,092 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link1 of layout LEGACY in volume: 53449-target
om1_1        | 2022-07-10 13:14:06,877 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34164
om1_1        | 2022-07-10 13:14:06,891 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-07-10 13:14:07,610 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket1 of layout LEGACY in volume: 53449-source
om1_1        | 2022-07-10 13:14:11,614 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34212
om1_1        | 2022-07-10 13:14:11,630 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-07-10 13:14:18,654 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34232
om1_1        | 2022-07-10 13:14:18,673 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-07-10 13:14:24,930 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34250
om1_1        | 2022-07-10 13:14:24,945 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-07-10 13:14:31,868 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34268
om1_1        | 2022-07-10 13:14:31,886 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-07-10 13:14:38,508 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34286
om1_1        | 2022-07-10 13:14:38,531 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-07-10 13:14:43,088 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34326
om1_1        | 2022-07-10 13:14:43,114 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-07-10 13:14:47,501 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34340
om1_1        | 2022-07-10 13:14:47,519 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-07-10 13:14:51,600 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34346
om1_1        | 2022-07-10 13:14:51,630 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-07-10 13:14:56,085 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34360
om1_1        | 2022-07-10 13:14:56,112 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-07-10 13:15:00,664 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34374
om1_1        | 2022-07-10 13:15:00,682 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-07-10 13:15:05,046 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34388
om1_1        | 2022-07-10 13:15:05,071 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-07-10 13:15:08,911 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34394
om1_1        | 2022-07-10 13:15:08,931 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-07-10 13:15:13,169 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34442
om1_1        | 2022-07-10 13:15:13,188 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-07-10 13:15:17,843 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34460
om1_1        | 2022-07-10 13:15:17,864 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-07-10 13:15:21,987 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34466
om1_1        | 2022-07-10 13:15:22,007 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-07-10 13:15:26,461 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34480
om1_1        | 2022-07-10 13:15:26,477 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-07-10 13:15:30,712 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34496
om1_1        | 2022-07-10 13:15:30,737 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-07-10 13:15:31,416 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link2 of layout LEGACY in volume: 53449-target
om1_1        | 2022-07-10 13:15:35,212 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34510
om1_1        | 2022-07-10 13:15:35,227 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-07-10 13:15:35,847 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:link2 in volume:53449-target
om1_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om1_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-07-10 13:15:48,586 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42872
om2_1        | 2022-07-10 13:15:48,591 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:15:53,131 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42886
om2_1        | 2022-07-10 13:15:53,136 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:15:53,661 [IPC Server handler 56 on default port 9862] WARN om.OzoneManager: User testuser2/scm@EXAMPLE.COM doesn't have READ permission to access bucket Volume:53449-target Bucket:unreadable-link 
om2_1        | 2022-07-10 13:15:57,225 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42892
om2_1        | 2022-07-10 13:15:57,230 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:16:01,379 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42906
om2_1        | 2022-07-10 13:16:01,396 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:16:01,896 [IPC Server handler 70 on default port 9862] WARN om.OzoneManager: User testuser2/scm@EXAMPLE.COM doesn't have LIST permission to access bucket Volume:53449-source Bucket:unreadable-bucket Key:
om2_1        | 2022-07-10 13:16:05,631 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42920
om2_1        | 2022-07-10 13:16:05,636 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:16:06,218 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: loop2 of layout LEGACY in volume: 53449-target
om2_1        | 2022-07-10 13:16:09,772 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42936
om2_1        | 2022-07-10 13:16:09,791 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:16:10,412 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: loop3 of layout LEGACY in volume: 53449-target
om2_1        | 2022-07-10 13:16:14,146 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42974
om2_1        | 2022-07-10 13:16:14,155 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:16:14,676 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: loop1 of layout LEGACY in volume: 53449-target
om2_1        | 2022-07-10 13:16:18,375 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42990
om2_1        | 2022-07-10 13:16:18,379 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:16:22,620 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42996
om2_1        | 2022-07-10 13:16:22,626 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:16:23,230 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link3 of layout LEGACY in volume: 53449-target
om2_1        | 2022-07-10 13:16:26,992 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:43010
om2_1        | 2022-07-10 13:16:26,997 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:16:33,716 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:43028
om2_1        | 2022-07-10 13:16:33,723 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:16:40,239 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:43046
om2_1        | 2022-07-10 13:16:40,246 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:16:42,087 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:35899
om2_1        | 2022-07-10 13:16:42,105 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:16:44,628 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:43086
om2_1        | 2022-07-10 13:16:44,635 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-07-10 13:15:39,478 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34516
om1_1        | 2022-07-10 13:15:39,501 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-07-10 13:15:40,093 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket3 of layout LEGACY in volume: 53449-target
om1_1        | 2022-07-10 13:15:43,788 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34556
om1_1        | 2022-07-10 13:15:43,803 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-07-10 13:15:44,577 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket3 in volume:53449-target
om1_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om1_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-07-10 13:15:48,527 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34570
om1_1        | 2022-07-10 13:15:48,547 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-07-10 13:15:53,080 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34576
om1_1        | 2022-07-10 13:15:53,099 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-07-10 13:15:57,180 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34590
om1_1        | 2022-07-10 13:15:57,195 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-07-10 13:16:01,335 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34604
om1_1        | 2022-07-10 13:16:01,348 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-07-10 13:16:05,587 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34618
om1_1        | 2022-07-10 13:16:05,603 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-07-10 13:16:06,231 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: loop2 of layout LEGACY in volume: 53449-target
om1_1        | 2022-07-10 13:16:09,719 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34634
om1_1        | 2022-07-10 13:16:09,735 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-07-10 13:16:10,419 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: loop3 of layout LEGACY in volume: 53449-target
om1_1        | 2022-07-10 13:16:14,093 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34672
om1_1        | 2022-07-10 13:16:14,111 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-07-10 13:16:14,682 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: loop1 of layout LEGACY in volume: 53449-target
om1_1        | 2022-07-10 13:16:18,326 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34688
om1_1        | 2022-07-10 13:16:18,343 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-07-10 13:16:22,570 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34694
om1_1        | 2022-07-10 13:16:22,588 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-07-10 13:16:23,236 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link3 of layout LEGACY in volume: 53449-target
om1_1        | 2022-07-10 13:16:26,947 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34708
om1_1        | 2022-07-10 13:16:26,958 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-07-10 13:16:33,660 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34726
om3_1        | 2022-07-10 13:11:29,240 [Listener at om3/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om3_1        | 2022-07-10 13:11:29,277 [Listener at om3/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@488e27f3{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-ozone-manager-1_3_0-SNAPSHOT_jar-_-any-5164996453900199768/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/ozoneManager}
om3_1        | 2022-07-10 13:11:29,308 [Listener at om3/9862] INFO server.AbstractConnector: Started ServerConnector@79dd676f{HTTP/1.1, (http/1.1)}{0.0.0.0:9874}
om3_1        | 2022-07-10 13:11:29,309 [Listener at om3/9862] INFO server.Server: Started @48994ms
om3_1        | 2022-07-10 13:11:29,322 [Listener at om3/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
om3_1        | 2022-07-10 13:11:29,323 [Listener at om3/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
om3_1        | 2022-07-10 13:11:29,326 [Listener at om3/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
om3_1        | 2022-07-10 13:11:29,332 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om3_1        | 2022-07-10 13:11:29,334 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om3_1        | 2022-07-10 13:11:29,519 [Listener at om3/9862] INFO om.OzoneManager: Trash Interval set to 0. Files deleted won't move to trash
om3_1        | 2022-07-10 13:11:29,781 [Listener at om3/9862] INFO om.GrpcOzoneManagerServer: GrpcOzoneManagerServer is started using port 8981
om3_1        | 2022-07-10 13:11:29,819 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@600c19ec] INFO util.JvmPauseMonitor: Starting JVM pause monitor
om3_1        | 2022-07-10 13:11:30,469 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:38175
om3_1        | 2022-07-10 13:11:30,484 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-07-10 13:11:32,512 [om3@group-562213E44849-FollowerState] INFO impl.FollowerState: om3@group-562213E44849-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5207895134ns, electionTimeout:5177ms
om3_1        | 2022-07-10 13:11:32,513 [om3@group-562213E44849-FollowerState] INFO impl.RoleInfo: om3: shutdown om3@group-562213E44849-FollowerState
om3_1        | 2022-07-10 13:11:32,513 [om3@group-562213E44849-FollowerState] INFO server.RaftServer$Division: om3@group-562213E44849: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
om3_1        | 2022-07-10 13:11:32,516 [om3@group-562213E44849-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
om3_1        | 2022-07-10 13:11:32,517 [om3@group-562213E44849-FollowerState] INFO impl.RoleInfo: om3: start om3@group-562213E44849-LeaderElection1
om3_1        | 2022-07-10 13:11:32,529 [om3@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om3@group-562213E44849-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om3_1        | 2022-07-10 13:11:34,215 [grpc-default-executor-3] INFO server.RaftServer$Division: om3@group-562213E44849: receive requestVote(ELECTION, om1, group-562213E44849, 1, (t:0, i:~))
om3_1        | 2022-07-10 13:11:34,218 [grpc-default-executor-3] INFO impl.VoteContext: om3@group-562213E44849-CANDIDATE: reject ELECTION from om1: already has voted for om3 at current term 1
om3_1        | 2022-07-10 13:11:34,246 [grpc-default-executor-0] INFO server.RaftServer$Division: om3@group-562213E44849: receive requestVote(ELECTION, om2, group-562213E44849, 1, (t:0, i:~))
om3_1        | 2022-07-10 13:11:34,265 [grpc-default-executor-3] INFO server.RaftServer$Division: om3@group-562213E44849 replies to ELECTION vote request: om1<-om3#0:FAIL-t1. Peer's state: om3@group-562213E44849:t1, leader=null, voted=om3, raftlog=om3@group-562213E44849-SegmentedRaftLog:OPENED:c-1, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om3_1        | 2022-07-10 13:11:34,265 [grpc-default-executor-0] INFO impl.VoteContext: om3@group-562213E44849-CANDIDATE: reject ELECTION from om2: already has voted for om3 at current term 1
om3_1        | 2022-07-10 13:11:34,265 [grpc-default-executor-0] INFO server.RaftServer$Division: om3@group-562213E44849 replies to ELECTION vote request: om2<-om3#0:FAIL-t1. Peer's state: om3@group-562213E44849:t1, leader=null, voted=om3, raftlog=om3@group-562213E44849-SegmentedRaftLog:OPENED:c-1, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om3_1        | 2022-07-10 13:11:34,610 [om3@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om3@group-562213E44849-LeaderElection1: ELECTION REJECTED received 2 response(s) and 0 exception(s):
om3_1        | 2022-07-10 13:11:34,610 [om3@group-562213E44849-LeaderElection1] INFO impl.LeaderElection:   Response 0: om3<-om1#0:FAIL-t1
om3_1        | 2022-07-10 13:11:34,610 [om3@group-562213E44849-LeaderElection1] INFO impl.LeaderElection:   Response 1: om3<-om2#0:FAIL-t1
om3_1        | 2022-07-10 13:11:34,611 [om3@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om3@group-562213E44849-LeaderElection1 ELECTION round 0: result REJECTED
om3_1        | 2022-07-10 13:11:34,620 [om3@group-562213E44849-LeaderElection1] INFO server.RaftServer$Division: om3@group-562213E44849: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
om3_1        | 2022-07-10 13:11:34,621 [om3@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om3: shutdown om3@group-562213E44849-LeaderElection1
om3_1        | 2022-07-10 13:11:34,622 [om3@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om3: start om3@group-562213E44849-FollowerState
om3_1        | 2022-07-10 13:11:38,221 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:53472
om3_1        | 2022-07-10 13:11:38,223 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-07-10 13:11:39,556 [grpc-default-executor-0] INFO server.RaftServer$Division: om3@group-562213E44849: receive requestVote(ELECTION, om2, group-562213E44849, 2, (t:0, i:~))
om3_1        | 2022-07-10 13:11:39,567 [grpc-default-executor-0] INFO impl.VoteContext: om3@group-562213E44849-FOLLOWER: accept ELECTION from om2: our priority 0 <= candidate's priority 0
om3_1        | 2022-07-10 13:11:39,567 [grpc-default-executor-0] INFO server.RaftServer$Division: om3@group-562213E44849: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:om2
om3_1        | 2022-07-10 13:11:39,567 [grpc-default-executor-0] INFO impl.RoleInfo: om3: shutdown om3@group-562213E44849-FollowerState
om3_1        | 2022-07-10 13:11:39,568 [grpc-default-executor-0] INFO impl.RoleInfo: om3: start om3@group-562213E44849-FollowerState
om3_1        | 2022-07-10 13:11:39,572 [grpc-default-executor-0] INFO server.RaftServer$Division: om3@group-562213E44849 replies to ELECTION vote request: om2<-om3#0:OK-t2. Peer's state: om3@group-562213E44849:t2, leader=null, voted=om2, raftlog=om3@group-562213E44849-SegmentedRaftLog:OPENED:c-1, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om3_1        | 2022-07-10 13:11:39,568 [om3@group-562213E44849-FollowerState] INFO impl.FollowerState: om3@group-562213E44849-FollowerState was interrupted
om3_1        | 2022-07-10 13:11:39,745 [om3-server-thread1] INFO server.RaftServer$Division: om3@group-562213E44849: change Leader from null to om2 at term 2 for appendEntries, leader elected after 19811ms
om1_1        | 2022-07-10 13:16:33,679 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-07-10 13:16:40,187 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34744
om1_1        | 2022-07-10 13:16:40,204 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-07-10 13:16:44,558 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34784
om1_1        | 2022-07-10 13:16:44,579 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-07-10 13:16:48,926 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34798
om1_1        | 2022-07-10 13:16:48,955 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-07-10 13:16:53,308 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34812
om1_1        | 2022-07-10 13:16:53,340 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-07-10 13:16:53,908 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link4 of layout LEGACY in volume: 53449-target
om1_1        | 2022-07-10 13:16:57,555 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34818
om1_1        | 2022-07-10 13:16:57,575 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-07-10 13:16:58,209 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketSetPropertyRequest: Setting bucket property failed for bucket:link4 in volume:53449-target
om1_1        | NOT_SUPPORTED_OPERATION org.apache.hadoop.ozone.om.exceptions.OMException: Cannot set property on link
om1_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketSetPropertyRequest.validateAndUpdateCache(OMBucketSetPropertyRequest.java:147)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-07-10 13:17:01,841 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34832
om1_1        | 2022-07-10 13:17:01,864 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-07-10 13:17:36,756 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35102
om1_1        | 2022-07-10 13:17:36,772 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-07-10 13:17:42,079 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:40293
om1_1        | 2022-07-10 13:17:42,096 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-07-10 13:17:42,725 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-1544450475 of layout LEGACY in volume: s3v
om1_1        | 2022-07-10 13:17:46,584 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35144
om1_1        | 2022-07-10 13:17:46,608 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-07-10 13:17:50,126 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-9384658644 of layout LEGACY in volume: s3v
om1_1        | 2022-07-10 13:18:01,143 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35196
om1_1        | 2022-07-10 13:18:01,168 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-07-10 13:18:04,779 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-3047552415 of layout LEGACY in volume: s3v
om1_1        | 2022-07-10 13:18:05,356 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ozone-test-uabmkkyzze of layout LEGACY in volume: s3v
om1_1        | 2022-07-10 13:18:09,299 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-qfntsnazxv of layout LEGACY in volume: s3v
om1_1        | 2022-07-10 13:18:16,887 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35270
om1_1        | 2022-07-10 13:18:16,907 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-07-10 13:18:20,550 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-2810480406 of layout LEGACY in volume: s3v
om1_1        | 2022-07-10 13:18:21,189 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-8869007246 of layout LEGACY in volume: s3v
om1_1        | 2022-07-10 13:18:21,856 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-6024978753 of layout LEGACY in volume: s3v
om3_1        | 2022-07-10 13:11:39,789 [om3-server-thread1] INFO server.RaftServer$Division: om3@group-562213E44849: set configuration 0: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om3_1        | 2022-07-10 13:11:39,806 [om3-server-thread1] INFO segmented.SegmentedRaftLogWorker: om3@group-562213E44849-SegmentedRaftLogWorker: Starting segment from index:0
om3_1        | 2022-07-10 13:11:39,975 [om3@group-562213E44849-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: om3@group-562213E44849-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/current/log_inprogress_0
om3_1        | 2022-07-10 13:11:42,885 [om3@group-562213E44849-StateMachineUpdater] INFO ratis.OzoneManagerStateMachine: Received Configuration change notification from Ratis. New Peer list:
om3_1        | [id: "om1"
om3_1        | address: "om1:9872"
om3_1        | , id: "om3"
om3_1        | address: "om3:9872"
om3_1        | , id: "om2"
om3_1        | address: "om2:9872"
om3_1        | ]
om3_1        | 2022-07-10 13:11:55,293 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:vol1 for user:testuser
om3_1        | 2022-07-10 13:11:55,520 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket1 of layout LEGACY in volume: vol1
om3_1        | 2022-07-10 13:12:10,961 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ombg0 of layout LEGACY in volume: vol1
om3_1        | 2022-07-10 13:12:30,763 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ombr0 of layout LEGACY in volume: vol1
om3_1        | 2022-07-10 13:12:55,828 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:53449-source for user:testuser
om3_1        | 2022-07-10 13:13:00,313 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:53449-target for user:testuser
om3_1        | 2022-07-10 13:13:04,502 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: readable-bucket of layout LEGACY in volume: 53449-source
om3_1        | 2022-07-10 13:13:16,104 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: unreadable-bucket of layout LEGACY in volume: 53449-source
om3_1        | 2022-07-10 13:13:20,352 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: readable-link of layout LEGACY in volume: 53449-target
om3_1        | 2022-07-10 13:13:24,650 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: unreadable-link of layout LEGACY in volume: 53449-target
om3_1        | 2022-07-10 13:13:29,054 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link-to-unreadable-bucket of layout LEGACY in volume: 53449-target
om3_1        | 2022-07-10 13:13:54,520 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: dangling-link of layout LEGACY in volume: 53449-target
om3_1        | 2022-07-10 13:14:03,080 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link1 of layout LEGACY in volume: 53449-target
om3_1        | 2022-07-10 13:14:07,605 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket1 of layout LEGACY in volume: 53449-source
om3_1        | 2022-07-10 13:15:31,408 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link2 of layout LEGACY in volume: 53449-target
om3_1        | 2022-07-10 13:15:35,822 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:link2 in volume:53449-target
om3_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om3_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-07-10 13:15:40,085 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket3 of layout LEGACY in volume: 53449-target
om3_1        | 2022-07-10 13:15:44,574 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket3 in volume:53449-target
om3_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om3_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-07-10 13:16:06,242 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: loop2 of layout LEGACY in volume: 53449-target
om3_1        | 2022-07-10 13:16:10,415 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: loop3 of layout LEGACY in volume: 53449-target
om3_1        | 2022-07-10 13:16:14,700 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: loop1 of layout LEGACY in volume: 53449-target
om3_1        | 2022-07-10 13:16:23,244 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link3 of layout LEGACY in volume: 53449-target
om3_1        | 2022-07-10 13:16:53,918 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link4 of layout LEGACY in volume: 53449-target
om3_1        | 2022-07-10 13:16:58,195 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketSetPropertyRequest: Setting bucket property failed for bucket:link4 in volume:53449-target
om3_1        | NOT_SUPPORTED_OPERATION org.apache.hadoop.ozone.om.exceptions.OMException: Cannot set property on link
om3_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketSetPropertyRequest.validateAndUpdateCache(OMBucketSetPropertyRequest.java:147)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-07-10 13:17:42,726 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-1544450475 of layout LEGACY in volume: s3v
om3_1        | 2022-07-10 13:17:50,142 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-9384658644 of layout LEGACY in volume: s3v
om3_1        | 2022-07-10 13:18:04,776 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-3047552415 of layout LEGACY in volume: s3v
om3_1        | 2022-07-10 13:18:05,365 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ozone-test-uabmkkyzze of layout LEGACY in volume: s3v
om3_1        | 2022-07-10 13:18:09,291 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-qfntsnazxv of layout LEGACY in volume: s3v
om3_1        | 2022-07-10 13:18:20,549 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-2810480406 of layout LEGACY in volume: s3v
om3_1        | 2022-07-10 13:18:21,189 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-8869007246 of layout LEGACY in volume: s3v
om3_1        | 2022-07-10 13:18:21,870 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-6024978753 of layout LEGACY in volume: s3v
om3_1        | 2022-07-10 13:18:22,505 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket-ozone-test-6024978753 in volume:s3v
om3_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om3_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-07-10 13:18:24,123 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-1090355142 of layout LEGACY in volume: s3v
om3_1        | 2022-07-10 13:18:35,937 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-7979361343 of layout LEGACY in volume: s3v
om3_1        | 2022-07-10 13:18:36,598 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-9923649996 of layout LEGACY in volume: s3v
om3_1        | 2022-07-10 13:18:37,918 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketDeleteRequest: Delete bucket failed for bucket:nosuchbucket-ozone-test-3783028772 in volume:s3v
om3_1        | BUCKET_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Bucket not found
om3_1        | 	at org.apache.hadoop.ozone.om.OzoneManager.getBucketOwner(OzoneManager.java:2496)
om3_1        | 	at org.apache.hadoop.ozone.om.OzoneManager.getBucketOwner(OzoneManager.java:2466)
om3_1        | 	at org.apache.hadoop.ozone.om.request.OMClientRequest.checkAcls(OMClientRequest.java:217)
om3_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketDeleteRequest.validateAndUpdateCache(OMBucketDeleteRequest.java:108)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-07-10 13:18:45,166 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-9508592014 of layout LEGACY in volume: s3v
om3_1        | 2022-07-10 13:18:53,306 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-6075713174 of layout LEGACY in volume: s3v
om3_1        | 2022-07-10 13:19:07,247 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-6322658386 of layout LEGACY in volume: s3v
om3_1        | 2022-07-10 13:19:23,928 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload: /s3v/bucket-ozone-test-6322658386/ozone-test-7990573019/multipartKey2 Part number: 1 size 6  is less than minimum part size 5242880
om3_1        | 2022-07-10 13:19:23,931 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-7990573019/multipartKey2 in Volume/Bucket s3v/bucket-ozone-test-6322658386
om3_1        | ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-6322658386 key: ozone-test-7990573019/multipartKey2. Entity too small.
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:535)
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:198)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-07-10 13:19:25,353 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-ozone-test-6322658386/ozone-test-0260461918/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 1
om3_1        | partName: "etag1"
om3_1        | , partNumber: 2
om3_1        | partName: "etag2"
om3_1        | ]
recon_1      | Sleeping for 5 seconds
recon_1      | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
recon_1      | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
recon_1      | 2022-07-10 13:08:48,620 [main] INFO recon.ReconServer: STARTUP_MSG: 
recon_1      | /************************************************************
recon_1      | STARTUP_MSG: Starting ReconServer
recon_1      | STARTUP_MSG:   host = recon/172.25.0.115
recon_1      | STARTUP_MSG:   args = []
recon_1      | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
recon_1      | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/hk2-utils-2.5.0.jar:/opt/hadoop/share/ozone/lib/jakarta.inject-2.6.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/solr-solrj-8.11.2.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/sqlite-jdbc-3.25.2.jar:/opt/hadoop/share/ozone/lib/aopalliance-repackaged-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/guice-4.0.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/orc-core-1.5.8.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.44.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/httpasyncclient-4.1.4.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-2.33.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/ranger-intg-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jakarta.xml.bind-api-2.3.3.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang-2.6.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jna-5.2.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jakarta.validation-api-2.0.2.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/hppc-0.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-tools-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.44.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jooq-3.11.10.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jetty-client-9.4.44.v20210927.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/osgi-resource-locator-1.0.3.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/spring-beans-5.2.20.RELEASE.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/derby-10.14.2.0.jar:/opt/hadoop/share/ozone/lib/zstd-jni-1.4.9-1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.44.0.jar:/opt/hadoop/share/ozone/lib/ranger-plugin-classloader-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/spring-core-5.2.20.RELEASE.jar:/opt/hadoop/share/ozone/lib/hive-storage-api-2.7.2.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/jooq-codegen-3.11.10.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/gethostname4j-0.0.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/spring-tx-5.2.20.RELEASE.jar:/opt/hadoop/share/ozone/lib/jersey-entity-filtering-2.33.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.44.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpmime-4.5.13.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/guice-servlet-4.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/guice-bridge-2.5.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/jna-platform-5.2.0.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.0.1.jar:/opt/hadoop/share/ozone/lib/hk2-locator-2.6.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/aopalliance-1.0.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.44.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/httpcore-nio-4.4.14.jar:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jakarta.ws.rs-api-2.1.6.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-audit-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.23.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-module-jaxb-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-core-2.33.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.44.0.jar:/opt/hadoop/share/ozone/lib/guice-multibindings-4.0.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.19.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/bonecp-0.8.0.RELEASE.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hk2-api-2.5.0.jar:/opt/hadoop/share/ozone/lib/javax.inject-1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/aws-java-sdk-bundle-1.12.125.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.44.0.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-client-2.33.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jersey-hk2-2.33.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jersey-media-jaxb-2.33.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/jakarta.annotation-api-1.3.5.jar:/opt/hadoop/share/ozone/lib/jersey-server-2.33.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-common-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kafka-clients-2.8.1.jar:/opt/hadoop/share/ozone/lib/guice-assistedinject-4.0.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-media-json-jackson-2.33.jar:/opt/hadoop/share/ozone/lib/jooq-meta-3.11.10.jar:/opt/hadoop/share/ozone/lib/ozone-reconcodegen-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/jersey-common-2.33.jar:/opt/hadoop/share/ozone/lib/spring-jdbc-5.2.20.RELEASE.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-cred-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/spring-jcl-5.2.20.RELEASE.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-recon-1.3.0-SNAPSHOT.jar
recon_1      | STARTUP_MSG:   build = https://github.com/apache/ozone/d088d199bf506d76f7046a4b19b690e2a9e6915e ; compiled by 'runner' on 2022-07-10T12:46Z
recon_1      | STARTUP_MSG:   java = 11.0.14.1
recon_1      | ************************************************************/
recon_1      | 2022-07-10 13:08:48,656 [main] INFO recon.ReconServer: registered UNIX signal handlers for [TERM, HUP, INT]
recon_1      | 2022-07-10 13:08:50,626 [main] INFO reflections.Reflections: Reflections took 177 ms to scan 1 urls, producing 13 keys and 35 values 
recon_1      | 2022-07-10 13:08:53,244 [main] INFO recon.ReconServer: Initializing Recon server...
recon_1      | 2022-07-10 13:08:53,383 [main] INFO recon.ReconServer: Ozone security is enabled. Attempting login for Recon service. Principal: recon/recon@EXAMPLE.COM, keytab: /etc/security/keytabs/recon.keytab
recon_1      | 2022-07-10 13:08:54,014 [main] INFO security.UserGroupInformation: Login successful for user recon/recon@EXAMPLE.COM using keytab file recon.keytab. Keytab auto renewal enabled : false
recon_1      | 2022-07-10 13:08:54,023 [main] INFO recon.ReconServer: Recon login successful.
recon_1      | 2022-07-10 13:08:54,024 [main] INFO recon.ReconServer: Initializing secure Recon.
recon_1      | 2022-07-10 13:08:55,380 [main] ERROR client.ReconCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
recon_1      | 2022-07-10 13:08:55,380 [main] INFO client.ReconCertificateClient: Certificate client init case: 0
recon_1      | 2022-07-10 13:08:55,381 [main] INFO client.ReconCertificateClient: Creating keypair for client as keypair and certificate not found.
recon_1      | 2022-07-10 13:08:57,729 [main] INFO recon.ReconServer: Init response: GETCERT
recon_1      | 2022-07-10 13:08:57,768 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.115,host:recon
recon_1      | 2022-07-10 13:08:57,768 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
recon_1      | 2022-07-10 13:08:57,781 [main] ERROR client.ReconCertificateClient: Invalid domain recon
recon_1      | 2022-07-10 13:08:58,015 [main] INFO recon.ReconServer: Creating CSR for Recon.
om1_1        | 2022-07-10 13:18:22,509 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket-ozone-test-6024978753 in volume:s3v
om1_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om1_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-07-10 13:18:24,128 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-1090355142 of layout LEGACY in volume: s3v
om1_1        | 2022-07-10 13:18:27,962 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35308
om1_1        | 2022-07-10 13:18:27,978 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-07-10 13:18:32,411 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35322
om1_1        | 2022-07-10 13:18:32,432 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-07-10 13:18:35,958 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-7979361343 of layout LEGACY in volume: s3v
om1_1        | 2022-07-10 13:18:36,614 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-9923649996 of layout LEGACY in volume: s3v
om1_1        | 2022-07-10 13:18:37,922 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketDeleteRequest: Delete bucket failed for bucket:nosuchbucket-ozone-test-3783028772 in volume:s3v
om1_1        | BUCKET_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Bucket not found
om1_1        | 	at org.apache.hadoop.ozone.om.OzoneManager.getBucketOwner(OzoneManager.java:2496)
om1_1        | 	at org.apache.hadoop.ozone.om.OzoneManager.getBucketOwner(OzoneManager.java:2466)
om1_1        | 	at org.apache.hadoop.ozone.om.request.OMClientRequest.checkAcls(OMClientRequest.java:217)
om1_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketDeleteRequest.validateAndUpdateCache(OMBucketDeleteRequest.java:108)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-07-10 13:18:41,726 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35376
om1_1        | 2022-07-10 13:18:41,751 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-07-10 13:18:45,171 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-9508592014 of layout LEGACY in volume: s3v
om1_1        | 2022-07-10 13:18:49,968 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35398
om1_1        | 2022-07-10 13:18:49,987 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-07-10 13:18:53,312 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-6075713174 of layout LEGACY in volume: s3v
om1_1        | 2022-07-10 13:18:57,808 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35416
om1_1        | 2022-07-10 13:18:57,821 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-07-10 13:19:03,712 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35432
om1_1        | 2022-07-10 13:19:03,735 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-07-10 13:19:07,242 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-6322658386 of layout LEGACY in volume: s3v
om1_1        | 2022-07-10 13:19:23,927 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload: /s3v/bucket-ozone-test-6322658386/ozone-test-7990573019/multipartKey2 Part number: 1 size 6  is less than minimum part size 5242880
om1_1        | 2022-07-10 13:19:23,939 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-7990573019/multipartKey2 in Volume/Bucket s3v/bucket-ozone-test-6322658386
om1_1        | ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-6322658386 key: ozone-test-7990573019/multipartKey2. Entity too small.
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:535)
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:198)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 2022-07-10 13:19:25,360 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-0260461918/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-6322658386
om3_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-6322658386 key: ozone-test-0260461918/multipartKey3
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:187)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-07-10 13:19:26,004 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-ozone-test-6322658386/ozone-test-0260461918/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 2
om3_1        | partName: "etag1"
om3_1        | , partNumber: 1
om3_1        | partName: "etag2"
om3_1        | ]
om3_1        | 2022-07-10 13:19:26,005 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-0260461918/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-6322658386
om3_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-6322658386 key: ozone-test-0260461918/multipartKey3
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:187)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-07-10 13:19:30,137 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-0260461918/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-6322658386
om3_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-6322658386 key: ozone-test-0260461918/multipartKey3. Provided Part info is { etag1, 1}, whereas OM has partName /s3v/bucket-ozone-test-6322658386/ozone-test-0260461918/multipartKey3-af1c271f-1abf-46c7-b20c-eda35dade449-108623243811946532-1
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:512)
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:198)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-07-10 13:19:30,777 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-0260461918/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-6322658386
om3_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-6322658386 key: ozone-test-0260461918/multipartKey3. Provided Part info is { etag2, 2}, whereas OM has partName /s3v/bucket-ozone-test-6322658386/ozone-test-0260461918/multipartKey3-af1c271f-1abf-46c7-b20c-eda35dade449-108623243811946532-2
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:512)
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:198)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-07-10 13:19:31,425 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: PartNumber at index 1 is 2, and its previous partNumber at index 0 is 4 for ozonekey is /s3v/bucket-ozone-test-6322658386/ozone-test-0260461918/multipartKey3
om3_1        | 2022-07-10 13:19:31,426 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-0260461918/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-6322658386
om3_1        | INVALID_PART_ORDER org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-6322658386 key: ozone-test-0260461918/multipartKey3 because parts are in Invalid order.
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getPartsListSize(S3MultipartUploadCompleteRequest.java:478)
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:194)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 2022-07-10 13:16:48,978 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:43100
om2_1        | 2022-07-10 13:16:48,980 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:16:53,383 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:43114
om2_1        | 2022-07-10 13:16:53,388 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:16:53,898 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link4 of layout LEGACY in volume: 53449-target
om2_1        | 2022-07-10 13:16:57,611 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:43120
om2_1        | 2022-07-10 13:16:57,621 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:16:58,180 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketSetPropertyRequest: Setting bucket property failed for bucket:link4 in volume:53449-target
om2_1        | NOT_SUPPORTED_OPERATION org.apache.hadoop.ozone.om.exceptions.OMException: Cannot set property on link
om2_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketSetPropertyRequest.validateAndUpdateCache(OMBucketSetPropertyRequest.java:147)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-07-10 13:17:01,904 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:43134
om2_1        | 2022-07-10 13:17:01,910 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:17:36,803 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:43404
om2_1        | 2022-07-10 13:17:36,809 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:17:42,123 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:40901
om2_1        | 2022-07-10 13:17:42,128 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:17:42,156 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:43241
om2_1        | 2022-07-10 13:17:42,165 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:17:42,615 [IPC Server handler 97 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:17:42,702 [IPC Server handler 72 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:17:42,717 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-1544450475 of layout LEGACY in volume: s3v
om2_1        | 2022-07-10 13:17:46,649 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:43446
om2_1        | 2022-07-10 13:17:46,655 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:17:50,105 [IPC Server handler 6 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:17:50,110 [IPC Server handler 90 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:17:50,119 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-9384658644 of layout LEGACY in volume: s3v
om2_1        | 2022-07-10 13:17:50,782 [IPC Server handler 75 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:17:50,799 [IPC Server handler 61 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:17:50,843 [IPC Server handler 55 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:17:52,754 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:17:53,467 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:17:53,471 [IPC Server handler 98 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:17:53,477 [IPC Server handler 78 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:17:53,657 [IPC Server handler 72 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:17:54,328 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:17:54,337 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:17:54,350 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:17:54,364 [IPC Server handler 98 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-07-10 13:19:25,333 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-ozone-test-6322658386/ozone-test-0260461918/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 1
om1_1        | partName: "etag1"
om1_1        | , partNumber: 2
om1_1        | partName: "etag2"
om1_1        | ]
om1_1        | 2022-07-10 13:19:25,350 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-0260461918/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-6322658386
om1_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-6322658386 key: ozone-test-0260461918/multipartKey3
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:187)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-07-10 13:19:25,992 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-ozone-test-6322658386/ozone-test-0260461918/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 2
om1_1        | partName: "etag1"
om1_1        | , partNumber: 1
om1_1        | partName: "etag2"
om1_1        | ]
om1_1        | 2022-07-10 13:19:25,998 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-0260461918/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-6322658386
om1_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-6322658386 key: ozone-test-0260461918/multipartKey3
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:187)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-07-10 13:19:30,144 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-0260461918/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-6322658386
om1_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-6322658386 key: ozone-test-0260461918/multipartKey3. Provided Part info is { etag1, 1}, whereas OM has partName /s3v/bucket-ozone-test-6322658386/ozone-test-0260461918/multipartKey3-af1c271f-1abf-46c7-b20c-eda35dade449-108623243811946532-1
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:512)
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:198)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-07-10 13:19:30,776 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-0260461918/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-6322658386
om1_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-6322658386 key: ozone-test-0260461918/multipartKey3. Provided Part info is { etag2, 2}, whereas OM has partName /s3v/bucket-ozone-test-6322658386/ozone-test-0260461918/multipartKey3-af1c271f-1abf-46c7-b20c-eda35dade449-108623243811946532-2
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:512)
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:198)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-07-10 13:19:31,418 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: PartNumber at index 1 is 2, and its previous partNumber at index 0 is 4 for ozonekey is /s3v/bucket-ozone-test-6322658386/ozone-test-0260461918/multipartKey3
om1_1        | 2022-07-10 13:19:31,424 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-0260461918/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-6322658386
om1_1        | INVALID_PART_ORDER org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-6322658386 key: ozone-test-0260461918/multipartKey3 because parts are in Invalid order.
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-07-10 13:19:35,002 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadAbortRequest: Abort Multipart request is failed for KeyName ozone-test-9861106675/multipartKey5 in VolumeName/Bucket s3v/bucket-ozone-test-6322658386
om3_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Abort Multipart Upload Failed: volume: s3vbucket: bucket-ozone-test-6322658386key: ozone-test-9861106675/multipartKey5
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadAbortRequest.validateAndUpdateCache(S3MultipartUploadAbortRequest.java:161)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-07-10 13:19:35,675 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyCreateRequest: Key creation failed. Volume:s3v, Bucket:bucket-ozone-test-6322658386, Key:ozone-test-5974425549/multipartKey. 
om3_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: No such Multipart upload is with specified uploadId random
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareMultipartFileInfo(OMKeyRequest.java:758)
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareFileInfo(OMKeyRequest.java:645)
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareKeyInfo(OMKeyRequest.java:622)
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyCreateRequest.validateAndUpdateCache(OMKeyCreateRequest.java:282)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-07-10 13:20:17,652 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-0642987608 of layout LEGACY in volume: s3v
om3_1        | 2022-07-10 13:20:18,324 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: destbucket-81026 of layout LEGACY in volume: s3v
om3_1        | 2022-07-10 13:20:32,608 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-7006625698 of layout LEGACY in volume: s3v
om3_1        | 2022-07-10 13:20:52,053 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-7750864646 of layout LEGACY in volume: s3v
om3_1        | 2022-07-10 13:20:55,747 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyDeleteRequest: Key delete failed. Volume:s3v, Bucket:bucket-ozone-test-7750864646, Key:ozone-test-6291015824/multidelete/key=value/f4.
om3_1        | KEY_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Key not found
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:152)
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:98)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-07-10 13:21:03,370 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-0984322854 of layout LEGACY in volume: s3v
om3_1        | 2022-07-10 13:21:24,272 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-2439360640 of layout LEGACY in volume: s3v
om2_1        | 2022-07-10 13:17:55,097 [IPC Server handler 6 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:17:55,102 [IPC Server handler 90 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:17:55,107 [IPC Server handler 8 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:17:55,111 [IPC Server handler 5 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:17:55,751 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:17:55,762 [IPC Server handler 75 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:17:55,767 [IPC Server handler 61 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:17:55,771 [IPC Server handler 26 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:17:56,435 [IPC Server handler 78 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:17:56,439 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:17:56,447 [IPC Server handler 85 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:17:56,611 [IPC Server handler 97 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:17:57,287 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:17:57,295 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:17:57,299 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:17:57,310 [IPC Server handler 98 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:01,220 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:43498
om2_1        | 2022-07-10 13:18:01,231 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:18:04,745 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:04,752 [IPC Server handler 75 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:04,766 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-3047552415 of layout LEGACY in volume: s3v
om2_1        | 2022-07-10 13:18:05,333 [IPC Server handler 78 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:05,339 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:05,349 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ozone-test-uabmkkyzze of layout LEGACY in volume: s3v
om2_1        | 2022-07-10 13:18:05,383 [IPC Server handler 85 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:05,387 [IPC Server handler 97 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:05,390 [IPC Server handler 56 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:05,550 [IPC Server handler 45 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:05,605 [IPC Server handler 72 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:05,610 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:05,617 [IPC Server handler 61 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:05,745 [IPC Server handler 75 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:05,822 [IPC Server handler 70 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:05,836 [IPC Server handler 60 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:05,841 [IPC Server handler 55 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:05,991 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:06,033 [IPC Server handler 0 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:06,041 [IPC Server handler 76 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:06,063 [IPC Server handler 2 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:06,270 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:06,279 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:06,289 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:06,356 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:06,371 [IPC Server handler 85 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:06,378 [IPC Server handler 97 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
recon_1      | 2022-07-10 13:09:00,790 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm2.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9961 after 1 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-07-10 13:09:02,792 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm3.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9961 after 2 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-07-10 13:09:04,793 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm1.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9961 after 3 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-07-10 13:09:06,795 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm2.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9961 after 4 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-07-10 13:09:08,797 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm3.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9961 after 5 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-07-10 13:09:10,799 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm1.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9961 after 6 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-07-10 13:09:12,801 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm2.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9961 after 7 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-07-10 13:09:14,803 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm3.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9961 after 8 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-07-10 13:09:16,970 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:988d83fb-8298-4167-8ff5-9318a8e0d8d4 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
recon_1      | 	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
recon_1      | 	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:93)
recon_1      | 	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:16080)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy39.submitRequest over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9961 after 9 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-07-10 13:09:18,972 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm2.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9961 after 10 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-07-10 13:09:20,974 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm3.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9961 after 11 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-07-10 13:09:23,668 [main] INFO recon.ReconServer: Successfully stored SCM signed certificate, case:GETCERT.
recon_1      | 2022-07-10 13:09:24,085 [main] INFO persistence.DefaultDataSourceProvider: JDBC Url for Recon : jdbc:derby:/data/metadata/recon/ozone_recon_derby.db 
recon_1      | 2022-07-10 13:09:26,544 [main] INFO codegen.SqlDbUtils: Created derby database at jdbc:derby:/data/metadata/recon/ozone_recon_derby.db.
recon_1      | WARNING: An illegal reflective access operation has occurred
recon_1      | WARNING: Illegal reflective access by org.jooq.tools.reflect.Reflect (file:/opt/hadoop/share/ozone/lib/jooq-3.11.10.jar) to constructor java.lang.invoke.MethodHandles$Lookup(java.lang.Class)
recon_1      | WARNING: Please consider reporting this to the maintainers of org.jooq.tools.reflect.Reflect
recon_1      | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
recon_1      | WARNING: All illegal access operations will be denied in a future release
recon_1      | 2022-07-10 13:09:27,180 [main] INFO persistence.DefaultDataSourceProvider: JDBC Url for Recon : jdbc:derby:/data/metadata/recon/ozone_recon_derby.db 
recon_1      | 2022-07-10 13:09:27,257 [main] INFO codegen.SqlDbUtils: Created derby database at jdbc:derby:/data/metadata/recon/ozone_recon_derby.db.
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getPartsListSize(S3MultipartUploadCompleteRequest.java:478)
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:194)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-07-10 13:19:35,002 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadAbortRequest: Abort Multipart request is failed for KeyName ozone-test-9861106675/multipartKey5 in VolumeName/Bucket s3v/bucket-ozone-test-6322658386
om1_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Abort Multipart Upload Failed: volume: s3vbucket: bucket-ozone-test-6322658386key: ozone-test-9861106675/multipartKey5
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadAbortRequest.validateAndUpdateCache(S3MultipartUploadAbortRequest.java:161)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-07-10 13:19:35,665 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyCreateRequest: Key creation failed. Volume:s3v, Bucket:bucket-ozone-test-6322658386, Key:ozone-test-5974425549/multipartKey. 
om1_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: No such Multipart upload is with specified uploadId random
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareMultipartFileInfo(OMKeyRequest.java:758)
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareFileInfo(OMKeyRequest.java:645)
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareKeyInfo(OMKeyRequest.java:622)
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyCreateRequest.validateAndUpdateCache(OMKeyCreateRequest.java:282)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-07-10 13:20:14,153 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35812
om1_1        | 2022-07-10 13:20:14,210 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-07-10 13:20:17,650 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-0642987608 of layout LEGACY in volume: s3v
om1_1        | 2022-07-10 13:20:18,317 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: destbucket-81026 of layout LEGACY in volume: s3v
om1_1        | 2022-07-10 13:20:29,025 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35872
om1_1        | 2022-07-10 13:20:29,043 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-07-10 13:20:32,600 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-7006625698 of layout LEGACY in volume: s3v
om1_1        | 2022-07-10 13:20:48,575 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35980
om1_1        | 2022-07-10 13:20:48,587 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-07-10 13:20:52,045 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-7750864646 of layout LEGACY in volume: s3v
om1_1        | 2022-07-10 13:20:55,768 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyDeleteRequest: Key delete failed. Volume:s3v, Bucket:bucket-ozone-test-7750864646, Key:ozone-test-6291015824/multidelete/key=value/f4.
om1_1        | KEY_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Key not found
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:152)
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:98)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-07-10 13:21:00,063 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36012
om1_1        | 2022-07-10 13:21:00,079 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-07-10 13:21:03,376 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-0984322854 of layout LEGACY in volume: s3v
om2_1        | 2022-07-10 13:18:06,395 [IPC Server handler 56 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:06,428 [IPC Server handler 45 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:07,273 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:07,923 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:08,025 [IPC Server handler 54 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:08,029 [IPC Server handler 67 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:08,052 [IPC Server handler 39 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:08,174 [IPC Server handler 9 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:08,178 [IPC Server handler 69 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:08,181 [IPC Server handler 10 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:08,249 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:08,252 [IPC Server handler 98 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:08,258 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:08,288 [IPC Server handler 78 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:08,311 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:08,319 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:08,330 [IPC Server handler 97 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:08,385 [IPC Server handler 56 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:08,923 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:09,120 [IPC Server handler 39 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:09,187 [IPC Server handler 10 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:09,197 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:09,202 [IPC Server handler 98 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:09,256 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:09,265 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:09,283 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-qfntsnazxv of layout LEGACY in volume: s3v
om2_1        | 2022-07-10 13:18:09,317 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:09,327 [IPC Server handler 78 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:09,335 [IPC Server handler 97 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:09,386 [IPC Server handler 56 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:09,393 [IPC Server handler 45 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:09,411 [IPC Server handler 85 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:09,420 [IPC Server handler 72 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:09,462 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:09,466 [IPC Server handler 61 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:09,471 [IPC Server handler 26 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:09,604 [IPC Server handler 75 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:09,649 [IPC Server handler 70 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:09,655 [IPC Server handler 60 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:09,659 [IPC Server handler 55 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:09,679 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:09,683 [IPC Server handler 57 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:09,687 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:09,702 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:09,707 [IPC Server handler 49 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om1_1        | 2022-07-10 13:21:20,754 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36132
om1_1        | 2022-07-10 13:21:20,787 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-07-10 13:21:24,270 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-2439360640 of layout LEGACY in volume: s3v
om1_1        | 2022-07-10 13:21:38,945 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36172
om1_1        | 2022-07-10 13:21:38,972 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
recon_1      | 2022-07-10 13:09:27,258 [main] INFO recon.ReconServer: Creating Recon Schema.
recon_1      | 2022-07-10 13:09:29,992 [main] INFO http.BaseHttpServer: Starting Web-server for recon at: http://0.0.0.0:9888
recon_1      | 2022-07-10 13:09:29,993 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
recon_1      | 2022-07-10 13:09:29,993 [main] INFO http.BaseHttpServer: HttpAuthType: ozone.recon.http.auth.type = kerberos
recon_1      | 2022-07-10 13:09:30,017 [main] INFO util.log: Logging initialized @46023ms to org.eclipse.jetty.util.log.Slf4jLog
recon_1      | 2022-07-10 13:09:30,284 [main] WARN http.HttpRequestLog: Jetty request log can only be enabled using Log4j
recon_1      | 2022-07-10 13:09:30,308 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
recon_1      | 2022-07-10 13:09:30,330 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context recon
recon_1      | 2022-07-10 13:09:30,333 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
recon_1      | 2022-07-10 13:09:30,333 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
recon_1      | 2022-07-10 13:09:30,336 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.recon.http.auth.kerberos.principal keytabKey: ozone.recon.http.auth.kerberos.keytab
recon_1      | 2022-07-10 13:09:30,580 [main] INFO tasks.ReconTaskControllerImpl: Registered task ContainerKeyMapperTask with controller.
recon_1      | 2022-07-10 13:09:31,078 [main] INFO tasks.ReconTaskControllerImpl: Registered task FileSizeCountTask with controller.
recon_1      | 2022-07-10 13:09:31,087 [main] INFO tasks.ReconTaskControllerImpl: Registered task TableCountTask with controller.
recon_1      | 2022-07-10 13:09:31,097 [main] INFO tasks.ReconTaskControllerImpl: Registered task NSSummaryTask with controller.
recon_1      | 2022-07-10 13:09:31,156 [main] INFO ozone.OmUtils: Using OzoneManager ServiceID 'id1'.
recon_1      | 2022-07-10 13:09:32,558 [main] WARN recon.ReconUtils: ozone.recon.om.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1      | 2022-07-10 13:09:33,041 [main] WARN recon.ReconUtils: ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1      | 2022-07-10 13:09:33,247 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar!/network-topology-default.xml]
recon_1      | 2022-07-10 13:09:33,255 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
recon_1      | 2022-07-10 13:09:33,401 [main] WARN db.DBStoreBuilder: ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1      | 2022-07-10 13:09:33,828 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
recon_1      | 2022-07-10 13:09:33,996 [main] INFO reflections.Reflections: Reflections took 151 ms to scan 3 urls, producing 109 keys and 243 values 
recon_1      | 2022-07-10 13:09:34,174 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
recon_1      | 2022-07-10 13:09:34,227 [main] INFO node.SCMNodeManager: Entering startup safe mode.
recon_1      | 2022-07-10 13:09:34,235 [main] INFO scm.ReconNodeManager: Loaded 0 nodes from node DB.
recon_1      | 2022-07-10 13:09:34,240 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
recon_1      | 2022-07-10 13:09:34,268 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
recon_1      | 2022-07-10 13:09:34,327 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
recon_1      | 2022-07-10 13:09:34,386 [Socket Reader #1 for port 9891] INFO ipc.Server: Starting Socket Reader #1 for port 9891
recon_1      | 2022-07-10 13:09:34,477 [Listener at 0.0.0.0/9891] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
recon_1      | 2022-07-10 13:09:34,726 [Listener at 0.0.0.0/9891] INFO recon.ReconServer: Recon server initialized successfully!
recon_1      | 2022-07-10 13:09:34,726 [Listener at 0.0.0.0/9891] INFO recon.ReconServer: Starting Recon server
recon_1      | 2022-07-10 13:09:34,883 [Listener at 0.0.0.0/9891] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
recon_1      | 2022-07-10 13:09:34,907 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
recon_1      | 2022-07-10 13:09:34,907 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Recon metrics system started
recon_1      | 2022-07-10 13:09:35,500 [Listener at 0.0.0.0/9891] INFO http.HttpServer2: Jetty bound to port 9888
recon_1      | 2022-07-10 13:09:35,508 [Listener at 0.0.0.0/9891] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
recon_1      | 2022-07-10 13:09:35,618 [Listener at 0.0.0.0/9891] INFO server.session: DefaultSessionIdManager workerName=node0
recon_1      | 2022-07-10 13:09:35,618 [Listener at 0.0.0.0/9891] INFO server.session: No SessionScavenger set, using defaults
recon_1      | 2022-07-10 13:09:35,624 [Listener at 0.0.0.0/9891] INFO server.session: node0 Scavenging every 660000ms
recon_1      | 2022-07-10 13:09:35,720 [Listener at 0.0.0.0/9891] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/recon.keytab, for principal HTTP/recon@EXAMPLE.COM
recon_1      | 2022-07-10 13:09:35,727 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@736eb2a2{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
recon_1      | 2022-07-10 13:09:35,728 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1174ff02{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-recon-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
recon_1      | 2022-07-10 13:09:36,547 [Listener at 0.0.0.0/9891] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/recon.keytab, for principal HTTP/recon@EXAMPLE.COM
recon_1      | 2022-07-10 13:09:36,556 [Listener at 0.0.0.0/9891] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/recon.keytab, for principal HTTP/recon@EXAMPLE.COM
recon_1      | 2022-07-10 13:09:39,836 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@1c07798b{recon,/,file:///tmp/jetty-0_0_0_0-9888-ozone-recon-1_3_0-SNAPSHOT_jar-_-any-166592505358626412/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-recon-1.3.0-SNAPSHOT.jar!/webapps/recon}
recon_1      | 2022-07-10 13:09:39,861 [Listener at 0.0.0.0/9891] INFO server.AbstractConnector: Started ServerConnector@3420547{HTTP/1.1, (http/1.1)}{0.0.0.0:9888}
recon_1      | 2022-07-10 13:09:39,861 [Listener at 0.0.0.0/9891] INFO server.Server: Started @55867ms
recon_1      | 2022-07-10 13:09:39,866 [Listener at 0.0.0.0/9891] INFO impl.MetricsSinkAdapter: Sink prometheus started
recon_1      | 2022-07-10 13:09:39,866 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Registered sink prometheus
recon_1      | 2022-07-10 13:09:39,877 [Listener at 0.0.0.0/9891] INFO http.BaseHttpServer: HTTP server of recon listening at http://0.0.0.0:9888
om2_1        | 2022-07-10 13:18:09,710 [IPC Server handler 96 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:09,741 [IPC Server handler 71 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:09,987 [IPC Server handler 83 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:09,991 [IPC Server handler 54 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:09,995 [IPC Server handler 67 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:10,019 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:10,051 [IPC Server handler 86 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:10,061 [IPC Server handler 3 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:10,065 [IPC Server handler 7 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:10,085 [IPC Server handler 6 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:10,096 [IPC Server handler 90 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:10,103 [IPC Server handler 8 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:10,145 [IPC Server handler 2 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:10,148 [IPC Server handler 39 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:10,152 [IPC Server handler 9 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:10,176 [IPC Server handler 69 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:10,180 [IPC Server handler 10 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:10,185 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:10,200 [IPC Server handler 98 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:10,203 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:10,206 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:10,281 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:11,543 [IPC Server handler 75 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:11,591 [IPC Server handler 70 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:11,599 [IPC Server handler 60 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:11,607 [IPC Server handler 55 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:11,656 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:11,665 [IPC Server handler 57 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:11,670 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:11,687 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:11,690 [IPC Server handler 49 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:11,693 [IPC Server handler 96 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:11,848 [IPC Server handler 83 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:12,787 [IPC Server handler 83 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:12,862 [IPC Server handler 54 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:12,866 [IPC Server handler 67 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:12,876 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:16,945 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:43572
om2_1        | 2022-07-10 13:18:16,955 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:18:20,525 [IPC Server handler 75 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:20,529 [IPC Server handler 70 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:20,536 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-2810480406 of layout LEGACY in volume: s3v
om2_1        | 2022-07-10 13:18:21,170 [IPC Server handler 9 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:21,174 [IPC Server handler 69 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
recon_1      | 2022-07-10 13:09:39,877 [Listener at 0.0.0.0/9891] INFO impl.OzoneManagerServiceProviderImpl: Starting Ozone Manager Service Provider.
recon_1      | 2022-07-10 13:09:39,904 [Listener at 0.0.0.0/9891] INFO impl.OzoneManagerServiceProviderImpl: Registered OmDeltaRequest task 
recon_1      | 2022-07-10 13:09:39,920 [Listener at 0.0.0.0/9891] INFO impl.OzoneManagerServiceProviderImpl: Registered OmSnapshotRequest task 
recon_1      | 2022-07-10 13:09:39,920 [Listener at 0.0.0.0/9891] INFO recovery.ReconOmMetadataManagerImpl: Starting ReconOMMetadataManagerImpl
recon_1      | 2022-07-10 13:09:39,920 [Listener at 0.0.0.0/9891] WARN recon.ReconUtils: ozone.recon.om.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1      | 2022-07-10 13:09:39,921 [Listener at 0.0.0.0/9891] INFO tasks.ReconTaskControllerImpl: Starting Recon Task Controller.
recon_1      | 2022-07-10 13:09:39,931 [Listener at 0.0.0.0/9891] INFO scm.ReconStorageContainerManagerFacade: Recon ScmDatanodeProtocol RPC server is listening at /0.0.0.0:9891
recon_1      | 2022-07-10 13:09:40,439 [Listener at 0.0.0.0/9891] INFO scm.ReconStorageContainerManagerFacade: Obtained 0 pipelines from SCM.
recon_1      | 2022-07-10 13:09:40,440 [Listener at 0.0.0.0/9891] INFO scm.ReconPipelineManager: Recon has 0 pipelines in house.
recon_1      | 2022-07-10 13:09:40,440 [Listener at 0.0.0.0/9891] INFO server.SCMDatanodeProtocolServer: ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:9891
recon_1      | 2022-07-10 13:09:40,449 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
recon_1      | 2022-07-10 13:09:40,460 [IPC Server listener on 9891] INFO ipc.Server: IPC Server listener on 9891: starting
recon_1      | 2022-07-10 13:09:40,721 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Registered PipelineSyncTask task 
recon_1      | 2022-07-10 13:09:40,722 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Starting PipelineSyncTask Thread.
recon_1      | 2022-07-10 13:09:40,775 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Registered ContainerHealthTask task 
recon_1      | 2022-07-10 13:09:40,775 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Starting ContainerHealthTask Thread.
recon_1      | 2022-07-10 13:09:40,857 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 0 pipelines in house.
recon_1      | 2022-07-10 13:09:40,860 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 98 milliseconds.
recon_1      | 2022-07-10 13:09:59,922 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-07-10 13:09:59,922 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-07-10 13:10:00,003 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:10:00,008 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 2 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-07-10 13:10:02,009 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 3 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:10:02,013 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 4 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:10:02,014 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 5 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-07-10 13:10:04,017 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 6 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:10:04,018 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 7 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:10:04,019 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 8 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-07-10 13:10:06,024 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 9 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:10:06,025 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 10 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:10:06,027 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 11 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-07-10 13:10:08,029 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 12 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:10:08,031 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 13 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:10:08,032 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 14 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-07-10 13:10:10,033 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 15 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:10:10,035 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 16 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:10:10,036 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 17 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-07-10 13:10:12,037 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 18 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:10:12,039 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 19 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:10:12,040 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 20 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-07-10 13:10:14,042 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 21 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:10:14,043 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 22 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:10:14,044 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 23 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-07-10 13:10:16,048 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 24 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:10:16,049 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 25 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:10:16,051 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 26 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-07-10 13:10:18,053 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 27 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:10:18,054 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 28 failover attempts. Trying to failover immediately.
om2_1        | 2022-07-10 13:18:21,184 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-8869007246 of layout LEGACY in volume: s3v
om2_1        | 2022-07-10 13:18:21,831 [IPC Server handler 54 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:21,836 [IPC Server handler 67 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:21,849 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-6024978753 of layout LEGACY in volume: s3v
om2_1        | 2022-07-10 13:18:22,487 [IPC Server handler 26 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:22,491 [IPC Server handler 75 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:22,500 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket-ozone-test-6024978753 in volume:s3v
om2_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om2_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-07-10 13:18:23,142 [IPC Server handler 39 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:24,102 [IPC Server handler 90 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:24,106 [IPC Server handler 8 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:24,115 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-1090355142 of layout LEGACY in volume: s3v
om2_1        | 2022-07-10 13:18:28,009 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:43610
om2_1        | 2022-07-10 13:18:28,011 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:18:32,461 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:43624
om2_1        | 2022-07-10 13:18:32,466 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:18:35,897 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:41809
om2_1        | 2022-07-10 13:18:35,909 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:18:35,911 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:35,921 [IPC Server handler 58 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:35,928 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-7979361343 of layout LEGACY in volume: s3v
om2_1        | 2022-07-10 13:18:36,569 [IPC Server handler 60 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:36,574 [IPC Server handler 55 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:36,586 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-9923649996 of layout LEGACY in volume: s3v
om2_1        | 2022-07-10 13:18:37,243 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:37,247 [IPC Server handler 78 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:37,893 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:37,899 [IPC Server handler 58 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:37,908 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketDeleteRequest: Delete bucket failed for bucket:nosuchbucket-ozone-test-3783028772 in volume:s3v
om2_1        | BUCKET_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Bucket not found
om2_1        | 	at org.apache.hadoop.ozone.om.OzoneManager.getBucketOwner(OzoneManager.java:2496)
om2_1        | 	at org.apache.hadoop.ozone.om.OzoneManager.getBucketOwner(OzoneManager.java:2466)
om2_1        | 	at org.apache.hadoop.ozone.om.request.OMClientRequest.checkAcls(OMClientRequest.java:217)
om2_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketDeleteRequest.validateAndUpdateCache(OMBucketDeleteRequest.java:108)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-07-10 13:18:41,787 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:43678
om2_1        | 2022-07-10 13:18:41,795 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:18:42,199 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:43077
om2_1        | 2022-07-10 13:18:42,214 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:18:45,145 [IPC Server handler 39 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:45,148 [IPC Server handler 2 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:45,160 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-9508592014 of layout LEGACY in volume: s3v
om2_1        | 2022-07-10 13:18:45,803 [IPC Server handler 54 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:45,807 [IPC Server handler 67 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:46,425 [IPC Server handler 72 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:46,428 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:50,013 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:43700
om2_1        | 2022-07-10 13:18:50,023 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:18:53,289 [IPC Server handler 97 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:53,293 [IPC Server handler 56 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:53,304 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-6075713174 of layout LEGACY in volume: s3v
om2_1        | 2022-07-10 13:18:53,937 [IPC Server handler 0 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:53,940 [IPC Server handler 99 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:53,943 [IPC Server handler 50 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:18:57,877 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:43718
om2_1        | 2022-07-10 13:18:57,881 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:19:03,777 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:43734
om2_1        | 2022-07-10 13:19:03,789 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:19:07,196 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:45097
om2_1        | 2022-07-10 13:19:07,206 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:19:07,210 [IPC Server handler 98 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:07,223 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:07,232 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-6322658386 of layout LEGACY in volume: s3v
om2_1        | 2022-07-10 13:19:07,966 [IPC Server handler 53 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:07,970 [IPC Server handler 31 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:07,975 [IPC Server handler 80 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:08,689 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:08,691 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:08,694 [IPC Server handler 49 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:08,715 [IPC Server handler 96 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:09,142 [IPC Server handler 39 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:10,045 [IPC Server handler 82 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:10,047 [IPC Server handler 77 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:10,054 [IPC Server handler 79 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:10,092 [IPC Server handler 6 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:10,255 [IPC Server handler 78 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:11,001 [IPC Server handler 82 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:11,004 [IPC Server handler 77 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:11,006 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:11,896 [IPC Server handler 58 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:11,902 [IPC Server handler 0 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:11,906 [IPC Server handler 99 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:11,952 [IPC Server handler 53 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:12,962 [IPC Server handler 31 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:12,967 [IPC Server handler 53 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:12,970 [IPC Server handler 80 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:13,659 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:13,662 [IPC Server handler 57 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:13,664 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:14,450 [IPC Server handler 61 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:14,455 [IPC Server handler 26 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:14,458 [IPC Server handler 75 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:14,482 [IPC Server handler 70 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:14,855 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:15,692 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:15,701 [IPC Server handler 49 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:15,709 [IPC Server handler 71 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:15,732 [IPC Server handler 96 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:16,066 [IPC Server handler 87 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:16,911 [IPC Server handler 99 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:16,915 [IPC Server handler 50 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:16,919 [IPC Server handler 31 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:17,722 [IPC Server handler 71 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:17,733 [IPC Server handler 96 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:17,737 [IPC Server handler 83 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:17,761 [IPC Server handler 54 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:18,079 [IPC Server handler 74 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:18,867 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:18,869 [IPC Server handler 58 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:18,872 [IPC Server handler 0 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:18,900 [IPC Server handler 99 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:19,010 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:19,809 [IPC Server handler 67 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:19,811 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:19,814 [IPC Server handler 58 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:20,454 [IPC Server handler 26 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:20,458 [IPC Server handler 75 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:20,461 [IPC Server handler 70 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:20,475 [IPC Server handler 60 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:21,521 [IPC Server handler 55 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:21,524 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:21,527 [IPC Server handler 57 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:22,218 [IPC Server handler 98 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:22,221 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:22,224 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
scm1.org_1   | Sleeping for 5 seconds
scm1.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm1.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm1.org_1   | 2022-07-10 13:08:49,225 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm1.org_1   | /************************************************************
scm1.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm1.org_1   | STARTUP_MSG:   host = scm1.org/172.25.0.116
scm1.org_1   | STARTUP_MSG:   args = [--init]
scm1.org_1   | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
scm1.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar
scm1.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/d088d199bf506d76f7046a4b19b690e2a9e6915e ; compiled by 'runner' on 2022-07-10T12:45Z
scm1.org_1   | STARTUP_MSG:   java = 11.0.14.1
scm1.org_1   | ************************************************************/
scm1.org_1   | 2022-07-10 13:08:49,293 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm1.org_1   | 2022-07-10 13:08:49,597 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm1.org_1   | 2022-07-10 13:08:49,881 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm1.org_1   | 2022-07-10 13:08:50,027 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm1.org_1   | 2022-07-10 13:08:50,310 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm1, RPC Address: scm1.org:9894 and Ratis port: 9894
scm1.org_1   | 2022-07-10 13:08:50,331 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm1: scm1.org
scm1.org_1   | 2022-07-10 13:08:50,362 [main] INFO ha.HASecurityUtils: Initializing secure StorageContainerManager.
scm1.org_1   | 2022-07-10 13:08:53,706 [main] ERROR client.SCMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
scm1.org_1   | 2022-07-10 13:08:53,709 [main] INFO client.SCMCertificateClient: Certificate client init case: 0
scm1.org_1   | 2022-07-10 13:08:53,712 [main] INFO client.SCMCertificateClient: Creating keypair for client as keypair and certificate not found.
scm1.org_1   | 2022-07-10 13:08:57,562 [main] INFO ha.HASecurityUtils: Init response: GETCERT
scm1.org_1   | 2022-07-10 13:08:59,765 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.116,host:scm1.org
scm1.org_1   | 2022-07-10 13:08:59,772 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
scm1.org_1   | 2022-07-10 13:09:00,213 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.116,host:scm1.org
scm1.org_1   | 2022-07-10 13:09:00,220 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
scm1.org_1   | 2022-07-10 13:09:00,221 [main] INFO ha.HASecurityUtils: Creating csr for SCM->hostName:scm1.org,scmId:988d83fb-8298-4167-8ff5-9318a8e0d8d4,clusterId:CID-f578972c-97f6-4a12-a46c-8eeea6081008,subject:scm-sub@scm1.org
scm1.org_1   | 2022-07-10 13:09:00,480 [main] INFO ha.HASecurityUtils: Successfully stored SCM signed certificate.
scm1.org_1   | 2022-07-10 13:09:00,931 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
scm1.org_1   | 2022-07-10 13:09:01,202 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
scm1.org_1   | 2022-07-10 13:09:01,202 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2022-07-10 13:09:01,203 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
scm1.org_1   | 2022-07-10 13:09:01,204 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2022-07-10 13:09:01,204 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2022-07-10 13:09:01,208 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
scm1.org_1   | 2022-07-10 13:09:01,215 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2022-07-10 13:09:01,216 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
scm1.org_1   | 2022-07-10 13:09:01,217 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm1.org_1   | 2022-07-10 13:09:01,243 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
scm1.org_1   | 2022-07-10 13:09:01,244 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
scm1.org_1   | 2022-07-10 13:09:01,958 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
scm1.org_1   | 2022-07-10 13:09:01,961 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
scm1.org_1   | 2022-07-10 13:09:01,963 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
scm1.org_1   | 2022-07-10 13:09:01,963 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm1.org_1   | 2022-07-10 13:09:01,964 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm1.org_1   | 2022-07-10 13:09:01,983 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm1.org_1   | 2022-07-10 13:09:02,040 [main] INFO server.RaftServer: 988d83fb-8298-4167-8ff5-9318a8e0d8d4: addNew group-8EEEA6081008:[988d83fb-8298-4167-8ff5-9318a8e0d8d4|rpc:scm1.org:9894|priority:0] returns group-8EEEA6081008:java.util.concurrent.CompletableFuture@43aeb5e0[Not completed]
scm1.org_1   | 2022-07-10 13:09:02,126 [pool-2-thread-1] INFO server.RaftServer$Division: 988d83fb-8298-4167-8ff5-9318a8e0d8d4: new RaftServerImpl for group-8EEEA6081008:[988d83fb-8298-4167-8ff5-9318a8e0d8d4|rpc:scm1.org:9894|priority:0] with SCMStateMachine:uninitialized
scm1.org_1   | 2022-07-10 13:09:02,128 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
scm1.org_1   | 2022-07-10 13:09:02,128 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
scm1.org_1   | 2022-07-10 13:09:02,129 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
scm1.org_1   | 2022-07-10 13:09:02,129 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm1.org_1   | 2022-07-10 13:09:02,131 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm1.org_1   | 2022-07-10 13:09:02,131 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
scm1.org_1   | 2022-07-10 13:09:02,154 [pool-2-thread-1] INFO server.RaftServer$Division: 988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008: ConfigurationManager, init=-1: [988d83fb-8298-4167-8ff5-9318a8e0d8d4|rpc:scm1.org:9894|priority:0], old=null, confs=<EMPTY_MAP>
scm1.org_1   | 2022-07-10 13:09:02,159 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm1.org_1   | 2022-07-10 13:09:02,168 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
scm1.org_1   | 2022-07-10 13:09:02,173 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
om2_1        | 2022-07-10 13:19:22,248 [IPC Server handler 78 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:22,405 [IPC Server handler 85 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:23,087 [IPC Server handler 87 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:23,090 [IPC Server handler 79 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:23,094 [IPC Server handler 74 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:23,109 [IPC Server handler 8 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:23,210 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:23,900 [IPC Server handler 50 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:23,903 [IPC Server handler 99 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:23,906 [IPC Server handler 31 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:23,916 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload: /s3v/bucket-ozone-test-6322658386/ozone-test-7990573019/multipartKey2 Part number: 1 size 6  is less than minimum part size 5242880
om2_1        | 2022-07-10 13:19:23,920 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-7990573019/multipartKey2 in Volume/Bucket s3v/bucket-ozone-test-6322658386
om2_1        | ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-6322658386 key: ozone-test-7990573019/multipartKey2. Entity too small.
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:535)
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:198)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-07-10 13:19:24,589 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:24,596 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:24,611 [IPC Server handler 49 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:25,308 [IPC Server handler 56 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:25,315 [IPC Server handler 45 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:25,319 [IPC Server handler 85 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:25,330 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-ozone-test-6322658386/ozone-test-0260461918/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 1
om2_1        | partName: "etag1"
om2_1        | , partNumber: 2
om2_1        | partName: "etag2"
om2_1        | ]
om2_1        | 2022-07-10 13:19:25,332 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-0260461918/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-6322658386
om2_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-6322658386 key: ozone-test-0260461918/multipartKey3
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:187)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-07-10 13:19:25,969 [IPC Server handler 53 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:25,973 [IPC Server handler 80 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:25,979 [IPC Server handler 82 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:25,989 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-ozone-test-6322658386/ozone-test-0260461918/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 2
om2_1        | partName: "etag1"
om2_1        | , partNumber: 1
om2_1        | partName: "etag2"
om2_1        | ]
om2_1        | 2022-07-10 13:19:25,990 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-0260461918/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-6322658386
om2_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-6322658386 key: ozone-test-0260461918/multipartKey3
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:187)
scm1.org_1   | 2022-07-10 13:09:02,174 [pool-2-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/scm-ha/f578972c-97f6-4a12-a46c-8eeea6081008 does not exist. Creating ...
scm1.org_1   | 2022-07-10 13:09:02,189 [pool-2-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/f578972c-97f6-4a12-a46c-8eeea6081008/in_use.lock acquired by nodename 87@scm1.org
scm1.org_1   | 2022-07-10 13:09:02,203 [pool-2-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/scm-ha/f578972c-97f6-4a12-a46c-8eeea6081008 has been successfully formatted.
scm1.org_1   | 2022-07-10 13:09:02,206 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
scm1.org_1   | 2022-07-10 13:09:02,227 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
scm1.org_1   | 2022-07-10 13:09:02,263 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
scm1.org_1   | 2022-07-10 13:09:02,263 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2022-07-10 13:09:02,265 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
scm1.org_1   | 2022-07-10 13:09:02,282 [pool-2-thread-1] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
scm1.org_1   | 2022-07-10 13:09:02,450 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm1.org_1   | 2022-07-10 13:09:02,457 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
scm1.org_1   | 2022-07-10 13:09:02,466 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
scm1.org_1   | 2022-07-10 13:09:02,481 [pool-2-thread-1] INFO segmented.SegmentedRaftLogWorker: new 988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/f578972c-97f6-4a12-a46c-8eeea6081008
scm1.org_1   | 2022-07-10 13:09:02,482 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
scm1.org_1   | 2022-07-10 13:09:02,482 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
scm1.org_1   | 2022-07-10 13:09:02,483 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm1.org_1   | 2022-07-10 13:09:02,484 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
scm1.org_1   | 2022-07-10 13:09:02,484 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
scm1.org_1   | 2022-07-10 13:09:02,485 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
scm1.org_1   | 2022-07-10 13:09:02,485 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
scm1.org_1   | 2022-07-10 13:09:02,486 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
scm1.org_1   | 2022-07-10 13:09:02,499 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
scm1.org_1   | 2022-07-10 13:09:02,500 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
scm1.org_1   | 2022-07-10 13:09:02,500 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
scm1.org_1   | 2022-07-10 13:09:02,505 [pool-2-thread-1] INFO segmented.SegmentedRaftLogWorker: 988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
scm1.org_1   | 2022-07-10 13:09:02,505 [pool-2-thread-1] INFO segmented.SegmentedRaftLogWorker: 988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
scm1.org_1   | 2022-07-10 13:09:02,509 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
scm1.org_1   | 2022-07-10 13:09:02,515 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
scm1.org_1   | 2022-07-10 13:09:02,516 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
scm1.org_1   | 2022-07-10 13:09:02,518 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
scm1.org_1   | 2022-07-10 13:09:02,520 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
scm1.org_1   | 2022-07-10 13:09:02,523 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
scm1.org_1   | 2022-07-10 13:09:02,620 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm1.org_1   | 2022-07-10 13:09:02,620 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
scm1.org_1   | 2022-07-10 13:09:02,621 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
scm1.org_1   | 2022-07-10 13:09:02,623 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
scm1.org_1   | 2022-07-10 13:09:02,624 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
scm1.org_1   | 2022-07-10 13:09:02,627 [988d83fb-8298-4167-8ff5-9318a8e0d8d4-impl-thread1] INFO server.RaftServer$Division: 988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008: start as a follower, conf=-1: [988d83fb-8298-4167-8ff5-9318a8e0d8d4|rpc:scm1.org:9894|priority:0], old=null
scm1.org_1   | 2022-07-10 13:09:02,628 [988d83fb-8298-4167-8ff5-9318a8e0d8d4-impl-thread1] INFO server.RaftServer$Division: 988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008: changes role from      null to FOLLOWER at term 0 for startAsFollower
scm1.org_1   | 2022-07-10 13:09:02,631 [988d83fb-8298-4167-8ff5-9318a8e0d8d4-impl-thread1] INFO impl.RoleInfo: 988d83fb-8298-4167-8ff5-9318a8e0d8d4: start 988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-FollowerState
scm1.org_1   | 2022-07-10 13:09:02,644 [988d83fb-8298-4167-8ff5-9318a8e0d8d4-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-8EEEA6081008,id=988d83fb-8298-4167-8ff5-9318a8e0d8d4
scm1.org_1   | 2022-07-10 13:09:02,655 [main] INFO server.RaftServer: 988d83fb-8298-4167-8ff5-9318a8e0d8d4: start RPC server
scm1.org_1   | 2022-07-10 13:09:02,750 [main] INFO server.GrpcService: 988d83fb-8298-4167-8ff5-9318a8e0d8d4: GrpcService started, listening on 9894
scm1.org_1   | 2022-07-10 13:09:02,771 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$354/0x000000084031f040@770beef5] INFO util.JvmPauseMonitor: JvmPauseMonitor-988d83fb-8298-4167-8ff5-9318a8e0d8d4: Started
scm1.org_1   | 2022-07-10 13:09:07,763 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-FollowerState] INFO impl.FollowerState: 988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5132717509ns, electionTimeout:5123ms
scm1.org_1   | 2022-07-10 13:09:07,764 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-FollowerState] INFO impl.RoleInfo: 988d83fb-8298-4167-8ff5-9318a8e0d8d4: shutdown 988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-FollowerState
scm1.org_1   | 2022-07-10 13:09:07,765 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-FollowerState] INFO server.RaftServer$Division: 988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
scm1.org_1   | 2022-07-10 13:09:07,767 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
scm1.org_1   | 2022-07-10 13:09:07,767 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-FollowerState] INFO impl.RoleInfo: 988d83fb-8298-4167-8ff5-9318a8e0d8d4: start 988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-LeaderElection1
scm1.org_1   | 2022-07-10 13:09:07,773 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-LeaderElection1] INFO impl.LeaderElection: 988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [988d83fb-8298-4167-8ff5-9318a8e0d8d4|rpc:scm1.org:9894|priority:0], old=null
scm1.org_1   | 2022-07-10 13:09:07,774 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-LeaderElection1] INFO impl.LeaderElection: 988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-LeaderElection1 ELECTION round 0: result PASSED (term=1)
scm1.org_1   | 2022-07-10 13:09:07,774 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-LeaderElection1] INFO impl.RoleInfo: 988d83fb-8298-4167-8ff5-9318a8e0d8d4: shutdown 988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-LeaderElection1
scm1.org_1   | 2022-07-10 13:09:07,776 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-LeaderElection1] INFO server.RaftServer$Division: 988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
scm1.org_1   | 2022-07-10 13:09:07,776 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-LeaderElection1] INFO server.RaftServer$Division: 988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008: change Leader from null to 988d83fb-8298-4167-8ff5-9318a8e0d8d4 at term 1 for becomeLeader, leader elected after 5569ms
scm1.org_1   | 2022-07-10 13:09:07,791 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
scm1.org_1   | 2022-07-10 13:09:07,824 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
scm1.org_1   | 2022-07-10 13:09:07,833 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
scm1.org_1   | 2022-07-10 13:09:07,839 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
scm1.org_1   | 2022-07-10 13:09:07,840 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
scm1.org_1   | 2022-07-10 13:09:07,842 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
scm1.org_1   | 2022-07-10 13:09:07,847 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
scm1.org_1   | 2022-07-10 13:09:07,865 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
scm1.org_1   | 2022-07-10 13:09:07,869 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-LeaderElection1] INFO impl.RoleInfo: 988d83fb-8298-4167-8ff5-9318a8e0d8d4: start 988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-LeaderStateImpl
scm1.org_1   | 2022-07-10 13:09:07,892 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-SegmentedRaftLogWorker: Starting segment from index:0
scm1.org_1   | 2022-07-10 13:09:07,932 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-LeaderElection1] INFO server.RaftServer$Division: 988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008: set configuration 0: [988d83fb-8298-4167-8ff5-9318a8e0d8d4|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm1.org_1   | 2022-07-10 13:09:07,979 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/f578972c-97f6-4a12-a46c-8eeea6081008/current/log_inprogress_0
scm1.org_1   | 2022-07-10 13:09:08,772 [main] INFO server.RaftServer: 988d83fb-8298-4167-8ff5-9318a8e0d8d4: close
scm1.org_1   | 2022-07-10 13:09:08,774 [main] INFO server.RaftServer$Division: 988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008: shutdown
scm1.org_1   | 2022-07-10 13:09:08,774 [main] INFO util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-8EEEA6081008,id=988d83fb-8298-4167-8ff5-9318a8e0d8d4
scm1.org_1   | 2022-07-10 13:09:08,774 [main] INFO impl.RoleInfo: 988d83fb-8298-4167-8ff5-9318a8e0d8d4: shutdown 988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-LeaderStateImpl
scm1.org_1   | 2022-07-10 13:09:08,779 [main] INFO impl.PendingRequests: 988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-PendingRequests: sendNotLeaderResponses
scm1.org_1   | 2022-07-10 13:09:08,782 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-StateMachineUpdater] INFO impl.StateMachineUpdater: 988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-StateMachineUpdater: Took a snapshot at index 0
scm1.org_1   | 2022-07-10 13:09:08,782 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-StateMachineUpdater] INFO impl.StateMachineUpdater: 988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
scm1.org_1   | 2022-07-10 13:09:08,783 [main] INFO impl.StateMachineUpdater: 988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-StateMachineUpdater: set stopIndex = 0
scm1.org_1   | 2022-07-10 13:09:08,787 [main] INFO server.RaftServer$Division: 988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008: closes. applyIndex: 0
scm1.org_1   | 2022-07-10 13:09:08,788 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
scm1.org_1   | 2022-07-10 13:09:08,789 [main] INFO segmented.SegmentedRaftLogWorker: 988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-SegmentedRaftLogWorker close()
scm1.org_1   | 2022-07-10 13:09:08,790 [main] INFO server.GrpcService: 988d83fb-8298-4167-8ff5-9318a8e0d8d4: shutdown server with port 9894 now
scm1.org_1   | 2022-07-10 13:09:08,800 [main] INFO server.GrpcService: 988d83fb-8298-4167-8ff5-9318a8e0d8d4: shutdown server with port 9894 successfully
scm1.org_1   | 2022-07-10 13:09:08,800 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$354/0x000000084031f040@770beef5] INFO util.JvmPauseMonitor: JvmPauseMonitor-988d83fb-8298-4167-8ff5-9318a8e0d8d4: Stopped
scm1.org_1   | 2022-07-10 13:09:08,801 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm1.org_1   | 2022-07-10 13:09:08,803 [main] INFO server.StorageContainerManager: SCM initialization succeeded. Current cluster id for sd=/data/metadata/scm; cid=CID-f578972c-97f6-4a12-a46c-8eeea6081008; layoutVersion=4; scmId=988d83fb-8298-4167-8ff5-9318a8e0d8d4
scm1.org_1   | 2022-07-10 13:09:08,810 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
scm1.org_1   | /************************************************************
scm1.org_1   | SHUTDOWN_MSG: Shutting down StorageContainerManager at scm1.org/172.25.0.116
scm1.org_1   | ************************************************************/
scm1.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm1.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm1.org_1   | 2022-07-10 13:09:10,429 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm1.org_1   | /************************************************************
scm1.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm1.org_1   | STARTUP_MSG:   host = scm1.org/172.25.0.116
scm1.org_1   | STARTUP_MSG:   args = []
scm1.org_1   | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
scm1.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar
scm1.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/d088d199bf506d76f7046a4b19b690e2a9e6915e ; compiled by 'runner' on 2022-07-10T12:45Z
scm1.org_1   | STARTUP_MSG:   java = 11.0.14.1
scm1.org_1   | ************************************************************/
scm1.org_1   | 2022-07-10 13:09:10,437 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm1.org_1   | 2022-07-10 13:09:10,480 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm1.org_1   | 2022-07-10 13:09:10,526 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm1.org_1   | 2022-07-10 13:09:10,542 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm1.org_1   | 2022-07-10 13:09:10,595 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm1, RPC Address: scm1.org:9894 and Ratis port: 9894
scm1.org_1   | 2022-07-10 13:09:10,595 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm1: scm1.org
scm1.org_1   | 2022-07-10 13:09:11,045 [main] INFO client.SCMCertificateClient: Loading certificate from location:/data/metadata/scm/sub-ca/certs.
scm1.org_1   | 2022-07-10 13:09:11,155 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/certificate.crt.
scm1.org_1   | 2022-07-10 13:09:11,163 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/CA-1.crt.
scm1.org_1   | 2022-07-10 13:09:11,166 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/844577728582.crt.
scm1.org_1   | 2022-07-10 13:09:11,331 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
scm1.org_1   | 2022-07-10 13:09:11,332 [main] INFO server.StorageContainerManager: SCM login successful.
scm1.org_1   | 2022-07-10 13:09:11,373 [main] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm1.org_1   | 2022-07-10 13:09:11,536 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm1.org_1   | 2022-07-10 13:09:11,737 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar!/network-topology-default.xml]
scm1.org_1   | 2022-07-10 13:09:11,737 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
scm1.org_1   | 2022-07-10 13:09:11,820 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
scm1.org_1   | 2022-07-10 13:09:11,837 [main] INFO ha.SCMRatisServerImpl: starting Raft server for scm:988d83fb-8298-4167-8ff5-9318a8e0d8d4
scm1.org_1   | 2022-07-10 13:09:11,898 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
scm1.org_1   | 2022-07-10 13:09:11,957 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
scm1.org_1   | 2022-07-10 13:09:11,958 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2022-07-10 13:09:11,958 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
scm1.org_1   | 2022-07-10 13:09:11,958 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2022-07-10 13:09:11,959 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2022-07-10 13:09:11,959 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
scm1.org_1   | 2022-07-10 13:09:11,961 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2022-07-10 13:09:11,962 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
scm1.org_1   | 2022-07-10 13:09:11,963 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm1.org_1   | 2022-07-10 13:09:11,974 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
scm1.org_1   | 2022-07-10 13:09:11,975 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
scm1.org_1   | 2022-07-10 13:09:12,507 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
scm1.org_1   | 2022-07-10 13:09:12,509 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
scm1.org_1   | 2022-07-10 13:09:12,510 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
scm1.org_1   | 2022-07-10 13:09:12,510 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm1.org_1   | 2022-07-10 13:09:12,510 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm1.org_1   | 2022-07-10 13:09:12,513 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm1.org_1   | 2022-07-10 13:09:12,520 [988d83fb-8298-4167-8ff5-9318a8e0d8d4-impl-thread1] INFO server.RaftServer: 988d83fb-8298-4167-8ff5-9318a8e0d8d4: found a subdirectory /data/metadata/scm-ha/f578972c-97f6-4a12-a46c-8eeea6081008
scm1.org_1   | 2022-07-10 13:09:12,525 [main] INFO server.RaftServer: 988d83fb-8298-4167-8ff5-9318a8e0d8d4: addNew group-8EEEA6081008:[] returns group-8EEEA6081008:java.util.concurrent.CompletableFuture@8c43966[Not completed]
scm1.org_1   | 2022-07-10 13:09:12,551 [pool-16-thread-1] INFO server.RaftServer$Division: 988d83fb-8298-4167-8ff5-9318a8e0d8d4: new RaftServerImpl for group-8EEEA6081008:[] with SCMStateMachine:uninitialized
scm1.org_1   | 2022-07-10 13:09:12,553 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
scm1.org_1   | 2022-07-10 13:09:12,553 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
scm1.org_1   | 2022-07-10 13:09:12,553 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
scm1.org_1   | 2022-07-10 13:09:12,553 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm1.org_1   | 2022-07-10 13:09:12,553 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm1.org_1   | 2022-07-10 13:09:12,553 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
scm1.org_1   | 2022-07-10 13:09:12,559 [pool-16-thread-1] INFO server.RaftServer$Division: 988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
scm1.org_1   | 2022-07-10 13:09:12,559 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm1.org_1   | 2022-07-10 13:09:12,561 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-07-10 13:19:26,687 [IPC Server handler 71 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:26,690 [IPC Server handler 96 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:26,696 [IPC Server handler 83 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:26,715 [IPC Server handler 54 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:27,108 [IPC Server handler 5 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:28,064 [IPC Server handler 37 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:28,071 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:28,076 [IPC Server handler 93 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:28,096 [IPC Server handler 74 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:28,560 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:29,302 [IPC Server handler 56 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:29,308 [IPC Server handler 45 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:29,312 [IPC Server handler 85 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:29,343 [IPC Server handler 72 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:29,430 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:30,119 [IPC Server handler 5 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:30,122 [IPC Server handler 74 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:30,125 [IPC Server handler 8 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:30,132 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-0260461918/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-6322658386
om2_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-6322658386 key: ozone-test-0260461918/multipartKey3. Provided Part info is { etag1, 1}, whereas OM has partName /s3v/bucket-ozone-test-6322658386/ozone-test-0260461918/multipartKey3-af1c271f-1abf-46c7-b20c-eda35dade449-108623243811946532-1
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:512)
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:198)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-07-10 13:19:30,749 [IPC Server handler 54 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:30,752 [IPC Server handler 67 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:30,755 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:30,773 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-0260461918/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-6322658386
om2_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-6322658386 key: ozone-test-0260461918/multipartKey3. Provided Part info is { etag2, 2}, whereas OM has partName /s3v/bucket-ozone-test-6322658386/ozone-test-0260461918/multipartKey3-af1c271f-1abf-46c7-b20c-eda35dade449-108623243811946532-2
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:512)
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:198)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm1.org_1   | 2022-07-10 13:09:12,561 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
scm1.org_1   | 2022-07-10 13:09:12,569 [pool-16-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/f578972c-97f6-4a12-a46c-8eeea6081008/in_use.lock acquired by nodename 7@scm1.org
scm1.org_1   | 2022-07-10 13:09:12,573 [pool-16-thread-1] INFO storage.RaftStorage: Read RaftStorageMetadata{term=1, votedFor=988d83fb-8298-4167-8ff5-9318a8e0d8d4} from /data/metadata/scm-ha/f578972c-97f6-4a12-a46c-8eeea6081008/current/raft-meta
scm1.org_1   | 2022-07-10 13:09:12,598 [pool-16-thread-1] INFO server.RaftServer$Division: 988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008: set configuration 0: [988d83fb-8298-4167-8ff5-9318a8e0d8d4|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm1.org_1   | 2022-07-10 13:09:12,599 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
scm1.org_1   | 2022-07-10 13:09:12,600 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
scm1.org_1   | 2022-07-10 13:09:12,606 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
scm1.org_1   | 2022-07-10 13:09:12,606 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2022-07-10 13:09:12,607 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
scm1.org_1   | 2022-07-10 13:09:12,665 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm1.org_1   | 2022-07-10 13:09:12,672 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
scm1.org_1   | 2022-07-10 13:09:12,672 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
scm1.org_1   | 2022-07-10 13:09:12,676 [pool-16-thread-1] INFO segmented.SegmentedRaftLogWorker: new 988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/f578972c-97f6-4a12-a46c-8eeea6081008
scm1.org_1   | 2022-07-10 13:09:12,677 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
scm1.org_1   | 2022-07-10 13:09:12,677 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
scm1.org_1   | 2022-07-10 13:09:12,678 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm1.org_1   | 2022-07-10 13:09:12,678 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
scm1.org_1   | 2022-07-10 13:09:12,678 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
scm1.org_1   | 2022-07-10 13:09:12,679 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
scm1.org_1   | 2022-07-10 13:09:12,679 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
scm1.org_1   | 2022-07-10 13:09:12,679 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
scm1.org_1   | 2022-07-10 13:09:12,687 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
scm1.org_1   | 2022-07-10 13:09:12,687 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
scm1.org_1   | 2022-07-10 13:09:12,687 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
scm1.org_1   | 2022-07-10 13:09:12,706 [pool-16-thread-1] INFO server.RaftServer$Division: 988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008: set configuration 0: [988d83fb-8298-4167-8ff5-9318a8e0d8d4|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm1.org_1   | 2022-07-10 13:09:12,707 [pool-16-thread-1] INFO segmented.LogSegment: Successfully read 1 entries from segment file /data/metadata/scm-ha/f578972c-97f6-4a12-a46c-8eeea6081008/current/log_inprogress_0
scm1.org_1   | 2022-07-10 13:09:12,709 [pool-16-thread-1] INFO segmented.SegmentedRaftLogWorker: 988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 0
scm1.org_1   | 2022-07-10 13:09:12,709 [pool-16-thread-1] INFO segmented.SegmentedRaftLogWorker: 988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
scm1.org_1   | 2022-07-10 13:09:12,755 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
scm1.org_1   | 2022-07-10 13:09:12,756 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
scm1.org_1   | 2022-07-10 13:09:12,757 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
scm1.org_1   | 2022-07-10 13:09:12,757 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
scm1.org_1   | 2022-07-10 13:09:12,759 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
scm1.org_1   | 2022-07-10 13:09:12,759 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
scm1.org_1   | 2022-07-10 13:09:12,821 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm1.org_1   | 2022-07-10 13:09:12,821 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
scm1.org_1   | 2022-07-10 13:09:12,822 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
scm1.org_1   | 2022-07-10 13:09:12,822 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
scm1.org_1   | 2022-07-10 13:09:12,823 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
scm1.org_1   | 2022-07-10 13:09:12,825 [main] INFO ha.SCMSnapshotProvider: Initializing SCM Snapshot Provider
scm1.org_1   | 2022-07-10 13:09:12,825 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
scm1.org_1   | 2022-07-10 13:09:12,825 [main] WARN ha.SCMHAUtils: SCM snapshot dir is not configured. Falling back to ozone.metadata.dirs config
scm1.org_1   | 2022-07-10 13:09:12,980 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
scm1.org_1   | 2022-07-10 13:09:13,155 [main] INFO reflections.Reflections: Reflections took 132 ms to scan 3 urls, producing 109 keys and 243 values 
scm1.org_1   | 2022-07-10 13:09:13,254 [main] INFO ha.SequenceIdGenerator: upgrade localId to 109611004723200000
scm1.org_1   | 2022-07-10 13:09:13,254 [main] INFO ha.SequenceIdGenerator: upgrade delTxnId to 0
scm1.org_1   | 2022-07-10 13:09:13,264 [main] INFO ha.SequenceIdGenerator: upgrade containerId to 0
scm1.org_1   | 2022-07-10 13:09:13,266 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
scm1.org_1   | 2022-07-10 13:09:13,321 [main] INFO node.SCMNodeManager: Entering startup safe mode.
scm1.org_1   | 2022-07-10 13:09:13,337 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
scm1.org_1   | 2022-07-10 13:09:13,348 [main] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
s3g_1        | Sleeping for 5 seconds
s3g_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
s3g_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
s3g_1        | 2022-07-10 13:08:51,629 [main] INFO security.UserGroupInformation: Login successful for user s3g/s3g@EXAMPLE.COM using keytab file s3g.keytab. Keytab auto renewal enabled : false
s3g_1        | 2022-07-10 13:08:51,630 [main] INFO s3.Gateway: S3Gateway login successful.
s3g_1        | 2022-07-10 13:08:52,052 [main] INFO http.BaseHttpServer: Starting Web-server for s3gateway at: http://0.0.0.0:9878
s3g_1        | 2022-07-10 13:08:52,053 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
s3g_1        | 2022-07-10 13:08:52,053 [main] INFO http.BaseHttpServer: HttpAuthType: ozone.s3g.http.auth.type = kerberos
s3g_1        | 2022-07-10 13:08:52,183 [main] INFO util.log: Logging initialized @6087ms to org.eclipse.jetty.util.log.Slf4jLog
s3g_1        | 2022-07-10 13:08:52,665 [main] INFO http.HttpRequestLog: Http request log for http.requests.s3gateway is not defined
s3g_1        | 2022-07-10 13:08:52,719 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
s3g_1        | 2022-07-10 13:08:52,736 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context s3gateway
s3g_1        | 2022-07-10 13:08:52,743 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
s3g_1        | 2022-07-10 13:08:52,744 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
s3g_1        | 2022-07-10 13:08:52,747 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.s3g.http.auth.kerberos.principal keytabKey: ozone.s3g.http.auth.kerberos.keytab
s3g_1        | 2022-07-10 13:08:53,139 [main] INFO s3.Gateway: STARTUP_MSG: 
s3g_1        | /************************************************************
s3g_1        | STARTUP_MSG: Starting Gateway
s3g_1        | STARTUP_MSG:   host = s3g/172.25.0.114
s3g_1        | STARTUP_MSG:   args = []
s3g_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
s3g_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/hk2-utils-2.5.0.jar:/opt/hadoop/share/ozone/lib/jakarta.inject-2.6.1.jar:/opt/hadoop/share/ozone/lib/hk2-locator-2.6.1.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/aopalliance-repackaged-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.interceptor-api-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.44.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.44.0.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/javax.el-api-3.0.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jakarta.ws.rs-api-2.1.6.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jackson-dataformat-xml-2.13.2.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.23.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-module-jaxb-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-core-2.33.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jakarta.xml.bind-api-2.3.3.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.44.0.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.19.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/cdi-api-1.2.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hk2-api-2.5.0.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/javax.inject-1.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/jakarta.validation-api-2.0.2.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.44.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-client-2.33.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.44.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jersey-hk2-2.33.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jersey-media-jaxb-2.33.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jakarta.annotation-api-1.3.5.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jersey-server-2.33.jar:/opt/hadoop/share/ozone/lib/jersey-cdi1x-2.33.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/osgi-resource-locator-1.0.3.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.44.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.44.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/jersey-common-2.33.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/weld-servlet-2.4.7.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-2.0.48.Final.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-s3gateway-1.3.0-SNAPSHOT.jar
s3g_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/d088d199bf506d76f7046a4b19b690e2a9e6915e ; compiled by 'runner' on 2022-07-10T12:46Z
s3g_1        | STARTUP_MSG:   java = 11.0.14.1
s3g_1        | ************************************************************/
s3g_1        | 2022-07-10 13:08:53,171 [main] INFO s3.Gateway: registered UNIX signal handlers for [TERM, HUP, INT]
s3g_1        | 2022-07-10 13:08:53,262 [main] INFO s3.Gateway: Starting Ozone S3 gateway
s3g_1        | 2022-07-10 13:08:53,542 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
s3g_1        | 2022-07-10 13:08:54,027 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
s3g_1        | 2022-07-10 13:08:54,027 [main] INFO impl.MetricsSystemImpl: S3Gateway metrics system started
s3g_1        | 2022-07-10 13:08:54,133 [main] INFO http.HttpServer2: Jetty bound to port 9878
s3g_1        | 2022-07-10 13:08:54,135 [main] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
s3g_1        | 2022-07-10 13:08:54,245 [main] INFO server.session: DefaultSessionIdManager workerName=node0
s3g_1        | 2022-07-10 13:08:54,245 [main] INFO server.session: No SessionScavenger set, using defaults
s3g_1        | 2022-07-10 13:08:54,256 [main] INFO server.session: node0 Scavenging every 600000ms
s3g_1        | 2022-07-10 13:08:54,336 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/s3g@EXAMPLE.COM
s3g_1        | 2022-07-10 13:08:54,403 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6a1d204a{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
s3g_1        | 2022-07-10 13:08:54,407 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@72ccd81a{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-s3gateway-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
s3g_1        | WARNING: An illegal reflective access operation has occurred
s3g_1        | WARNING: Illegal reflective access by org.jboss.weld.util.reflection.Formats (file:/opt/hadoop/share/ozone/lib/weld-servlet-2.4.7.Final.jar) to constructor com.sun.org.apache.bcel.internal.classfile.ClassParser(java.io.InputStream,java.lang.String)
s3g_1        | WARNING: Please consider reporting this to the maintainers of org.jboss.weld.util.reflection.Formats
s3g_1        | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
s3g_1        | WARNING: All illegal access operations will be denied in a future release
s3g_1        | 2022-07-10 13:08:59,760 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/s3g@EXAMPLE.COM
s3g_1        | Jul 10, 2022 1:09:01 PM org.glassfish.jersey.internal.Errors logErrors
scm1.org_1   | 2022-07-10 13:09:13,418 [main] INFO algorithms.LeaderChoosePolicyFactory: Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
scm1.org_1   | 2022-07-10 13:09:13,419 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
scm1.org_1   | 2022-07-10 13:09:13,425 [main] INFO pipeline.BackgroundPipelineCreator: Starting RatisPipelineUtilsThread.
scm1.org_1   | 2022-07-10 13:09:13,428 [main] INFO BackgroundPipelineScrubber: Starting BackgroundPipelineScrubber Service.
scm1.org_1   | 2022-07-10 13:09:13,429 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineCreator.
scm1.org_1   | 2022-07-10 13:09:13,429 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineScrubber.
scm1.org_1   | 2022-07-10 13:09:13,435 [main] INFO ExpiredContainerReplicaOpScrubber: Starting ExpiredContainerReplicaOpScrubber Service.
scm1.org_1   | 2022-07-10 13:09:13,439 [main] INFO ha.SCMServiceManager: Registering service ExpiredContainerReplicaOpScrubber.
scm1.org_1   | 2022-07-10 13:09:13,466 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
scm1.org_1   | 2022-07-10 13:09:13,483 [main] INFO ha.SCMServiceManager: Registering service SCMBlockDeletingService.
scm1.org_1   | 2022-07-10 13:09:13,516 [main] INFO replication.ReplicationManager: Starting Replication Monitor Thread.
scm1.org_1   | 2022-07-10 13:09:13,531 [main] INFO ha.SCMServiceManager: Registering service ReplicationManager.
scm1.org_1   | 2022-07-10 13:09:13,540 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm1.org_1   | 2022-07-10 13:09:13,540 [main] INFO safemode.ContainerSafeModeRule: containers with one replica threshold count 0
scm1.org_1   | 2022-07-10 13:09:13,543 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-07-10 13:09:13,545 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm1.org_1   | 2022-07-10 13:09:13,579 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
scm1.org_1   | 2022-07-10 13:09:13,595 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
scm1.org_1   | 2022-07-10 13:09:13,596 [main] INFO server.StorageContainerManager: Storing sub-ca certificate serialId 844577728582 on primary SCM
scm1.org_1   | 2022-07-10 13:09:13,600 [main] INFO server.StorageContainerManager: Storing root certificate serialId 1
scm1.org_1   | 2022-07-10 13:09:13,628 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 200, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm1.org_1   | 2022-07-10 13:09:13,666 [Socket Reader #1 for port 9961] INFO ipc.Server: Starting Socket Reader #1 for port 9961
scm1.org_1   | 2022-07-10 13:09:14,376 [Listener at 0.0.0.0/9961] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm1.org_1   | 2022-07-10 13:09:14,384 [Listener at 0.0.0.0/9961] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm1.org_1   | 2022-07-10 13:09:14,385 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
scm1.org_1   | 2022-07-10 13:09:14,439 [Listener at 0.0.0.0/9861] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm1.org_1   | 2022-07-10 13:09:14,449 [Listener at 0.0.0.0/9861] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm1.org_1   | 2022-07-10 13:09:14,453 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
scm1.org_1   | 2022-07-10 13:09:14,520 [Listener at 0.0.0.0/9863] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm1.org_1   | 2022-07-10 13:09:14,529 [Listener at 0.0.0.0/9863] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm1.org_1   | 2022-07-10 13:09:14,530 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
scm1.org_1   | 2022-07-10 13:09:14,640 [Listener at 0.0.0.0/9860] INFO ha.SCMServiceManager: Registering service ContainerBalancer.
scm1.org_1   | 2022-07-10 13:09:14,644 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: 
scm1.org_1   | Container Balancer status:
scm1.org_1   | Key                            Value
scm1.org_1   | Running                        false
scm1.org_1   | Container Balancer Configuration values:
scm1.org_1   | Key                                                Value
scm1.org_1   | Threshold                                          10
scm1.org_1   | Max Datanodes to Involve per Iteration(percent)    20
scm1.org_1   | Max Size to Move per Iteration                     500GB
scm1.org_1   | Max Size Entering Target per Iteration             26GB
scm1.org_1   | Max Size Leaving Source per Iteration              26GB
scm1.org_1   | 
scm1.org_1   | 2022-07-10 13:09:14,644 [Listener at 0.0.0.0/9860] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm1.org_1   | 2022-07-10 13:09:14,651 [Listener at 0.0.0.0/9860] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
scm1.org_1   | 2022-07-10 13:09:14,654 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
scm1.org_1   | 2022-07-10 13:09:14,655 [Listener at 0.0.0.0/9860] INFO ha.SCMRatisServerImpl: starting ratis server 0.0.0.0:9894
scm1.org_1   | 2022-07-10 13:09:14,662 [988d83fb-8298-4167-8ff5-9318a8e0d8d4-impl-thread1] INFO server.RaftServer$Division: 988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008: start as a follower, conf=0: [988d83fb-8298-4167-8ff5-9318a8e0d8d4|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm1.org_1   | 2022-07-10 13:09:14,663 [988d83fb-8298-4167-8ff5-9318a8e0d8d4-impl-thread1] INFO server.RaftServer$Division: 988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008: changes role from      null to FOLLOWER at term 1 for startAsFollower
scm1.org_1   | 2022-07-10 13:09:14,664 [988d83fb-8298-4167-8ff5-9318a8e0d8d4-impl-thread1] INFO impl.RoleInfo: 988d83fb-8298-4167-8ff5-9318a8e0d8d4: start 988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-FollowerState
scm1.org_1   | 2022-07-10 13:09:14,674 [988d83fb-8298-4167-8ff5-9318a8e0d8d4-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-8EEEA6081008,id=988d83fb-8298-4167-8ff5-9318a8e0d8d4
scm1.org_1   | 2022-07-10 13:09:14,677 [Listener at 0.0.0.0/9860] INFO server.RaftServer: 988d83fb-8298-4167-8ff5-9318a8e0d8d4: start RPC server
scm1.org_1   | 2022-07-10 13:09:14,765 [Listener at 0.0.0.0/9860] INFO server.GrpcService: 988d83fb-8298-4167-8ff5-9318a8e0d8d4: GrpcService started, listening on 9894
scm1.org_1   | 2022-07-10 13:09:14,772 [Listener at 0.0.0.0/9860] INFO ha.SCMHAManagerImpl:  scm role is FOLLOWER peers [988d83fb-8298-4167-8ff5-9318a8e0d8d4|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0]
scm1.org_1   | 2022-07-10 13:09:14,772 [Listener at 0.0.0.0/9860] INFO ha.InterSCMGrpcService: Starting SCM Grpc Service at port 9895
scm1.org_1   | 2022-07-10 13:09:14,773 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$480/0x000000084055f040@365fde74] INFO util.JvmPauseMonitor: JvmPauseMonitor-988d83fb-8298-4167-8ff5-9318a8e0d8d4: Started
om2_1        | 2022-07-10 13:19:31,394 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:31,397 [IPC Server handler 61 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:31,400 [IPC Server handler 26 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:31,410 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: PartNumber at index 1 is 2, and its previous partNumber at index 0 is 4 for ozonekey is /s3v/bucket-ozone-test-6322658386/ozone-test-0260461918/multipartKey3
om2_1        | 2022-07-10 13:19:31,411 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-0260461918/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-6322658386
om2_1        | INVALID_PART_ORDER org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-6322658386 key: ozone-test-0260461918/multipartKey3 because parts are in Invalid order.
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getPartsListSize(S3MultipartUploadCompleteRequest.java:478)
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:194)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-07-10 13:19:32,048 [IPC Server handler 37 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:32,050 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:32,053 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:32,698 [IPC Server handler 83 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:32,702 [IPC Server handler 54 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:32,704 [IPC Server handler 67 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:32,756 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:33,648 [IPC Server handler 71 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:33,653 [IPC Server handler 96 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:33,660 [IPC Server handler 83 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:34,321 [IPC Server handler 85 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:34,324 [IPC Server handler 72 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:34,330 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:34,977 [IPC Server handler 82 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:34,980 [IPC Server handler 77 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:34,983 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:34,991 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadAbortRequest: Abort Multipart request is failed for KeyName ozone-test-9861106675/multipartKey5 in VolumeName/Bucket s3v/bucket-ozone-test-6322658386
om2_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Abort Multipart Upload Failed: volume: s3vbucket: bucket-ozone-test-6322658386key: ozone-test-9861106675/multipartKey5
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadAbortRequest.validateAndUpdateCache(S3MultipartUploadAbortRequest.java:161)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-07-10 13:19:35,635 [IPC Server handler 71 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:35,638 [IPC Server handler 96 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:35,642 [IPC Server handler 83 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:35,656 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyCreateRequest: Key creation failed. Volume:s3v, Bucket:bucket-ozone-test-6322658386, Key:ozone-test-5974425549/multipartKey. 
om2_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: No such Multipart upload is with specified uploadId random
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareMultipartFileInfo(OMKeyRequest.java:758)
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareFileInfo(OMKeyRequest.java:645)
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareKeyInfo(OMKeyRequest.java:622)
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyCreateRequest.validateAndUpdateCache(OMKeyCreateRequest.java:282)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
recon_1      | 2022-07-10 13:10:18,054 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 29 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-07-10 13:10:20,056 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 30 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:10:20,058 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 31 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:10:20,062 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 32 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-07-10 13:10:22,068 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 33 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:10:22,069 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 34 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:10:22,070 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 35 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-07-10 13:10:24,072 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 36 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:10:24,073 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 37 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:10:24,073 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 38 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-07-10 13:10:26,075 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 39 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:10:26,076 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 40 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:10:26,077 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 41 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-07-10 13:10:28,084 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 42 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:10:28,085 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 43 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:10:28,088 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 44 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-07-10 13:10:30,089 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 45 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:10:30,090 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 46 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:10:30,091 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 47 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-07-10 13:10:32,093 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 48 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:10:32,094 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 49 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:10:32,095 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 50 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-07-10 13:10:34,108 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 51 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:10:34,110 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 52 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:10:34,110 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 53 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-07-10 13:10:36,116 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 54 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:10:36,117 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 55 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:10:36,118 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 56 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-07-10 13:10:38,119 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 57 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:10:38,121 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 58 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:10:38,121 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 59 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-07-10 13:10:40,123 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 60 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:10:40,125 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 61 failover attempts. Trying to failover immediately.
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-07-10 13:19:36,310 [IPC Server handler 45 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:36,314 [IPC Server handler 85 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:36,317 [IPC Server handler 72 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:37,078 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:37,081 [IPC Server handler 81 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:37,085 [IPC Server handler 20 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:37,101 [IPC Server handler 5 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:37,456 [IPC Server handler 75 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:38,141 [IPC Server handler 6 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:38,144 [IPC Server handler 2 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:38,147 [IPC Server handler 39 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:38,165 [IPC Server handler 9 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:38,267 [IPC Server handler 78 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:38,934 [IPC Server handler 53 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:38,937 [IPC Server handler 80 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:38,945 [IPC Server handler 82 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:39,767 [IPC Server handler 58 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:39,770 [IPC Server handler 0 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:39,773 [IPC Server handler 50 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:40,445 [IPC Server handler 70 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:40,448 [IPC Server handler 75 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:40,450 [IPC Server handler 60 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:41,093 [IPC Server handler 87 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:41,096 [IPC Server handler 79 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:41,102 [IPC Server handler 20 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:42,076 [IPC Server handler 3 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:42,080 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:42,083 [IPC Server handler 81 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:42,179 [IPC Server handler 9 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:42,182 [IPC Server handler 10 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:42,184 [IPC Server handler 69 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:42,196 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:42,231 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:42,264 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:37749
om2_1        | 2022-07-10 13:19:42,266 [IPC Server handler 78 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:42,272 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:19:42,275 [IPC Server handler 56 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:42,315 [IPC Server handler 85 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:42,367 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:42,411 [IPC Server handler 61 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:42,423 [IPC Server handler 70 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
scm1.org_1   | 2022-07-10 13:09:14,774 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Starting token manager
scm1.org_1   | 2022-07-10 13:09:14,774 [Listener at 0.0.0.0/9860] INFO token.ContainerTokenSecretManager: Updating the current master key for generating tokens
scm1.org_1   | 2022-07-10 13:09:14,851 [Listener at 0.0.0.0/9860] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
scm1.org_1   | 2022-07-10 13:09:14,861 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
scm1.org_1   | 2022-07-10 13:09:14,862 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
scm1.org_1   | 2022-07-10 13:09:15,094 [Listener at 0.0.0.0/9860] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
scm1.org_1   | 2022-07-10 13:09:15,094 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm1.org_1   | 2022-07-10 13:09:15,095 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
scm1.org_1   | 2022-07-10 13:09:15,206 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
scm1.org_1   | 2022-07-10 13:09:15,225 [Listener at 0.0.0.0/9860] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
scm1.org_1   | 2022-07-10 13:09:15,231 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm1.org_1   | 2022-07-10 13:09:15,439 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
scm1.org_1   | 2022-07-10 13:09:15,496 [Listener at 0.0.0.0/9860] INFO server.SCMSecurityProtocolServer: Starting RPC server for SCMSecurityProtocolServer. is listening at /0.0.0.0:9961
scm1.org_1   | 2022-07-10 13:09:15,503 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm1.org_1   | 2022-07-10 13:09:15,507 [IPC Server listener on 9961] INFO ipc.Server: IPC Server listener on 9961: starting
scm1.org_1   | 2022-07-10 13:09:15,508 [Listener at 0.0.0.0/9860] INFO server.SCMUpdateServiceGrpcServer: SCMUpdateService starting
scm1.org_1   | 2022-07-10 13:09:15,563 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47704
scm1.org_1   | 2022-07-10 13:09:15,605 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@49de2cc4] INFO util.JvmPauseMonitor: Starting JVM pause monitor
scm1.org_1   | 2022-07-10 13:09:15,606 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-07-10 13:09:15,636 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
scm1.org_1   | 2022-07-10 13:09:15,637 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
scm1.org_1   | 2022-07-10 13:09:15,642 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HttpAuthType: hdds.scm.http.auth.type = kerberos
scm1.org_1   | 2022-07-10 13:09:15,688 [Listener at 0.0.0.0/9860] INFO util.log: Logging initialized @6392ms to org.eclipse.jetty.util.log.Slf4jLog
scm1.org_1   | 2022-07-10 13:09:15,930 [Listener at 0.0.0.0/9860] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
scm1.org_1   | 2022-07-10 13:09:15,936 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
scm1.org_1   | 2022-07-10 13:09:15,938 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context scm
scm1.org_1   | 2022-07-10 13:09:15,938 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
scm1.org_1   | 2022-07-10 13:09:15,938 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
scm1.org_1   | 2022-07-10 13:09:15,940 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.scm.http.auth.kerberos.principal keytabKey: hdds.scm.http.auth.kerberos.keytab
scm1.org_1   | 2022-07-10 13:09:15,969 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Jetty bound to port 9876
scm1.org_1   | 2022-07-10 13:09:15,970 [Listener at 0.0.0.0/9860] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
scm1.org_1   | 2022-07-10 13:09:16,006 [Listener at 0.0.0.0/9860] INFO server.session: DefaultSessionIdManager workerName=node0
scm1.org_1   | 2022-07-10 13:09:16,006 [Listener at 0.0.0.0/9860] INFO server.session: No SessionScavenger set, using defaults
scm1.org_1   | 2022-07-10 13:09:16,007 [Listener at 0.0.0.0/9860] INFO server.session: node0 Scavenging every 660000ms
scm1.org_1   | 2022-07-10 13:09:16,021 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm1.org_1   | 2022-07-10 13:09:16,024 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1cda3a6d{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
scm1.org_1   | 2022-07-10 13:09:16,024 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5ded2dfc{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
scm1.org_1   | 2022-07-10 13:09:16,131 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm1.org_1   | 2022-07-10 13:09:16,148 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@652cb87d{scm,/,file:///tmp/jetty-0_0_0_0-9876-hdds-server-scm-1_3_0-SNAPSHOT_jar-_-any-9262536617474967132/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar!/webapps/scm}
scm1.org_1   | 2022-07-10 13:09:16,156 [Listener at 0.0.0.0/9860] INFO server.AbstractConnector: Started ServerConnector@419ac0f5{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
scm1.org_1   | 2022-07-10 13:09:16,156 [Listener at 0.0.0.0/9860] INFO server.Server: Started @6860ms
scm1.org_1   | 2022-07-10 13:09:16,159 [Listener at 0.0.0.0/9860] INFO impl.MetricsSinkAdapter: Sink prometheus started
scm1.org_1   | 2022-07-10 13:09:16,159 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Registered sink prometheus
scm1.org_1   | 2022-07-10 13:09:16,161 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
scm1.org_1   | 2022-07-10 13:09:16,876 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:45617
scm1.org_1   | 2022-07-10 13:09:16,901 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-07-10 13:09:16,962 [IPC Server handler 0 on default port 9961] INFO ipc.Server: IPC Server handler 0 on default port 9961, call Call#0 Retry#9 org.apache.hadoop.hdds.protocol.SCMSecurityProtocol.submitRequest from 172.25.0.115:45617
scm1.org_1   | org.apache.hadoop.hdds.ratis.ServerNotLeaderException: Server:988d83fb-8298-4167-8ff5-9318a8e0d8d4 is not the leader. Could not determine the leader node.
scm1.org_1   | 	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
om2_1        | 2022-07-10 13:19:42,480 [IPC Server handler 55 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:43,333 [IPC Server handler 72 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:43,569 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:43,681 [IPC Server handler 54 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:43,758 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:43,761 [IPC Server handler 58 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:43,764 [IPC Server handler 0 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:44,534 [IPC Server handler 57 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:44,538 [IPC Server handler 55 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:44,540 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:44,560 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:44,567 [IPC Server handler 49 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:44,569 [IPC Server handler 71 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:44,578 [IPC Server handler 96 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:44,581 [IPC Server handler 54 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:44,582 [IPC Server handler 83 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:44,584 [IPC Server handler 67 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:44,585 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:44,592 [IPC Server handler 58 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:44,671 [IPC Server handler 50 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:44,681 [IPC Server handler 99 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:44,689 [IPC Server handler 0 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:46,193 [IPC Server handler 69 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:46,196 [IPC Server handler 98 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:46,198 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:46,218 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:47,083 [IPC Server handler 88 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:47,088 [IPC Server handler 1 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:47,091 [IPC Server handler 7 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:47,463 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:48,204 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:48,212 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:48,216 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:48,976 [IPC Server handler 77 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:48,979 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:48,984 [IPC Server handler 37 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:49,006 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:49,009 [IPC Server handler 43 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:49,019 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:49,033 [IPC Server handler 63 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:49,036 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:49,039 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:49,100 [IPC Server handler 81 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:49,581 [IPC Server handler 83 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:50,374 [IPC Server handler 26 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
recon_1      | 2022-07-10 13:10:40,127 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 62 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-07-10 13:10:42,129 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 63 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:10:42,132 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 64 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:10:42,134 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 65 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-07-10 13:10:44,135 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 66 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:10:44,137 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 67 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:10:44,138 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 68 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-07-10 13:10:46,139 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 69 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:10:46,140 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 70 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:10:46,141 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 71 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-07-10 13:10:48,142 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 72 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:10:48,145 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 73 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:10:48,145 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 74 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-07-10 13:10:50,147 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 75 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:10:50,148 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 76 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:10:50,148 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 77 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-07-10 13:10:52,152 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 78 failover attempts. Trying to failover immediately.
om2_1        | 2022-07-10 13:19:50,381 [IPC Server handler 61 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:50,384 [IPC Server handler 70 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:51,019 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:51,022 [IPC Server handler 63 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:51,024 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:51,037 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:52,020 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:52,023 [IPC Server handler 63 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:52,033 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:52,579 [IPC Server handler 96 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:53,273 [IPC Server handler 97 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:53,276 [IPC Server handler 56 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:53,278 [IPC Server handler 45 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:53,973 [IPC Server handler 77 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:53,975 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:53,977 [IPC Server handler 37 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:54,000 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:54,003 [IPC Server handler 43 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:54,006 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:54,017 [IPC Server handler 63 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:54,019 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:54,021 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:54,066 [IPC Server handler 3 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:54,758 [IPC Server handler 31 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:55,514 [IPC Server handler 57 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:55,517 [IPC Server handler 55 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:55,520 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:55,540 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:55,549 [IPC Server handler 49 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:55,552 [IPC Server handler 54 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:55,561 [IPC Server handler 67 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:55,564 [IPC Server handler 83 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:55,565 [IPC Server handler 96 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:55,596 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:55,695 [IPC Server handler 50 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:56,452 [IPC Server handler 60 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:56,454 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:56,456 [IPC Server handler 57 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:57,097 [IPC Server handler 79 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:57,102 [IPC Server handler 20 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:57,104 [IPC Server handler 7 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:57,115 [IPC Server handler 81 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:58,332 [IPC Server handler 72 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:58,335 [IPC Server handler 85 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:58,339 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
scm2.org_1   | Sleeping for 5 seconds
scm2.org_1   | Waiting for the service scm1.org:9894
scm2.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm2.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm2.org_1   | 2022-07-10 13:09:04,533 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm2.org_1   | /************************************************************
scm2.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm2.org_1   | STARTUP_MSG:   host = scm2.org/172.25.0.117
scm2.org_1   | STARTUP_MSG:   args = [--bootstrap]
scm2.org_1   | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
s3g_1        | WARNING: The following warnings have been detected: WARNING: A HTTP GET method, public javax.ws.rs.core.Response org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.get(java.lang.String,java.lang.String,java.lang.String,int,java.lang.String,java.io.InputStream) throws java.io.IOException,org.apache.hadoop.ozone.s3.exception.OS3Exception, should not consume any entity.
s3g_1        | 
s3g_1        | 2022-07-10 13:09:01,938 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@5fa5c8cf{s3gateway,/,file:///tmp/jetty-0_0_0_0-9878-ozone-s3gateway-1_3_0-SNAPSHOT_jar-_-any-16706942509156971342/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-s3gateway-1.3.0-SNAPSHOT.jar!/webapps/s3gateway}
s3g_1        | 2022-07-10 13:09:01,961 [main] INFO server.AbstractConnector: Started ServerConnector@2f2bf0e2{HTTP/1.1, (http/1.1)}{0.0.0.0:9878}
s3g_1        | 2022-07-10 13:09:01,962 [main] INFO server.Server: Started @15867ms
s3g_1        | 2022-07-10 13:09:01,970 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
s3g_1        | 2022-07-10 13:09:01,970 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
s3g_1        | 2022-07-10 13:09:01,972 [main] INFO http.BaseHttpServer: HTTP server of s3gateway listening at http://0.0.0.0:9878
s3g_1        | 2022-07-10 13:17:40,630 [qtp1157943921-21] INFO audit.AuditLogger: Refresh DebugCmdSet for S3GAudit to [].
s3g_1        | 2022-07-10 13:17:40,665 [qtp1157943921-21] INFO ozone.OmUtils: Using OzoneManager ServiceID 'id1'.
s3g_1        | 2022-07-10 13:17:42,683 [qtp1157943921-21] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-1544450475, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-07-10 13:17:42,719 [qtp1157943921-21] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-1544450475
s3g_1        | 2022-07-10 13:17:50,108 [qtp1157943921-22] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-9384658644, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-07-10 13:17:50,123 [qtp1157943921-22] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-9384658644
s3g_1        | 2022-07-10 13:17:51,128 [qtp1157943921-22] WARN impl.MetricsSystemImpl: S3Gateway metrics system already initialized!
s3g_1        | 2022-07-10 13:17:51,523 [qtp1157943921-22] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
s3g_1        | 2022-07-10 13:18:04,747 [qtp1157943921-22] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-3047552415, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-07-10 13:18:04,771 [qtp1157943921-22] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-3047552415
s3g_1        | 2022-07-10 13:18:05,337 [qtp1157943921-23] INFO rpc.RpcClient: Creating Bucket: s3v/ozone-test-uabmkkyzze, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-07-10 13:18:05,357 [qtp1157943921-23] INFO endpoint.BucketEndpoint: Location is /ozone-test-uabmkkyzze
s3g_1        | 2022-07-10 13:18:09,258 [qtp1157943921-20] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-qfntsnazxv, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-07-10 13:18:09,303 [qtp1157943921-20] INFO endpoint.BucketEndpoint: Location is /bucket-qfntsnazxv
s3g_1        | 2022-07-10 13:18:20,527 [qtp1157943921-21] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-2810480406, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-07-10 13:18:20,538 [qtp1157943921-21] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-2810480406
s3g_1        | 2022-07-10 13:18:21,173 [qtp1157943921-20] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-8869007246, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-07-10 13:18:21,191 [qtp1157943921-20] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-8869007246
s3g_1        | 2022-07-10 13:18:21,833 [qtp1157943921-21] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-6024978753, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-07-10 13:18:21,857 [qtp1157943921-21] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-6024978753
s3g_1        | 2022-07-10 13:18:22,489 [qtp1157943921-21] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-6024978753, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-07-10 13:18:22,512 [qtp1157943921-21] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-6024978753
s3g_1        | 2022-07-10 13:18:24,104 [qtp1157943921-21] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-1090355142, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-07-10 13:18:24,120 [qtp1157943921-21] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-1090355142
s3g_1        | 2022-07-10 13:18:35,919 [qtp1157943921-24] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-7979361343, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-07-10 13:18:35,932 [qtp1157943921-24] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-7979361343
s3g_1        | 2022-07-10 13:18:36,571 [qtp1157943921-21] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-9923649996, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-07-10 13:18:36,589 [qtp1157943921-21] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-9923649996
s3g_1        | 2022-07-10 13:18:45,146 [qtp1157943921-24] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-9508592014, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-07-10 13:18:45,162 [qtp1157943921-24] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-9508592014
s3g_1        | 2022-07-10 13:18:53,292 [qtp1157943921-21] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-6075713174, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-07-10 13:18:53,307 [qtp1157943921-21] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-6075713174
s3g_1        | 2022-07-10 13:18:59,860 [qtp1157943921-21] ERROR signature.AuthorizationV4HeaderParser: AWS access id shouldn't be empty. credential:/20220710/us-west-1/s3/aws4_request
s3g_1        | Jul 10, 2022 1:18:59 PM org.glassfish.jersey.internal.Errors logErrors
s3g_1        | WARNING: The following warnings have been detected: WARNING: Unknown HK2 failure detected:
s3g_1        | MultiException stack 1 of 1
s3g_1        | javax.ws.rs.WebApplicationException: The authorization header you provided is invalid.
s3g_1        | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.wrapOS3Exception(OzoneClientProducer.java:141)
s3g_1        | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getSignature(OzoneClientProducer.java:102)
s3g_1        | 	at jdk.internal.reflect.GeneratedMethodAccessor19.invoke(Unknown Source)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:93)
scm1.org_1   | 	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:16080)
scm1.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
scm1.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
scm1.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
scm1.org_1   | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
scm1.org_1   | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm1.org_1   | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm1.org_1   | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
scm1.org_1   | 2022-07-10 13:09:17,176 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:41104
scm1.org_1   | 2022-07-10 13:09:17,193 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-07-10 13:09:19,705 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-FollowerState] INFO impl.FollowerState: 988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5041582498ns, electionTimeout:5027ms
scm1.org_1   | 2022-07-10 13:09:19,706 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-FollowerState] INFO impl.RoleInfo: 988d83fb-8298-4167-8ff5-9318a8e0d8d4: shutdown 988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-FollowerState
scm1.org_1   | 2022-07-10 13:09:19,707 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-FollowerState] INFO server.RaftServer$Division: 988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
scm1.org_1   | 2022-07-10 13:09:19,710 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
scm1.org_1   | 2022-07-10 13:09:19,710 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-FollowerState] INFO impl.RoleInfo: 988d83fb-8298-4167-8ff5-9318a8e0d8d4: start 988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-LeaderElection1
scm1.org_1   | 2022-07-10 13:09:19,725 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-LeaderElection1] INFO impl.LeaderElection: 988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-LeaderElection1 ELECTION round 0: submit vote requests at term 2 for 0: [988d83fb-8298-4167-8ff5-9318a8e0d8d4|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm1.org_1   | 2022-07-10 13:09:19,726 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-LeaderElection1] INFO impl.LeaderElection: 988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-LeaderElection1 ELECTION round 0: result PASSED (term=2)
scm1.org_1   | 2022-07-10 13:09:19,726 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-LeaderElection1] INFO impl.RoleInfo: 988d83fb-8298-4167-8ff5-9318a8e0d8d4: shutdown 988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-LeaderElection1
scm1.org_1   | 2022-07-10 13:09:19,726 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-LeaderElection1] INFO server.RaftServer$Division: 988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
scm1.org_1   | 2022-07-10 13:09:19,726 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-LeaderElection1] INFO ha.SCMStateMachine: current SCM becomes leader of term 2.
scm1.org_1   | 2022-07-10 13:09:19,727 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-LeaderElection1] INFO ha.SCMContext: update <isLeader,term> from <false,0> to <true,2>
scm1.org_1   | 2022-07-10 13:09:19,728 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-LeaderElection1] INFO server.RaftServer$Division: 988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008: change Leader from null to 988d83fb-8298-4167-8ff5-9318a8e0d8d4 at term 2 for becomeLeader, leader elected after 7127ms
scm1.org_1   | 2022-07-10 13:09:19,734 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
scm1.org_1   | 2022-07-10 13:09:19,738 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
scm1.org_1   | 2022-07-10 13:09:19,738 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
scm1.org_1   | 2022-07-10 13:09:19,742 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
scm1.org_1   | 2022-07-10 13:09:19,743 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
scm1.org_1   | 2022-07-10 13:09:19,743 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
scm1.org_1   | 2022-07-10 13:09:19,747 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
scm1.org_1   | 2022-07-10 13:09:19,750 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
scm1.org_1   | 2022-07-10 13:09:19,752 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-LeaderElection1] INFO impl.RoleInfo: 988d83fb-8298-4167-8ff5-9318a8e0d8d4: start 988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-LeaderStateImpl
scm1.org_1   | 2022-07-10 13:09:19,758 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
scm1.org_1   | 2022-07-10 13:09:19,761 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/scm-ha/f578972c-97f6-4a12-a46c-8eeea6081008/current/log_inprogress_0 to /data/metadata/scm-ha/f578972c-97f6-4a12-a46c-8eeea6081008/current/log_0-0
scm1.org_1   | 2022-07-10 13:09:19,767 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-LeaderElection1] INFO server.RaftServer$Division: 988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008: set configuration 1: [988d83fb-8298-4167-8ff5-9318a8e0d8d4|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm1.org_1   | 2022-07-10 13:09:19,783 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/f578972c-97f6-4a12-a46c-8eeea6081008/current/log_inprogress_1
scm1.org_1   | 2022-07-10 13:09:19,788 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-StateMachineUpdater] INFO ha.SCMContext: update <isLeaderReady> from <false> to <true>
recon_1      | 2022-07-10 13:10:52,153 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 79 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:10:52,155 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 80 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-07-10 13:10:52,852 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47272
recon_1      | 2022-07-10 13:10:52,911 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-07-10 13:10:54,174 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 81 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:10:54,196 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 82 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:10:54,205 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 83 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-07-10 13:10:54,418 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:41956
recon_1      | 2022-07-10 13:10:54,456 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-07-10 13:10:56,206 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 84 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:10:56,207 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 85 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:10:56,208 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 86 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-07-10 13:10:56,826 [IPC Server handler 19 on default port 9891] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/a1e412ee-75aa-4bf8-87bc-4e8e615b1959
recon_1      | 2022-07-10 13:10:56,883 [IPC Server handler 82 on default port 9891] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/992f3c0d-344e-4060-87f0-890ffe8b867e
recon_1      | 2022-07-10 13:10:56,911 [IPC Server handler 19 on default port 9891] INFO node.SCMNodeManager: Registered Data node : a1e412ee-75aa-4bf8-87bc-4e8e615b1959{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886], networkLocation: /default-rack, certSerialId: 933456427477, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-07-10 13:10:56,895 [IPC Server handler 82 on default port 9891] INFO node.SCMNodeManager: Registered Data node : 992f3c0d-344e-4060-87f0-890ffe8b867e{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 933105602287, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-07-10 13:10:57,061 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node a1e412ee-75aa-4bf8-87bc-4e8e615b1959 to Node DB.
recon_1      | 2022-07-10 13:10:57,067 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node 992f3c0d-344e-4060-87f0-890ffe8b867e to Node DB.
recon_1      | 2022-07-10 13:10:58,148 [IPC Server handler 55 on default port 9891] INFO scm.ReconNodeManager: Sending ReregisterCommand() for ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net
recon_1      | 2022-07-10 13:10:58,156 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34742
recon_1      | 2022-07-10 13:10:58,213 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 87 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:10:58,215 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 88 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:10:58,219 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 89 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar
scm2.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/d088d199bf506d76f7046a4b19b690e2a9e6915e ; compiled by 'runner' on 2022-07-10T12:45Z
scm2.org_1   | STARTUP_MSG:   java = 11.0.14.1
scm2.org_1   | ************************************************************/
scm2.org_1   | 2022-07-10 13:09:04,546 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm2.org_1   | 2022-07-10 13:09:04,622 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm2.org_1   | 2022-07-10 13:09:04,653 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm2.org_1   | 2022-07-10 13:09:04,653 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm2.org_1   | 2022-07-10 13:09:04,683 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm2, RPC Address: scm2.org:9894 and Ratis port: 9894
scm2.org_1   | 2022-07-10 13:09:04,684 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm2: scm2.org
scm2.org_1   | 2022-07-10 13:09:04,815 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
scm2.org_1   | 2022-07-10 13:09:04,815 [main] INFO server.StorageContainerManager: SCM login successful.
scm2.org_1   | 2022-07-10 13:09:04,850 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 2 nodes: [nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
scm2.org_1   | 2022-07-10 13:09:07,047 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm3.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863 after 1 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2022-07-10 13:09:09,050 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm1.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863 after 2 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2022-07-10 13:09:11,051 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm3.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863 after 3 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2022-07-10 13:09:13,055 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm1.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863 after 4 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2022-07-10 13:09:15,059 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm3.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863 after 5 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2022-07-10 13:09:17,232 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:988d83fb-8298-4167-8ff5-9318a8e0d8d4 is not the leader. Could not determine the leader node.
scm2.org_1   | 	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
scm2.org_1   | 	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
scm2.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:109)
scm2.org_1   | 	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:14202)
scm2.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
scm2.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
scm2.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
scm2.org_1   | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
scm2.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
scm2.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
scm2.org_1   | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm2.org_1   | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm2.org_1   | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
scm2.org_1   | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
scm2.org_1   | , while invoking $Proxy15.send over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863 after 6 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2022-07-10 13:09:19,237 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm3.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863 after 7 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2022-07-10 13:09:21,412 [main] INFO ha.HASecurityUtils: Initializing secure StorageContainerManager.
scm1.org_1   | 2022-07-10 13:09:19,789 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-StateMachineUpdater] INFO pipeline.BackgroundPipelineCreator: Service BackgroundPipelineCreator transitions to RUNNING.
scm1.org_1   | 2022-07-10 13:09:19,791 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-07-10 13:09:19,792 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-StateMachineUpdater] INFO safemode.ContainerSafeModeRule: Refreshed one replica container threshold 0, currentThreshold 0
scm1.org_1   | 2022-07-10 13:09:19,793 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-StateMachineUpdater] INFO safemode.OneReplicaPipelineSafeModeRule: Refreshed Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm1.org_1   | 2022-07-10 13:09:19,793 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-StateMachineUpdater] INFO server.SCMDatanodeProtocolServer: ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:9861
scm1.org_1   | 2022-07-10 13:09:19,804 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm1.org_1   | 2022-07-10 13:09:19,806 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
scm1.org_1   | 2022-07-10 13:09:22,993 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:39762
scm1.org_1   | 2022-07-10 13:09:23,030 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-07-10 13:09:23,096 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for RECON recon, UUID: d02cf604-ba28-4b08-b071-c10b85e9b32e
scm1.org_1   | 2022-07-10 13:09:23,096 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for scm scm2.org, nodeId: 8b10ddc2-41d5-41cc-935f-57a9babc5d91
scm1.org_1   | 2022-07-10 13:09:23,568 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-07-10 13:09:23,568 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-StateMachineUpdater] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm1.org_1   | 2022-07-10 13:09:23,568 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-StateMachineUpdater] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm1.org_1   | 2022-07-10 13:09:24,563 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-07-10 13:09:35,589 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:48034
scm1.org_1   | 2022-07-10 13:09:35,659 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-07-10 13:09:40,007 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:34321
scm1.org_1   | 2022-07-10 13:09:40,019 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-07-10 13:09:41,635 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:41492
scm1.org_1   | 2022-07-10 13:09:41,748 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-07-10 13:09:41,751 [IPC Server handler 5 on default port 9863] INFO ha.SCMRatisServerImpl: 988d83fb-8298-4167-8ff5-9318a8e0d8d4: Submitting SetConfiguration request to Ratis server with new SCM peers list: [988d83fb-8298-4167-8ff5-9318a8e0d8d4|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 8b10ddc2-41d5-41cc-935f-57a9babc5d91|rpc:scm2.org:9894|priority:0]
scm1.org_1   | 2022-07-10 13:09:41,758 [IPC Server handler 5 on default port 9863] INFO server.RaftServer$Division: 988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008: receive setConfiguration SetConfigurationRequest:client-9EB0A70496C7->988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008, cid=1, seq=0, RW, null, peers:[988d83fb-8298-4167-8ff5-9318a8e0d8d4|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 8b10ddc2-41d5-41cc-935f-57a9babc5d91|rpc:scm2.org:9894|priority:0]
scm1.org_1   | 2022-07-10 13:09:41,759 [IPC Server handler 5 on default port 9863] INFO server.RaftServer$Division: 988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-LeaderStateImpl: startSetConfiguration SetConfigurationRequest:client-9EB0A70496C7->988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008, cid=1, seq=0, RW, null, peers:[988d83fb-8298-4167-8ff5-9318a8e0d8d4|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 8b10ddc2-41d5-41cc-935f-57a9babc5d91|rpc:scm2.org:9894|priority:0]
scm1.org_1   | 2022-07-10 13:09:41,809 [IPC Server handler 5 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
scm1.org_1   | 2022-07-10 13:09:41,812 [IPC Server handler 5 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2022-07-10 13:09:41,814 [IPC Server handler 5 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1024 (custom)
scm1.org_1   | 2022-07-10 13:09:41,848 [IPC Server handler 5 on default port 9863] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
scm1.org_1   | 2022-07-10 13:09:41,851 [IPC Server handler 5 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm1.org_1   | 2022-07-10 13:09:41,851 [IPC Server handler 5 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm1.org_1   | 2022-07-10 13:09:41,885 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008->8b10ddc2-41d5-41cc-935f-57a9babc5d91-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008->8b10ddc2-41d5-41cc-935f-57a9babc5d91-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:1, i:0)
scm1.org_1   | 2022-07-10 13:09:41,915 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008->8b10ddc2-41d5-41cc-935f-57a9babc5d91-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008->8b10ddc2-41d5-41cc-935f-57a9babc5d91-GrpcLogAppender: send 988d83fb-8298-4167-8ff5-9318a8e0d8d4->8b10ddc2-41d5-41cc-935f-57a9babc5d91#0-t2,notify:(t:1, i:0)
scm1.org_1   | 2022-07-10 13:09:42,917 [grpc-default-executor-0] INFO server.GrpcLogAppender: 988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008->8b10ddc2-41d5-41cc-935f-57a9babc5d91-InstallSnapshotResponseHandler: received the first reply 988d83fb-8298-4167-8ff5-9318a8e0d8d4<-8b10ddc2-41d5-41cc-935f-57a9babc5d91#0:FAIL-t0,ALREADY_INSTALLED
recon_1      | 2022-07-10 13:10:58,235 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-07-10 13:10:58,445 [IPC Server handler 59 on default port 9891] INFO scm.ReconNodeManager: Sending ReregisterCommand() for ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net
recon_1      | 2022-07-10 13:10:59,976 [IPC Server handler 82 on default port 9891] INFO scm.ReconNodeManager: Updating nodeDB for ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net
recon_1      | 2022-07-10 13:11:00,213 [IPC Server handler 49 on default port 9891] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/257634a0-3792-468a-a5a2-186b5a295fa1
recon_1      | 2022-07-10 13:11:00,213 [IPC Server handler 49 on default port 9891] INFO node.SCMNodeManager: Registered Data node : 257634a0-3792-468a-a5a2-186b5a295fa1{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 935900506483, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-07-10 13:11:00,214 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node 257634a0-3792-468a-a5a2-186b5a295fa1 to Node DB.
recon_1      | 2022-07-10 13:11:00,226 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 90 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:11:00,227 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 91 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:11:00,228 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 92 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-07-10 13:11:00,326 [IPC Server handler 56 on default port 9891] INFO scm.ReconNodeManager: Updating nodeDB for ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net
recon_1      | 2022-07-10 13:11:01,605 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=b77b6ac4-c103-4125-90f3-f25d482aaf22. Trying to get from SCM.
recon_1      | 2022-07-10 13:11:01,865 [IPC Server handler 82 on default port 9891] INFO scm.ReconNodeManager: Sending ReregisterCommand() for ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net
recon_1      | 2022-07-10 13:11:02,025 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: b77b6ac4-c103-4125-90f3-f25d482aaf22, Nodes: 992f3c0d-344e-4060-87f0-890ffe8b867e{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:992f3c0d-344e-4060-87f0-890ffe8b867e, CreationTimestamp2022-07-10T13:10:58.769Z[UTC]] to Recon pipeline metadata.
recon_1      | 2022-07-10 13:11:02,229 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 93 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:11:02,237 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 94 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:11:02,244 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 95 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-07-10 13:11:02,257 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: b77b6ac4-c103-4125-90f3-f25d482aaf22, Nodes: 992f3c0d-344e-4060-87f0-890ffe8b867e{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:992f3c0d-344e-4060-87f0-890ffe8b867e, CreationTimestamp2022-07-10T13:10:58.769Z[UTC]].
recon_1      | 2022-07-10 13:11:02,427 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=b1d72510-c7b3-4886-b6f1-097f02077230. Trying to get from SCM.
recon_1      | 2022-07-10 13:11:02,496 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: b1d72510-c7b3-4886-b6f1-097f02077230, Nodes: a1e412ee-75aa-4bf8-87bc-4e8e615b1959{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:a1e412ee-75aa-4bf8-87bc-4e8e615b1959, CreationTimestamp2022-07-10T13:10:59.707Z[UTC]] to Recon pipeline metadata.
recon_1      | 2022-07-10 13:11:02,497 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: b1d72510-c7b3-4886-b6f1-097f02077230, Nodes: a1e412ee-75aa-4bf8-87bc-4e8e615b1959{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:a1e412ee-75aa-4bf8-87bc-4e8e615b1959, CreationTimestamp2022-07-10T13:10:59.707Z[UTC]].
s3g_1        | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
s3g_1        | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
s3g_1        | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
s3g_1        | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
s3g_1        | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1        | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1        | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1        | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1        | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
s3g_1        | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
s3g_1        | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
s3g_1        | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
s3g_1        | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
s3g_1        | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
s3g_1        | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
s3g_1        | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
s3g_1        | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:874)
s3g_1        | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
s3g_1        | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1        | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1        | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1        | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1        | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
s3g_1        | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
s3g_1        | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
s3g_1        | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:127)
s3g_1        | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:69)
s3g_1        | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:103)
s3g_1        | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:46)
s3g_1        | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:53)
s3g_1        | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:129)
s3g_1        | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:463)
s3g_1        | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:46)
s3g_1        | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2102)
s3g_1        | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:758)
s3g_1        | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:721)
s3g_1        | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:691)
s3g_1        | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:160)
s3g_1        | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:30)
s3g_1        | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:105)
s3g_1        | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:260)
s3g_1        | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:51)
s3g_1        | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:86)
s3g_1        | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:89)
s3g_1        | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:89)
s3g_1        | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:89)
s3g_1        | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:69)
s3g_1        | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:38)
s3g_1        | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:173)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:247)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1678)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
recon_1      | 2022-07-10 13:11:02,498 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/ONE PipelineID=b1d72510-c7b3-4886-b6f1-097f02077230 reported by a1e412ee-75aa-4bf8-87bc-4e8e615b1959{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 933456427477, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-07-10 13:11:02,498 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: b1d72510-c7b3-4886-b6f1-097f02077230, Nodes: a1e412ee-75aa-4bf8-87bc-4e8e615b1959{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:a1e412ee-75aa-4bf8-87bc-4e8e615b1959, CreationTimestamp2022-07-10T13:10:59.707Z[UTC]] moved to OPEN state
recon_1      | 2022-07-10 13:11:03,453 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=199762fc-7613-447a-a2fc-b841d041c364. Trying to get from SCM.
recon_1      | 2022-07-10 13:11:03,463 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: 199762fc-7613-447a-a2fc-b841d041c364, Nodes: 257634a0-3792-468a-a5a2-186b5a295fa1{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}a1e412ee-75aa-4bf8-87bc-4e8e615b1959{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}992f3c0d-344e-4060-87f0-890ffe8b867e{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-07-10T13:11:02.344Z[UTC]] to Recon pipeline metadata.
recon_1      | 2022-07-10 13:11:03,465 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 199762fc-7613-447a-a2fc-b841d041c364, Nodes: 257634a0-3792-468a-a5a2-186b5a295fa1{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}a1e412ee-75aa-4bf8-87bc-4e8e615b1959{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}992f3c0d-344e-4060-87f0-890ffe8b867e{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-07-10T13:11:02.344Z[UTC]].
recon_1      | 2022-07-10 13:11:03,465 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=199762fc-7613-447a-a2fc-b841d041c364 reported by a1e412ee-75aa-4bf8-87bc-4e8e615b1959{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 933456427477, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-07-10 13:11:03,791 [IPC Server handler 55 on default port 9891] INFO scm.ReconNodeManager: Updating nodeDB for ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net
recon_1      | 2022-07-10 13:11:04,246 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 96 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:11:04,247 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 97 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:11:04,252 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 98 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-07-10 13:11:05,748 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=8d6e1a79-b70d-40e6-a234-6dc84a45f007. Trying to get from SCM.
recon_1      | 2022-07-10 13:11:05,757 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: 8d6e1a79-b70d-40e6-a234-6dc84a45f007, Nodes: 257634a0-3792-468a-a5a2-186b5a295fa1{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-07-10T13:11:01.880Z[UTC]] to Recon pipeline metadata.
recon_1      | 2022-07-10 13:11:05,759 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 8d6e1a79-b70d-40e6-a234-6dc84a45f007, Nodes: 257634a0-3792-468a-a5a2-186b5a295fa1{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-07-10T13:11:01.880Z[UTC]].
recon_1      | 2022-07-10 13:11:05,759 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/ONE PipelineID=8d6e1a79-b70d-40e6-a234-6dc84a45f007 reported by 257634a0-3792-468a-a5a2-186b5a295fa1{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 935900506483, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
om2_1        | 2022-07-10 13:19:58,747 [IPC Server handler 31 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:59,387 [IPC Server handler 70 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:59,393 [IPC Server handler 60 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:19:59,407 [IPC Server handler 75 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:00,092 [IPC Server handler 15 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:00,095 [IPC Server handler 87 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:00,097 [IPC Server handler 79 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:01,542 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:01,544 [IPC Server handler 49 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:01,546 [IPC Server handler 54 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:01,568 [IPC Server handler 96 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:01,573 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:01,577 [IPC Server handler 58 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:01,591 [IPC Server handler 71 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:02,240 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:02,245 [IPC Server handler 78 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:02,247 [IPC Server handler 97 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:02,260 [IPC Server handler 56 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:02,265 [IPC Server handler 45 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:02,271 [IPC Server handler 72 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:02,280 [IPC Server handler 85 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:02,923 [IPC Server handler 53 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:02,927 [IPC Server handler 80 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:02,942 [IPC Server handler 82 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:02,957 [IPC Server handler 77 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:02,962 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:02,966 [IPC Server handler 37 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:02,984 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:02,987 [IPC Server handler 43 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:02,989 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:03,038 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:03,576 [IPC Server handler 58 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:04,295 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:04,298 [IPC Server handler 26 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:04,300 [IPC Server handler 61 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:04,317 [IPC Server handler 70 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:04,320 [IPC Server handler 60 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:04,322 [IPC Server handler 75 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:04,341 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:04,344 [IPC Server handler 57 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:04,347 [IPC Server handler 55 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:04,380 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:04,498 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:05,393 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:05,396 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
scm1.org_1   | 2022-07-10 13:09:42,940 [grpc-default-executor-0] INFO server.GrpcLogAppender: 988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008->8b10ddc2-41d5-41cc-935f-57a9babc5d91-InstallSnapshotResponseHandler: Follower snapshot is already at index 0.
scm1.org_1   | 2022-07-10 13:09:42,967 [grpc-default-executor-0] INFO leader.FollowerInfo: 988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008->8b10ddc2-41d5-41cc-935f-57a9babc5d91: snapshotIndex: setUnconditionally 0 -> 0
scm1.org_1   | 2022-07-10 13:09:42,967 [grpc-default-executor-0] INFO leader.FollowerInfo: 988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008->8b10ddc2-41d5-41cc-935f-57a9babc5d91: matchIndex: setUnconditionally 0 -> 0
scm1.org_1   | 2022-07-10 13:09:42,967 [grpc-default-executor-0] INFO leader.FollowerInfo: 988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008->8b10ddc2-41d5-41cc-935f-57a9babc5d91: nextIndex: setUnconditionally 0 -> 1
scm1.org_1   | 2022-07-10 13:09:42,967 [grpc-default-executor-0] INFO leader.FollowerInfo: Follower 988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008->8b10ddc2-41d5-41cc-935f-57a9babc5d91 acknowledged installing snapshot
scm1.org_1   | 2022-07-10 13:09:42,968 [grpc-default-executor-0] INFO leader.FollowerInfo: 988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008->8b10ddc2-41d5-41cc-935f-57a9babc5d91: nextIndex: updateToMax old=1, new=1, updated? false
scm1.org_1   | 2022-07-10 13:09:43,039 [grpc-default-executor-0] INFO leader.FollowerInfo: 988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008->8b10ddc2-41d5-41cc-935f-57a9babc5d91: nextIndex: updateUnconditionally 7 -> 0
scm1.org_1   | 2022-07-10 13:09:43,043 [grpc-default-executor-0] INFO leader.FollowerInfo: 988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008->8b10ddc2-41d5-41cc-935f-57a9babc5d91: nextIndex: updateUnconditionally 7 -> 0
scm1.org_1   | 2022-07-10 13:09:43,470 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-LeaderStateImpl] INFO server.RaftServer$Division: 988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008: set configuration 7: [8b10ddc2-41d5-41cc-935f-57a9babc5d91|rpc:scm2.org:9894|priority:0, 988d83fb-8298-4167-8ff5-9318a8e0d8d4|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=[988d83fb-8298-4167-8ff5-9318a8e0d8d4|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0]
scm1.org_1   | 2022-07-10 13:09:43,650 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-LeaderStateImpl] INFO server.RaftServer$Division: 988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008: set configuration 9: [8b10ddc2-41d5-41cc-935f-57a9babc5d91|rpc:scm2.org:9894|priority:0, 988d83fb-8298-4167-8ff5-9318a8e0d8d4|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm1.org_1   | 2022-07-10 13:09:43,755 [IPC Server handler 5 on default port 9863] INFO ha.SCMRatisServerImpl: Successfully added new SCM: 8b10ddc2-41d5-41cc-935f-57a9babc5d91.
scm1.org_1   | 2022-07-10 13:09:45,967 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:40130
scm1.org_1   | 2022-07-10 13:09:45,993 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-07-10 13:09:46,611 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.118:33004
scm1.org_1   | 2022-07-10 13:09:46,664 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-07-10 13:09:49,214 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:48246
scm1.org_1   | 2022-07-10 13:09:49,251 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-07-10 13:09:50,013 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.118:43342
scm1.org_1   | 2022-07-10 13:09:50,027 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-07-10 13:09:50,028 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for scm scm3.org, nodeId: 6f9a84f7-8019-4c66-ba45-e86fba2381f6
scm1.org_1   | 2022-07-10 13:09:50,411 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-07-10 13:09:59,540 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:48394
scm1.org_1   | 2022-07-10 13:09:59,585 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-07-10 13:10:00,697 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.118:33204
scm1.org_1   | 2022-07-10 13:10:00,721 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-07-10 13:10:00,722 [IPC Server handler 2 on default port 9863] INFO ha.SCMRatisServerImpl: 988d83fb-8298-4167-8ff5-9318a8e0d8d4: Submitting SetConfiguration request to Ratis server with new SCM peers list: [8b10ddc2-41d5-41cc-935f-57a9babc5d91|rpc:scm2.org:9894|priority:0, 988d83fb-8298-4167-8ff5-9318a8e0d8d4|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 6f9a84f7-8019-4c66-ba45-e86fba2381f6|rpc:scm3.org:9894|priority:0]
scm1.org_1   | 2022-07-10 13:10:00,722 [IPC Server handler 2 on default port 9863] INFO server.RaftServer$Division: 988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008: receive setConfiguration SetConfigurationRequest:client-9EB0A70496C7->988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008, cid=2, seq=0, RW, null, peers:[8b10ddc2-41d5-41cc-935f-57a9babc5d91|rpc:scm2.org:9894|priority:0, 988d83fb-8298-4167-8ff5-9318a8e0d8d4|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 6f9a84f7-8019-4c66-ba45-e86fba2381f6|rpc:scm3.org:9894|priority:0]
scm1.org_1   | 2022-07-10 13:10:00,722 [IPC Server handler 2 on default port 9863] INFO server.RaftServer$Division: 988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-LeaderStateImpl: startSetConfiguration SetConfigurationRequest:client-9EB0A70496C7->988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008, cid=2, seq=0, RW, null, peers:[8b10ddc2-41d5-41cc-935f-57a9babc5d91|rpc:scm2.org:9894|priority:0, 988d83fb-8298-4167-8ff5-9318a8e0d8d4|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 6f9a84f7-8019-4c66-ba45-e86fba2381f6|rpc:scm3.org:9894|priority:0]
scm1.org_1   | 2022-07-10 13:10:00,723 [IPC Server handler 2 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
scm1.org_1   | 2022-07-10 13:10:00,723 [IPC Server handler 2 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2022-07-10 13:10:00,723 [IPC Server handler 2 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1024 (custom)
scm1.org_1   | 2022-07-10 13:10:00,724 [IPC Server handler 2 on default port 9863] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
scm1.org_1   | 2022-07-10 13:10:00,724 [IPC Server handler 2 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm2.org_1   | 2022-07-10 13:09:21,772 [main] ERROR client.SCMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
scm2.org_1   | 2022-07-10 13:09:21,772 [main] INFO client.SCMCertificateClient: Certificate client init case: 0
scm2.org_1   | 2022-07-10 13:09:21,773 [main] INFO client.SCMCertificateClient: Creating keypair for client as keypair and certificate not found.
scm2.org_1   | 2022-07-10 13:09:22,714 [main] INFO ha.HASecurityUtils: Init response: GETCERT
scm2.org_1   | 2022-07-10 13:09:22,756 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.117,host:scm2.org
scm2.org_1   | 2022-07-10 13:09:22,757 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
scm2.org_1   | 2022-07-10 13:09:22,760 [main] INFO ha.HASecurityUtils: Creating csr for SCM->hostName:scm2.org,scmId:8b10ddc2-41d5-41cc-935f-57a9babc5d91,clusterId:CID-f578972c-97f6-4a12-a46c-8eeea6081008,subject:scm-sub@scm2.org
scm2.org_1   | 2022-07-10 13:09:24,708 [main] INFO ha.HASecurityUtils: Successfully stored SCM signed certificate.
scm2.org_1   | 2022-07-10 13:09:24,743 [main] INFO server.StorageContainerManager: SCM BootStrap  is successful for ClusterID CID-f578972c-97f6-4a12-a46c-8eeea6081008, SCMID 8b10ddc2-41d5-41cc-935f-57a9babc5d91
scm2.org_1   | 2022-07-10 13:09:24,743 [main] INFO server.StorageContainerManager: Primary SCM Node ID 988d83fb-8298-4167-8ff5-9318a8e0d8d4
scm2.org_1   | 2022-07-10 13:09:24,807 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
scm2.org_1   | /************************************************************
scm2.org_1   | SHUTDOWN_MSG: Shutting down StorageContainerManager at scm2.org/172.25.0.117
scm2.org_1   | ************************************************************/
scm2.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm2.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm2.org_1   | 2022-07-10 13:09:28,853 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm2.org_1   | /************************************************************
scm2.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm2.org_1   | STARTUP_MSG:   host = scm2.org/172.25.0.117
scm2.org_1   | STARTUP_MSG:   args = []
scm2.org_1   | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
scm2.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar
scm2.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/d088d199bf506d76f7046a4b19b690e2a9e6915e ; compiled by 'runner' on 2022-07-10T12:45Z
scm2.org_1   | STARTUP_MSG:   java = 11.0.14.1
scm2.org_1   | ************************************************************/
scm2.org_1   | 2022-07-10 13:09:28,892 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm2.org_1   | 2022-07-10 13:09:29,024 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm2.org_1   | 2022-07-10 13:09:29,135 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm2.org_1   | 2022-07-10 13:09:29,171 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm2.org_1   | 2022-07-10 13:09:29,271 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm2, RPC Address: scm2.org:9894 and Ratis port: 9894
scm2.org_1   | 2022-07-10 13:09:29,271 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm2: scm2.org
scm2.org_1   | 2022-07-10 13:09:30,522 [main] INFO client.SCMCertificateClient: Loading certificate from location:/data/metadata/scm/sub-ca/certs.
scm2.org_1   | 2022-07-10 13:09:30,905 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/867407459181.crt.
scm2.org_1   | 2022-07-10 13:09:30,923 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/certificate.crt.
scm2.org_1   | 2022-07-10 13:09:30,933 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/CA-1.crt.
scm2.org_1   | 2022-07-10 13:09:31,282 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
scm2.org_1   | 2022-07-10 13:09:31,282 [main] INFO server.StorageContainerManager: SCM login successful.
scm2.org_1   | 2022-07-10 13:09:31,405 [main] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm2.org_1   | 2022-07-10 13:09:31,835 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm2.org_1   | 2022-07-10 13:09:32,447 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar!/network-topology-default.xml]
scm2.org_1   | 2022-07-10 13:09:32,453 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
scm2.org_1   | 2022-07-10 13:09:32,664 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
scm2.org_1   | 2022-07-10 13:09:32,715 [main] INFO ha.SCMRatisServerImpl: starting Raft server for scm:8b10ddc2-41d5-41cc-935f-57a9babc5d91
scm2.org_1   | 2022-07-10 13:09:32,954 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
scm2.org_1   | 2022-07-10 13:09:33,134 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
scm2.org_1   | 2022-07-10 13:09:33,137 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm2.org_1   | 2022-07-10 13:09:33,138 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
scm2.org_1   | 2022-07-10 13:09:33,138 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm2.org_1   | 2022-07-10 13:09:33,140 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm2.org_1   | 2022-07-10 13:09:33,141 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
scm2.org_1   | 2022-07-10 13:09:33,157 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm2.org_1   | 2022-07-10 13:09:33,157 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
scm2.org_1   | 2022-07-10 13:09:33,158 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm2.org_1   | 2022-07-10 13:09:33,222 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
scm2.org_1   | 2022-07-10 13:09:33,243 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
scm2.org_1   | 2022-07-10 13:09:34,917 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
scm2.org_1   | 2022-07-10 13:09:34,935 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
scm2.org_1   | 2022-07-10 13:09:34,936 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
scm2.org_1   | 2022-07-10 13:09:34,936 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm2.org_1   | 2022-07-10 13:09:34,937 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm2.org_1   | 2022-07-10 13:09:34,948 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm2.org_1   | 2022-07-10 13:09:35,009 [main] INFO server.RaftServer: 8b10ddc2-41d5-41cc-935f-57a9babc5d91: addNew group-8EEEA6081008:[] returns group-8EEEA6081008:java.util.concurrent.CompletableFuture@1edccfd4[Not completed]
scm1.org_1   | 2022-07-10 13:10:00,724 [IPC Server handler 2 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm1.org_1   | 2022-07-10 13:10:00,725 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008->6f9a84f7-8019-4c66-ba45-e86fba2381f6-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008->6f9a84f7-8019-4c66-ba45-e86fba2381f6-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:1, i:0)
scm1.org_1   | 2022-07-10 13:10:00,726 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008->6f9a84f7-8019-4c66-ba45-e86fba2381f6-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008->6f9a84f7-8019-4c66-ba45-e86fba2381f6-GrpcLogAppender: send 988d83fb-8298-4167-8ff5-9318a8e0d8d4->6f9a84f7-8019-4c66-ba45-e86fba2381f6#0-t2,notify:(t:1, i:0)
scm1.org_1   | 2022-07-10 13:10:03,402 [grpc-default-executor-1] INFO server.GrpcLogAppender: 988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008->6f9a84f7-8019-4c66-ba45-e86fba2381f6-InstallSnapshotResponseHandler: received the first reply 988d83fb-8298-4167-8ff5-9318a8e0d8d4<-6f9a84f7-8019-4c66-ba45-e86fba2381f6#0:FAIL-t0,ALREADY_INSTALLED
scm1.org_1   | 2022-07-10 13:10:03,402 [grpc-default-executor-1] INFO server.GrpcLogAppender: 988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008->6f9a84f7-8019-4c66-ba45-e86fba2381f6-InstallSnapshotResponseHandler: Follower snapshot is already at index 0.
scm1.org_1   | 2022-07-10 13:10:03,410 [grpc-default-executor-1] INFO leader.FollowerInfo: 988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008->6f9a84f7-8019-4c66-ba45-e86fba2381f6: snapshotIndex: setUnconditionally 0 -> 0
scm1.org_1   | 2022-07-10 13:10:03,413 [grpc-default-executor-1] INFO leader.FollowerInfo: 988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008->6f9a84f7-8019-4c66-ba45-e86fba2381f6: matchIndex: setUnconditionally 0 -> 0
scm1.org_1   | 2022-07-10 13:10:03,413 [grpc-default-executor-1] INFO leader.FollowerInfo: 988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008->6f9a84f7-8019-4c66-ba45-e86fba2381f6: nextIndex: setUnconditionally 0 -> 1
scm1.org_1   | 2022-07-10 13:10:03,413 [grpc-default-executor-1] INFO leader.FollowerInfo: Follower 988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008->6f9a84f7-8019-4c66-ba45-e86fba2381f6 acknowledged installing snapshot
scm1.org_1   | 2022-07-10 13:10:03,436 [grpc-default-executor-1] INFO leader.FollowerInfo: 988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008->6f9a84f7-8019-4c66-ba45-e86fba2381f6: nextIndex: updateToMax old=1, new=1, updated? false
scm1.org_1   | 2022-07-10 13:10:03,575 [grpc-default-executor-1] INFO leader.FollowerInfo: 988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008->6f9a84f7-8019-4c66-ba45-e86fba2381f6: nextIndex: updateUnconditionally 13 -> 0
scm1.org_1   | 2022-07-10 13:10:03,602 [grpc-default-executor-1] INFO leader.FollowerInfo: 988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008->6f9a84f7-8019-4c66-ba45-e86fba2381f6: nextIndex: updateUnconditionally 13 -> 0
scm1.org_1   | 2022-07-10 13:10:04,480 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-LeaderStateImpl] INFO server.RaftServer$Division: 988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008: set configuration 13: [8b10ddc2-41d5-41cc-935f-57a9babc5d91|rpc:scm2.org:9894|priority:0, 988d83fb-8298-4167-8ff5-9318a8e0d8d4|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 6f9a84f7-8019-4c66-ba45-e86fba2381f6|rpc:scm3.org:9894|priority:0], old=[8b10ddc2-41d5-41cc-935f-57a9babc5d91|rpc:scm2.org:9894|priority:0, 988d83fb-8298-4167-8ff5-9318a8e0d8d4|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0]
scm1.org_1   | 2022-07-10 13:10:04,540 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-LeaderStateImpl] INFO server.RaftServer$Division: 988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008: set configuration 15: [8b10ddc2-41d5-41cc-935f-57a9babc5d91|rpc:scm2.org:9894|priority:0, 988d83fb-8298-4167-8ff5-9318a8e0d8d4|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 6f9a84f7-8019-4c66-ba45-e86fba2381f6|rpc:scm3.org:9894|priority:0], old=null
scm1.org_1   | 2022-07-10 13:10:04,584 [IPC Server handler 2 on default port 9863] INFO ha.SCMRatisServerImpl: Successfully added new SCM: 6f9a84f7-8019-4c66-ba45-e86fba2381f6.
scm1.org_1   | 2022-07-10 13:10:11,982 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.118:43546
scm1.org_1   | 2022-07-10 13:10:12,020 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-07-10 13:10:25,422 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:41846
scm1.org_1   | 2022-07-10 13:10:25,585 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-07-10 13:10:26,186 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:58562
scm1.org_1   | 2022-07-10 13:10:26,278 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-07-10 13:10:27,487 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:52786
scm1.org_1   | 2022-07-10 13:10:27,605 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-07-10 13:10:28,775 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:50762
scm1.org_1   | 2022-07-10 13:10:28,900 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-07-10 13:10:28,907 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn f001020ea054, UUID: 992f3c0d-344e-4060-87f0-890ffe8b867e
scm1.org_1   | 2022-07-10 13:10:29,031 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:55454
scm1.org_1   | 2022-07-10 13:10:29,122 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-07-10 13:10:29,125 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn 377a412caf09, UUID: a1e412ee-75aa-4bf8-87bc-4e8e615b1959
scm1.org_1   | 2022-07-10 13:10:29,228 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-07-10 13:10:29,502 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-07-10 13:10:31,490 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35032
recon_1      | 2022-07-10 13:11:05,760 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 8d6e1a79-b70d-40e6-a234-6dc84a45f007, Nodes: 257634a0-3792-468a-a5a2-186b5a295fa1{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:257634a0-3792-468a-a5a2-186b5a295fa1, CreationTimestamp2022-07-10T13:11:01.880Z[UTC]] moved to OPEN state
recon_1      | 2022-07-10 13:11:06,256 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 99 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:11:06,258 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 100 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:11:06,258 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 101 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-07-10 13:11:06,914 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=199762fc-7613-447a-a2fc-b841d041c364 reported by 257634a0-3792-468a-a5a2-186b5a295fa1{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 935900506483, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-07-10 13:11:08,260 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 102 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:11:08,261 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 103 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:11:08,262 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 104 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-07-10 13:11:08,451 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=199762fc-7613-447a-a2fc-b841d041c364 reported by a1e412ee-75aa-4bf8-87bc-4e8e615b1959{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 933456427477, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-07-10 13:11:10,263 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 105 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:11:10,265 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 106 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:11:10,265 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 107 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-07-10 13:11:11,514 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=199762fc-7613-447a-a2fc-b841d041c364 reported by 992f3c0d-344e-4060-87f0-890ffe8b867e{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 933105602287, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-07-10 13:11:11,632 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=199762fc-7613-447a-a2fc-b841d041c364 reported by a1e412ee-75aa-4bf8-87bc-4e8e615b1959{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 933456427477, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm2.org_1   | 2022-07-10 13:09:35,120 [pool-16-thread-1] INFO server.RaftServer$Division: 8b10ddc2-41d5-41cc-935f-57a9babc5d91: new RaftServerImpl for group-8EEEA6081008:[] with SCMStateMachine:uninitialized
scm2.org_1   | 2022-07-10 13:09:35,145 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
scm2.org_1   | 2022-07-10 13:09:35,147 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
scm2.org_1   | 2022-07-10 13:09:35,147 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
scm2.org_1   | 2022-07-10 13:09:35,148 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm2.org_1   | 2022-07-10 13:09:35,148 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm2.org_1   | 2022-07-10 13:09:35,148 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
scm2.org_1   | 2022-07-10 13:09:35,174 [pool-16-thread-1] INFO server.RaftServer$Division: 8b10ddc2-41d5-41cc-935f-57a9babc5d91@group-8EEEA6081008: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
scm2.org_1   | 2022-07-10 13:09:35,183 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm2.org_1   | 2022-07-10 13:09:35,187 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
scm2.org_1   | 2022-07-10 13:09:35,191 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
scm2.org_1   | 2022-07-10 13:09:35,193 [pool-16-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/scm-ha/f578972c-97f6-4a12-a46c-8eeea6081008 does not exist. Creating ...
scm2.org_1   | 2022-07-10 13:09:35,270 [pool-16-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/f578972c-97f6-4a12-a46c-8eeea6081008/in_use.lock acquired by nodename 7@scm2.org
scm2.org_1   | 2022-07-10 13:09:35,368 [pool-16-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/scm-ha/f578972c-97f6-4a12-a46c-8eeea6081008 has been successfully formatted.
scm2.org_1   | 2022-07-10 13:09:35,375 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
scm2.org_1   | 2022-07-10 13:09:35,390 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
scm2.org_1   | 2022-07-10 13:09:35,419 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
scm2.org_1   | 2022-07-10 13:09:35,420 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm2.org_1   | 2022-07-10 13:09:35,421 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
scm2.org_1   | 2022-07-10 13:09:35,665 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm2.org_1   | 2022-07-10 13:09:35,675 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
scm2.org_1   | 2022-07-10 13:09:35,676 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
scm2.org_1   | 2022-07-10 13:09:35,692 [pool-16-thread-1] INFO segmented.SegmentedRaftLogWorker: new 8b10ddc2-41d5-41cc-935f-57a9babc5d91@group-8EEEA6081008-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/f578972c-97f6-4a12-a46c-8eeea6081008
scm2.org_1   | 2022-07-10 13:09:35,696 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
scm2.org_1   | 2022-07-10 13:09:35,697 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
scm2.org_1   | 2022-07-10 13:09:35,698 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm2.org_1   | 2022-07-10 13:09:35,699 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
scm2.org_1   | 2022-07-10 13:09:35,699 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
scm2.org_1   | 2022-07-10 13:09:35,700 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
scm2.org_1   | 2022-07-10 13:09:35,702 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
scm2.org_1   | 2022-07-10 13:09:35,702 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
scm2.org_1   | 2022-07-10 13:09:35,726 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
scm2.org_1   | 2022-07-10 13:09:35,735 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
scm2.org_1   | 2022-07-10 13:09:35,736 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
scm2.org_1   | 2022-07-10 13:09:35,748 [pool-16-thread-1] INFO segmented.SegmentedRaftLogWorker: 8b10ddc2-41d5-41cc-935f-57a9babc5d91@group-8EEEA6081008-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
scm2.org_1   | 2022-07-10 13:09:35,751 [pool-16-thread-1] INFO segmented.SegmentedRaftLogWorker: 8b10ddc2-41d5-41cc-935f-57a9babc5d91@group-8EEEA6081008-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
scm2.org_1   | 2022-07-10 13:09:35,756 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
scm2.org_1   | 2022-07-10 13:09:35,758 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
scm2.org_1   | 2022-07-10 13:09:35,763 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
scm2.org_1   | 2022-07-10 13:09:35,764 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
scm2.org_1   | 2022-07-10 13:09:35,766 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
scm2.org_1   | 2022-07-10 13:09:35,766 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
scm2.org_1   | 2022-07-10 13:09:35,866 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm2.org_1   | 2022-07-10 13:09:35,866 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
scm2.org_1   | 2022-07-10 13:09:35,868 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
scm2.org_1   | 2022-07-10 13:09:35,869 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
scm2.org_1   | 2022-07-10 13:09:35,873 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
scm2.org_1   | 2022-07-10 13:09:35,881 [main] INFO ha.SCMSnapshotProvider: Initializing SCM Snapshot Provider
scm2.org_1   | 2022-07-10 13:09:35,887 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
scm2.org_1   | 2022-07-10 13:09:35,889 [main] WARN ha.SCMHAUtils: SCM snapshot dir is not configured. Falling back to ozone.metadata.dirs config
scm2.org_1   | 2022-07-10 13:09:36,281 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
scm1.org_1   | 2022-07-10 13:10:31,596 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-07-10 13:10:31,607 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn 129fc2057256, UUID: 257634a0-3792-468a-a5a2-186b5a295fa1
scm1.org_1   | 2022-07-10 13:10:32,256 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-07-10 13:10:33,379 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:48506
scm1.org_1   | 2022-07-10 13:10:33,622 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-07-10 13:10:36,659 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:54808
scm1.org_1   | 2022-07-10 13:10:36,711 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-07-10 13:10:36,730 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for om om1, UUID: 330f214b-ed74-4ef4-8e45-7cb0220b881f
scm1.org_1   | 2022-07-10 13:10:36,914 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-07-10 13:10:37,412 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:35812
scm1.org_1   | 2022-07-10 13:10:37,457 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-07-10 13:10:37,458 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for om om2, UUID: 84fb36c4-ae8a-414a-b433-75a036f2f56a
scm1.org_1   | 2022-07-10 13:10:37,498 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-07-10 13:10:38,227 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:59734
scm1.org_1   | 2022-07-10 13:10:38,274 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-07-10 13:10:38,275 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for om om3, UUID: d4a69ade-4f5d-431e-8038-365e65135c4a
scm1.org_1   | 2022-07-10 13:10:38,518 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-07-10 13:10:39,176 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:50788
scm1.org_1   | 2022-07-10 13:10:39,197 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-07-10 13:10:39,503 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:55480
scm1.org_1   | 2022-07-10 13:10:39,563 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-07-10 13:10:42,236 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35070
scm1.org_1   | 2022-07-10 13:10:42,270 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-07-10 13:10:52,613 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:45246
scm1.org_1   | 2022-07-10 13:10:52,655 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:10:54,227 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:47038
scm1.org_1   | 2022-07-10 13:10:54,429 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:10:58,179 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34058
scm1.org_1   | 2022-07-10 13:10:58,294 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:10:58,344 [IPC Server handler 13 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/992f3c0d-344e-4060-87f0-890ffe8b867e
scm1.org_1   | 2022-07-10 13:10:58,404 [IPC Server handler 86 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/a1e412ee-75aa-4bf8-87bc-4e8e615b1959
scm1.org_1   | 2022-07-10 13:10:58,405 [IPC Server handler 86 on default port 9861] INFO node.SCMNodeManager: Registered Data node : a1e412ee-75aa-4bf8-87bc-4e8e615b1959{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 933456427477, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm1.org_1   | 2022-07-10 13:10:58,473 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm1.org_1   | 2022-07-10 13:10:58,554 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 3 required.
scm1.org_1   | 2022-07-10 13:10:58,578 [IPC Server handler 13 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 992f3c0d-344e-4060-87f0-890ffe8b867e{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 933105602287, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm1.org_1   | 2022-07-10 13:10:58,621 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm1.org_1   | 2022-07-10 13:10:58,828 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 3 required.
scm2.org_1   | 2022-07-10 13:09:36,622 [main] INFO reflections.Reflections: Reflections took 236 ms to scan 3 urls, producing 109 keys and 243 values 
scm2.org_1   | 2022-07-10 13:09:36,829 [main] INFO ha.SequenceIdGenerator: upgrade localId to 109611004723200000
scm2.org_1   | 2022-07-10 13:09:36,829 [main] INFO ha.SequenceIdGenerator: upgrade delTxnId to 0
scm2.org_1   | 2022-07-10 13:09:36,832 [main] INFO ha.SequenceIdGenerator: upgrade containerId to 0
scm2.org_1   | 2022-07-10 13:09:36,834 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
scm2.org_1   | 2022-07-10 13:09:36,976 [main] INFO node.SCMNodeManager: Entering startup safe mode.
scm2.org_1   | 2022-07-10 13:09:37,025 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
scm2.org_1   | 2022-07-10 13:09:37,052 [main] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
scm2.org_1   | 2022-07-10 13:09:37,132 [main] INFO algorithms.LeaderChoosePolicyFactory: Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
scm2.org_1   | 2022-07-10 13:09:37,143 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
scm2.org_1   | 2022-07-10 13:09:37,173 [main] INFO pipeline.BackgroundPipelineCreator: Starting RatisPipelineUtilsThread.
scm2.org_1   | 2022-07-10 13:09:37,187 [main] INFO BackgroundPipelineScrubber: Starting BackgroundPipelineScrubber Service.
scm2.org_1   | 2022-07-10 13:09:37,189 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineCreator.
scm2.org_1   | 2022-07-10 13:09:37,189 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineScrubber.
scm2.org_1   | 2022-07-10 13:09:37,213 [main] INFO ExpiredContainerReplicaOpScrubber: Starting ExpiredContainerReplicaOpScrubber Service.
scm2.org_1   | 2022-07-10 13:09:37,232 [main] INFO ha.SCMServiceManager: Registering service ExpiredContainerReplicaOpScrubber.
scm2.org_1   | 2022-07-10 13:09:37,303 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
scm2.org_1   | 2022-07-10 13:09:37,345 [main] INFO ha.SCMServiceManager: Registering service SCMBlockDeletingService.
scm2.org_1   | 2022-07-10 13:09:37,383 [main] INFO replication.ReplicationManager: Starting Replication Monitor Thread.
scm2.org_1   | 2022-07-10 13:09:37,403 [main] INFO ha.SCMServiceManager: Registering service ReplicationManager.
scm2.org_1   | 2022-07-10 13:09:37,415 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm2.org_1   | 2022-07-10 13:09:37,416 [main] INFO safemode.ContainerSafeModeRule: containers with one replica threshold count 0
scm2.org_1   | 2022-07-10 13:09:37,423 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-07-10 13:09:37,426 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm2.org_1   | 2022-07-10 13:09:37,497 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
scm2.org_1   | 2022-07-10 13:09:37,562 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 200, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm2.org_1   | 2022-07-10 13:09:37,664 [Socket Reader #1 for port 9961] INFO ipc.Server: Starting Socket Reader #1 for port 9961
scm2.org_1   | 2022-07-10 13:09:39,775 [Listener at 0.0.0.0/9961] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm2.org_1   | 2022-07-10 13:09:39,815 [Listener at 0.0.0.0/9961] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm2.org_1   | 2022-07-10 13:09:39,827 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
scm2.org_1   | 2022-07-10 13:09:39,952 [Listener at 0.0.0.0/9861] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm2.org_1   | 2022-07-10 13:09:39,974 [Listener at 0.0.0.0/9861] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm2.org_1   | 2022-07-10 13:09:39,987 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
scm2.org_1   | 2022-07-10 13:09:40,128 [Listener at 0.0.0.0/9863] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm2.org_1   | 2022-07-10 13:09:40,159 [Listener at 0.0.0.0/9863] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm2.org_1   | 2022-07-10 13:09:40,164 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
scm2.org_1   | 2022-07-10 13:09:40,507 [Listener at 0.0.0.0/9860] INFO ha.SCMServiceManager: Registering service ContainerBalancer.
scm2.org_1   | 2022-07-10 13:09:40,508 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: 
scm2.org_1   | Container Balancer status:
scm2.org_1   | Key                            Value
scm2.org_1   | Running                        false
scm2.org_1   | Container Balancer Configuration values:
scm2.org_1   | Key                                                Value
scm2.org_1   | Threshold                                          10
scm2.org_1   | Max Datanodes to Involve per Iteration(percent)    20
scm2.org_1   | Max Size to Move per Iteration                     500GB
scm2.org_1   | Max Size Entering Target per Iteration             26GB
scm2.org_1   | Max Size Leaving Source per Iteration              26GB
scm2.org_1   | 
scm2.org_1   | 2022-07-10 13:09:40,508 [Listener at 0.0.0.0/9860] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm2.org_1   | 2022-07-10 13:09:40,508 [Listener at 0.0.0.0/9860] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
scm2.org_1   | 2022-07-10 13:09:40,514 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
scm2.org_1   | 2022-07-10 13:09:40,516 [Listener at 0.0.0.0/9860] INFO ha.SCMRatisServerImpl: starting ratis server 0.0.0.0:9894
scm2.org_1   | 2022-07-10 13:09:40,588 [8b10ddc2-41d5-41cc-935f-57a9babc5d91-impl-thread1] INFO server.RaftServer$Division: 8b10ddc2-41d5-41cc-935f-57a9babc5d91@group-8EEEA6081008: start with initializing state, conf=-1: [], old=null
scm2.org_1   | 2022-07-10 13:09:40,588 [8b10ddc2-41d5-41cc-935f-57a9babc5d91-impl-thread1] INFO server.RaftServer$Division: 8b10ddc2-41d5-41cc-935f-57a9babc5d91@group-8EEEA6081008: changes role from      null to FOLLOWER at term 0 for startInitializing
scm2.org_1   | 2022-07-10 13:09:40,615 [8b10ddc2-41d5-41cc-935f-57a9babc5d91-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-8EEEA6081008,id=8b10ddc2-41d5-41cc-935f-57a9babc5d91
scm2.org_1   | 2022-07-10 13:09:40,621 [Listener at 0.0.0.0/9860] INFO server.RaftServer: 8b10ddc2-41d5-41cc-935f-57a9babc5d91: start RPC server
scm2.org_1   | 2022-07-10 13:09:40,870 [Listener at 0.0.0.0/9860] INFO server.GrpcService: 8b10ddc2-41d5-41cc-935f-57a9babc5d91: GrpcService started, listening on 9894
scm2.org_1   | 2022-07-10 13:09:40,909 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$466/0x0000000840529840@487f025] INFO util.JvmPauseMonitor: JvmPauseMonitor-8b10ddc2-41d5-41cc-935f-57a9babc5d91: Started
recon_1      | 2022-07-10 13:11:11,635 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 199762fc-7613-447a-a2fc-b841d041c364, Nodes: 257634a0-3792-468a-a5a2-186b5a295fa1{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}a1e412ee-75aa-4bf8-87bc-4e8e615b1959{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}992f3c0d-344e-4060-87f0-890ffe8b867e{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:a1e412ee-75aa-4bf8-87bc-4e8e615b1959, CreationTimestamp2022-07-10T13:11:02.344Z[UTC]] moved to OPEN state
recon_1      | 2022-07-10 13:11:11,869 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=79d7f9ff-9479-4fdc-a3f9-09a40f9f1d96. Trying to get from SCM.
recon_1      | 2022-07-10 13:11:11,876 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: 79d7f9ff-9479-4fdc-a3f9-09a40f9f1d96, Nodes: 257634a0-3792-468a-a5a2-186b5a295fa1{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}a1e412ee-75aa-4bf8-87bc-4e8e615b1959{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}992f3c0d-344e-4060-87f0-890ffe8b867e{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-07-10T13:11:02.595Z[UTC]] to Recon pipeline metadata.
recon_1      | 2022-07-10 13:11:11,877 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 79d7f9ff-9479-4fdc-a3f9-09a40f9f1d96, Nodes: 257634a0-3792-468a-a5a2-186b5a295fa1{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}a1e412ee-75aa-4bf8-87bc-4e8e615b1959{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}992f3c0d-344e-4060-87f0-890ffe8b867e{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-07-10T13:11:02.595Z[UTC]].
recon_1      | 2022-07-10 13:11:11,878 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=79d7f9ff-9479-4fdc-a3f9-09a40f9f1d96 reported by 257634a0-3792-468a-a5a2-186b5a295fa1{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 935900506483, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-07-10 13:11:11,941 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=79d7f9ff-9479-4fdc-a3f9-09a40f9f1d96 reported by a1e412ee-75aa-4bf8-87bc-4e8e615b1959{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 933456427477, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-07-10 13:11:12,151 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=79d7f9ff-9479-4fdc-a3f9-09a40f9f1d96 reported by 257634a0-3792-468a-a5a2-186b5a295fa1{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 935900506483, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-07-10 13:11:12,267 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 108 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:11:12,268 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 109 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:11:12,269 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 110 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-07-10 13:11:14,270 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 111 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:11:14,271 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 112 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:11:14,272 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 113 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-07-10 13:11:14,325 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=79d7f9ff-9479-4fdc-a3f9-09a40f9f1d96 reported by 992f3c0d-344e-4060-87f0-890ffe8b867e{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 933105602287, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm1.org_1   | 2022-07-10 13:10:58,878 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=b77b6ac4-c103-4125-90f3-f25d482aaf22 to datanode:992f3c0d-344e-4060-87f0-890ffe8b867e
scm1.org_1   | 2022-07-10 13:10:59,559 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: b77b6ac4-c103-4125-90f3-f25d482aaf22, Nodes: 992f3c0d-344e-4060-87f0-890ffe8b867e{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-07-10T13:10:58.769Z[UTC]].
scm1.org_1   | 2022-07-10 13:10:59,615 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-07-10 13:10:59,707 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=b1d72510-c7b3-4886-b6f1-097f02077230 to datanode:a1e412ee-75aa-4bf8-87bc-4e8e615b1959
scm1.org_1   | 2022-07-10 13:10:59,805 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: b1d72510-c7b3-4886-b6f1-097f02077230, Nodes: a1e412ee-75aa-4bf8-87bc-4e8e615b1959{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-07-10T13:10:59.707Z[UTC]].
scm1.org_1   | 2022-07-10 13:10:59,811 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-07-10 13:11:01,675 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: b77b6ac4-c103-4125-90f3-f25d482aaf22, Nodes: 992f3c0d-344e-4060-87f0-890ffe8b867e{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:992f3c0d-344e-4060-87f0-890ffe8b867e, CreationTimestamp2022-07-10T13:10:58.769Z[UTC]] moved to OPEN state
scm1.org_1   | 2022-07-10 13:11:01,812 [IPC Server handler 13 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/257634a0-3792-468a-a5a2-186b5a295fa1
scm1.org_1   | 2022-07-10 13:11:01,822 [IPC Server handler 13 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 257634a0-3792-468a-a5a2-186b5a295fa1{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 935900506483, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm1.org_1   | 2022-07-10 13:11:01,824 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm1.org_1   | 2022-07-10 13:11:01,856 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 3 required.
scm1.org_1   | 2022-07-10 13:11:01,856 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm1.org_1   | 2022-07-10 13:11:01,840 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-07-10 13:11:01,869 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
scm1.org_1   | 2022-07-10 13:11:01,878 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm1.org_1   | 2022-07-10 13:11:01,878 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
scm1.org_1   | 2022-07-10 13:11:01,879 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm1.org_1   | 2022-07-10 13:11:01,880 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=8d6e1a79-b70d-40e6-a234-6dc84a45f007 to datanode:257634a0-3792-468a-a5a2-186b5a295fa1
scm1.org_1   | 2022-07-10 13:11:01,903 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm1.org_1   | 2022-07-10 13:11:01,946 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:44065
scm1.org_1   | 2022-07-10 13:11:01,971 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-07-10 13:11:02,204 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 8d6e1a79-b70d-40e6-a234-6dc84a45f007, Nodes: 257634a0-3792-468a-a5a2-186b5a295fa1{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-07-10T13:11:01.880Z[UTC]].
scm1.org_1   | 2022-07-10 13:11:02,215 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-07-10 13:11:02,344 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=199762fc-7613-447a-a2fc-b841d041c364 to datanode:257634a0-3792-468a-a5a2-186b5a295fa1
scm1.org_1   | 2022-07-10 13:11:02,363 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=199762fc-7613-447a-a2fc-b841d041c364 to datanode:a1e412ee-75aa-4bf8-87bc-4e8e615b1959
scm1.org_1   | 2022-07-10 13:11:02,371 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=199762fc-7613-447a-a2fc-b841d041c364 to datanode:992f3c0d-344e-4060-87f0-890ffe8b867e
om2_1        | 2022-07-10 13:20:05,400 [IPC Server handler 49 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:05,410 [IPC Server handler 54 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:05,416 [IPC Server handler 67 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:05,420 [IPC Server handler 83 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:05,434 [IPC Server handler 96 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:05,436 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:05,438 [IPC Server handler 58 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:05,487 [IPC Server handler 71 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:06,167 [IPC Server handler 39 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:06,939 [IPC Server handler 82 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:06,942 [IPC Server handler 77 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:06,944 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:07,583 [IPC Server handler 50 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:07,586 [IPC Server handler 0 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:07,588 [IPC Server handler 99 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:07,609 [IPC Server handler 31 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:08,627 [IPC Server handler 53 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:08,630 [IPC Server handler 80 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:08,634 [IPC Server handler 82 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:09,309 [IPC Server handler 61 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:09,312 [IPC Server handler 70 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:09,314 [IPC Server handler 60 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:10,004 [IPC Server handler 63 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:10,006 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:10,011 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:14,250 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44116
om2_1        | 2022-07-10 13:20:14,255 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:20:17,631 [IPC Server handler 80 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:17,638 [IPC Server handler 82 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:17,644 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-0642987608 of layout LEGACY in volume: s3v
om2_1        | 2022-07-10 13:20:18,298 [IPC Server handler 26 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:18,307 [IPC Server handler 61 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:18,315 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: destbucket-81026 of layout LEGACY in volume: s3v
om2_1        | 2022-07-10 13:20:18,961 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:18,967 [IPC Server handler 37 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:18,970 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:19,102 [IPC Server handler 20 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:19,742 [IPC Server handler 77 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:19,744 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:19,749 [IPC Server handler 37 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:19,752 [IPC Server handler 43 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:20,378 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:20,380 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:20,382 [IPC Server handler 49 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
recon_1      | 2022-07-10 13:11:16,274 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 114 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:11:16,275 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 115 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:11:16,278 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 116 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-07-10 13:11:17,412 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=79d7f9ff-9479-4fdc-a3f9-09a40f9f1d96 reported by a1e412ee-75aa-4bf8-87bc-4e8e615b1959{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 933456427477, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-07-10 13:11:17,421 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 79d7f9ff-9479-4fdc-a3f9-09a40f9f1d96, Nodes: 257634a0-3792-468a-a5a2-186b5a295fa1{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}a1e412ee-75aa-4bf8-87bc-4e8e615b1959{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}992f3c0d-344e-4060-87f0-890ffe8b867e{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:a1e412ee-75aa-4bf8-87bc-4e8e615b1959, CreationTimestamp2022-07-10T13:11:02.595Z[UTC]] moved to OPEN state
recon_1      | 2022-07-10 13:11:18,280 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 117 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:11:18,281 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 118 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:11:18,282 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 119 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-07-10 13:11:20,284 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 120 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:11:20,285 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 121 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:11:20,286 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 122 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-07-10 13:11:29,653 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om1 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:248)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:235)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:228)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:175)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:147)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
scm1.org_1   | 2022-07-10 13:11:02,551 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 199762fc-7613-447a-a2fc-b841d041c364, Nodes: 257634a0-3792-468a-a5a2-186b5a295fa1{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}a1e412ee-75aa-4bf8-87bc-4e8e615b1959{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}992f3c0d-344e-4060-87f0-890ffe8b867e{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-07-10T13:11:02.344Z[UTC]].
scm1.org_1   | 2022-07-10 13:11:02,565 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-07-10 13:11:02,595 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=79d7f9ff-9479-4fdc-a3f9-09a40f9f1d96 to datanode:257634a0-3792-468a-a5a2-186b5a295fa1
scm1.org_1   | 2022-07-10 13:11:02,655 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=79d7f9ff-9479-4fdc-a3f9-09a40f9f1d96 to datanode:a1e412ee-75aa-4bf8-87bc-4e8e615b1959
scm1.org_1   | 2022-07-10 13:11:02,655 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=79d7f9ff-9479-4fdc-a3f9-09a40f9f1d96 to datanode:992f3c0d-344e-4060-87f0-890ffe8b867e
scm1.org_1   | 2022-07-10 13:11:02,693 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 79d7f9ff-9479-4fdc-a3f9-09a40f9f1d96, Nodes: 257634a0-3792-468a-a5a2-186b5a295fa1{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}a1e412ee-75aa-4bf8-87bc-4e8e615b1959{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}992f3c0d-344e-4060-87f0-890ffe8b867e{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-07-10T13:11:02.595Z[UTC]].
scm1.org_1   | 2022-07-10 13:11:02,705 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-07-10 13:11:02,710 [RatisPipelineUtilsThread - 0] INFO pipeline.PipelineManagerImpl: Pipeline: PipelineID=79d7f9ff-9479-4fdc-a3f9-09a40f9f1d96 contains same datanodes as previous pipelines: PipelineID=199762fc-7613-447a-a2fc-b841d041c364 nodeIds: 257634a0-3792-468a-a5a2-186b5a295fa1, a1e412ee-75aa-4bf8-87bc-4e8e615b1959, 992f3c0d-344e-4060-87f0-890ffe8b867e
scm1.org_1   | 2022-07-10 13:11:02,766 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: b1d72510-c7b3-4886-b6f1-097f02077230, Nodes: a1e412ee-75aa-4bf8-87bc-4e8e615b1959{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:a1e412ee-75aa-4bf8-87bc-4e8e615b1959, CreationTimestamp2022-07-10T13:10:59.707Z[UTC]] moved to OPEN state
scm1.org_1   | 2022-07-10 13:11:02,824 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-07-10 13:11:02,846 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm1.org_1   | 2022-07-10 13:11:03,446 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm1.org_1   | 2022-07-10 13:11:03,709 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:58670
scm1.org_1   | 2022-07-10 13:11:03,787 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-07-10 13:11:04,429 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:52894
scm1.org_1   | 2022-07-10 13:11:04,623 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-07-10 13:11:05,786 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 8d6e1a79-b70d-40e6-a234-6dc84a45f007, Nodes: 257634a0-3792-468a-a5a2-186b5a295fa1{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:257634a0-3792-468a-a5a2-186b5a295fa1, CreationTimestamp2022-07-10T13:11:01.880Z[UTC]] moved to OPEN state
scm1.org_1   | 2022-07-10 13:11:05,824 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-07-10 13:11:05,828 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm1.org_1   | 2022-07-10 13:11:06,054 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:41968
scm1.org_1   | 2022-07-10 13:11:06,181 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-07-10 13:11:06,934 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm1.org_1   | 2022-07-10 13:11:07,526 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:48612
om2_1        | 2022-07-10 13:20:20,384 [IPC Server handler 54 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:20,386 [IPC Server handler 67 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:20,410 [IPC Server handler 83 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:20,423 [IPC Server handler 96 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:20,555 [IPC Server handler 50 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:20,576 [IPC Server handler 0 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:21,229 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:21,232 [IPC Server handler 78 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:21,234 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:21,239 [IPC Server handler 97 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:21,884 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:21,887 [IPC Server handler 63 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:21,889 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:21,890 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:21,891 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:21,901 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:21,909 [IPC Server handler 68 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:22,030 [IPC Server handler 41 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:22,057 [IPC Server handler 94 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:22,793 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:22,796 [IPC Server handler 63 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:22,798 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:22,800 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:23,424 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:23,427 [IPC Server handler 58 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:24,055 [IPC Server handler 41 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:24,058 [IPC Server handler 94 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:24,063 [IPC Server handler 89 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:24,065 [IPC Server handler 65 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:24,712 [IPC Server handler 77 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:24,714 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:25,343 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:25,346 [IPC Server handler 57 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:25,348 [IPC Server handler 55 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:25,350 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:25,352 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:29,080 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44174
om2_1        | 2022-07-10 13:20:29,086 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:20:32,579 [IPC Server handler 0 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:32,582 [IPC Server handler 99 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:32,589 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-7006625698 of layout LEGACY in volume: s3v
om2_1        | 2022-07-10 13:20:33,225 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:33,228 [IPC Server handler 78 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:33,231 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:33,334 [IPC Server handler 75 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 123 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:11:30,324 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:248)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:235)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:228)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:175)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:147)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 124 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:11:30,900 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om3 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:248)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:235)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:228)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:175)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:147)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 125 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-07-10 13:11:32,904 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om1 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:248)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:235)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:228)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:175)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:147)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 126 failover attempts. Trying to failover immediately.
om2_1        | 2022-07-10 13:20:33,979 [IPC Server handler 41 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:33,981 [IPC Server handler 94 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:33,983 [IPC Server handler 89 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:33,986 [IPC Server handler 65 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:34,622 [IPC Server handler 53 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:34,629 [IPC Server handler 80 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:34,633 [IPC Server handler 82 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:34,668 [IPC Server handler 77 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:35,296 [IPC Server handler 85 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:35,298 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:35,300 [IPC Server handler 26 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:35,930 [IPC Server handler 41 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:35,933 [IPC Server handler 94 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:35,935 [IPC Server handler 89 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:36,568 [IPC Server handler 50 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:36,570 [IPC Server handler 0 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:36,574 [IPC Server handler 99 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:37,186 [IPC Server handler 9 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:37,191 [IPC Server handler 98 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:37,198 [IPC Server handler 69 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:37,833 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:37,835 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:37,838 [IPC Server handler 68 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:37,924 [IPC Server handler 41 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:38,596 [IPC Server handler 31 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:38,598 [IPC Server handler 53 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:38,600 [IPC Server handler 80 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:38,602 [IPC Server handler 82 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:39,220 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:39,222 [IPC Server handler 78 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:39,224 [IPC Server handler 97 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:39,839 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:39,842 [IPC Server handler 68 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:39,843 [IPC Server handler 94 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:39,845 [IPC Server handler 89 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:40,474 [IPC Server handler 71 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:40,476 [IPC Server handler 50 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:40,478 [IPC Server handler 0 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:40,485 [IPC Server handler 99 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:41,136 [IPC Server handler 5 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:41,157 [IPC Server handler 9 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:41,163 [IPC Server handler 10 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:41,437 [IPC Server handler 96 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:42,119 [IPC Server handler 7 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:42,121 [IPC Server handler 81 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
recon_1      | 2022-07-10 13:11:32,907 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:248)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:235)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:228)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:175)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:147)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 127 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:11:32,916 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om3 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:248)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:235)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:228)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:175)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:147)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 128 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-07-10 13:11:34,928 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om1 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:248)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:235)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:228)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:175)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:147)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 129 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:11:34,935 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:248)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:235)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:228)
scm2.org_1   | 2022-07-10 13:09:40,929 [Listener at 0.0.0.0/9860] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 2 nodes: [nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
scm2.org_1   | 2022-07-10 13:09:42,474 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: 8b10ddc2-41d5-41cc-935f-57a9babc5d91@group-8EEEA6081008: receive installSnapshot: 988d83fb-8298-4167-8ff5-9318a8e0d8d4->8b10ddc2-41d5-41cc-935f-57a9babc5d91#0-t2,notify:(t:1, i:0)
scm2.org_1   | 2022-07-10 13:09:42,480 [grpc-default-executor-0] INFO ha.SCMStateMachine: leader changed, yet current SCM is still follower.
scm2.org_1   | 2022-07-10 13:09:42,480 [grpc-default-executor-0] INFO server.RaftServer$Division: 8b10ddc2-41d5-41cc-935f-57a9babc5d91@group-8EEEA6081008: change Leader from null to 988d83fb-8298-4167-8ff5-9318a8e0d8d4 at term 2 for installSnapshot, leader elected after 7107ms
scm2.org_1   | 2022-07-10 13:09:42,491 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: 8b10ddc2-41d5-41cc-935f-57a9babc5d91@group-8EEEA6081008: Received notification to install snapshot at index 0
scm2.org_1   | 2022-07-10 13:09:42,492 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: 8b10ddc2-41d5-41cc-935f-57a9babc5d91@group-8EEEA6081008: InstallSnapshot notification result: ALREADY_INSTALLED, current snapshot index: -1
scm2.org_1   | 2022-07-10 13:09:42,885 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: 8b10ddc2-41d5-41cc-935f-57a9babc5d91@group-8EEEA6081008: set new configuration index: 1
scm2.org_1   | configurationEntry {
scm2.org_1   |   peers {
scm2.org_1   |     id: "988d83fb-8298-4167-8ff5-9318a8e0d8d4"
scm2.org_1   |     address: "scm1.org:9894"
scm2.org_1   |   }
scm2.org_1   | }
scm2.org_1   |  from snapshot
scm2.org_1   | 2022-07-10 13:09:42,887 [grpc-default-executor-0] INFO server.RaftServer$Division: 8b10ddc2-41d5-41cc-935f-57a9babc5d91@group-8EEEA6081008: set configuration 1: [988d83fb-8298-4167-8ff5-9318a8e0d8d4|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2022-07-10 13:09:42,895 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: 8b10ddc2-41d5-41cc-935f-57a9babc5d91@group-8EEEA6081008: reply installSnapshot: 988d83fb-8298-4167-8ff5-9318a8e0d8d4<-8b10ddc2-41d5-41cc-935f-57a9babc5d91#0:FAIL-t0,ALREADY_INSTALLED
scm2.org_1   | 2022-07-10 13:09:42,919 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: 8b10ddc2-41d5-41cc-935f-57a9babc5d91: Completed INSTALL_SNAPSHOT, lastRequest: 988d83fb-8298-4167-8ff5-9318a8e0d8d4->8b10ddc2-41d5-41cc-935f-57a9babc5d91#0-t2,notify:(t:1, i:0)
scm2.org_1   | 2022-07-10 13:09:43,009 [8b10ddc2-41d5-41cc-935f-57a9babc5d91-server-thread1] INFO impl.RoleInfo: 8b10ddc2-41d5-41cc-935f-57a9babc5d91: start 8b10ddc2-41d5-41cc-935f-57a9babc5d91@group-8EEEA6081008-FollowerState
scm2.org_1   | 2022-07-10 13:09:43,022 [8b10ddc2-41d5-41cc-935f-57a9babc5d91-server-thread1] INFO server.RaftServer$Division: 8b10ddc2-41d5-41cc-935f-57a9babc5d91@group-8EEEA6081008: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
scm2.org_1   | 2022-07-10 13:09:43,024 [8b10ddc2-41d5-41cc-935f-57a9babc5d91-server-thread1] INFO server.RaftServer$Division: 8b10ddc2-41d5-41cc-935f-57a9babc5d91@group-8EEEA6081008: inconsistency entries. Reply:988d83fb-8298-4167-8ff5-9318a8e0d8d4<-8b10ddc2-41d5-41cc-935f-57a9babc5d91#0:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm2.org_1   | 2022-07-10 13:09:43,037 [8b10ddc2-41d5-41cc-935f-57a9babc5d91-server-thread2] INFO server.RaftServer$Division: 8b10ddc2-41d5-41cc-935f-57a9babc5d91@group-8EEEA6081008: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
scm2.org_1   | 2022-07-10 13:09:43,039 [8b10ddc2-41d5-41cc-935f-57a9babc5d91-server-thread2] INFO server.RaftServer$Division: 8b10ddc2-41d5-41cc-935f-57a9babc5d91@group-8EEEA6081008: inconsistency entries. Reply:988d83fb-8298-4167-8ff5-9318a8e0d8d4<-8b10ddc2-41d5-41cc-935f-57a9babc5d91#1:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm2.org_1   | 2022-07-10 13:09:43,047 [8b10ddc2-41d5-41cc-935f-57a9babc5d91-server-thread2] INFO server.RaftServer$Division: 8b10ddc2-41d5-41cc-935f-57a9babc5d91@group-8EEEA6081008: set configuration 0: [988d83fb-8298-4167-8ff5-9318a8e0d8d4|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2022-07-10 13:09:43,050 [8b10ddc2-41d5-41cc-935f-57a9babc5d91-server-thread2] INFO server.RaftServer$Division: 8b10ddc2-41d5-41cc-935f-57a9babc5d91@group-8EEEA6081008: set configuration 1: [988d83fb-8298-4167-8ff5-9318a8e0d8d4|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2022-07-10 13:09:43,073 [8b10ddc2-41d5-41cc-935f-57a9babc5d91-server-thread2] INFO segmented.SegmentedRaftLogWorker: 8b10ddc2-41d5-41cc-935f-57a9babc5d91@group-8EEEA6081008-SegmentedRaftLogWorker: Starting segment from index:0
scm2.org_1   | 2022-07-10 13:09:43,119 [8b10ddc2-41d5-41cc-935f-57a9babc5d91-server-thread2] INFO segmented.SegmentedRaftLogWorker: 8b10ddc2-41d5-41cc-935f-57a9babc5d91@group-8EEEA6081008-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
scm2.org_1   | 2022-07-10 13:09:43,136 [8b10ddc2-41d5-41cc-935f-57a9babc5d91-server-thread1] INFO server.RaftServer$Division: 8b10ddc2-41d5-41cc-935f-57a9babc5d91@group-8EEEA6081008: set configuration 0: [988d83fb-8298-4167-8ff5-9318a8e0d8d4|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2022-07-10 13:09:43,139 [8b10ddc2-41d5-41cc-935f-57a9babc5d91-server-thread1] INFO server.RaftServer$Division: 8b10ddc2-41d5-41cc-935f-57a9babc5d91@group-8EEEA6081008: set configuration 1: [988d83fb-8298-4167-8ff5-9318a8e0d8d4|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2022-07-10 13:09:43,385 [8b10ddc2-41d5-41cc-935f-57a9babc5d91@group-8EEEA6081008-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 8b10ddc2-41d5-41cc-935f-57a9babc5d91@group-8EEEA6081008-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/f578972c-97f6-4a12-a46c-8eeea6081008/current/log_inprogress_0
scm2.org_1   | 2022-07-10 13:09:43,389 [8b10ddc2-41d5-41cc-935f-57a9babc5d91@group-8EEEA6081008-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 8b10ddc2-41d5-41cc-935f-57a9babc5d91@group-8EEEA6081008-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/scm-ha/f578972c-97f6-4a12-a46c-8eeea6081008/current/log_inprogress_0 to /data/metadata/scm-ha/f578972c-97f6-4a12-a46c-8eeea6081008/current/log_0-0
scm2.org_1   | 2022-07-10 13:09:43,415 [8b10ddc2-41d5-41cc-935f-57a9babc5d91@group-8EEEA6081008-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 8b10ddc2-41d5-41cc-935f-57a9babc5d91@group-8EEEA6081008-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/f578972c-97f6-4a12-a46c-8eeea6081008/current/log_inprogress_1
scm2.org_1   | 2022-07-10 13:09:43,423 [8b10ddc2-41d5-41cc-935f-57a9babc5d91@group-8EEEA6081008-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-07-10 13:09:43,432 [8b10ddc2-41d5-41cc-935f-57a9babc5d91@group-8EEEA6081008-StateMachineUpdater] INFO safemode.ContainerSafeModeRule: Refreshed one replica container threshold 0, currentThreshold 0
scm2.org_1   | 2022-07-10 13:09:43,435 [8b10ddc2-41d5-41cc-935f-57a9babc5d91@group-8EEEA6081008-StateMachineUpdater] INFO safemode.OneReplicaPipelineSafeModeRule: Refreshed Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm2.org_1   | 2022-07-10 13:09:43,435 [8b10ddc2-41d5-41cc-935f-57a9babc5d91@group-8EEEA6081008-StateMachineUpdater] INFO server.SCMDatanodeProtocolServer: ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:9861
scm2.org_1   | 2022-07-10 13:09:43,445 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm2.org_1   | 2022-07-10 13:09:43,447 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
scm1.org_1   | 2022-07-10 13:11:07,681 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-07-10 13:11:07,733 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm1.org_1   | 2022-07-10 13:11:08,474 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm1.org_1   | 2022-07-10 13:11:11,516 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm1.org_1   | 2022-07-10 13:11:11,640 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 199762fc-7613-447a-a2fc-b841d041c364, Nodes: 257634a0-3792-468a-a5a2-186b5a295fa1{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}a1e412ee-75aa-4bf8-87bc-4e8e615b1959{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}992f3c0d-344e-4060-87f0-890ffe8b867e{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:a1e412ee-75aa-4bf8-87bc-4e8e615b1959, CreationTimestamp2022-07-10T13:11:02.344Z[UTC]] moved to OPEN state
scm1.org_1   | 2022-07-10 13:11:11,657 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 1, healthy pipeline threshold count is 1
scm1.org_1   | 2022-07-10 13:11:11,663 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
scm1.org_1   | 2022-07-10 13:11:11,671 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
scm1.org_1   | 2022-07-10 13:11:11,671 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
scm1.org_1   | 2022-07-10 13:11:11,671 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
scm1.org_1   | 2022-07-10 13:11:11,671 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm1.org_1   | 2022-07-10 13:11:11,672 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
scm1.org_1   | 2022-07-10 13:11:11,672 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO BackgroundPipelineScrubber: Service BackgroundPipelineScrubber transitions to RUNNING.
scm1.org_1   | 2022-07-10 13:11:11,672 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ExpiredContainerReplicaOpScrubber: Service ExpiredContainerReplicaOpScrubber transitions to RUNNING.
scm1.org_1   | 2022-07-10 13:11:11,672 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO replication.ReplicationManager: Service ReplicationManager transitions to RUNNING.
scm1.org_1   | 2022-07-10 13:11:11,673 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN balancer.ContainerBalancer: Could not find persisted configuration for ContainerBalancer when checking if ContainerBalancer should run. ContainerBalancer should not run now.
scm1.org_1   | 2022-07-10 13:11:14,811 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:54940
scm1.org_1   | 2022-07-10 13:11:14,837 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-07-10 13:11:15,134 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:35944
scm1.org_1   | 2022-07-10 13:11:15,140 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-07-10 13:11:15,583 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:59866
scm1.org_1   | 2022-07-10 13:11:15,607 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-07-10 13:11:17,433 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 79d7f9ff-9479-4fdc-a3f9-09a40f9f1d96, Nodes: 257634a0-3792-468a-a5a2-186b5a295fa1{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}a1e412ee-75aa-4bf8-87bc-4e8e615b1959{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}992f3c0d-344e-4060-87f0-890ffe8b867e{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:a1e412ee-75aa-4bf8-87bc-4e8e615b1959, CreationTimestamp2022-07-10T13:11:02.595Z[UTC]] moved to OPEN state
scm1.org_1   | 2022-07-10 13:11:29,843 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:48694
scm1.org_1   | 2022-07-10 13:11:29,889 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-07-10 13:11:42,129 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34214
scm1.org_1   | 2022-07-10 13:11:42,148 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:11:47,448 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:45428
om2_1        | 2022-07-10 13:20:42,125 [IPC Server handler 5 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:42,127 [IPC Server handler 90 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:42,325 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:45439
om2_1        | 2022-07-10 13:20:42,334 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:20:42,772 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:42,774 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:42,776 [IPC Server handler 63 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:43,387 [IPC Server handler 67 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:43,390 [IPC Server handler 83 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:43,392 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:43,394 [IPC Server handler 58 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:44,030 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:44,033 [IPC Server handler 66 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:44,036 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:44,051 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:44,761 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:44,766 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:48,614 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44282
om2_1        | 2022-07-10 13:20:48,617 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:20:52,031 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:52,034 [IPC Server handler 66 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:52,041 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-7750864646 of layout LEGACY in volume: s3v
om2_1        | 2022-07-10 13:20:52,682 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:52,684 [IPC Server handler 37 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:52,686 [IPC Server handler 43 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:52,829 [IPC Server handler 89 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:53,464 [IPC Server handler 71 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:53,466 [IPC Server handler 50 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:53,468 [IPC Server handler 0 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:53,547 [IPC Server handler 31 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:54,193 [IPC Server handler 98 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:54,195 [IPC Server handler 69 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:54,198 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:54,297 [IPC Server handler 85 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:55,001 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:55,003 [IPC Server handler 66 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:55,005 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:55,007 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:55,688 [IPC Server handler 43 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:55,692 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:55,694 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:55,716 [IPC Server handler 63 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:55,734 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:55,745 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyDeleteRequest: Key delete failed. Volume:s3v, Bucket:bucket-ozone-test-7750864646, Key:ozone-test-6291015824/multidelete/key=value/f4.
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1        | Caused by: org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.newError(S3ErrorTable.java:139)
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.newError(S3ErrorTable.java:126)
s3g_1        | 	at org.apache.hadoop.ozone.s3.signature.AuthorizationV4HeaderParser.parseCredentials(AuthorizationV4HeaderParser.java:171)
s3g_1        | 	at org.apache.hadoop.ozone.s3.signature.AuthorizationV4HeaderParser.parseSignature(AuthorizationV4HeaderParser.java:91)
s3g_1        | 	at org.apache.hadoop.ozone.s3.signature.AWSSignatureProcessor.parseSignature(AWSSignatureProcessor.java:70)
s3g_1        | 	at org.apache.hadoop.ozone.s3.signature.AWSSignatureProcessor$Proxy$_$$_WeldClientProxy.parseSignature(Unknown Source)
s3g_1        | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getSignature(OzoneClientProducer.java:81)
s3g_1        | 	... 114 more
s3g_1        | 
s3g_1        | 
s3g_1        | 2022-07-10 13:19:07,220 [qtp1157943921-24] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-6322658386, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-07-10 13:19:07,251 [qtp1157943921-24] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-6322658386
s3g_1        | 2022-07-10 13:19:35,673 [qtp1157943921-21] ERROR endpoint.ObjectEndpoint: Exception occurred in PutObject
s3g_1        | 2022-07-10 13:20:01,606 [qtp1157943921-20] ERROR endpoint.ObjectEndpoint: Exception occurred in PutObject
s3g_1        | 2022-07-10 13:20:02,291 [qtp1157943921-20] ERROR endpoint.ObjectEndpoint: Exception occurred in PutObject
s3g_1        | 2022-07-10 13:20:17,636 [qtp1157943921-22] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-0642987608, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-07-10 13:20:17,657 [qtp1157943921-22] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-0642987608
s3g_1        | 2022-07-10 13:20:18,302 [qtp1157943921-18] INFO rpc.RpcClient: Creating Bucket: s3v/destbucket-81026, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-07-10 13:20:18,322 [qtp1157943921-18] INFO endpoint.BucketEndpoint: Location is /destbucket-81026
s3g_1        | 2022-07-10 13:20:23,428 [qtp1157943921-18] ERROR endpoint.ObjectEndpoint: Exception occurred in PutObject
s3g_1        | 2022-07-10 13:20:24,066 [qtp1157943921-22] ERROR endpoint.ObjectEndpoint: Exception occurred in PutObject
s3g_1        | 2022-07-10 13:20:25,354 [qtp1157943921-18] ERROR endpoint.ObjectEndpoint: Exception occurred in PutObject
s3g_1        | 2022-07-10 13:20:32,581 [qtp1157943921-22] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-7006625698, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-07-10 13:20:32,595 [qtp1157943921-22] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-7006625698
s3g_1        | 2022-07-10 13:20:52,033 [qtp1157943921-18] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-7750864646, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-07-10 13:20:52,047 [qtp1157943921-18] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-7750864646
s3g_1        | 2022-07-10 13:21:03,344 [qtp1157943921-22] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-0984322854, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-07-10 13:21:03,361 [qtp1157943921-22] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-0984322854
s3g_1        | 2022-07-10 13:21:24,256 [qtp1157943921-22] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-2439360640, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-07-10 13:21:24,267 [qtp1157943921-22] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-2439360640
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:175)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:147)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 130 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:11:34,944 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om3 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:248)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:235)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:228)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:175)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:147)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 131 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-07-10 13:11:36,950 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om1 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:248)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:235)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:228)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:175)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:147)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 132 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:11:36,955 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:248)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:235)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:228)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:175)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:147)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
scm1.org_1   | 2022-07-10 13:11:47,465 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:11:48,914 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:47220
scm1.org_1   | 2022-07-10 13:11:48,937 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:11:55,683 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:53076
scm1.org_1   | 2022-07-10 13:11:55,693 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-07-10 13:11:55,754 [IPC Server handler 27 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for containerId, change lastId from 0 to 1000.
scm1.org_1   | 2022-07-10 13:11:55,874 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-StateMachineUpdater] WARN ha.SequenceIdGenerator: Failed to allocate a batch for localId, expected lastId is 0, actual lastId is 109611004723200000.
scm1.org_1   | 2022-07-10 13:11:55,961 [IPC Server handler 27 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for localId, change lastId from 109611004723200000 to 109611004723201000.
scm1.org_1   | 2022-07-10 13:11:58,452 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:55744
scm1.org_1   | 2022-07-10 13:11:58,486 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-07-10 13:11:58,572 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35322
scm1.org_1   | 2022-07-10 13:11:58,588 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-07-10 13:11:58,657 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:51058
scm1.org_1   | 2022-07-10 13:11:58,668 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-07-10 13:11:59,124 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:45919
scm1.org_1   | 2022-07-10 13:11:59,192 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-07-10 13:11:59,196 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:45478
scm1.org_1   | 2022-07-10 13:11:59,219 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34290
scm1.org_1   | 2022-07-10 13:11:59,232 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:11:59,279 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:11:59,282 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:47268
scm1.org_1   | 2022-07-10 13:11:59,379 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:12:16,549 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:53180
scm1.org_1   | 2022-07-10 13:12:16,557 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-07-10 13:12:26,841 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:53200
scm1.org_1   | 2022-07-10 13:12:26,857 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-07-10 13:12:26,928 [IPC Server handler 40 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for delTxnId, change lastId from 0 to 1000.
scm1.org_1   | 2022-07-10 13:12:28,912 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:45596
scm1.org_1   | 2022-07-10 13:12:28,942 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:12:29,086 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:47388
scm1.org_1   | 2022-07-10 13:12:29,109 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34408
scm1.org_1   | 2022-07-10 13:12:29,161 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:12:29,173 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:12:41,119 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:44340
scm1.org_1   | 2022-07-10 13:12:41,130 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-07-10 13:12:58,915 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:45694
scm1.org_1   | 2022-07-10 13:12:58,956 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:12:59,178 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:47488
scm1.org_1   | 2022-07-10 13:12:59,185 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34506
scm1.org_1   | 2022-07-10 13:12:59,195 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:12:59,214 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:13:08,916 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:53356
scm1.org_1   | 2022-07-10 13:13:08,918 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-07-10 13:13:11,209 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:47550
scm1.org_1   | 2022-07-10 13:13:11,238 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34574
scm1.org_1   | 2022-07-10 13:13:11,263 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:45778
scm1.org_1   | 2022-07-10 13:13:11,274 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:13:11,294 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:41921
scm1.org_1   | 2022-07-10 13:13:11,308 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-07-10 13:13:11,373 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:13:11,396 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:13:41,235 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34666
scm1.org_1   | 2022-07-10 13:13:41,300 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:13:41,331 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:47654
scm1.org_1   | 2022-07-10 13:13:41,336 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:45882
scm1.org_1   | 2022-07-10 13:13:41,380 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:13:41,443 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:14:11,264 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34792
scm1.org_1   | 2022-07-10 13:14:11,296 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46004
scm1.org_1   | 2022-07-10 13:14:11,300 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:47770
scm1.org_1   | 2022-07-10 13:14:11,321 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:14:11,333 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:14:11,356 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:14:12,344 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:53632
scm1.org_1   | 2022-07-10 13:14:12,348 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-07-10 13:14:13,540 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm1.org_1   | 2022-07-10 13:14:19,221 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:44722
scm1.org_1   | 2022-07-10 13:14:19,227 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-07-10 13:14:25,521 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:53670
scm1.org_1   | 2022-07-10 13:14:25,530 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-07-10 13:14:32,537 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:44758
scm1.org_1   | 2022-07-10 13:14:32,543 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-07-10 13:14:41,011 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:39137
scm1.org_1   | 2022-07-10 13:14:41,013 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-07-10 13:14:41,283 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:47882
scm1.org_1   | 2022-07-10 13:14:41,343 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34906
scm1.org_1   | 2022-07-10 13:14:41,343 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:09:43,473 [8b10ddc2-41d5-41cc-935f-57a9babc5d91-server-thread2] INFO server.RaftServer$Division: 8b10ddc2-41d5-41cc-935f-57a9babc5d91@group-8EEEA6081008: set configuration 7: [8b10ddc2-41d5-41cc-935f-57a9babc5d91|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, 988d83fb-8298-4167-8ff5-9318a8e0d8d4|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=[988d83fb-8298-4167-8ff5-9318a8e0d8d4|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0]
scm2.org_1   | 2022-07-10 13:09:43,686 [8b10ddc2-41d5-41cc-935f-57a9babc5d91-server-thread2] INFO server.RaftServer$Division: 8b10ddc2-41d5-41cc-935f-57a9babc5d91@group-8EEEA6081008: set configuration 9: [8b10ddc2-41d5-41cc-935f-57a9babc5d91|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, 988d83fb-8298-4167-8ff5-9318a8e0d8d4|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2022-07-10 13:09:43,913 [Listener at 0.0.0.0/9860] INFO ha.SCMHAManagerImpl: Successfully added SCM scm2 to group group-8EEEA6081008:[8b10ddc2-41d5-41cc-935f-57a9babc5d91|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, 988d83fb-8298-4167-8ff5-9318a8e0d8d4|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0]
scm2.org_1   | 2022-07-10 13:09:43,925 [Listener at 0.0.0.0/9860] INFO ha.InterSCMGrpcService: Starting SCM Grpc Service at port 9895
scm2.org_1   | 2022-07-10 13:09:43,946 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Starting token manager
scm2.org_1   | 2022-07-10 13:09:43,947 [Listener at 0.0.0.0/9860] INFO token.ContainerTokenSecretManager: Updating the current master key for generating tokens
scm2.org_1   | 2022-07-10 13:09:43,957 [8b10ddc2-41d5-41cc-935f-57a9babc5d91@group-8EEEA6081008-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-07-10 13:09:43,959 [8b10ddc2-41d5-41cc-935f-57a9babc5d91@group-8EEEA6081008-StateMachineUpdater] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm2.org_1   | 2022-07-10 13:09:43,967 [8b10ddc2-41d5-41cc-935f-57a9babc5d91@group-8EEEA6081008-StateMachineUpdater] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm2.org_1   | 2022-07-10 13:09:44,131 [8b10ddc2-41d5-41cc-935f-57a9babc5d91@group-8EEEA6081008-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-07-10 13:09:44,370 [Listener at 0.0.0.0/9860] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
scm2.org_1   | 2022-07-10 13:09:44,431 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
scm2.org_1   | 2022-07-10 13:09:44,431 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
scm2.org_1   | 2022-07-10 13:09:45,144 [Listener at 0.0.0.0/9860] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
scm2.org_1   | 2022-07-10 13:09:45,163 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm2.org_1   | 2022-07-10 13:09:45,163 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
scm2.org_1   | 2022-07-10 13:09:45,341 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
scm2.org_1   | 2022-07-10 13:09:45,341 [Listener at 0.0.0.0/9860] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
scm2.org_1   | 2022-07-10 13:09:45,342 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm2.org_1   | 2022-07-10 13:09:45,342 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
scm2.org_1   | 2022-07-10 13:09:45,383 [Listener at 0.0.0.0/9860] INFO server.SCMSecurityProtocolServer: Starting RPC server for SCMSecurityProtocolServer. is listening at /0.0.0.0:9961
scm2.org_1   | 2022-07-10 13:09:45,388 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm2.org_1   | 2022-07-10 13:09:45,388 [IPC Server listener on 9961] INFO ipc.Server: IPC Server listener on 9961: starting
scm2.org_1   | 2022-07-10 13:09:45,389 [Listener at 0.0.0.0/9860] INFO server.SCMUpdateServiceGrpcServer: SCMUpdateService starting
scm2.org_1   | 2022-07-10 13:09:45,597 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
scm2.org_1   | 2022-07-10 13:09:45,597 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
scm2.org_1   | 2022-07-10 13:09:45,597 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
scm2.org_1   | 2022-07-10 13:09:46,095 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Persist certificate serialId 844577728582 on Scm Bootstrap Node 8b10ddc2-41d5-41cc-935f-57a9babc5d91
scm2.org_1   | 2022-07-10 13:09:46,105 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Persist certificate serialId 1 on Scm Bootstrap Node 8b10ddc2-41d5-41cc-935f-57a9babc5d91
scm2.org_1   | 2022-07-10 13:09:46,155 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@223c42b0] INFO util.JvmPauseMonitor: Starting JVM pause monitor
scm2.org_1   | 2022-07-10 13:09:46,196 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
scm2.org_1   | 2022-07-10 13:09:46,196 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
scm2.org_1   | 2022-07-10 13:09:46,200 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HttpAuthType: hdds.scm.http.auth.type = kerberos
scm2.org_1   | 2022-07-10 13:09:46,283 [Listener at 0.0.0.0/9860] INFO util.log: Logging initialized @20579ms to org.eclipse.jetty.util.log.Slf4jLog
scm2.org_1   | 2022-07-10 13:09:46,578 [Listener at 0.0.0.0/9860] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
scm2.org_1   | 2022-07-10 13:09:46,619 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
scm2.org_1   | 2022-07-10 13:09:46,620 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context scm
scm2.org_1   | 2022-07-10 13:09:46,620 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
scm2.org_1   | 2022-07-10 13:09:46,620 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
scm2.org_1   | 2022-07-10 13:09:46,623 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.scm.http.auth.kerberos.principal keytabKey: hdds.scm.http.auth.kerberos.keytab
scm2.org_1   | 2022-07-10 13:09:46,725 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Jetty bound to port 9876
scm2.org_1   | 2022-07-10 13:09:46,726 [Listener at 0.0.0.0/9860] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
scm2.org_1   | 2022-07-10 13:09:46,947 [Listener at 0.0.0.0/9860] INFO server.session: DefaultSessionIdManager workerName=node0
scm2.org_1   | 2022-07-10 13:09:46,948 [Listener at 0.0.0.0/9860] INFO server.session: No SessionScavenger set, using defaults
scm2.org_1   | 2022-07-10 13:09:46,950 [Listener at 0.0.0.0/9860] INFO server.session: node0 Scavenging every 600000ms
scm1.org_1   | 2022-07-10 13:14:41,345 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46114
scm1.org_1   | 2022-07-10 13:14:41,363 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:14:41,364 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:15:11,247 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48008
scm1.org_1   | 2022-07-10 13:15:11,284 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:15:11,342 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35026
scm1.org_1   | 2022-07-10 13:15:11,347 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:15:11,361 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46232
scm1.org_1   | 2022-07-10 13:15:11,374 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:15:26,788 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:53900
scm1.org_1   | 2022-07-10 13:15:26,796 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-07-10 13:15:41,284 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35128
scm1.org_1   | 2022-07-10 13:15:41,285 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48120
scm1.org_1   | 2022-07-10 13:15:41,307 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:15:41,330 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46348
scm1.org_1   | 2022-07-10 13:15:41,334 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:15:41,369 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:16:11,337 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48230
scm1.org_1   | 2022-07-10 13:16:11,337 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35248
scm1.org_1   | 2022-07-10 13:16:11,345 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:16:11,361 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46464
scm1.org_1   | 2022-07-10 13:16:11,362 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:16:11,367 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:16:27,527 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:54128
scm1.org_1   | 2022-07-10 13:16:27,530 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-07-10 13:16:34,267 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:45216
scm1.org_1   | 2022-07-10 13:16:34,278 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-07-10 13:16:41,286 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46570
scm1.org_1   | 2022-07-10 13:16:41,292 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35364
scm1.org_1   | 2022-07-10 13:16:41,295 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:16:41,302 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48338
scm1.org_1   | 2022-07-10 13:16:41,303 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:16:41,311 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:17:11,292 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46678
scm1.org_1   | 2022-07-10 13:17:11,349 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:17:11,375 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48438
scm1.org_1   | 2022-07-10 13:17:11,379 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35458
scm3.org_1   | Sleeping for 5 seconds
scm3.org_1   | Waiting for the service scm2.org:9894
scm3.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm3.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm3.org_1   | 2022-07-10 13:09:44,823 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm3.org_1   | /************************************************************
scm3.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm3.org_1   | STARTUP_MSG:   host = scm3.org/172.25.0.118
scm3.org_1   | STARTUP_MSG:   args = [--bootstrap]
scm3.org_1   | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
om2_1        | KEY_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Key not found
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:152)
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:98)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-07-10 13:20:56,382 [IPC Server handler 49 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:56,384 [IPC Server handler 67 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:56,386 [IPC Server handler 54 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:20:56,389 [IPC Server handler 83 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:21:00,103 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44322
om2_1        | 2022-07-10 13:21:00,108 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:21:03,342 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:21:03,346 [IPC Server handler 57 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:21:03,359 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-0984322854 of layout LEGACY in volume: s3v
om2_1        | 2022-07-10 13:21:04,030 [IPC Server handler 88 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:21:04,038 [IPC Server handler 76 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:21:04,041 [IPC Server handler 62 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:21:04,117 [IPC Server handler 7 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:21:04,787 [IPC Server handler 89 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:21:04,790 [IPC Server handler 68 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:21:04,791 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:21:04,795 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:21:05,446 [IPC Server handler 96 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:21:05,448 [IPC Server handler 71 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:21:05,450 [IPC Server handler 50 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:21:05,482 [IPC Server handler 0 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:21:06,144 [IPC Server handler 74 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:21:06,149 [IPC Server handler 8 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:21:06,151 [IPC Server handler 6 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:21:06,153 [IPC Server handler 2 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:21:06,789 [IPC Server handler 89 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:21:06,791 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:21:06,797 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:21:06,836 [IPC Server handler 94 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:21:07,534 [IPC Server handler 31 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:21:07,536 [IPC Server handler 80 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:21:07,538 [IPC Server handler 53 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:21:07,547 [IPC Server handler 82 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:21:08,213 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:21:08,222 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:21:08,224 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:21:08,237 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:21:08,903 [IPC Server handler 41 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
scm1.org_1   | 2022-07-10 13:17:11,381 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:17:11,387 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:17:41,190 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46928
scm1.org_1   | 2022-07-10 13:17:41,241 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35706
scm1.org_1   | 2022-07-10 13:17:41,269 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:17:41,273 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:17:41,304 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48704
scm1.org_1   | 2022-07-10 13:17:41,374 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:17:50,886 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:54576
scm1.org_1   | 2022-07-10 13:17:50,894 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-07-10 13:18:09,725 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:45714
scm1.org_1   | 2022-07-10 13:18:09,727 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-07-10 13:18:11,226 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48822
scm1.org_1   | 2022-07-10 13:18:11,254 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35836
scm1.org_1   | 2022-07-10 13:18:11,292 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:18:11,425 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:18:11,448 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47054
scm1.org_1   | 2022-07-10 13:18:11,484 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:18:26,797 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:54722
scm1.org_1   | 2022-07-10 13:18:26,799 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-07-10 13:18:41,284 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35942
scm1.org_1   | 2022-07-10 13:18:41,289 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:18:41,292 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47158
scm1.org_1   | 2022-07-10 13:18:41,303 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48930
scm1.org_1   | 2022-07-10 13:18:41,324 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:18:41,330 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:19:08,744 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:54866
scm1.org_1   | 2022-07-10 13:19:08,747 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-07-10 13:19:11,235 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49058
scm1.org_1   | 2022-07-10 13:19:11,253 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36068
scm1.org_1   | 2022-07-10 13:19:11,272 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:19:11,277 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:19:11,309 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47282
scm1.org_1   | 2022-07-10 13:19:11,319 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:19:11,928 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:45988
scm1.org_1   | 2022-07-10 13:19:11,939 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-07-10 13:19:13,542 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 2 milliseconds for processing 2 containers.
scm1.org_1   | 2022-07-10 13:19:32,741 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:46070
scm3.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar
scm3.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/d088d199bf506d76f7046a4b19b690e2a9e6915e ; compiled by 'runner' on 2022-07-10T12:45Z
scm3.org_1   | STARTUP_MSG:   java = 11.0.14.1
scm3.org_1   | ************************************************************/
scm3.org_1   | 2022-07-10 13:09:44,877 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm3.org_1   | 2022-07-10 13:09:45,113 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm3.org_1   | 2022-07-10 13:09:45,225 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm3.org_1   | 2022-07-10 13:09:45,226 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm3.org_1   | 2022-07-10 13:09:45,306 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm3, RPC Address: scm3.org:9894 and Ratis port: 9894
scm3.org_1   | 2022-07-10 13:09:45,307 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm3: scm3.org
scm3.org_1   | 2022-07-10 13:09:45,723 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
scm3.org_1   | 2022-07-10 13:09:45,727 [main] INFO server.StorageContainerManager: SCM login successful.
scm3.org_1   | 2022-07-10 13:09:45,880 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 2 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863]
scm3.org_1   | 2022-07-10 13:09:46,743 [main] INFO ha.HASecurityUtils: Initializing secure StorageContainerManager.
scm3.org_1   | 2022-07-10 13:09:48,066 [main] ERROR client.SCMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
scm3.org_1   | 2022-07-10 13:09:48,067 [main] INFO client.SCMCertificateClient: Certificate client init case: 0
scm3.org_1   | 2022-07-10 13:09:48,072 [main] INFO client.SCMCertificateClient: Creating keypair for client as keypair and certificate not found.
scm3.org_1   | 2022-07-10 13:09:49,622 [main] INFO ha.HASecurityUtils: Init response: GETCERT
scm3.org_1   | 2022-07-10 13:09:49,711 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.118,host:scm3.org
scm3.org_1   | 2022-07-10 13:09:49,712 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
scm3.org_1   | 2022-07-10 13:09:49,721 [main] INFO ha.HASecurityUtils: Creating csr for SCM->hostName:scm3.org,scmId:6f9a84f7-8019-4c66-ba45-e86fba2381f6,clusterId:CID-f578972c-97f6-4a12-a46c-8eeea6081008,subject:scm-sub@scm3.org
scm3.org_1   | 2022-07-10 13:09:50,513 [main] INFO ha.HASecurityUtils: Successfully stored SCM signed certificate.
scm3.org_1   | 2022-07-10 13:09:50,533 [main] INFO server.StorageContainerManager: SCM BootStrap  is successful for ClusterID CID-f578972c-97f6-4a12-a46c-8eeea6081008, SCMID 6f9a84f7-8019-4c66-ba45-e86fba2381f6
scm3.org_1   | 2022-07-10 13:09:50,533 [main] INFO server.StorageContainerManager: Primary SCM Node ID 988d83fb-8298-4167-8ff5-9318a8e0d8d4
scm3.org_1   | 2022-07-10 13:09:50,572 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
scm3.org_1   | /************************************************************
scm3.org_1   | SHUTDOWN_MSG: Shutting down StorageContainerManager at scm3.org/172.25.0.118
scm3.org_1   | ************************************************************/
scm3.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm3.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm3.org_1   | 2022-07-10 13:09:51,807 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm3.org_1   | /************************************************************
scm3.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm3.org_1   | STARTUP_MSG:   host = scm3.org/172.25.0.118
scm3.org_1   | STARTUP_MSG:   args = []
scm3.org_1   | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
om2_1        | 2022-07-10 13:21:08,905 [IPC Server handler 65 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:21:08,907 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:21:08,917 [IPC Server handler 66 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:21:09,581 [IPC Server handler 77 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:21:09,583 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:21:09,585 [IPC Server handler 37 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:21:10,227 [IPC Server handler 97 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:21:10,229 [IPC Server handler 10 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:21:10,235 [IPC Server handler 78 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:21:10,246 [IPC Server handler 45 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:21:10,911 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:21:10,914 [IPC Server handler 66 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:21:10,917 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:21:10,925 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:21:11,807 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:21:11,810 [IPC Server handler 94 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:21:11,813 [IPC Server handler 41 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:21:11,823 [IPC Server handler 65 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:21:12,492 [IPC Server handler 0 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:21:12,496 [IPC Server handler 99 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:21:12,498 [IPC Server handler 31 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:21:12,507 [IPC Server handler 80 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:21:13,175 [IPC Server handler 39 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:21:13,178 [IPC Server handler 98 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:21:13,180 [IPC Server handler 69 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:21:13,187 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:21:13,853 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:21:13,855 [IPC Server handler 66 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:21:13,857 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:21:13,865 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:21:14,567 [IPC Server handler 77 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:21:14,569 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:21:14,572 [IPC Server handler 37 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:21:14,581 [IPC Server handler 43 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:21:15,230 [IPC Server handler 10 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:21:15,236 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:21:15,239 [IPC Server handler 78 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:21:15,257 [IPC Server handler 45 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:21:15,933 [IPC Server handler 88 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:21:15,935 [IPC Server handler 76 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:21:15,937 [IPC Server handler 62 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:21:16,570 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:21:16,572 [IPC Server handler 37 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:21:16,579 [IPC Server handler 43 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:21:17,245 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
scm1.org_1   | 2022-07-10 13:19:32,747 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-07-10 13:19:41,050 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:38149
scm1.org_1   | 2022-07-10 13:19:41,064 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-07-10 13:19:41,231 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49212
scm1.org_1   | 2022-07-10 13:19:41,232 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47436
scm1.org_1   | 2022-07-10 13:19:41,239 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36220
scm1.org_1   | 2022-07-10 13:19:41,261 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:19:41,304 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:19:41,324 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:19:44,639 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:46156
scm1.org_1   | 2022-07-10 13:19:44,649 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-07-10 13:20:11,302 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36382
scm1.org_1   | 2022-07-10 13:20:11,312 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47592
scm1.org_1   | 2022-07-10 13:20:11,314 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:20:11,316 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49370
scm1.org_1   | 2022-07-10 13:20:11,322 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:20:11,326 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:20:18,982 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:55250
scm1.org_1   | 2022-07-10 13:20:18,984 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-07-10 13:20:20,397 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:46328
scm1.org_1   | 2022-07-10 13:20:20,400 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-07-10 13:20:34,658 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:46380
scm1.org_1   | 2022-07-10 13:20:34,661 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-07-10 13:20:41,329 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36530
scm1.org_1   | 2022-07-10 13:20:41,338 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49508
scm1.org_1   | 2022-07-10 13:20:41,345 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:20:41,348 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47738
scm1.org_1   | 2022-07-10 13:20:41,373 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:20:41,383 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:20:52,711 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:55404
scm1.org_1   | 2022-07-10 13:20:52,712 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-07-10 13:21:06,823 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:46530
scm1.org_1   | 2022-07-10 13:21:06,825 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-07-10 13:21:11,243 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49652
scm1.org_1   | 2022-07-10 13:21:11,269 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36676
scm1.org_1   | 2022-07-10 13:21:11,271 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47884
scm1.org_1   | 2022-07-10 13:21:11,287 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:21:11,310 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar
scm3.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/d088d199bf506d76f7046a4b19b690e2a9e6915e ; compiled by 'runner' on 2022-07-10T12:45Z
scm3.org_1   | STARTUP_MSG:   java = 11.0.14.1
scm3.org_1   | ************************************************************/
scm3.org_1   | 2022-07-10 13:09:51,820 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm3.org_1   | 2022-07-10 13:09:51,999 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm3.org_1   | 2022-07-10 13:09:52,088 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm3.org_1   | 2022-07-10 13:09:52,111 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm3.org_1   | 2022-07-10 13:09:52,205 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm3, RPC Address: scm3.org:9894 and Ratis port: 9894
scm3.org_1   | 2022-07-10 13:09:52,205 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm3: scm3.org
scm3.org_1   | 2022-07-10 13:09:53,091 [main] INFO client.SCMCertificateClient: Loading certificate from location:/data/metadata/scm/sub-ca/certs.
scm3.org_1   | 2022-07-10 13:09:53,248 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/certificate.crt.
scm3.org_1   | 2022-07-10 13:09:53,251 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/894205468497.crt.
scm3.org_1   | 2022-07-10 13:09:53,260 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/CA-1.crt.
scm3.org_1   | 2022-07-10 13:09:53,423 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
scm3.org_1   | 2022-07-10 13:09:53,426 [main] INFO server.StorageContainerManager: SCM login successful.
scm3.org_1   | 2022-07-10 13:09:53,491 [main] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm3.org_1   | 2022-07-10 13:09:53,766 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 133 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:11:36,968 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om3 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:248)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:235)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:228)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:175)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:147)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 134 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-07-10 13:11:38,973 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om1 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:248)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:235)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:228)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:175)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:147)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 135 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:11:38,976 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:248)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:235)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:228)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:175)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:147)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm1.org_1   | 2022-07-10 13:21:11,335 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:21:26,799 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:55566
scm1.org_1   | 2022-07-10 13:21:26,808 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-07-10 13:21:39,547 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:55592
scm1.org_1   | 2022-07-10 13:21:39,549 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-07-10 13:21:41,228 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36776
scm1.org_1   | 2022-07-10 13:21:41,266 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:21:41,292 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49768
scm1.org_1   | 2022-07-10 13:21:41,293 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47992
scm1.org_1   | 2022-07-10 13:21:41,306 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:21:41,319 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:21:47,304 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:37352
scm1.org_1   | 2022-07-10 13:21:47,324 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-07-10 13:21:47,678 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:51338
scm1.org_1   | 2022-07-10 13:21:47,687 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-07-10 13:21:47,718 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 4b252efb-01a1-4e01-91ab-55e9b6197fe7, Nodes: 992f3c0d-344e-4060-87f0-890ffe8b867e{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: STANDALONE/ONE, State:OPEN, leaderId:, CreationTimestamp2022-07-10T13:21:47.707Z[UTC]].
scm1.org_1   | 2022-07-10 13:21:49,858 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:45605
scm1.org_1   | 2022-07-10 13:21:49,863 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-07-10 13:21:53,881 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:51352
scm1.org_1   | 2022-07-10 13:21:53,900 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-07-10 13:21:57,913 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:51364
scm1.org_1   | 2022-07-10 13:21:57,939 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-07-10 13:22:02,266 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:51376
scm1.org_1   | 2022-07-10 13:22:02,283 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-07-10 13:22:06,281 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:51380
scm1.org_1   | 2022-07-10 13:22:06,303 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-07-10 13:22:10,460 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:51402
scm1.org_1   | 2022-07-10 13:22:10,481 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-07-10 13:22:11,257 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36882
scm1.org_1   | 2022-07-10 13:22:11,277 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:22:11,304 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48090
scm1.org_1   | 2022-07-10 13:22:11,312 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:22:14,553 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:51430
scm1.org_1   | 2022-07-10 13:22:14,582 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-07-10 13:22:18,786 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:51444
scm2.org_1   | 2022-07-10 13:09:47,014 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm2.org_1   | 2022-07-10 13:09:47,025 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@631990cc{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
scm2.org_1   | 2022-07-10 13:09:47,026 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@47814094{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
scm2.org_1   | 2022-07-10 13:09:47,308 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm2.org_1   | 2022-07-10 13:09:47,342 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@52072c45{scm,/,file:///tmp/jetty-0_0_0_0-9876-hdds-server-scm-1_3_0-SNAPSHOT_jar-_-any-5805176658926333404/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar!/webapps/scm}
scm2.org_1   | 2022-07-10 13:09:47,376 [Listener at 0.0.0.0/9860] INFO server.AbstractConnector: Started ServerConnector@74cf108b{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
scm2.org_1   | 2022-07-10 13:09:47,376 [Listener at 0.0.0.0/9860] INFO server.Server: Started @21673ms
scm2.org_1   | 2022-07-10 13:09:47,403 [Listener at 0.0.0.0/9860] INFO impl.MetricsSinkAdapter: Sink prometheus started
scm2.org_1   | 2022-07-10 13:09:47,403 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Registered sink prometheus
scm2.org_1   | 2022-07-10 13:09:47,408 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
scm2.org_1   | 2022-07-10 13:09:50,419 [8b10ddc2-41d5-41cc-935f-57a9babc5d91@group-8EEEA6081008-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-07-10 13:10:04,487 [8b10ddc2-41d5-41cc-935f-57a9babc5d91-server-thread2] INFO server.RaftServer$Division: 8b10ddc2-41d5-41cc-935f-57a9babc5d91@group-8EEEA6081008: set configuration 13: [8b10ddc2-41d5-41cc-935f-57a9babc5d91|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, 988d83fb-8298-4167-8ff5-9318a8e0d8d4|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 6f9a84f7-8019-4c66-ba45-e86fba2381f6|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0], old=[8b10ddc2-41d5-41cc-935f-57a9babc5d91|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, 988d83fb-8298-4167-8ff5-9318a8e0d8d4|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0]
scm2.org_1   | 2022-07-10 13:10:04,547 [8b10ddc2-41d5-41cc-935f-57a9babc5d91-server-thread2] INFO server.RaftServer$Division: 8b10ddc2-41d5-41cc-935f-57a9babc5d91@group-8EEEA6081008: set configuration 15: [8b10ddc2-41d5-41cc-935f-57a9babc5d91|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, 988d83fb-8298-4167-8ff5-9318a8e0d8d4|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 6f9a84f7-8019-4c66-ba45-e86fba2381f6|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2022-07-10 13:10:29,251 [8b10ddc2-41d5-41cc-935f-57a9babc5d91@group-8EEEA6081008-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-07-10 13:10:29,545 [8b10ddc2-41d5-41cc-935f-57a9babc5d91@group-8EEEA6081008-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-07-10 13:10:32,183 [8b10ddc2-41d5-41cc-935f-57a9babc5d91@group-8EEEA6081008-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-07-10 13:10:34,624 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$466/0x0000000840529840@487f025] WARN util.JvmPauseMonitor: JvmPauseMonitor-8b10ddc2-41d5-41cc-935f-57a9babc5d91: Detected pause in JVM or host machine (eg GC): pause of approximately 117863759ns.
scm2.org_1   | GC pool 'ParNew' had collection(s): count=1 time=164ms
scm2.org_1   | 2022-07-10 13:10:36,947 [8b10ddc2-41d5-41cc-935f-57a9babc5d91@group-8EEEA6081008-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-07-10 13:10:37,548 [8b10ddc2-41d5-41cc-935f-57a9babc5d91@group-8EEEA6081008-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-07-10 13:10:38,544 [8b10ddc2-41d5-41cc-935f-57a9babc5d91@group-8EEEA6081008-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-07-10 13:10:52,764 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:43250
scm2.org_1   | 2022-07-10 13:10:52,843 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:10:54,288 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:41670
scm2.org_1   | 2022-07-10 13:10:54,642 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:10:58,185 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:40488
scm2.org_1   | 2022-07-10 13:10:58,211 [IPC Server handler 30 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/992f3c0d-344e-4060-87f0-890ffe8b867e
scm2.org_1   | 2022-07-10 13:10:58,249 [IPC Server handler 30 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 992f3c0d-344e-4060-87f0-890ffe8b867e{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 933105602287, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm2.org_1   | 2022-07-10 13:10:58,334 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:10:58,402 [IPC Server handler 21 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/a1e412ee-75aa-4bf8-87bc-4e8e615b1959
scm2.org_1   | 2022-07-10 13:10:58,451 [IPC Server handler 21 on default port 9861] INFO node.SCMNodeManager: Registered Data node : a1e412ee-75aa-4bf8-87bc-4e8e615b1959{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 933456427477, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm2.org_1   | 2022-07-10 13:10:58,383 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 3 required.
scm2.org_1   | 2022-07-10 13:10:58,450 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm2.org_1   | 2022-07-10 13:10:58,467 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm2.org_1   | 2022-07-10 13:10:58,469 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 3 required.
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 136 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:11:38,980 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om3 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:248)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:235)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:228)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:175)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:147)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 137 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-07-10 13:11:40,992 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om1 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:248)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:235)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:228)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:175)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:147)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 138 failover attempts. Trying to failover immediately.
recon_1      | 2022-07-10 13:11:41,791 [pool-28-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om2:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
om2_1        | 2022-07-10 13:21:17,248 [IPC Server handler 78 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:21:17,251 [IPC Server handler 45 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:21:20,816 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44434
om2_1        | 2022-07-10 13:21:20,821 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:21:24,253 [IPC Server handler 45 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:21:24,258 [IPC Server handler 56 on default port 9862] INFO security.AWSV4AuthValidator: 0e1624586d81beeeed49a246e334b9db2770f40a5c9aa08b94d0985727504dda
om2_1        | 2022-07-10 13:21:24,265 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-2439360640 of layout LEGACY in volume: s3v
om2_1        | 2022-07-10 13:21:39,003 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44474
om2_1        | 2022-07-10 13:21:39,006 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:21:42,367 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:43401
om2_1        | 2022-07-10 13:21:42,379 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:22:42,415 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:45899
om2_1        | 2022-07-10 13:22:42,430 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:23:42,477 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:40787
om2_1        | 2022-07-10 13:23:42,503 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-07-10 13:24:42,566 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:33151
om2_1        | 2022-07-10 13:24:42,570 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2022-07-10 13:10:59,741 [8b10ddc2-41d5-41cc-935f-57a9babc5d91@group-8EEEA6081008-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: b77b6ac4-c103-4125-90f3-f25d482aaf22, Nodes: 992f3c0d-344e-4060-87f0-890ffe8b867e{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-07-10T13:10:58.769Z[UTC]].
scm2.org_1   | 2022-07-10 13:10:59,830 [8b10ddc2-41d5-41cc-935f-57a9babc5d91@group-8EEEA6081008-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-07-10 13:10:59,840 [8b10ddc2-41d5-41cc-935f-57a9babc5d91@group-8EEEA6081008-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: b1d72510-c7b3-4886-b6f1-097f02077230, Nodes: a1e412ee-75aa-4bf8-87bc-4e8e615b1959{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-07-10T13:10:59.707Z[UTC]].
scm2.org_1   | 2022-07-10 13:10:59,844 [8b10ddc2-41d5-41cc-935f-57a9babc5d91@group-8EEEA6081008-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-07-10 13:11:01,636 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: b77b6ac4-c103-4125-90f3-f25d482aaf22, Nodes: 992f3c0d-344e-4060-87f0-890ffe8b867e{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:992f3c0d-344e-4060-87f0-890ffe8b867e, CreationTimestamp2022-07-10T13:10:58.769Z[UTC]] moved to OPEN state
scm2.org_1   | 2022-07-10 13:11:01,789 [IPC Server handler 99 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/257634a0-3792-468a-a5a2-186b5a295fa1
scm2.org_1   | 2022-07-10 13:11:01,799 [IPC Server handler 99 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 257634a0-3792-468a-a5a2-186b5a295fa1{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 935900506483, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm2.org_1   | 2022-07-10 13:11:01,809 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm2.org_1   | 2022-07-10 13:11:01,983 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 3 required.
scm2.org_1   | 2022-07-10 13:11:02,051 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm2.org_1   | 2022-07-10 13:11:02,052 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
scm2.org_1   | 2022-07-10 13:11:02,052 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm2.org_1   | 2022-07-10 13:11:02,156 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
scm2.org_1   | 2022-07-10 13:11:02,184 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm2.org_1   | 2022-07-10 13:11:02,184 [8b10ddc2-41d5-41cc-935f-57a9babc5d91@group-8EEEA6081008-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-07-10 13:11:02,233 [8b10ddc2-41d5-41cc-935f-57a9babc5d91@group-8EEEA6081008-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 8d6e1a79-b70d-40e6-a234-6dc84a45f007, Nodes: 257634a0-3792-468a-a5a2-186b5a295fa1{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-07-10T13:11:01.880Z[UTC]].
scm2.org_1   | 2022-07-10 13:11:02,234 [8b10ddc2-41d5-41cc-935f-57a9babc5d91@group-8EEEA6081008-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-07-10 13:11:02,440 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: b1d72510-c7b3-4886-b6f1-097f02077230, Nodes: a1e412ee-75aa-4bf8-87bc-4e8e615b1959{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:a1e412ee-75aa-4bf8-87bc-4e8e615b1959, CreationTimestamp2022-07-10T13:10:59.707Z[UTC]] moved to OPEN state
scm2.org_1   | 2022-07-10 13:11:02,557 [8b10ddc2-41d5-41cc-935f-57a9babc5d91@group-8EEEA6081008-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 199762fc-7613-447a-a2fc-b841d041c364, Nodes: 257634a0-3792-468a-a5a2-186b5a295fa1{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}a1e412ee-75aa-4bf8-87bc-4e8e615b1959{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}992f3c0d-344e-4060-87f0-890ffe8b867e{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-07-10T13:11:02.344Z[UTC]].
scm2.org_1   | 2022-07-10 13:11:02,557 [8b10ddc2-41d5-41cc-935f-57a9babc5d91@group-8EEEA6081008-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-07-10 13:11:42,077 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34896
recon_1      | 2022-07-10 13:11:42,105 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-07-10 13:11:47,408 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47460
recon_1      | 2022-07-10 13:11:47,463 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-07-10 13:11:48,917 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:42142
recon_1      | 2022-07-10 13:11:48,968 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-07-10 13:11:59,001 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47508
recon_1      | 2022-07-10 13:11:59,045 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-07-10 13:11:59,088 [FixedThreadPoolWithAffinityExecutor-0-0] INFO scm.ReconContainerManager: New container #1 got from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net.
recon_1      | 2022-07-10 13:11:59,144 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34976
recon_1      | 2022-07-10 13:11:59,192 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:42190
recon_1      | 2022-07-10 13:11:59,218 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-07-10 13:11:59,223 [FixedThreadPoolWithAffinityExecutor-1-0] INFO scm.ReconContainerManager: New container #1 got from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net.
recon_1      | 2022-07-10 13:11:59,285 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-07-10 13:11:59,288 [FixedThreadPoolWithAffinityExecutor-8-0] INFO scm.ReconContainerManager: New container #1 got from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net.
recon_1      | 2022-07-10 13:11:59,343 [FixedThreadPoolWithAffinityExecutor-1-0] INFO scm.ReconContainerManager: Successfully added container #1 to Recon.
recon_1      | 2022-07-10 13:11:59,350 [FixedThreadPoolWithAffinityExecutor-0-0] INFO scm.ReconContainerManager: Successfully added container #1 to Recon.
recon_1      | 2022-07-10 13:11:59,381 [FixedThreadPoolWithAffinityExecutor-8-0] INFO scm.ReconContainerManager: Successfully added container #1 to Recon.
recon_1      | 2022-07-10 13:12:28,890 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47626
recon_1      | 2022-07-10 13:12:28,914 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-07-10 13:12:29,093 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:42310
recon_1      | 2022-07-10 13:12:29,119 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm2.org_1   | 2022-07-10 13:11:02,720 [8b10ddc2-41d5-41cc-935f-57a9babc5d91@group-8EEEA6081008-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 79d7f9ff-9479-4fdc-a3f9-09a40f9f1d96, Nodes: 257634a0-3792-468a-a5a2-186b5a295fa1{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}a1e412ee-75aa-4bf8-87bc-4e8e615b1959{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}992f3c0d-344e-4060-87f0-890ffe8b867e{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-07-10T13:11:02.595Z[UTC]].
scm2.org_1   | 2022-07-10 13:11:02,720 [8b10ddc2-41d5-41cc-935f-57a9babc5d91@group-8EEEA6081008-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-07-10 13:11:02,871 [8b10ddc2-41d5-41cc-935f-57a9babc5d91@group-8EEEA6081008-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-07-10 13:11:03,450 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm2.org_1   | 2022-07-10 13:11:05,788 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 8d6e1a79-b70d-40e6-a234-6dc84a45f007, Nodes: 257634a0-3792-468a-a5a2-186b5a295fa1{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:257634a0-3792-468a-a5a2-186b5a295fa1, CreationTimestamp2022-07-10T13:11:01.880Z[UTC]] moved to OPEN state
scm2.org_1   | 2022-07-10 13:11:05,831 [8b10ddc2-41d5-41cc-935f-57a9babc5d91@group-8EEEA6081008-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-07-10 13:11:06,924 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm2.org_1   | 2022-07-10 13:11:07,717 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm2.org_1   | 2022-07-10 13:11:08,473 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm2.org_1   | 2022-07-10 13:11:11,528 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm2.org_1   | 2022-07-10 13:11:11,642 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 199762fc-7613-447a-a2fc-b841d041c364, Nodes: 257634a0-3792-468a-a5a2-186b5a295fa1{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}a1e412ee-75aa-4bf8-87bc-4e8e615b1959{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}992f3c0d-344e-4060-87f0-890ffe8b867e{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:a1e412ee-75aa-4bf8-87bc-4e8e615b1959, CreationTimestamp2022-07-10T13:11:02.344Z[UTC]] moved to OPEN state
scm2.org_1   | 2022-07-10 13:11:11,643 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm2.org_1   | 2022-07-10 13:11:11,704 [8b10ddc2-41d5-41cc-935f-57a9babc5d91@group-8EEEA6081008-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 1, healthy pipeline threshold count is 1
scm2.org_1   | 2022-07-10 13:11:11,906 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm2.org_1   | 2022-07-10 13:11:11,907 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
scm2.org_1   | 2022-07-10 13:11:11,907 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
scm2.org_1   | 2022-07-10 13:11:11,907 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
scm2.org_1   | 2022-07-10 13:11:11,907 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
scm2.org_1   | 2022-07-10 13:11:11,907 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm2.org_1   | 2022-07-10 13:11:11,908 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
scm2.org_1   | 2022-07-10 13:11:17,417 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 79d7f9ff-9479-4fdc-a3f9-09a40f9f1d96, Nodes: 257634a0-3792-468a-a5a2-186b5a295fa1{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}a1e412ee-75aa-4bf8-87bc-4e8e615b1959{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}992f3c0d-344e-4060-87f0-890ffe8b867e{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:a1e412ee-75aa-4bf8-87bc-4e8e615b1959, CreationTimestamp2022-07-10T13:11:02.595Z[UTC]] moved to OPEN state
scm1.org_1   | 2022-07-10 13:22:18,803 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-07-10 13:22:19,864 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49910
scm1.org_1   | 2022-07-10 13:22:19,889 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:22:19,914 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:45509
scm1.org_1   | 2022-07-10 13:22:19,920 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-07-10 13:22:22,947 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:51456
scm1.org_1   | 2022-07-10 13:22:22,965 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-07-10 13:22:26,904 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:51468
scm1.org_1   | 2022-07-10 13:22:26,927 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-07-10 13:22:27,147 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #1
scm1.org_1   | 2022-07-10 13:22:31,101 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:51480
scm1.org_1   | 2022-07-10 13:22:31,122 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-07-10 13:22:35,135 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:51484
scm1.org_1   | 2022-07-10 13:22:35,156 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-07-10 13:22:41,222 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36972
scm1.org_1   | 2022-07-10 13:22:41,242 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:22:41,252 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48180
scm1.org_1   | 2022-07-10 13:22:41,278 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:22:42,292 [FixedThreadPoolWithAffinityExecutor-1-0] INFO container.IncrementalContainerReportHandler: Moving container #1 to CLOSED state, datanode a1e412ee-75aa-4bf8-87bc-4e8e615b1959{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} reported CLOSED replica.
scm1.org_1   | 2022-07-10 13:22:42,365 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49972
scm1.org_1   | 2022-07-10 13:22:42,394 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:22:49,389 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:51538
scm1.org_1   | 2022-07-10 13:22:49,441 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-07-10 13:22:56,456 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:51552
scm1.org_1   | 2022-07-10 13:22:56,474 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-07-10 13:22:56,477 [IPC Server handler 11 on default port 9860] INFO ipc.Server: IPC Server handler 11 on default port 9860, call Call#0 Retry#0 org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol.submitRequest from 172.25.0.116:51552
scm1.org_1   | org.apache.hadoop.security.AccessControlException: Access denied for user testuser2/scm@EXAMPLE.COM. Superuser privilege is required.
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.server.StorageContainerManager.checkAdminAccess(StorageContainerManager.java:1777)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.server.SCMClientProtocolServer.getContainer(SCMClientProtocolServer.java:223)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.getContainer(StorageContainerLocationProtocolServerSideTranslatorPB.java:683)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.processRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:404)
scm1.org_1   | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:213)
scm1.org_1   | 	at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:61195)
scm1.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
scm1.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
scm1.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
scm1.org_1   | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
scm1.org_1   | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm1.org_1   | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm1.org_1   | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 2022-07-10 13:12:29,159 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35092
recon_1      | 2022-07-10 13:12:29,189 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-07-10 13:12:41,804 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-07-10 13:12:41,804 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-07-10 13:12:41,865 [pool-28-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om2:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-07-10 13:12:58,887 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47724
recon_1      | 2022-07-10 13:12:58,903 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-07-10 13:12:59,089 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:42406
recon_1      | 2022-07-10 13:12:59,105 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35192
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
scm1.org_1   | 2022-07-10 13:23:00,462 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:37572
scm1.org_1   | 2022-07-10 13:23:00,484 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-07-10 13:23:00,818 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:51566
scm1.org_1   | 2022-07-10 13:23:00,825 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-07-10 13:23:00,825 [IPC Server handler 94 on default port 9860] INFO ipc.Server: IPC Server handler 94 on default port 9860, call Call#1 Retry#0 org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol.submitRequest from 172.25.0.116:51566
scm1.org_1   | org.apache.hadoop.security.AccessControlException: Access denied for user testuser2/scm@EXAMPLE.COM. Superuser privilege is required.
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.server.StorageContainerManager.checkAdminAccess(StorageContainerManager.java:1777)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.server.SCMClientProtocolServer.allocateContainer(SCMClientProtocolServer.java:203)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.allocateContainer(StorageContainerLocationProtocolServerSideTranslatorPB.java:672)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.processRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:396)
scm1.org_1   | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:213)
scm1.org_1   | 	at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:61195)
scm1.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
scm1.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
scm1.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
scm1.org_1   | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
scm1.org_1   | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm1.org_1   | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm1.org_1   | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
scm1.org_1   | 2022-07-10 13:23:04,298 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:51570
scm1.org_1   | 2022-07-10 13:23:04,325 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-07-10 13:23:08,184 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:51582
scm1.org_1   | 2022-07-10 13:23:08,212 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-07-10 13:23:12,328 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48276
scm1.org_1   | 2022-07-10 13:23:12,343 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:51596
scm1.org_1   | 2022-07-10 13:23:12,369 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-07-10 13:23:12,381 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:23:12,531 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:50070
scm1.org_1   | 2022-07-10 13:23:12,545 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37104
scm1.org_1   | 2022-07-10 13:23:12,576 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:23:12,588 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:23:16,734 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:51632
scm1.org_1   | 2022-07-10 13:23:16,752 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-07-10 13:23:20,911 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:51646
scm1.org_1   | 2022-07-10 13:23:20,927 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-07-10 13:23:24,958 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:51658
scm1.org_1   | 2022-07-10 13:23:24,980 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-07-10 13:23:28,897 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:51662
scm1.org_1   | 2022-07-10 13:23:28,915 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-07-10 13:23:32,894 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:51674
scm2.org_1   | 2022-07-10 13:11:42,095 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:40646
scm2.org_1   | 2022-07-10 13:11:42,108 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:11:47,459 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:43438
scm2.org_1   | 2022-07-10 13:11:47,469 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:11:48,915 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:41854
scm2.org_1   | 2022-07-10 13:11:48,972 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:11:55,906 [8b10ddc2-41d5-41cc-935f-57a9babc5d91@group-8EEEA6081008-StateMachineUpdater] WARN ha.SequenceIdGenerator: Failed to allocate a batch for localId, expected lastId is 0, actual lastId is 109611004723200000.
scm2.org_1   | 2022-07-10 13:11:58,969 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:43484
scm2.org_1   | 2022-07-10 13:11:59,019 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:11:59,169 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:41902
scm2.org_1   | 2022-07-10 13:11:59,187 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:40722
scm2.org_1   | 2022-07-10 13:11:59,214 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:11:59,221 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:12:28,868 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:43602
scm2.org_1   | 2022-07-10 13:12:28,881 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:12:29,094 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:42014
scm2.org_1   | 2022-07-10 13:12:29,129 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:40842
scm2.org_1   | 2022-07-10 13:12:29,157 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:12:29,180 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:12:58,914 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:43698
scm2.org_1   | 2022-07-10 13:12:58,946 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:12:59,132 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:40936
scm2.org_1   | 2022-07-10 13:12:59,143 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:42114
scm2.org_1   | 2022-07-10 13:12:59,174 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:12:59,185 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:13:11,232 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:40992
scm2.org_1   | 2022-07-10 13:13:11,248 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:42184
scm2.org_1   | 2022-07-10 13:13:11,286 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:13:11,378 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:43790
scm2.org_1   | 2022-07-10 13:13:11,397 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:13:11,454 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:13:41,237 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:41106
scm2.org_1   | 2022-07-10 13:13:41,241 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:42286
scm2.org_1   | 2022-07-10 13:13:41,275 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:13:41,279 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:13:41,309 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:43892
scm2.org_1   | 2022-07-10 13:13:41,356 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:14:11,219 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:41224
recon_1      | 2022-07-10 13:12:59,159 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-07-10 13:12:59,170 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-07-10 13:13:11,196 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:42472
recon_1      | 2022-07-10 13:13:11,234 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35242
recon_1      | 2022-07-10 13:13:11,265 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47808
recon_1      | 2022-07-10 13:13:11,273 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-07-10 13:13:11,274 [FixedThreadPoolWithAffinityExecutor-1-0] INFO scm.ReconContainerManager: New container #2 got from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net.
recon_1      | 2022-07-10 13:13:11,325 [FixedThreadPoolWithAffinityExecutor-1-0] INFO scm.ReconContainerManager: Successfully added container #2 to Recon.
recon_1      | 2022-07-10 13:13:11,331 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-07-10 13:13:11,371 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-07-10 13:13:41,209 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35360
recon_1      | 2022-07-10 13:13:41,258 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-07-10 13:13:41,268 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47916
recon_1      | 2022-07-10 13:13:41,297 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:42580
recon_1      | 2022-07-10 13:13:41,367 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-07-10 13:13:41,435 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-07-10 13:13:41,875 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-07-10 13:13:41,875 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-07-10 13:13:41,925 [pool-28-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om2:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
scm1.org_1   | 2022-07-10 13:23:32,913 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-07-10 13:23:36,967 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:51686
scm1.org_1   | 2022-07-10 13:23:36,983 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-07-10 13:23:42,340 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48372
scm1.org_1   | 2022-07-10 13:23:42,379 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:23:42,442 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:50164
scm1.org_1   | 2022-07-10 13:23:42,478 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:23:42,550 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37186
scm1.org_1   | 2022-07-10 13:23:42,571 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:23:44,062 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:51726
scm1.org_1   | 2022-07-10 13:23:44,086 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-07-10 13:23:44,101 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 53ed973d-ea12-43b6-82a5-130c22b6b2db, Nodes: a1e412ee-75aa-4bf8-87bc-4e8e615b1959{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: STANDALONE/ONE, State:OPEN, leaderId:, CreationTimestamp2022-07-10T13:23:44.088Z[UTC]].
scm1.org_1   | 2022-07-10 13:23:48,278 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:51730
scm1.org_1   | 2022-07-10 13:23:48,304 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-07-10 13:23:52,415 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:51742
scm1.org_1   | 2022-07-10 13:23:52,436 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-07-10 13:23:56,532 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:51754
scm1.org_1   | 2022-07-10 13:23:56,556 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-07-10 13:24:00,656 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:51758
scm1.org_1   | 2022-07-10 13:24:00,674 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-07-10 13:24:04,821 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:51770
scm1.org_1   | 2022-07-10 13:24:04,840 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-07-10 13:24:08,772 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:51782
scm1.org_1   | 2022-07-10 13:24:08,795 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-07-10 13:24:12,354 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48478
scm1.org_1   | 2022-07-10 13:24:12,369 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:24:12,471 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:50270
scm1.org_1   | 2022-07-10 13:24:12,488 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:24:12,505 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37294
scm1.org_1   | 2022-07-10 13:24:12,525 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:33185
scm1.org_1   | 2022-07-10 13:24:12,531 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-07-10 13:24:12,554 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:24:12,838 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:51832
scm1.org_1   | 2022-07-10 13:24:12,868 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm3.org_1   | 2022-07-10 13:09:54,187 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar!/network-topology-default.xml]
scm3.org_1   | 2022-07-10 13:09:54,188 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
scm3.org_1   | 2022-07-10 13:09:54,289 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
scm3.org_1   | 2022-07-10 13:09:54,330 [main] INFO ha.SCMRatisServerImpl: starting Raft server for scm:6f9a84f7-8019-4c66-ba45-e86fba2381f6
scm3.org_1   | 2022-07-10 13:09:54,523 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
scm3.org_1   | 2022-07-10 13:09:54,708 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
scm3.org_1   | 2022-07-10 13:09:54,714 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm3.org_1   | 2022-07-10 13:09:54,716 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
scm3.org_1   | 2022-07-10 13:09:54,723 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm3.org_1   | 2022-07-10 13:09:54,724 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm3.org_1   | 2022-07-10 13:09:54,726 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
scm3.org_1   | 2022-07-10 13:09:54,727 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm3.org_1   | 2022-07-10 13:09:54,734 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
scm3.org_1   | 2022-07-10 13:09:54,735 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm3.org_1   | 2022-07-10 13:09:54,778 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
scm3.org_1   | 2022-07-10 13:09:54,785 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
scm3.org_1   | 2022-07-10 13:09:56,003 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
scm3.org_1   | 2022-07-10 13:09:56,005 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
scm3.org_1   | 2022-07-10 13:09:56,006 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
scm3.org_1   | 2022-07-10 13:09:56,006 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm3.org_1   | 2022-07-10 13:09:56,006 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm3.org_1   | 2022-07-10 13:09:56,017 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm3.org_1   | 2022-07-10 13:09:56,059 [main] INFO server.RaftServer: 6f9a84f7-8019-4c66-ba45-e86fba2381f6: addNew group-8EEEA6081008:[] returns group-8EEEA6081008:java.util.concurrent.CompletableFuture@1edccfd4[Not completed]
scm3.org_1   | 2022-07-10 13:09:56,141 [pool-16-thread-1] INFO server.RaftServer$Division: 6f9a84f7-8019-4c66-ba45-e86fba2381f6: new RaftServerImpl for group-8EEEA6081008:[] with SCMStateMachine:uninitialized
scm3.org_1   | 2022-07-10 13:09:56,147 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
scm3.org_1   | 2022-07-10 13:09:56,181 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
scm3.org_1   | 2022-07-10 13:09:56,182 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
scm3.org_1   | 2022-07-10 13:09:56,182 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm3.org_1   | 2022-07-10 13:09:56,182 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm3.org_1   | 2022-07-10 13:09:56,183 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
scm3.org_1   | 2022-07-10 13:09:56,202 [pool-16-thread-1] INFO server.RaftServer$Division: 6f9a84f7-8019-4c66-ba45-e86fba2381f6@group-8EEEA6081008: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
scm3.org_1   | 2022-07-10 13:09:56,206 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm3.org_1   | 2022-07-10 13:09:56,217 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
scm3.org_1   | 2022-07-10 13:09:56,218 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
scm3.org_1   | 2022-07-10 13:09:56,220 [pool-16-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/scm-ha/f578972c-97f6-4a12-a46c-8eeea6081008 does not exist. Creating ...
scm3.org_1   | 2022-07-10 13:09:56,259 [pool-16-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/f578972c-97f6-4a12-a46c-8eeea6081008/in_use.lock acquired by nodename 8@scm3.org
scm3.org_1   | 2022-07-10 13:09:56,284 [pool-16-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/scm-ha/f578972c-97f6-4a12-a46c-8eeea6081008 has been successfully formatted.
scm3.org_1   | 2022-07-10 13:09:56,288 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
scm3.org_1   | 2022-07-10 13:09:56,296 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
scm3.org_1   | 2022-07-10 13:09:56,310 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
scm3.org_1   | 2022-07-10 13:09:56,310 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm3.org_1   | 2022-07-10 13:09:56,318 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
scm3.org_1   | 2022-07-10 13:09:56,480 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm3.org_1   | 2022-07-10 13:09:56,496 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
scm3.org_1   | 2022-07-10 13:09:56,499 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
scm3.org_1   | 2022-07-10 13:09:56,507 [pool-16-thread-1] INFO segmented.SegmentedRaftLogWorker: new 6f9a84f7-8019-4c66-ba45-e86fba2381f6@group-8EEEA6081008-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/f578972c-97f6-4a12-a46c-8eeea6081008
scm3.org_1   | 2022-07-10 13:09:56,510 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
scm3.org_1   | 2022-07-10 13:09:56,511 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
scm3.org_1   | 2022-07-10 13:09:56,512 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm3.org_1   | 2022-07-10 13:09:56,513 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
scm3.org_1   | 2022-07-10 13:09:56,513 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
scm3.org_1   | 2022-07-10 13:09:56,515 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
scm3.org_1   | 2022-07-10 13:09:56,517 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
scm3.org_1   | 2022-07-10 13:09:56,518 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
scm3.org_1   | 2022-07-10 13:09:56,535 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
scm1.org_1   | 2022-07-10 13:24:12,910 [IPC Server handler 9 on default port 9860] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 53ed973d-ea12-43b6-82a5-130c22b6b2db, Nodes: a1e412ee-75aa-4bf8-87bc-4e8e615b1959{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: STANDALONE/ONE, State:OPEN, leaderId:, CreationTimestamp2022-07-10T13:23:44.088Z[UTC]] moved to CLOSED state
scm1.org_1   | 2022-07-10 13:24:13,437 [BackgroundPipelineScrubberThread] INFO pipeline.PipelineManagerImpl: Scrubbing pipeline: id: PipelineID=53ed973d-ea12-43b6-82a5-130c22b6b2db since it stays at CLOSED stage.
scm1.org_1   | 2022-07-10 13:24:13,458 [988d83fb-8298-4167-8ff5-9318a8e0d8d4@group-8EEEA6081008-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Pipeline Pipeline[ Id: 53ed973d-ea12-43b6-82a5-130c22b6b2db, Nodes: a1e412ee-75aa-4bf8-87bc-4e8e615b1959{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: STANDALONE/ONE, State:CLOSED, leaderId:, CreationTimestamp2022-07-10T13:23:44.088Z[UTC]] removed.
scm1.org_1   | 2022-07-10 13:24:13,557 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 14 milliseconds for processing 3 containers.
scm1.org_1   | 2022-07-10 13:24:17,165 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:51836
scm1.org_1   | 2022-07-10 13:24:17,196 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-07-10 13:24:24,096 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:51852
scm1.org_1   | 2022-07-10 13:24:24,122 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-07-10 13:24:28,053 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:51864
scm1.org_1   | 2022-07-10 13:24:28,095 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-07-10 13:24:32,412 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:51878
scm1.org_1   | 2022-07-10 13:24:32,417 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-07-10 13:24:32,420 [IPC Server handler 44 on default port 9860] INFO replication.ReplicationManager: Stopping Replication Monitor Thread.
scm1.org_1   | 2022-07-10 13:24:32,423 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread is stopped
scm1.org_1   | 2022-07-10 13:24:36,840 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:51884
scm1.org_1   | 2022-07-10 13:24:36,864 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-07-10 13:24:41,110 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:33921
scm1.org_1   | 2022-07-10 13:24:41,114 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-07-10 13:24:41,197 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:51898
scm1.org_1   | 2022-07-10 13:24:41,209 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-07-10 13:24:41,210 [IPC Server handler 22 on default port 9860] INFO replication.ReplicationManager: Starting Replication Monitor Thread.
scm1.org_1   | 2022-07-10 13:24:41,225 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 3 containers.
scm1.org_1   | 2022-07-10 13:24:42,342 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48582
scm1.org_1   | 2022-07-10 13:24:42,376 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:24:42,450 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:50374
scm1.org_1   | 2022-07-10 13:24:42,493 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:24:42,548 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37398
scm1.org_1   | 2022-07-10 13:24:42,565 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:24:45,001 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:51938
scm1.org_1   | 2022-07-10 13:24:45,020 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-07-10 13:24:51,611 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:51952
scm1.org_1   | 2022-07-10 13:24:51,642 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-07-10 13:24:55,506 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:51964
scm1.org_1   | 2022-07-10 13:24:55,533 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-07-10 13:24:59,359 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:51968
scm2.org_1   | 2022-07-10 13:14:11,221 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:42404
scm2.org_1   | 2022-07-10 13:14:11,274 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44016
scm2.org_1   | 2022-07-10 13:14:11,302 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:14:11,331 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:14:11,348 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:14:37,415 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm2.org_1   | 2022-07-10 13:14:41,239 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:41336
scm2.org_1   | 2022-07-10 13:14:41,250 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:42514
scm2.org_1   | 2022-07-10 13:14:41,257 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44124
scm2.org_1   | 2022-07-10 13:14:41,269 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:14:41,270 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:14:41,288 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:15:11,271 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44246
scm2.org_1   | 2022-07-10 13:15:11,283 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:41458
scm2.org_1   | 2022-07-10 13:15:11,290 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:15:11,308 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:42632
scm2.org_1   | 2022-07-10 13:15:11,328 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:15:11,329 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:15:41,251 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:42756
scm2.org_1   | 2022-07-10 13:15:41,258 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44358
scm2.org_1   | 2022-07-10 13:15:41,273 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:15:41,295 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:15:41,308 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:41560
scm2.org_1   | 2022-07-10 13:15:41,344 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:16:11,231 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:41680
scm2.org_1   | 2022-07-10 13:16:11,232 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:42870
scm2.org_1   | 2022-07-10 13:16:11,279 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44474
scm2.org_1   | 2022-07-10 13:16:11,283 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:16:11,299 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:16:11,309 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:16:41,221 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:42972
scm2.org_1   | 2022-07-10 13:16:41,235 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44582
scm2.org_1   | 2022-07-10 13:16:41,238 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:41794
scm2.org_1   | 2022-07-10 13:16:41,250 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:16:41,268 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:16:41,279 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:17:11,208 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44692
scm2.org_1   | 2022-07-10 13:17:11,244 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:41890
scm3.org_1   | 2022-07-10 13:09:56,536 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
scm3.org_1   | 2022-07-10 13:09:56,537 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
scm3.org_1   | 2022-07-10 13:09:56,548 [pool-16-thread-1] INFO segmented.SegmentedRaftLogWorker: 6f9a84f7-8019-4c66-ba45-e86fba2381f6@group-8EEEA6081008-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
scm3.org_1   | 2022-07-10 13:09:56,550 [pool-16-thread-1] INFO segmented.SegmentedRaftLogWorker: 6f9a84f7-8019-4c66-ba45-e86fba2381f6@group-8EEEA6081008-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
scm3.org_1   | 2022-07-10 13:09:56,558 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
scm3.org_1   | 2022-07-10 13:09:56,558 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
scm3.org_1   | 2022-07-10 13:09:56,559 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
scm3.org_1   | 2022-07-10 13:09:56,560 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
scm3.org_1   | 2022-07-10 13:09:56,562 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
scm3.org_1   | 2022-07-10 13:09:56,565 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
scm3.org_1   | 2022-07-10 13:09:56,666 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm3.org_1   | 2022-07-10 13:09:56,668 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
scm3.org_1   | 2022-07-10 13:09:56,669 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
scm3.org_1   | 2022-07-10 13:09:56,669 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
scm3.org_1   | 2022-07-10 13:09:56,670 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
scm3.org_1   | 2022-07-10 13:09:56,681 [main] INFO ha.SCMSnapshotProvider: Initializing SCM Snapshot Provider
scm3.org_1   | 2022-07-10 13:09:56,682 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
scm3.org_1   | 2022-07-10 13:09:56,683 [main] WARN ha.SCMHAUtils: SCM snapshot dir is not configured. Falling back to ozone.metadata.dirs config
scm3.org_1   | 2022-07-10 13:09:57,000 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
scm3.org_1   | 2022-07-10 13:09:57,256 [main] INFO reflections.Reflections: Reflections took 203 ms to scan 3 urls, producing 109 keys and 243 values 
scm3.org_1   | 2022-07-10 13:09:57,542 [main] INFO ha.SequenceIdGenerator: upgrade localId to 109611004723200000
scm3.org_1   | 2022-07-10 13:09:57,542 [main] INFO ha.SequenceIdGenerator: upgrade delTxnId to 0
scm3.org_1   | 2022-07-10 13:09:57,546 [main] INFO ha.SequenceIdGenerator: upgrade containerId to 0
scm3.org_1   | 2022-07-10 13:09:57,548 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
scm3.org_1   | 2022-07-10 13:09:57,654 [main] INFO node.SCMNodeManager: Entering startup safe mode.
scm3.org_1   | 2022-07-10 13:09:57,677 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
scm3.org_1   | 2022-07-10 13:09:57,690 [main] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
scm3.org_1   | 2022-07-10 13:09:57,799 [main] INFO algorithms.LeaderChoosePolicyFactory: Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
scm3.org_1   | 2022-07-10 13:09:57,803 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
scm3.org_1   | 2022-07-10 13:09:57,832 [main] INFO pipeline.BackgroundPipelineCreator: Starting RatisPipelineUtilsThread.
scm3.org_1   | 2022-07-10 13:09:57,852 [main] INFO BackgroundPipelineScrubber: Starting BackgroundPipelineScrubber Service.
scm3.org_1   | 2022-07-10 13:09:57,857 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineCreator.
scm3.org_1   | 2022-07-10 13:09:57,857 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineScrubber.
scm3.org_1   | 2022-07-10 13:09:57,867 [main] INFO ExpiredContainerReplicaOpScrubber: Starting ExpiredContainerReplicaOpScrubber Service.
scm3.org_1   | 2022-07-10 13:09:57,868 [main] INFO ha.SCMServiceManager: Registering service ExpiredContainerReplicaOpScrubber.
scm3.org_1   | 2022-07-10 13:09:57,903 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
scm3.org_1   | 2022-07-10 13:09:57,926 [main] INFO ha.SCMServiceManager: Registering service SCMBlockDeletingService.
scm3.org_1   | 2022-07-10 13:09:57,992 [main] INFO replication.ReplicationManager: Starting Replication Monitor Thread.
scm3.org_1   | 2022-07-10 13:09:58,044 [main] INFO ha.SCMServiceManager: Registering service ReplicationManager.
scm3.org_1   | 2022-07-10 13:09:58,057 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm3.org_1   | 2022-07-10 13:09:58,087 [main] INFO safemode.ContainerSafeModeRule: containers with one replica threshold count 0
scm3.org_1   | 2022-07-10 13:09:58,100 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-07-10 13:09:58,111 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm3.org_1   | 2022-07-10 13:09:58,155 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
scm3.org_1   | 2022-07-10 13:09:58,259 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 200, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm3.org_1   | 2022-07-10 13:09:58,324 [Socket Reader #1 for port 9961] INFO ipc.Server: Starting Socket Reader #1 for port 9961
scm3.org_1   | 2022-07-10 13:09:59,777 [Listener at 0.0.0.0/9961] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm3.org_1   | 2022-07-10 13:09:59,813 [Listener at 0.0.0.0/9961] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm3.org_1   | 2022-07-10 13:09:59,814 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
scm3.org_1   | 2022-07-10 13:09:59,906 [Listener at 0.0.0.0/9861] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm3.org_1   | 2022-07-10 13:09:59,918 [Listener at 0.0.0.0/9861] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm3.org_1   | 2022-07-10 13:09:59,927 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
scm3.org_1   | 2022-07-10 13:10:00,017 [Listener at 0.0.0.0/9863] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm2.org_1   | 2022-07-10 13:17:11,276 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:17:11,280 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:17:11,312 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:43078
scm2.org_1   | 2022-07-10 13:17:11,338 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:17:41,261 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44932
scm2.org_1   | 2022-07-10 13:17:41,280 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:42146
scm2.org_1   | 2022-07-10 13:17:41,298 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:43330
scm2.org_1   | 2022-07-10 13:17:41,317 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:17:41,334 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:17:41,365 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:18:11,258 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:43448
scm2.org_1   | 2022-07-10 13:18:11,290 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:42270
scm2.org_1   | 2022-07-10 13:18:11,314 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:45058
scm2.org_1   | 2022-07-10 13:18:11,338 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:18:11,442 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:18:11,489 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:18:41,198 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:43566
scm2.org_1   | 2022-07-10 13:18:41,228 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:42378
scm2.org_1   | 2022-07-10 13:18:41,254 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:45172
scm2.org_1   | 2022-07-10 13:18:41,272 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:18:41,303 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:18:41,318 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:19:11,220 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:43690
scm2.org_1   | 2022-07-10 13:19:11,231 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:42498
scm2.org_1   | 2022-07-10 13:19:11,244 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:45292
scm2.org_1   | 2022-07-10 13:19:11,270 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:19:11,280 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:19:11,296 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:19:37,415 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm2.org_1   | 2022-07-10 13:19:41,256 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:42652
scm2.org_1   | 2022-07-10 13:19:41,260 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:43844
scm2.org_1   | 2022-07-10 13:19:41,285 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:19:41,293 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:45448
scm2.org_1   | 2022-07-10 13:19:41,311 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:19:41,339 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:20:11,225 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:43998
scm2.org_1   | 2022-07-10 13:20:11,237 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:42806
scm2.org_1   | 2022-07-10 13:20:11,264 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:24:59,380 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-07-10 13:25:05,660 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:51982
scm1.org_1   | 2022-07-10 13:25:05,683 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-07-10 13:25:12,330 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48680
scm1.org_1   | 2022-07-10 13:25:12,362 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:25:12,445 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:50472
scm1.org_1   | 2022-07-10 13:25:12,494 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37500
scm1.org_1   | 2022-07-10 13:25:12,499 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-07-10 13:25:12,542 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:10:00,069 [Listener at 0.0.0.0/9863] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm3.org_1   | 2022-07-10 13:10:00,091 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
scm3.org_1   | 2022-07-10 13:10:00,303 [Listener at 0.0.0.0/9860] INFO ha.SCMServiceManager: Registering service ContainerBalancer.
scm3.org_1   | 2022-07-10 13:10:00,305 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: 
scm3.org_1   | Container Balancer status:
scm3.org_1   | Key                            Value
scm3.org_1   | Running                        false
scm3.org_1   | Container Balancer Configuration values:
scm3.org_1   | Key                                                Value
scm3.org_1   | Threshold                                          10
scm3.org_1   | Max Datanodes to Involve per Iteration(percent)    20
scm3.org_1   | Max Size to Move per Iteration                     500GB
scm3.org_1   | Max Size Entering Target per Iteration             26GB
scm3.org_1   | Max Size Leaving Source per Iteration              26GB
scm3.org_1   | 
scm3.org_1   | 2022-07-10 13:10:00,306 [Listener at 0.0.0.0/9860] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm3.org_1   | 2022-07-10 13:10:00,306 [Listener at 0.0.0.0/9860] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
scm3.org_1   | 2022-07-10 13:10:00,309 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
scm3.org_1   | 2022-07-10 13:10:00,321 [Listener at 0.0.0.0/9860] INFO ha.SCMRatisServerImpl: starting ratis server 0.0.0.0:9894
scm3.org_1   | 2022-07-10 13:10:00,326 [6f9a84f7-8019-4c66-ba45-e86fba2381f6-impl-thread1] INFO server.RaftServer$Division: 6f9a84f7-8019-4c66-ba45-e86fba2381f6@group-8EEEA6081008: start with initializing state, conf=-1: [], old=null
scm3.org_1   | 2022-07-10 13:10:00,326 [6f9a84f7-8019-4c66-ba45-e86fba2381f6-impl-thread1] INFO server.RaftServer$Division: 6f9a84f7-8019-4c66-ba45-e86fba2381f6@group-8EEEA6081008: changes role from      null to FOLLOWER at term 0 for startInitializing
scm3.org_1   | 2022-07-10 13:10:00,328 [6f9a84f7-8019-4c66-ba45-e86fba2381f6-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-8EEEA6081008,id=6f9a84f7-8019-4c66-ba45-e86fba2381f6
scm3.org_1   | 2022-07-10 13:10:00,339 [Listener at 0.0.0.0/9860] INFO server.RaftServer: 6f9a84f7-8019-4c66-ba45-e86fba2381f6: start RPC server
scm3.org_1   | 2022-07-10 13:10:00,406 [Listener at 0.0.0.0/9860] INFO server.GrpcService: 6f9a84f7-8019-4c66-ba45-e86fba2381f6: GrpcService started, listening on 9894
scm3.org_1   | 2022-07-10 13:10:00,419 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$463/0x000000084052ac40@64547a83] INFO util.JvmPauseMonitor: JvmPauseMonitor-6f9a84f7-8019-4c66-ba45-e86fba2381f6: Started
scm3.org_1   | 2022-07-10 13:10:00,423 [Listener at 0.0.0.0/9860] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 2 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863]
scm3.org_1   | 2022-07-10 13:10:01,899 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: 6f9a84f7-8019-4c66-ba45-e86fba2381f6@group-8EEEA6081008: receive installSnapshot: 988d83fb-8298-4167-8ff5-9318a8e0d8d4->6f9a84f7-8019-4c66-ba45-e86fba2381f6#0-t2,notify:(t:1, i:0)
scm3.org_1   | 2022-07-10 13:10:01,951 [grpc-default-executor-0] INFO ha.SCMStateMachine: leader changed, yet current SCM is still follower.
scm3.org_1   | 2022-07-10 13:10:01,951 [grpc-default-executor-0] INFO server.RaftServer$Division: 6f9a84f7-8019-4c66-ba45-e86fba2381f6@group-8EEEA6081008: change Leader from null to 988d83fb-8298-4167-8ff5-9318a8e0d8d4 at term 2 for installSnapshot, leader elected after 5663ms
scm3.org_1   | 2022-07-10 13:10:01,954 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: 6f9a84f7-8019-4c66-ba45-e86fba2381f6@group-8EEEA6081008: Received notification to install snapshot at index 0
scm3.org_1   | 2022-07-10 13:10:01,982 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: 6f9a84f7-8019-4c66-ba45-e86fba2381f6@group-8EEEA6081008: InstallSnapshot notification result: ALREADY_INSTALLED, current snapshot index: -1
scm3.org_1   | 2022-07-10 13:10:03,256 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: 6f9a84f7-8019-4c66-ba45-e86fba2381f6@group-8EEEA6081008: set new configuration index: 9
scm3.org_1   | configurationEntry {
scm3.org_1   |   peers {
scm3.org_1   |     id: "8b10ddc2-41d5-41cc-935f-57a9babc5d91"
scm3.org_1   |     address: "scm2.org:9894"
scm3.org_1   |   }
scm3.org_1   |   peers {
scm3.org_1   |     id: "988d83fb-8298-4167-8ff5-9318a8e0d8d4"
scm3.org_1   |     address: "scm1.org:9894"
scm3.org_1   |   }
scm3.org_1   | }
scm3.org_1   |  from snapshot
scm3.org_1   | 2022-07-10 13:10:03,270 [grpc-default-executor-0] INFO server.RaftServer$Division: 6f9a84f7-8019-4c66-ba45-e86fba2381f6@group-8EEEA6081008: set configuration 9: [8b10ddc2-41d5-41cc-935f-57a9babc5d91|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, 988d83fb-8298-4167-8ff5-9318a8e0d8d4|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2022-07-10 13:10:03,296 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: 6f9a84f7-8019-4c66-ba45-e86fba2381f6@group-8EEEA6081008: reply installSnapshot: 988d83fb-8298-4167-8ff5-9318a8e0d8d4<-6f9a84f7-8019-4c66-ba45-e86fba2381f6#0:FAIL-t0,ALREADY_INSTALLED
scm3.org_1   | 2022-07-10 13:10:03,356 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: 6f9a84f7-8019-4c66-ba45-e86fba2381f6: Completed INSTALL_SNAPSHOT, lastRequest: 988d83fb-8298-4167-8ff5-9318a8e0d8d4->6f9a84f7-8019-4c66-ba45-e86fba2381f6#0-t2,notify:(t:1, i:0)
scm3.org_1   | 2022-07-10 13:10:03,540 [6f9a84f7-8019-4c66-ba45-e86fba2381f6-server-thread1] INFO impl.RoleInfo: 6f9a84f7-8019-4c66-ba45-e86fba2381f6: start 6f9a84f7-8019-4c66-ba45-e86fba2381f6@group-8EEEA6081008-FollowerState
scm3.org_1   | 2022-07-10 13:10:03,542 [6f9a84f7-8019-4c66-ba45-e86fba2381f6-server-thread1] INFO server.RaftServer$Division: 6f9a84f7-8019-4c66-ba45-e86fba2381f6@group-8EEEA6081008: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
scm3.org_1   | 2022-07-10 13:10:03,555 [6f9a84f7-8019-4c66-ba45-e86fba2381f6-server-thread1] INFO server.RaftServer$Division: 6f9a84f7-8019-4c66-ba45-e86fba2381f6@group-8EEEA6081008: inconsistency entries. Reply:988d83fb-8298-4167-8ff5-9318a8e0d8d4<-6f9a84f7-8019-4c66-ba45-e86fba2381f6#0:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm3.org_1   | 2022-07-10 13:10:03,597 [6f9a84f7-8019-4c66-ba45-e86fba2381f6-server-thread2] INFO server.RaftServer$Division: 6f9a84f7-8019-4c66-ba45-e86fba2381f6@group-8EEEA6081008: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
scm3.org_1   | 2022-07-10 13:10:03,597 [6f9a84f7-8019-4c66-ba45-e86fba2381f6-server-thread2] INFO server.RaftServer$Division: 6f9a84f7-8019-4c66-ba45-e86fba2381f6@group-8EEEA6081008: inconsistency entries. Reply:988d83fb-8298-4167-8ff5-9318a8e0d8d4<-6f9a84f7-8019-4c66-ba45-e86fba2381f6#1:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm3.org_1   | 2022-07-10 13:10:03,627 [6f9a84f7-8019-4c66-ba45-e86fba2381f6-server-thread1] INFO server.RaftServer$Division: 6f9a84f7-8019-4c66-ba45-e86fba2381f6@group-8EEEA6081008: set configuration 0: [988d83fb-8298-4167-8ff5-9318a8e0d8d4|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2022-07-10 13:10:03,628 [6f9a84f7-8019-4c66-ba45-e86fba2381f6-server-thread1] INFO server.RaftServer$Division: 6f9a84f7-8019-4c66-ba45-e86fba2381f6@group-8EEEA6081008: set configuration 1: [988d83fb-8298-4167-8ff5-9318a8e0d8d4|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-07-10 13:14:11,196 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35478
recon_1      | 2022-07-10 13:14:11,232 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:42692
recon_1      | 2022-07-10 13:14:11,265 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-07-10 13:14:11,271 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48030
recon_1      | 2022-07-10 13:14:11,315 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-07-10 13:14:11,323 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-07-10 13:14:40,903 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 48 milliseconds to process 0 existing database records.
recon_1      | 2022-07-10 13:14:40,919 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 16 milliseconds for processing 2 containers.
recon_1      | 2022-07-10 13:14:41,018 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 5 pipelines in house.
recon_1      | 2022-07-10 13:14:41,024 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 25 milliseconds.
recon_1      | 2022-07-10 13:14:41,162 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:42806
recon_1      | 2022-07-10 13:14:41,188 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48146
recon_1      | 2022-07-10 13:14:41,227 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35590
recon_1      | 2022-07-10 13:14:41,234 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-07-10 13:14:41,247 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-07-10 13:14:41,278 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-07-10 13:14:41,934 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-07-10 13:14:41,934 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-07-10 13:14:41,988 [pool-28-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om2:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
scm3.org_1   | 2022-07-10 13:10:03,630 [6f9a84f7-8019-4c66-ba45-e86fba2381f6-server-thread1] INFO server.RaftServer$Division: 6f9a84f7-8019-4c66-ba45-e86fba2381f6@group-8EEEA6081008: set configuration 7: [8b10ddc2-41d5-41cc-935f-57a9babc5d91|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, 988d83fb-8298-4167-8ff5-9318a8e0d8d4|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=[988d83fb-8298-4167-8ff5-9318a8e0d8d4|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0]
scm3.org_1   | 2022-07-10 13:10:03,631 [6f9a84f7-8019-4c66-ba45-e86fba2381f6-server-thread1] INFO server.RaftServer$Division: 6f9a84f7-8019-4c66-ba45-e86fba2381f6@group-8EEEA6081008: set configuration 9: [8b10ddc2-41d5-41cc-935f-57a9babc5d91|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, 988d83fb-8298-4167-8ff5-9318a8e0d8d4|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2022-07-10 13:10:03,652 [6f9a84f7-8019-4c66-ba45-e86fba2381f6-server-thread1] INFO segmented.SegmentedRaftLogWorker: 6f9a84f7-8019-4c66-ba45-e86fba2381f6@group-8EEEA6081008-SegmentedRaftLogWorker: Starting segment from index:0
scm3.org_1   | 2022-07-10 13:10:03,824 [6f9a84f7-8019-4c66-ba45-e86fba2381f6-server-thread1] INFO segmented.SegmentedRaftLogWorker: 6f9a84f7-8019-4c66-ba45-e86fba2381f6@group-8EEEA6081008-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
scm3.org_1   | 2022-07-10 13:10:03,920 [6f9a84f7-8019-4c66-ba45-e86fba2381f6-server-thread1] INFO server.RaftServer$Division: 6f9a84f7-8019-4c66-ba45-e86fba2381f6@group-8EEEA6081008: set configuration 0: [988d83fb-8298-4167-8ff5-9318a8e0d8d4|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2022-07-10 13:10:03,928 [6f9a84f7-8019-4c66-ba45-e86fba2381f6-server-thread1] INFO server.RaftServer$Division: 6f9a84f7-8019-4c66-ba45-e86fba2381f6@group-8EEEA6081008: set configuration 1: [988d83fb-8298-4167-8ff5-9318a8e0d8d4|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2022-07-10 13:10:03,931 [6f9a84f7-8019-4c66-ba45-e86fba2381f6-server-thread1] INFO server.RaftServer$Division: 6f9a84f7-8019-4c66-ba45-e86fba2381f6@group-8EEEA6081008: set configuration 7: [8b10ddc2-41d5-41cc-935f-57a9babc5d91|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, 988d83fb-8298-4167-8ff5-9318a8e0d8d4|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=[988d83fb-8298-4167-8ff5-9318a8e0d8d4|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0]
scm3.org_1   | 2022-07-10 13:10:03,938 [6f9a84f7-8019-4c66-ba45-e86fba2381f6-server-thread1] INFO server.RaftServer$Division: 6f9a84f7-8019-4c66-ba45-e86fba2381f6@group-8EEEA6081008: set configuration 9: [8b10ddc2-41d5-41cc-935f-57a9babc5d91|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, 988d83fb-8298-4167-8ff5-9318a8e0d8d4|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2022-07-10 13:10:04,252 [6f9a84f7-8019-4c66-ba45-e86fba2381f6@group-8EEEA6081008-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 6f9a84f7-8019-4c66-ba45-e86fba2381f6@group-8EEEA6081008-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/f578972c-97f6-4a12-a46c-8eeea6081008/current/log_inprogress_0
scm3.org_1   | 2022-07-10 13:10:04,273 [6f9a84f7-8019-4c66-ba45-e86fba2381f6@group-8EEEA6081008-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 6f9a84f7-8019-4c66-ba45-e86fba2381f6@group-8EEEA6081008-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/scm-ha/f578972c-97f6-4a12-a46c-8eeea6081008/current/log_inprogress_0 to /data/metadata/scm-ha/f578972c-97f6-4a12-a46c-8eeea6081008/current/log_0-0
scm3.org_1   | 2022-07-10 13:10:04,407 [6f9a84f7-8019-4c66-ba45-e86fba2381f6@group-8EEEA6081008-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 6f9a84f7-8019-4c66-ba45-e86fba2381f6@group-8EEEA6081008-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/f578972c-97f6-4a12-a46c-8eeea6081008/current/log_inprogress_1
scm3.org_1   | 2022-07-10 13:10:04,494 [6f9a84f7-8019-4c66-ba45-e86fba2381f6@group-8EEEA6081008-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-07-10 13:10:04,496 [6f9a84f7-8019-4c66-ba45-e86fba2381f6@group-8EEEA6081008-StateMachineUpdater] INFO safemode.ContainerSafeModeRule: Refreshed one replica container threshold 0, currentThreshold 0
scm3.org_1   | 2022-07-10 13:10:04,503 [6f9a84f7-8019-4c66-ba45-e86fba2381f6@group-8EEEA6081008-StateMachineUpdater] INFO safemode.OneReplicaPipelineSafeModeRule: Refreshed Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm3.org_1   | 2022-07-10 13:10:04,504 [6f9a84f7-8019-4c66-ba45-e86fba2381f6@group-8EEEA6081008-StateMachineUpdater] INFO server.SCMDatanodeProtocolServer: ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:9861
scm3.org_1   | 2022-07-10 13:10:04,522 [6f9a84f7-8019-4c66-ba45-e86fba2381f6-server-thread1] INFO server.RaftServer$Division: 6f9a84f7-8019-4c66-ba45-e86fba2381f6@group-8EEEA6081008: set configuration 13: [8b10ddc2-41d5-41cc-935f-57a9babc5d91|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, 988d83fb-8298-4167-8ff5-9318a8e0d8d4|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 6f9a84f7-8019-4c66-ba45-e86fba2381f6|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0], old=[8b10ddc2-41d5-41cc-935f-57a9babc5d91|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, 988d83fb-8298-4167-8ff5-9318a8e0d8d4|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0]
scm3.org_1   | 2022-07-10 13:10:04,590 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm3.org_1   | 2022-07-10 13:10:04,592 [6f9a84f7-8019-4c66-ba45-e86fba2381f6-server-thread1] INFO server.RaftServer$Division: 6f9a84f7-8019-4c66-ba45-e86fba2381f6@group-8EEEA6081008: set configuration 15: [8b10ddc2-41d5-41cc-935f-57a9babc5d91|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, 988d83fb-8298-4167-8ff5-9318a8e0d8d4|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 6f9a84f7-8019-4c66-ba45-e86fba2381f6|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2022-07-10 13:10:04,609 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
scm3.org_1   | 2022-07-10 13:10:05,018 [Listener at 0.0.0.0/9860] INFO ha.SCMHAManagerImpl: Successfully added SCM scm3 to group group-8EEEA6081008:[8b10ddc2-41d5-41cc-935f-57a9babc5d91|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, 988d83fb-8298-4167-8ff5-9318a8e0d8d4|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 6f9a84f7-8019-4c66-ba45-e86fba2381f6|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0]
scm3.org_1   | 2022-07-10 13:10:05,018 [Listener at 0.0.0.0/9860] INFO ha.InterSCMGrpcService: Starting SCM Grpc Service at port 9895
scm3.org_1   | 2022-07-10 13:10:05,448 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Starting token manager
scm3.org_1   | 2022-07-10 13:10:05,448 [Listener at 0.0.0.0/9860] INFO token.ContainerTokenSecretManager: Updating the current master key for generating tokens
scm3.org_1   | 2022-07-10 13:10:06,179 [6f9a84f7-8019-4c66-ba45-e86fba2381f6@group-8EEEA6081008-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-07-10 13:10:06,206 [6f9a84f7-8019-4c66-ba45-e86fba2381f6@group-8EEEA6081008-StateMachineUpdater] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm3.org_1   | 2022-07-10 13:10:06,208 [6f9a84f7-8019-4c66-ba45-e86fba2381f6@group-8EEEA6081008-StateMachineUpdater] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm3.org_1   | 2022-07-10 13:10:06,370 [6f9a84f7-8019-4c66-ba45-e86fba2381f6@group-8EEEA6081008-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-07-10 13:20:11,265 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:45602
scm2.org_1   | 2022-07-10 13:20:11,266 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:20:11,289 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:20:41,210 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:42962
scm2.org_1   | 2022-07-10 13:20:41,283 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:45752
scm2.org_1   | 2022-07-10 13:20:41,286 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:44142
scm2.org_1   | 2022-07-10 13:20:41,293 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:20:41,324 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:20:41,355 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:21:11,238 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:44288
scm2.org_1   | 2022-07-10 13:21:11,245 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:45898
scm2.org_1   | 2022-07-10 13:21:11,257 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:43108
scm2.org_1   | 2022-07-10 13:21:11,273 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:21:11,288 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:21:11,330 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:21:41,230 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:43208
scm2.org_1   | 2022-07-10 13:21:41,236 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46002
scm2.org_1   | 2022-07-10 13:21:41,242 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:44400
scm2.org_1   | 2022-07-10 13:21:41,246 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:21:41,263 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:21:41,290 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:21:47,725 [8b10ddc2-41d5-41cc-935f-57a9babc5d91@group-8EEEA6081008-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 4b252efb-01a1-4e01-91ab-55e9b6197fe7, Nodes: 992f3c0d-344e-4060-87f0-890ffe8b867e{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: STANDALONE/ONE, State:OPEN, leaderId:, CreationTimestamp2022-07-10T13:21:47.707Z[UTC]].
scm2.org_1   | 2022-07-10 13:22:11,190 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:43316
scm2.org_1   | 2022-07-10 13:22:11,207 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46102
scm2.org_1   | 2022-07-10 13:22:11,238 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:22:11,269 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:22:19,863 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:44542
scm2.org_1   | 2022-07-10 13:22:19,882 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:22:41,215 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46194
scm2.org_1   | 2022-07-10 13:22:41,220 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:43404
scm2.org_1   | 2022-07-10 13:22:41,233 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:22:41,266 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:22:42,324 [FixedThreadPoolWithAffinityExecutor-8-0] INFO container.IncrementalContainerReportHandler: Moving container #1 to CLOSED state, datanode a1e412ee-75aa-4bf8-87bc-4e8e615b1959{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} reported CLOSED replica.
scm2.org_1   | 2022-07-10 13:22:42,366 [FixedThreadPoolWithAffinityExecutor-8-0] ERROR container.IncrementalContainerReportHandler: Exception while processing ICR for container 1
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-07-10 13:15:11,246 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48262
recon_1      | 2022-07-10 13:15:11,256 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:42932
recon_1      | 2022-07-10 13:15:11,260 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35702
recon_1      | 2022-07-10 13:15:11,263 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-07-10 13:15:11,287 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-07-10 13:15:11,312 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-07-10 13:15:41,195 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:43042
recon_1      | 2022-07-10 13:15:41,209 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48374
recon_1      | 2022-07-10 13:15:41,216 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35810
recon_1      | 2022-07-10 13:15:41,237 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-07-10 13:15:41,262 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-07-10 13:15:41,274 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-07-10 13:15:41,997 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-07-10 13:15:41,997 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-07-10 13:15:42,064 [pool-28-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om2:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-07-10 13:16:11,226 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:43162
recon_1      | 2022-07-10 13:16:11,229 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35934
recon_1      | 2022-07-10 13:16:11,242 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48490
recon_1      | 2022-07-10 13:16:11,260 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-07-10 13:16:11,263 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-07-10 13:16:11,312 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-07-10 13:16:41,203 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:43264
recon_1      | 2022-07-10 13:16:41,213 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48600
recon_1      | 2022-07-10 13:16:41,232 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36048
recon_1      | 2022-07-10 13:16:41,250 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-07-10 13:16:41,264 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-07-10 13:16:41,276 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-07-10 13:16:42,068 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-07-10 13:16:42,068 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-07-10 13:16:42,124 [pool-28-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
scm3.org_1   | 2022-07-10 13:10:06,431 [6f9a84f7-8019-4c66-ba45-e86fba2381f6@group-8EEEA6081008-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-07-10 13:10:06,784 [Listener at 0.0.0.0/9860] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
scm3.org_1   | 2022-07-10 13:10:06,912 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
scm3.org_1   | 2022-07-10 13:10:06,912 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
scm3.org_1   | 2022-07-10 13:10:09,374 [Listener at 0.0.0.0/9860] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
scm3.org_1   | 2022-07-10 13:10:09,385 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm3.org_1   | 2022-07-10 13:10:09,424 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
scm3.org_1   | 2022-07-10 13:10:10,067 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
scm3.org_1   | 2022-07-10 13:10:10,068 [Listener at 0.0.0.0/9860] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
scm3.org_1   | 2022-07-10 13:10:10,069 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm3.org_1   | 2022-07-10 13:10:10,076 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
scm3.org_1   | 2022-07-10 13:10:10,506 [Listener at 0.0.0.0/9860] INFO server.SCMSecurityProtocolServer: Starting RPC server for SCMSecurityProtocolServer. is listening at /0.0.0.0:9961
scm3.org_1   | 2022-07-10 13:10:10,507 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm3.org_1   | 2022-07-10 13:10:10,507 [IPC Server listener on 9961] INFO ipc.Server: IPC Server listener on 9961: starting
scm3.org_1   | 2022-07-10 13:10:10,508 [Listener at 0.0.0.0/9860] INFO server.SCMUpdateServiceGrpcServer: SCMUpdateService starting
scm3.org_1   | 2022-07-10 13:10:11,017 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
scm3.org_1   | 2022-07-10 13:10:11,017 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
scm3.org_1   | 2022-07-10 13:10:11,022 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
scm3.org_1   | 2022-07-10 13:10:12,353 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Persist certificate serialId 844577728582 on Scm Bootstrap Node 6f9a84f7-8019-4c66-ba45-e86fba2381f6
scm3.org_1   | 2022-07-10 13:10:12,387 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Persist certificate serialId 1 on Scm Bootstrap Node 6f9a84f7-8019-4c66-ba45-e86fba2381f6
scm3.org_1   | 2022-07-10 13:10:12,546 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@67c64b9c] INFO util.JvmPauseMonitor: Starting JVM pause monitor
scm3.org_1   | 2022-07-10 13:10:12,740 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
scm3.org_1   | 2022-07-10 13:10:12,741 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
scm3.org_1   | 2022-07-10 13:10:12,742 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HttpAuthType: hdds.scm.http.auth.type = kerberos
scm3.org_1   | 2022-07-10 13:10:13,043 [Listener at 0.0.0.0/9860] INFO util.log: Logging initialized @22296ms to org.eclipse.jetty.util.log.Slf4jLog
scm3.org_1   | 2022-07-10 13:10:13,902 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$463/0x000000084052ac40@64547a83] WARN util.JvmPauseMonitor: JvmPauseMonitor-6f9a84f7-8019-4c66-ba45-e86fba2381f6: Detected pause in JVM or host machine (eg GC): pause of approximately 130623492ns.
scm3.org_1   | GC pool 'ParNew' had collection(s): count=1 time=184ms
scm3.org_1   | 2022-07-10 13:10:14,056 [Listener at 0.0.0.0/9860] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
scm3.org_1   | 2022-07-10 13:10:14,124 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
scm3.org_1   | 2022-07-10 13:10:14,127 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context scm
scm3.org_1   | 2022-07-10 13:10:14,127 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
scm3.org_1   | 2022-07-10 13:10:14,127 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
scm3.org_1   | 2022-07-10 13:10:14,149 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.scm.http.auth.kerberos.principal keytabKey: hdds.scm.http.auth.kerberos.keytab
scm3.org_1   | 2022-07-10 13:10:14,551 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Jetty bound to port 9876
scm3.org_1   | 2022-07-10 13:10:14,561 [Listener at 0.0.0.0/9860] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
scm3.org_1   | 2022-07-10 13:10:14,801 [Listener at 0.0.0.0/9860] INFO server.session: DefaultSessionIdManager workerName=node0
scm3.org_1   | 2022-07-10 13:10:14,801 [Listener at 0.0.0.0/9860] INFO server.session: No SessionScavenger set, using defaults
scm3.org_1   | 2022-07-10 13:10:14,812 [Listener at 0.0.0.0/9860] INFO server.session: node0 Scavenging every 600000ms
scm3.org_1   | 2022-07-10 13:10:14,985 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm3.org_1   | 2022-07-10 13:10:14,999 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6bc6400e{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
scm3.org_1   | 2022-07-10 13:10:15,016 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@77d771a2{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
scm3.org_1   | 2022-07-10 13:10:15,823 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm3.org_1   | 2022-07-10 13:10:15,978 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@580581b4{scm,/,file:///tmp/jetty-0_0_0_0-9876-hdds-server-scm-1_3_0-SNAPSHOT_jar-_-any-16310334236245953383/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar!/webapps/scm}
scm3.org_1   | 2022-07-10 13:10:16,052 [Listener at 0.0.0.0/9860] INFO server.AbstractConnector: Started ServerConnector@3c995eae{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
scm3.org_1   | 2022-07-10 13:10:16,059 [Listener at 0.0.0.0/9860] INFO server.Server: Started @25312ms
scm3.org_1   | 2022-07-10 13:10:16,079 [Listener at 0.0.0.0/9860] INFO impl.MetricsSinkAdapter: Sink prometheus started
scm3.org_1   | 2022-07-10 13:10:16,083 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Registered sink prometheus
scm3.org_1   | 2022-07-10 13:10:16,089 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
scm3.org_1   | 2022-07-10 13:10:29,264 [6f9a84f7-8019-4c66-ba45-e86fba2381f6@group-8EEEA6081008-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-07-10 13:10:29,534 [6f9a84f7-8019-4c66-ba45-e86fba2381f6@group-8EEEA6081008-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-07-10 13:10:32,185 [6f9a84f7-8019-4c66-ba45-e86fba2381f6@group-8EEEA6081008-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-07-10 13:10:36,963 [6f9a84f7-8019-4c66-ba45-e86fba2381f6@group-8EEEA6081008-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-07-10 13:10:37,515 [6f9a84f7-8019-4c66-ba45-e86fba2381f6@group-8EEEA6081008-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-07-10 13:10:38,600 [6f9a84f7-8019-4c66-ba45-e86fba2381f6@group-8EEEA6081008-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-07-10 13:10:52,744 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:36260
scm3.org_1   | 2022-07-10 13:10:52,834 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:10:54,399 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54896
scm3.org_1   | 2022-07-10 13:10:54,416 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:10:58,155 [IPC Server handler 20 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/992f3c0d-344e-4060-87f0-890ffe8b867e
scm3.org_1   | 2022-07-10 13:10:58,167 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56454
scm3.org_1   | 2022-07-10 13:10:58,184 [IPC Server handler 20 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 992f3c0d-344e-4060-87f0-890ffe8b867e{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 933105602287, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm3.org_1   | 2022-07-10 13:10:58,291 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm3.org_1   | 2022-07-10 13:10:58,305 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:10:58,406 [IPC Server handler 86 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/a1e412ee-75aa-4bf8-87bc-4e8e615b1959
scm3.org_1   | 2022-07-10 13:10:58,446 [IPC Server handler 86 on default port 9861] INFO node.SCMNodeManager: Registered Data node : a1e412ee-75aa-4bf8-87bc-4e8e615b1959{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 933456427477, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm3.org_1   | 2022-07-10 13:10:58,446 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm3.org_1   | 2022-07-10 13:10:58,432 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 3 required.
scm3.org_1   | 2022-07-10 13:10:58,468 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 3 required.
scm3.org_1   | 2022-07-10 13:10:59,884 [6f9a84f7-8019-4c66-ba45-e86fba2381f6@group-8EEEA6081008-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: b77b6ac4-c103-4125-90f3-f25d482aaf22, Nodes: 992f3c0d-344e-4060-87f0-890ffe8b867e{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-07-10T13:10:58.769Z[UTC]].
scm3.org_1   | 2022-07-10 13:10:59,941 [6f9a84f7-8019-4c66-ba45-e86fba2381f6@group-8EEEA6081008-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-07-10 13:10:59,942 [6f9a84f7-8019-4c66-ba45-e86fba2381f6@group-8EEEA6081008-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: b1d72510-c7b3-4886-b6f1-097f02077230, Nodes: a1e412ee-75aa-4bf8-87bc-4e8e615b1959{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-07-10T13:10:59.707Z[UTC]].
scm3.org_1   | 2022-07-10 13:10:59,942 [6f9a84f7-8019-4c66-ba45-e86fba2381f6@group-8EEEA6081008-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-07-10 13:11:01,641 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: b77b6ac4-c103-4125-90f3-f25d482aaf22, Nodes: 992f3c0d-344e-4060-87f0-890ffe8b867e{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:992f3c0d-344e-4060-87f0-890ffe8b867e, CreationTimestamp2022-07-10T13:10:58.769Z[UTC]] moved to OPEN state
scm3.org_1   | 2022-07-10 13:11:01,920 [IPC Server handler 13 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/257634a0-3792-468a-a5a2-186b5a295fa1
scm3.org_1   | 2022-07-10 13:11:01,923 [IPC Server handler 13 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 257634a0-3792-468a-a5a2-186b5a295fa1{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 935900506483, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm3.org_1   | 2022-07-10 13:11:01,972 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm3.org_1   | 2022-07-10 13:11:01,972 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 3 required.
scm3.org_1   | 2022-07-10 13:11:02,051 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om2:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-07-10 13:17:11,165 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36136
recon_1      | 2022-07-10 13:17:11,214 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:43380
recon_1      | 2022-07-10 13:17:11,259 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48708
recon_1      | 2022-07-10 13:17:11,272 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-07-10 13:17:11,283 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-07-10 13:17:11,329 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-07-10 13:17:41,249 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48950
recon_1      | 2022-07-10 13:17:41,253 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36392
recon_1      | 2022-07-10 13:17:41,300 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm2.org_1   | org.apache.ratis.protocol.exceptions.NotLeaderException: Server 8b10ddc2-41d5-41cc-935f-57a9babc5d91@group-8EEEA6081008 is not the leader 988d83fb-8298-4167-8ff5-9318a8e0d8d4|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0
scm2.org_1   | 	at org.apache.ratis.server.impl.RaftServerImpl.generateNotLeaderException(RaftServerImpl.java:696)
scm2.org_1   | 	at org.apache.ratis.server.impl.RaftServerImpl.checkLeaderState(RaftServerImpl.java:661)
scm2.org_1   | 	at org.apache.ratis.server.impl.RaftServerImpl.submitClientRequestAsync(RaftServerImpl.java:800)
scm2.org_1   | 	at org.apache.ratis.server.impl.RaftServerImpl.lambda$null$12(RaftServerImpl.java:783)
scm2.org_1   | 	at org.apache.ratis.util.JavaUtils.callAsUnchecked(JavaUtils.java:115)
scm2.org_1   | 	at org.apache.ratis.server.impl.RaftServerImpl.lambda$executeSubmitClientRequestAsync$13(RaftServerImpl.java:783)
scm2.org_1   | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm2.org_1   | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm2.org_1   | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm2.org_1   | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm2.org_1   | 2022-07-10 13:22:42,391 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:44604
scm2.org_1   | 2022-07-10 13:22:42,495 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:23:12,352 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46290
scm2.org_1   | 2022-07-10 13:23:12,428 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:23:12,515 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:43530
scm2.org_1   | 2022-07-10 13:23:12,525 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:44704
scm2.org_1   | 2022-07-10 13:23:12,544 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:23:12,553 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:23:42,325 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46382
scm2.org_1   | 2022-07-10 13:23:42,367 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:23:42,433 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:44798
scm2.org_1   | 2022-07-10 13:23:42,472 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:23:42,544 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:43620
scm2.org_1   | 2022-07-10 13:23:42,565 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:23:44,109 [8b10ddc2-41d5-41cc-935f-57a9babc5d91@group-8EEEA6081008-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 53ed973d-ea12-43b6-82a5-130c22b6b2db, Nodes: a1e412ee-75aa-4bf8-87bc-4e8e615b1959{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: STANDALONE/ONE, State:OPEN, leaderId:, CreationTimestamp2022-07-10T13:23:44.088Z[UTC]].
scm2.org_1   | 2022-07-10 13:24:12,328 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46492
scm2.org_1   | 2022-07-10 13:24:12,360 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:24:12,438 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:44902
scm2.org_1   | 2022-07-10 13:24:12,492 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:24:12,512 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:43726
scm2.org_1   | 2022-07-10 13:24:12,543 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:24:13,459 [8b10ddc2-41d5-41cc-935f-57a9babc5d91@group-8EEEA6081008-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Pipeline Pipeline[ Id: 53ed973d-ea12-43b6-82a5-130c22b6b2db, Nodes: a1e412ee-75aa-4bf8-87bc-4e8e615b1959{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: STANDALONE/ONE, State:CLOSED, leaderId:, CreationTimestamp2022-07-10T13:23:44.088Z[UTC]] removed.
scm2.org_1   | 2022-07-10 13:24:31,829 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49506
scm2.org_1   | 2022-07-10 13:24:31,852 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm2.org_1   | 2022-07-10 13:24:32,137 [IPC Server handler 1 on default port 9860] INFO replication.ReplicationManager: Stopping Replication Monitor Thread.
scm2.org_1   | 2022-07-10 13:24:32,140 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread is stopped
scm2.org_1   | 2022-07-10 13:24:40,921 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49526
scm2.org_1   | 2022-07-10 13:24:40,960 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm3.org_1   | 2022-07-10 13:11:02,051 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
scm3.org_1   | 2022-07-10 13:11:02,052 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm3.org_1   | 2022-07-10 13:11:02,100 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
scm3.org_1   | 2022-07-10 13:11:02,130 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm3.org_1   | 2022-07-10 13:11:02,131 [6f9a84f7-8019-4c66-ba45-e86fba2381f6@group-8EEEA6081008-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-07-10 13:11:02,269 [6f9a84f7-8019-4c66-ba45-e86fba2381f6@group-8EEEA6081008-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 8d6e1a79-b70d-40e6-a234-6dc84a45f007, Nodes: 257634a0-3792-468a-a5a2-186b5a295fa1{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-07-10T13:11:01.880Z[UTC]].
scm3.org_1   | 2022-07-10 13:11:02,287 [6f9a84f7-8019-4c66-ba45-e86fba2381f6@group-8EEEA6081008-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-07-10 13:11:02,634 [6f9a84f7-8019-4c66-ba45-e86fba2381f6@group-8EEEA6081008-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 199762fc-7613-447a-a2fc-b841d041c364, Nodes: 257634a0-3792-468a-a5a2-186b5a295fa1{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}a1e412ee-75aa-4bf8-87bc-4e8e615b1959{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}992f3c0d-344e-4060-87f0-890ffe8b867e{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-07-10T13:11:02.344Z[UTC]].
scm3.org_1   | 2022-07-10 13:11:02,637 [6f9a84f7-8019-4c66-ba45-e86fba2381f6@group-8EEEA6081008-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-07-10 13:11:02,815 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: b1d72510-c7b3-4886-b6f1-097f02077230, Nodes: a1e412ee-75aa-4bf8-87bc-4e8e615b1959{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:a1e412ee-75aa-4bf8-87bc-4e8e615b1959, CreationTimestamp2022-07-10T13:10:59.707Z[UTC]] moved to OPEN state
scm3.org_1   | 2022-07-10 13:11:02,828 [6f9a84f7-8019-4c66-ba45-e86fba2381f6@group-8EEEA6081008-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 79d7f9ff-9479-4fdc-a3f9-09a40f9f1d96, Nodes: 257634a0-3792-468a-a5a2-186b5a295fa1{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}a1e412ee-75aa-4bf8-87bc-4e8e615b1959{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}992f3c0d-344e-4060-87f0-890ffe8b867e{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-07-10T13:11:02.595Z[UTC]].
scm3.org_1   | 2022-07-10 13:11:02,845 [6f9a84f7-8019-4c66-ba45-e86fba2381f6@group-8EEEA6081008-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-07-10 13:11:02,988 [6f9a84f7-8019-4c66-ba45-e86fba2381f6@group-8EEEA6081008-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-07-10 13:11:03,444 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm3.org_1   | 2022-07-10 13:11:05,782 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 8d6e1a79-b70d-40e6-a234-6dc84a45f007, Nodes: 257634a0-3792-468a-a5a2-186b5a295fa1{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:257634a0-3792-468a-a5a2-186b5a295fa1, CreationTimestamp2022-07-10T13:11:01.880Z[UTC]] moved to OPEN state
scm3.org_1   | 2022-07-10 13:11:05,846 [6f9a84f7-8019-4c66-ba45-e86fba2381f6@group-8EEEA6081008-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-07-10 13:11:06,922 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm3.org_1   | 2022-07-10 13:11:07,705 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm3.org_1   | 2022-07-10 13:11:08,463 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm3.org_1   | 2022-07-10 13:11:11,517 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
recon_1      | 2022-07-10 13:17:41,326 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:43618
recon_1      | 2022-07-10 13:17:41,330 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-07-10 13:17:41,374 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-07-10 13:17:42,131 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-07-10 13:17:42,131 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-07-10 13:17:42,183 [pool-28-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om2:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-07-10 13:18:11,228 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:43744
recon_1      | 2022-07-10 13:18:11,248 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49074
recon_1      | 2022-07-10 13:18:11,250 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36524
scm3.org_1   | 2022-07-10 13:11:11,634 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 199762fc-7613-447a-a2fc-b841d041c364, Nodes: 257634a0-3792-468a-a5a2-186b5a295fa1{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}a1e412ee-75aa-4bf8-87bc-4e8e615b1959{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}992f3c0d-344e-4060-87f0-890ffe8b867e{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:a1e412ee-75aa-4bf8-87bc-4e8e615b1959, CreationTimestamp2022-07-10T13:11:02.344Z[UTC]] moved to OPEN state
scm3.org_1   | 2022-07-10 13:11:11,638 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm3.org_1   | 2022-07-10 13:11:11,696 [6f9a84f7-8019-4c66-ba45-e86fba2381f6@group-8EEEA6081008-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 1, healthy pipeline threshold count is 1
scm3.org_1   | 2022-07-10 13:11:11,896 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm3.org_1   | 2022-07-10 13:11:11,896 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
scm3.org_1   | 2022-07-10 13:11:11,896 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
scm3.org_1   | 2022-07-10 13:11:11,896 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
scm3.org_1   | 2022-07-10 13:11:11,897 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
scm3.org_1   | 2022-07-10 13:11:11,897 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm3.org_1   | 2022-07-10 13:11:11,897 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
scm3.org_1   | 2022-07-10 13:11:17,415 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 79d7f9ff-9479-4fdc-a3f9-09a40f9f1d96, Nodes: 257634a0-3792-468a-a5a2-186b5a295fa1{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}a1e412ee-75aa-4bf8-87bc-4e8e615b1959{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}992f3c0d-344e-4060-87f0-890ffe8b867e{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:a1e412ee-75aa-4bf8-87bc-4e8e615b1959, CreationTimestamp2022-07-10T13:11:02.595Z[UTC]] moved to OPEN state
scm3.org_1   | 2022-07-10 13:11:42,144 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56602
scm3.org_1   | 2022-07-10 13:11:42,159 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:11:47,442 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:36446
scm3.org_1   | 2022-07-10 13:11:47,466 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:11:48,951 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55088
scm3.org_1   | 2022-07-10 13:11:48,973 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:11:56,018 [6f9a84f7-8019-4c66-ba45-e86fba2381f6@group-8EEEA6081008-StateMachineUpdater] WARN ha.SequenceIdGenerator: Failed to allocate a batch for localId, expected lastId is 0, actual lastId is 109611004723200000.
scm3.org_1   | 2022-07-10 13:11:58,912 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:36494
scm3.org_1   | 2022-07-10 13:11:58,972 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:11:59,182 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56682
scm3.org_1   | 2022-07-10 13:11:59,203 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55144
scm3.org_1   | 2022-07-10 13:11:59,275 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:11:59,279 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:12:28,950 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:36604
scm3.org_1   | 2022-07-10 13:12:28,959 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:12:29,089 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55248
scm3.org_1   | 2022-07-10 13:12:29,118 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:24:40,961 [IPC Server handler 1 on default port 9860] INFO replication.ReplicationManager: Starting Replication Monitor Thread.
scm2.org_1   | 2022-07-10 13:24:40,968 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm2.org_1   | 2022-07-10 13:24:42,326 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46592
scm2.org_1   | 2022-07-10 13:24:42,366 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:24:42,444 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:45008
scm2.org_1   | 2022-07-10 13:24:42,499 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:24:42,516 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:43828
scm2.org_1   | 2022-07-10 13:24:42,542 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:25:12,324 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46694
scm2.org_1   | 2022-07-10 13:25:12,351 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:25:12,425 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:45104
scm2.org_1   | 2022-07-10 13:25:12,486 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:43924
scm2.org_1   | 2022-07-10 13:25:12,491 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-07-10 13:25:12,538 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 2022-07-10 13:18:11,292 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-07-10 13:18:11,380 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-07-10 13:18:11,443 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-07-10 13:18:41,160 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36628
recon_1      | 2022-07-10 13:18:41,191 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:43860
recon_1      | 2022-07-10 13:18:41,242 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49188
recon_1      | 2022-07-10 13:18:41,255 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-07-10 13:18:41,269 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-07-10 13:18:41,292 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-07-10 13:18:42,184 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-07-10 13:18:42,185 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-07-10 13:18:42,230 [pool-28-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om2:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
scm3.org_1   | 2022-07-10 13:12:29,125 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56800
scm3.org_1   | 2022-07-10 13:12:29,176 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:12:58,912 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:36704
scm3.org_1   | 2022-07-10 13:12:58,945 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:12:59,075 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55344
scm3.org_1   | 2022-07-10 13:12:59,123 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56900
scm3.org_1   | 2022-07-10 13:12:59,167 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:12:59,189 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:13:11,232 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56950
scm3.org_1   | 2022-07-10 13:13:11,259 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:13:11,377 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:36788
scm3.org_1   | 2022-07-10 13:13:11,404 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55418
scm3.org_1   | 2022-07-10 13:13:11,437 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:13:11,457 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:13:41,303 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55520
scm3.org_1   | 2022-07-10 13:13:41,317 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:57058
scm3.org_1   | 2022-07-10 13:13:41,339 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:36898
scm3.org_1   | 2022-07-10 13:13:41,346 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:13:41,380 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:13:41,435 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:14:11,192 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:37018
scm3.org_1   | 2022-07-10 13:14:11,241 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55640
scm3.org_1   | 2022-07-10 13:14:11,250 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:57190
scm3.org_1   | 2022-07-10 13:14:11,266 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:14:11,301 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:14:11,351 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:14:41,204 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:37124
scm3.org_1   | 2022-07-10 13:14:41,239 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:14:41,267 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55750
scm3.org_1   | 2022-07-10 13:14:41,306 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:57310
scm3.org_1   | 2022-07-10 13:14:41,315 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:14:41,327 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:14:58,061 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm3.org_1   | 2022-07-10 13:15:11,173 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55862
scm3.org_1   | 2022-07-10 13:15:11,276 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:15:11,290 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:57410
scm3.org_1   | 2022-07-10 13:15:11,315 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:15:11,338 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:37248
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-07-10 13:19:11,212 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:43984
recon_1      | 2022-07-10 13:19:11,218 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36752
recon_1      | 2022-07-10 13:19:11,223 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49314
recon_1      | 2022-07-10 13:19:11,250 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-07-10 13:19:11,260 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-07-10 13:19:11,279 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-07-10 13:19:40,921 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 2 milliseconds to process 0 existing database records.
recon_1      | 2022-07-10 13:19:40,924 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 3 milliseconds for processing 2 containers.
recon_1      | 2022-07-10 13:19:41,069 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 5 pipelines in house.
recon_1      | 2022-07-10 13:19:41,071 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 39 milliseconds.
recon_1      | 2022-07-10 13:19:41,154 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36906
recon_1      | 2022-07-10 13:19:41,222 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49466
recon_1      | 2022-07-10 13:19:41,247 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-07-10 13:19:41,279 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:44136
recon_1      | 2022-07-10 13:19:41,308 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-07-10 13:19:41,315 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-07-10 13:19:42,232 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-07-10 13:19:42,232 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-07-10 13:19:42,293 [pool-28-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om2:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
scm3.org_1   | 2022-07-10 13:15:11,364 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:15:41,167 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55986
scm3.org_1   | 2022-07-10 13:15:41,252 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:15:41,276 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:37356
scm3.org_1   | 2022-07-10 13:15:41,286 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:57524
scm3.org_1   | 2022-07-10 13:15:41,336 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:15:41,365 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:16:11,208 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:37472
scm3.org_1   | 2022-07-10 13:16:11,230 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:57640
scm3.org_1   | 2022-07-10 13:16:11,244 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:16:11,286 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56114
scm3.org_1   | 2022-07-10 13:16:11,306 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:16:11,322 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:16:41,219 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:57752
scm3.org_1   | 2022-07-10 13:16:41,221 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56202
scm3.org_1   | 2022-07-10 13:16:41,242 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:37588
scm3.org_1   | 2022-07-10 13:16:41,244 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:16:41,253 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:16:41,283 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:17:11,263 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56312
scm3.org_1   | 2022-07-10 13:17:11,271 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:37694
scm3.org_1   | 2022-07-10 13:17:11,302 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:17:11,334 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:57850
scm3.org_1   | 2022-07-10 13:17:11,337 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:17:11,363 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:17:41,230 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56554
scm3.org_1   | 2022-07-10 13:17:41,275 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:58100
scm3.org_1   | 2022-07-10 13:17:41,278 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:37938
scm3.org_1   | 2022-07-10 13:17:41,307 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:17:41,321 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:17:41,336 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:18:11,199 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56678
scm3.org_1   | 2022-07-10 13:18:11,242 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:38064
scm3.org_1   | 2022-07-10 13:18:11,302 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:58238
scm3.org_1   | 2022-07-10 13:18:11,321 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:18:11,396 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:18:11,486 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:18:41,246 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56790
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-07-10 13:20:11,212 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37060
recon_1      | 2022-07-10 13:20:11,219 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:44292
recon_1      | 2022-07-10 13:20:11,236 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-07-10 13:20:11,240 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49624
recon_1      | 2022-07-10 13:20:11,254 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-07-10 13:20:11,274 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-07-10 13:20:41,209 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37212
recon_1      | 2022-07-10 13:20:41,268 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:44430
recon_1      | 2022-07-10 13:20:41,292 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49768
recon_1      | 2022-07-10 13:20:41,293 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-07-10 13:20:41,325 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-07-10 13:20:41,354 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-07-10 13:20:42,298 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-07-10 13:20:42,298 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-07-10 13:20:42,353 [pool-28-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om2:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
scm3.org_1   | 2022-07-10 13:18:41,267 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:58344
scm3.org_1   | 2022-07-10 13:18:41,280 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:18:41,291 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:38174
scm3.org_1   | 2022-07-10 13:18:41,312 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:18:41,325 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:19:11,349 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:58456
scm3.org_1   | 2022-07-10 13:19:11,360 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56924
scm3.org_1   | 2022-07-10 13:19:11,361 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:19:11,378 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:19:11,384 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:38300
scm3.org_1   | 2022-07-10 13:19:11,392 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:19:41,236 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:58612
scm3.org_1   | 2022-07-10 13:19:41,239 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:57080
scm3.org_1   | 2022-07-10 13:19:41,257 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:19:41,267 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:38454
scm3.org_1   | 2022-07-10 13:19:41,310 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:19:41,337 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:19:58,062 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm3.org_1   | 2022-07-10 13:20:11,213 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:57236
scm3.org_1   | 2022-07-10 13:20:11,265 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:38610
scm3.org_1   | 2022-07-10 13:20:11,271 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:58766
scm3.org_1   | 2022-07-10 13:20:11,279 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:20:11,290 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:20:11,296 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:20:41,271 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:58926
scm3.org_1   | 2022-07-10 13:20:41,279 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:57368
scm3.org_1   | 2022-07-10 13:20:41,296 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:20:41,326 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:38754
scm3.org_1   | 2022-07-10 13:20:41,349 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:20:41,371 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:21:11,227 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:38898
scm3.org_1   | 2022-07-10 13:21:11,230 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:57518
scm3.org_1   | 2022-07-10 13:21:11,254 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:21:11,265 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:59072
scm3.org_1   | 2022-07-10 13:21:11,287 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:21:11,337 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:21:41,215 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:59172
scm3.org_1   | 2022-07-10 13:21:41,242 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:39010
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-07-10 13:21:11,217 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:44574
recon_1      | 2022-07-10 13:21:11,279 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37358
recon_1      | 2022-07-10 13:21:11,280 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49916
recon_1      | 2022-07-10 13:21:11,303 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-07-10 13:21:11,317 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-07-10 13:21:11,338 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-07-10 13:21:41,202 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37458
recon_1      | 2022-07-10 13:21:41,221 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50024
recon_1      | 2022-07-10 13:21:41,231 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:44692
recon_1      | 2022-07-10 13:21:41,237 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-07-10 13:21:41,255 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-07-10 13:21:41,267 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-07-10 13:21:42,356 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-07-10 13:21:42,356 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-07-10 13:21:42,391 [pool-28-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm3.org_1   | 2022-07-10 13:21:41,254 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:21:41,264 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:21:41,271 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:57636
scm3.org_1   | 2022-07-10 13:21:41,295 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:21:47,733 [6f9a84f7-8019-4c66-ba45-e86fba2381f6@group-8EEEA6081008-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 4b252efb-01a1-4e01-91ab-55e9b6197fe7, Nodes: 992f3c0d-344e-4060-87f0-890ffe8b867e{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: STANDALONE/ONE, State:OPEN, leaderId:, CreationTimestamp2022-07-10T13:21:47.707Z[UTC]].
scm3.org_1   | 2022-07-10 13:22:11,177 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:59276
scm3.org_1   | 2022-07-10 13:22:11,219 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:22:11,242 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:39108
scm3.org_1   | 2022-07-10 13:22:11,291 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:22:19,874 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:57770
scm3.org_1   | 2022-07-10 13:22:19,893 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:22:41,223 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:59364
scm3.org_1   | 2022-07-10 13:22:41,234 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:39194
scm3.org_1   | 2022-07-10 13:22:41,242 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:22:41,273 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:22:42,315 [FixedThreadPoolWithAffinityExecutor-8-0] INFO container.IncrementalContainerReportHandler: Moving container #1 to CLOSED state, datanode a1e412ee-75aa-4bf8-87bc-4e8e615b1959{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} reported CLOSED replica.
scm3.org_1   | 2022-07-10 13:22:42,360 [FixedThreadPoolWithAffinityExecutor-8-0] ERROR container.IncrementalContainerReportHandler: Exception while processing ICR for container 1
scm3.org_1   | org.apache.ratis.protocol.exceptions.NotLeaderException: Server 6f9a84f7-8019-4c66-ba45-e86fba2381f6@group-8EEEA6081008 is not the leader 988d83fb-8298-4167-8ff5-9318a8e0d8d4|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0
scm3.org_1   | 	at org.apache.ratis.server.impl.RaftServerImpl.generateNotLeaderException(RaftServerImpl.java:696)
scm3.org_1   | 	at org.apache.ratis.server.impl.RaftServerImpl.checkLeaderState(RaftServerImpl.java:661)
scm3.org_1   | 	at org.apache.ratis.server.impl.RaftServerImpl.submitClientRequestAsync(RaftServerImpl.java:800)
scm3.org_1   | 	at org.apache.ratis.server.impl.RaftServerImpl.lambda$null$12(RaftServerImpl.java:783)
scm3.org_1   | 	at org.apache.ratis.util.JavaUtils.callAsUnchecked(JavaUtils.java:115)
scm3.org_1   | 	at org.apache.ratis.server.impl.RaftServerImpl.lambda$executeSubmitClientRequestAsync$13(RaftServerImpl.java:783)
scm3.org_1   | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm3.org_1   | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm3.org_1   | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm3.org_1   | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm3.org_1   | 2022-07-10 13:22:42,427 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:57840
scm3.org_1   | 2022-07-10 13:22:42,493 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:23:12,353 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:39290
scm3.org_1   | 2022-07-10 13:23:12,404 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:23:12,482 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:57930
scm3.org_1   | 2022-07-10 13:23:12,548 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:59490
scm3.org_1   | 2022-07-10 13:23:12,553 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:23:12,571 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:23:42,331 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:39382
scm3.org_1   | 2022-07-10 13:23:42,367 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:23:42,437 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:58024
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om2:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-07-10 13:21:49,838 [FixedThreadPoolWithAffinityExecutor-1-0] INFO scm.ReconContainerManager: New container #3 got from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net.
recon_1      | 2022-07-10 13:21:49,868 [FixedThreadPoolWithAffinityExecutor-1-0] WARN scm.ReconContainerManager: Pipeline PipelineID=4b252efb-01a1-4e01-91ab-55e9b6197fe7 not found. Cannot add container #3
recon_1      | 2022-07-10 13:21:49,869 [FixedThreadPoolWithAffinityExecutor-1-0] WARN scm.ReconIncrementalContainerReportHandler: Container 3 not found!
recon_1      | 2022-07-10 13:22:11,195 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37564
recon_1      | 2022-07-10 13:22:11,252 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50120
recon_1      | 2022-07-10 13:22:11,270 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-07-10 13:22:11,309 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-07-10 13:22:19,876 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:44834
recon_1      | 2022-07-10 13:22:19,890 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-07-10 13:22:19,925 [FixedThreadPoolWithAffinityExecutor-1-0] WARN scm.ReconContainerManager: Pipeline PipelineID=4b252efb-01a1-4e01-91ab-55e9b6197fe7 not found. Cannot add container #3
recon_1      | 2022-07-10 13:22:19,926 [FixedThreadPoolWithAffinityExecutor-1-0] ERROR container.ContainerReportHandler: Received container report for an unknown container 3 from datanode 992f3c0d-344e-4060-87f0-890ffe8b867e{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
recon_1      | 2022-07-10 13:22:41,165 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37658
recon_1      | 2022-07-10 13:22:41,203 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50212
recon_1      | 2022-07-10 13:22:41,218 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm3.org_1   | 2022-07-10 13:23:42,490 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:23:42,540 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:59580
scm3.org_1   | 2022-07-10 13:23:42,564 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:23:44,111 [6f9a84f7-8019-4c66-ba45-e86fba2381f6@group-8EEEA6081008-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 53ed973d-ea12-43b6-82a5-130c22b6b2db, Nodes: a1e412ee-75aa-4bf8-87bc-4e8e615b1959{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: STANDALONE/ONE, State:OPEN, leaderId:, CreationTimestamp2022-07-10T13:23:44.088Z[UTC]].
scm3.org_1   | 2022-07-10 13:24:12,323 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:39494
scm3.org_1   | 2022-07-10 13:24:12,358 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:24:12,539 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:58136
scm3.org_1   | 2022-07-10 13:24:12,545 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:59690
scm3.org_1   | 2022-07-10 13:24:12,546 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:24:12,550 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:24:13,457 [6f9a84f7-8019-4c66-ba45-e86fba2381f6@group-8EEEA6081008-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Pipeline Pipeline[ Id: 53ed973d-ea12-43b6-82a5-130c22b6b2db, Nodes: a1e412ee-75aa-4bf8-87bc-4e8e615b1959{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: STANDALONE/ONE, State:CLOSED, leaderId:, CreationTimestamp2022-07-10T13:23:44.088Z[UTC]] removed.
scm3.org_1   | 2022-07-10 13:24:32,467 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:59202
scm3.org_1   | 2022-07-10 13:24:32,479 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm3.org_1   | 2022-07-10 13:24:32,951 [IPC Server handler 17 on default port 9860] INFO replication.ReplicationManager: Stopping Replication Monitor Thread.
scm3.org_1   | 2022-07-10 13:24:32,953 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread is stopped
scm3.org_1   | 2022-07-10 13:24:41,237 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:59222
scm3.org_1   | 2022-07-10 13:24:41,241 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm3.org_1   | 2022-07-10 13:24:41,242 [IPC Server handler 98 on default port 9860] INFO replication.ReplicationManager: Starting Replication Monitor Thread.
scm3.org_1   | 2022-07-10 13:24:41,253 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm3.org_1   | 2022-07-10 13:24:42,323 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:39598
scm3.org_1   | 2022-07-10 13:24:42,365 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:24:42,478 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:58242
scm3.org_1   | 2022-07-10 13:24:42,503 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:24:42,534 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:59794
scm3.org_1   | 2022-07-10 13:24:42,550 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:25:12,354 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:39694
scm3.org_1   | 2022-07-10 13:25:12,368 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:25:12,427 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:58340
scm3.org_1   | 2022-07-10 13:25:12,483 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:59892
scm3.org_1   | 2022-07-10 13:25:12,490 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-07-10 13:25:12,548 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 2022-07-10 13:22:41,239 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-07-10 13:22:42,157 [FixedThreadPoolWithAffinityExecutor-8-0] INFO scm.ReconContainerManager: Container #1 has state OPEN, but given state is CLOSING.
recon_1      | 2022-07-10 13:22:42,304 [FixedThreadPoolWithAffinityExecutor-1-0] INFO container.IncrementalContainerReportHandler: Moving container #1 to CLOSED state, datanode a1e412ee-75aa-4bf8-87bc-4e8e615b1959{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} reported CLOSED replica.
recon_1      | 2022-07-10 13:22:42,369 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:44896
recon_1      | 2022-07-10 13:22:42,395 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-07-10 13:22:42,396 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-07-10 13:22:42,454 [pool-28-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om2:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-07-10 13:22:42,465 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-07-10 13:23:12,319 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50308
recon_1      | 2022-07-10 13:23:12,381 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-07-10 13:23:12,441 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:44998
recon_1      | 2022-07-10 13:23:12,513 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37786
recon_1      | 2022-07-10 13:23:12,521 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-07-10 13:23:12,534 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-07-10 13:23:42,327 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50404
recon_1      | 2022-07-10 13:23:42,377 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-07-10 13:23:42,431 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:45086
recon_1      | 2022-07-10 13:23:42,455 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-07-10 13:23:42,455 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-07-10 13:23:42,470 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-07-10 13:23:42,531 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37868
recon_1      | 2022-07-10 13:23:42,537 [pool-28-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om2:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-07-10 13:23:42,562 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-07-10 13:24:12,324 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50508
recon_1      | 2022-07-10 13:24:12,352 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-07-10 13:24:12,437 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:45196
recon_1      | 2022-07-10 13:24:12,465 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-07-10 13:24:12,505 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37976
recon_1      | 2022-07-10 13:24:12,517 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-07-10 13:24:12,553 [FixedThreadPoolWithAffinityExecutor-1-0] WARN scm.ReconContainerManager: Pipeline PipelineID=4b252efb-01a1-4e01-91ab-55e9b6197fe7 not found. Cannot add container #3
recon_1      | 2022-07-10 13:24:12,553 [FixedThreadPoolWithAffinityExecutor-1-0] ERROR container.ContainerReportHandler: Received container report for an unknown container 3 from datanode 992f3c0d-344e-4060-87f0-890ffe8b867e{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
recon_1      | 2022-07-10 13:24:40,926 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 1 milliseconds to process 0 existing database records.
recon_1      | 2022-07-10 13:24:40,935 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 9 milliseconds for processing 2 containers.
recon_1      | 2022-07-10 13:24:41,118 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 5 pipelines in house.
recon_1      | 2022-07-10 13:24:41,119 [PipelineSyncTask] INFO scm.ReconPipelineManager: Adding new pipeline PipelineID=4b252efb-01a1-4e01-91ab-55e9b6197fe7 from SCM.
recon_1      | 2022-07-10 13:24:41,121 [PipelineSyncTask] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 4b252efb-01a1-4e01-91ab-55e9b6197fe7, Nodes: 992f3c0d-344e-4060-87f0-890ffe8b867e{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: STANDALONE/ONE, State:OPEN, leaderId:, CreationTimestamp2022-07-10T13:21:47.707Z[UTC]].
recon_1      | 2022-07-10 13:24:41,124 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 46 milliseconds.
recon_1      | 2022-07-10 13:24:42,329 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50616
recon_1      | 2022-07-10 13:24:42,366 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-07-10 13:24:42,418 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:45296
recon_1      | 2022-07-10 13:24:42,459 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-07-10 13:24:42,505 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:38082
recon_1      | 2022-07-10 13:24:42,543 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-07-10 13:24:42,544 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-07-10 13:24:42,549 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-07-10 13:24:42,591 [pool-28-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om2:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-07-10 13:25:12,351 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50712
recon_1      | 2022-07-10 13:25:12,366 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-07-10 13:25:12,453 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:45396
recon_1      | 2022-07-10 13:25:12,475 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:38178
recon_1      | 2022-07-10 13:25:12,499 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-07-10 13:25:12,536 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
