rm: cannot remove '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/*': No such file or directory
Executing test in ozone-mr
rm: cannot remove '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/ozone-mr/result/*': No such file or directory
Executing test in hadoop27
Removing network hadoop27_default
Network hadoop27_default not found.
Creating network "hadoop27_default" with the default driver
Pulling datanode (apache/ozone-runner:20220623-1)...
20220623-1: Pulling from apache/ozone-runner
Digest: sha256:ba2ed07322bc8f888150fa2a1ec0523fca85e09c8eb9779445f8bca0d58cff97
Status: Downloaded newer image for apache/ozone-runner:20220623-1
Pulling rm (flokkr/hadoop:2.7.3)...
2.7.3: Pulling from flokkr/hadoop
Digest: sha256:e791dc9bfa858e24443e1f1d70bfacf8382e0b8b9c4063fee38a460c26967b8e
Status: Downloaded newer image for flokkr/hadoop:2.7.3
Creating hadoop27_om_1 ... 
Creating hadoop27_nm_1 ... 
Creating hadoop27_datanode_1 ... 
Creating hadoop27_datanode_2 ... 
Creating hadoop27_datanode_3 ... 
Creating hadoop27_s3g_1      ... 
Creating hadoop27_scm_1      ... 
Creating hadoop27_rm_1       ... 
Creating hadoop27_om_1       ... done
Creating hadoop27_datanode_2 ... done
Creating hadoop27_nm_1       ... done
Creating hadoop27_s3g_1      ... done
Creating hadoop27_scm_1      ... done
Creating hadoop27_rm_1       ... done
Creating hadoop27_datanode_3 ... done
Creating hadoop27_datanode_1 ... done
SECONDS: 44
com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm/172.18.0.8 to scm:9860 failed on connection exception: java.net.ConnectException: Connection refused; For more details see: http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy19.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.8:9860 after 1 failover attempts. Trying to failover after sleeping for 2000ms. com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm/172.18.0.8 to scm:9860 failed on connection exception: java.net.ConnectException: Connection refused; For more details see: http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy19.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.8:9860 after 2 failover attempts. Trying to failover after sleeping for 2000ms. com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:a82484f7-ac63-4fec-a26b-b599ce196f05 is not the leader. Could not determine the leader node. at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109) at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246) at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:191) at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:61195) at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:423) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966) , while invoking $Proxy19.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.8:9860 after 3 failover attempts. Trying to failover after sleeping for 2000ms. com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:a82484f7-ac63-4fec-a26b-b599ce196f05 is not the leader. Could not determine the leader node. at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109) at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246) at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:191) at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:61195) at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:423) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966) , while invoking $Proxy19.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.8:9860 after 4 failover attempts. Trying to failover after sleeping for 2000ms. com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:a82484f7-ac63-4fec-a26b-b599ce196f05 is not the leader. Could not determine the leader node. at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109) at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246) at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:191) at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:61195) at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:423) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966) , while invoking $Proxy19.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.8:9860 after 5 failover attempts. Trying to failover after sleeping for 2000ms. SCM is in safe mode. validated:false, DataNodeSafeModeRule, registered datanodes (=2) >= required datanodes (=3) validated:false, HealthyPipelineSafeModeRule, healthy Ratis/THREE pipelines (=0) >= healthyPipelineThresholdCount (=1) validated:true, ContainerSafeModeRule, % of containers with at least one reported replica (=1.00) >= safeModeCutoff (=0.99) validated:true, AtleastOneDatanodeReportedRule, reported Ratis/THREE pipelines with at least one datanode (=0) >= threshold (=0)
SECONDS: 56
SCM is in safe mode. validated:true, DataNodeSafeModeRule, registered datanodes (=3) >= required datanodes (=3) validated:false, HealthyPipelineSafeModeRule, healthy Ratis/THREE pipelines (=0) >= healthyPipelineThresholdCount (=1) validated:true, ContainerSafeModeRule, % of containers with at least one reported replica (=1.00) >= safeModeCutoff (=0.99) validated:true, AtleastOneDatanodeReportedRule, reported Ratis/THREE pipelines with at least one datanode (=0) >= threshold (=0)
SECONDS: 62
SCM is in safe mode. validated:true, DataNodeSafeModeRule, registered datanodes (=3) >= required datanodes (=3) validated:false, HealthyPipelineSafeModeRule, healthy Ratis/THREE pipelines (=0) >= healthyPipelineThresholdCount (=1) validated:true, ContainerSafeModeRule, % of containers with at least one reported replica (=1.00) >= safeModeCutoff (=0.99) validated:true, AtleastOneDatanodeReportedRule, reported Ratis/THREE pipelines with at least one datanode (=0) >= threshold (=0)
SECONDS: 69
SCM is out of safe mode.
Safe mode is off
No OM HA service, no need to wait
==============================================================================
Createmrenv :: Create directories required for MR test                        
==============================================================================
Create test volume, bucket and key                                    | PASS |
------------------------------------------------------------------------------
Create user dir for hadoop                                            | PASS |
------------------------------------------------------------------------------
Createmrenv :: Create directories required for MR test                | PASS |
2 tests, 2 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/hadoop27/result/robot-hadoop27-hadoop27-createmrenv-scm.xml
==============================================================================
hadoopfs-o3fs :: Test ozone fs with hadoopfs                                  
==============================================================================
Test hadoop dfs                                                       | PASS |
------------------------------------------------------------------------------
hadoopfs-o3fs :: Test ozone fs with hadoopfs                          | PASS |
1 critical test, 1 passed, 0 failed
1 test total, 1 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/hadoop27/result/robot-hadoop27-hadoop27-createmrenv-scm-1.xml
==============================================================================
mapreduce-o3fs :: Execute MR jobs                                             
==============================================================================
Execute PI calculation                                                | PASS |
------------------------------------------------------------------------------
Execute WordCount                                                     | PASS |
------------------------------------------------------------------------------
mapreduce-o3fs :: Execute MR jobs                                     | PASS |
2 critical tests, 2 passed, 0 failed
2 tests total, 2 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/hadoop27/result/robot-hadoop27-hadoop27-createmrenv-scm-2.xml
==============================================================================
hadoopfs-ofs :: Test ozone fs with hadoopfs                                   
==============================================================================
Test hadoop dfs                                                       | PASS |
------------------------------------------------------------------------------
hadoopfs-ofs :: Test ozone fs with hadoopfs                           | PASS |
1 critical test, 1 passed, 0 failed
1 test total, 1 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/hadoop27/result/robot-hadoop27-hadoop27-createmrenv-scm-3.xml
==============================================================================
mapreduce-ofs :: Execute MR jobs                                              
==============================================================================
Execute PI calculation                                                | PASS |
------------------------------------------------------------------------------
Execute WordCount                                                     | PASS |
------------------------------------------------------------------------------
mapreduce-ofs :: Execute MR jobs                                      | PASS |
2 critical tests, 2 passed, 0 failed
2 tests total, 2 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/hadoop27/result/robot-hadoop27-hadoop27-createmrenv-scm-4.xml
Stopping hadoop27_rm_1       ... 
Stopping hadoop27_datanode_3 ... 
Stopping hadoop27_scm_1      ... 
Stopping hadoop27_datanode_1 ... 
Stopping hadoop27_s3g_1      ... 
Stopping hadoop27_datanode_2 ... 
Stopping hadoop27_om_1       ... 
Stopping hadoop27_nm_1       ... 
Stopping hadoop27_rm_1       ... done
Stopping hadoop27_nm_1       ... done
Stopping hadoop27_s3g_1      ... done
Stopping hadoop27_om_1       ... done
Stopping hadoop27_datanode_3 ... done
Stopping hadoop27_scm_1      ... done
Stopping hadoop27_datanode_1 ... done
Stopping hadoop27_datanode_2 ... done
Removing hadoop27_rm_1       ... 
Removing hadoop27_datanode_3 ... 
Removing hadoop27_scm_1      ... 
Removing hadoop27_datanode_1 ... 
Removing hadoop27_s3g_1      ... 
Removing hadoop27_datanode_2 ... 
Removing hadoop27_om_1       ... 
Removing hadoop27_nm_1       ... 
Removing hadoop27_datanode_2 ... done
Removing hadoop27_rm_1       ... done
Removing hadoop27_s3g_1      ... done
Removing hadoop27_om_1       ... done
Removing hadoop27_scm_1      ... done
Removing hadoop27_datanode_1 ... done
Removing hadoop27_datanode_3 ... done
Removing hadoop27_nm_1       ... done
Removing network hadoop27_default
Log:     /home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/ozone-mr/hadoop27/result/log.html
Report:  /home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/ozone-mr/hadoop27/result/report.html
Output:  /home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/ozone-mr/result/hadoop27.xml
removed 'hadoop27/result/robot-hadoop27-hadoop27-createmrenv-scm-1.xml'
removed 'hadoop27/result/robot-hadoop27-hadoop27-createmrenv-scm-2.xml'
removed 'hadoop27/result/robot-hadoop27-hadoop27-createmrenv-scm-3.xml'
removed 'hadoop27/result/robot-hadoop27-hadoop27-createmrenv-scm-4.xml'
removed 'hadoop27/result/robot-hadoop27-hadoop27-createmrenv-scm.xml'
removed 'hadoop27/result/log.html'
removed 'hadoop27/result/report.html'
renamed 'hadoop27/result/dn-audit-5b008efd1866.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/ozone-mr/result/hadoop27/dn-audit-5b008efd1866.log'
renamed 'hadoop27/result/dn-audit-b4a118ef0e00.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/ozone-mr/result/hadoop27/dn-audit-b4a118ef0e00.log'
renamed 'hadoop27/result/dn-audit-ff70d4143b2a.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/ozone-mr/result/hadoop27/dn-audit-ff70d4143b2a.log'
renamed 'hadoop27/result/docker-hadoop27-hadoop27-createmrenv-scm.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/ozone-mr/result/hadoop27/docker-hadoop27-hadoop27-createmrenv-scm.log'
renamed 'hadoop27/result/om-audit-om.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/ozone-mr/result/hadoop27/om-audit-om.log'
renamed 'hadoop27/result/s3g-audit-s3g.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/ozone-mr/result/hadoop27/s3g-audit-s3g.log'
renamed 'hadoop27/result/scm-audit-scm.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/ozone-mr/result/hadoop27/scm-audit-scm.log'
Executing test in hadoop31
Removing network hadoop31_default
Network hadoop31_default not found.
Creating network "hadoop31_default" with the default driver
Pulling rm (flokkr/hadoop:3.1.2)...
3.1.2: Pulling from flokkr/hadoop
Digest: sha256:1a24784735a3f243d7c0b2d1f49e74c42bb2ae8d7fc0f24aca2c740875f379f5
Status: Downloaded newer image for flokkr/hadoop:3.1.2
Creating hadoop31_s3g_1 ... 
Creating hadoop31_nm_1  ... 
Creating hadoop31_datanode_1 ... 
Creating hadoop31_om_1       ... 
Creating hadoop31_datanode_2 ... 
Creating hadoop31_rm_1       ... 
Creating hadoop31_datanode_3 ... 
Creating hadoop31_scm_1      ... 
Creating hadoop31_s3g_1      ... done
Creating hadoop31_nm_1       ... done
Creating hadoop31_rm_1       ... done
Creating hadoop31_om_1       ... done
Creating hadoop31_datanode_2 ... done
Creating hadoop31_datanode_3 ... done
Creating hadoop31_scm_1      ... done
Creating hadoop31_datanode_1 ... done
SECONDS: 45
com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm/172.19.0.7 to scm:9860 failed on connection exception: java.net.ConnectException: Connection refused; For more details see: http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy19.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.19.0.7:9860 after 1 failover attempts. Trying to failover after sleeping for 2000ms. com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm/172.19.0.7 to scm:9860 failed on connection exception: java.net.ConnectException: Connection refused; For more details see: http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy19.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.19.0.7:9860 after 2 failover attempts. Trying to failover after sleeping for 2000ms. com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:350452ba-deab-4d4c-84af-8fe2a55bad6e is not the leader. Could not determine the leader node. at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109) at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246) at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:191) at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:61195) at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:423) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966) , while invoking $Proxy19.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.19.0.7:9860 after 3 failover attempts. Trying to failover after sleeping for 2000ms. com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:350452ba-deab-4d4c-84af-8fe2a55bad6e is not the leader. Could not determine the leader node. at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109) at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246) at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:191) at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:61195) at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:423) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966) , while invoking $Proxy19.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.19.0.7:9860 after 4 failover attempts. Trying to failover after sleeping for 2000ms. com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:350452ba-deab-4d4c-84af-8fe2a55bad6e is not the leader. Could not determine the leader node. at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109) at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246) at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:191) at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:61195) at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:423) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966) , while invoking $Proxy19.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.19.0.7:9860 after 5 failover attempts. Trying to failover after sleeping for 2000ms. SCM is in safe mode. validated:false, DataNodeSafeModeRule, registered datanodes (=0) >= required datanodes (=3) validated:false, HealthyPipelineSafeModeRule, healthy Ratis/THREE pipelines (=0) >= healthyPipelineThresholdCount (=1) validated:true, ContainerSafeModeRule, % of containers with at least one reported replica (=1.00) >= safeModeCutoff (=0.99) validated:true, AtleastOneDatanodeReportedRule, reported Ratis/THREE pipelines with at least one datanode (=0) >= threshold (=0)
SECONDS: 58
SCM is in safe mode. validated:true, DataNodeSafeModeRule, registered datanodes (=3) >= required datanodes (=3) validated:false, HealthyPipelineSafeModeRule, healthy Ratis/THREE pipelines (=0) >= healthyPipelineThresholdCount (=1) validated:true, ContainerSafeModeRule, % of containers with at least one reported replica (=1.00) >= safeModeCutoff (=0.99) validated:true, AtleastOneDatanodeReportedRule, reported Ratis/THREE pipelines with at least one datanode (=0) >= threshold (=0)
SECONDS: 64
SCM is in safe mode. validated:true, DataNodeSafeModeRule, registered datanodes (=3) >= required datanodes (=3) validated:false, HealthyPipelineSafeModeRule, healthy Ratis/THREE pipelines (=0) >= healthyPipelineThresholdCount (=1) validated:true, ContainerSafeModeRule, % of containers with at least one reported replica (=1.00) >= safeModeCutoff (=0.99) validated:true, AtleastOneDatanodeReportedRule, reported Ratis/THREE pipelines with at least one datanode (=0) >= threshold (=0)
SECONDS: 70
SCM is out of safe mode.
Safe mode is off
No OM HA service, no need to wait
==============================================================================
Createmrenv :: Create directories required for MR test                        
==============================================================================
Create test volume, bucket and key                                    | PASS |
------------------------------------------------------------------------------
Create user dir for hadoop                                            | PASS |
------------------------------------------------------------------------------
Createmrenv :: Create directories required for MR test                | PASS |
2 tests, 2 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/hadoop31/result/robot-hadoop31-hadoop31-createmrenv-scm.xml
==============================================================================
hadoopfs-o3fs :: Test ozone fs with hadoopfs                                  
==============================================================================
Test hadoop dfs                                                       | PASS |
------------------------------------------------------------------------------
hadoopfs-o3fs :: Test ozone fs with hadoopfs                          | PASS |
1 critical test, 1 passed, 0 failed
1 test total, 1 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/hadoop31/result/robot-hadoop31-hadoop31-createmrenv-scm-1.xml
==============================================================================
mapreduce-o3fs :: Execute MR jobs                                             
==============================================================================
Execute PI calculation                                                | PASS |
------------------------------------------------------------------------------
Execute WordCount                                                     | PASS |
------------------------------------------------------------------------------
mapreduce-o3fs :: Execute MR jobs                                     | PASS |
2 critical tests, 2 passed, 0 failed
2 tests total, 2 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/hadoop31/result/robot-hadoop31-hadoop31-createmrenv-scm-2.xml
==============================================================================
hadoopfs-ofs :: Test ozone fs with hadoopfs                                   
==============================================================================
Test hadoop dfs                                                       | PASS |
------------------------------------------------------------------------------
hadoopfs-ofs :: Test ozone fs with hadoopfs                           | PASS |
1 critical test, 1 passed, 0 failed
1 test total, 1 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/hadoop31/result/robot-hadoop31-hadoop31-createmrenv-scm-3.xml
==============================================================================
mapreduce-ofs :: Execute MR jobs                                              
==============================================================================
Execute PI calculation                                                | PASS |
------------------------------------------------------------------------------
Execute WordCount                                                     | PASS |
------------------------------------------------------------------------------
mapreduce-ofs :: Execute MR jobs                                      | PASS |
2 critical tests, 2 passed, 0 failed
2 tests total, 2 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/hadoop31/result/robot-hadoop31-hadoop31-createmrenv-scm-4.xml
Stopping hadoop31_datanode_2 ... 
Stopping hadoop31_scm_1      ... 
Stopping hadoop31_datanode_1 ... 
Stopping hadoop31_datanode_3 ... 
Stopping hadoop31_om_1       ... 
Stopping hadoop31_rm_1       ... 
Stopping hadoop31_s3g_1      ... 
Stopping hadoop31_nm_1       ... 
Stopping hadoop31_nm_1       ... done
Stopping hadoop31_rm_1       ... done
Stopping hadoop31_s3g_1      ... done
Stopping hadoop31_om_1       ... done
Stopping hadoop31_datanode_2 ... done
Stopping hadoop31_datanode_1 ... done
Stopping hadoop31_scm_1      ... done
Stopping hadoop31_datanode_3 ... done
Removing hadoop31_datanode_2 ... 
Removing hadoop31_scm_1      ... 
Removing hadoop31_datanode_1 ... 
Removing hadoop31_datanode_3 ... 
Removing hadoop31_om_1       ... 
Removing hadoop31_rm_1       ... 
Removing hadoop31_s3g_1      ... 
Removing hadoop31_nm_1       ... 
Removing hadoop31_om_1       ... done
Removing hadoop31_scm_1      ... done
Removing hadoop31_s3g_1      ... done
Removing hadoop31_rm_1       ... done
Removing hadoop31_nm_1       ... done
Removing hadoop31_datanode_2 ... done
Removing hadoop31_datanode_3 ... done
Removing hadoop31_datanode_1 ... done
Removing network hadoop31_default
Log:     /home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/ozone-mr/hadoop31/result/log.html
Report:  /home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/ozone-mr/hadoop31/result/report.html
Untagged: flokkr/hadoop:3.1.2
Untagged: flokkr/hadoop@sha256:1a24784735a3f243d7c0b2d1f49e74c42bb2ae8d7fc0f24aca2c740875f379f5
Deleted: sha256:16c3587f922f8fb5e1b0ac05de821efd30d04d85836aaa10a2df79dd1f92f615
Deleted: sha256:010620410c1e290373202ccc6f4442d3354cef0923d714584b73d0e736f2c205
Deleted: sha256:58dbdfa32985cd3e46f4e5850b907165cce65888d72bdfb664296c1f522323f6
Deleted: sha256:6b56022c9f422dc0caf5f6f96ae46bcf482a8d5447868cf8dee4d40dc87c965c
Deleted: sha256:26cbf04863ce6238d4bd93150f7072cd4c4d1a1914970abd8ba9fc2ea2b3a947
Deleted: sha256:ac193886605465fa3803c944393eb4d1717cca0dffd84a3dc692b1871974f205
Deleted: sha256:6b9224926483f93910c167e35e2cf0a186c2203cff0a71fc19986a6db3033750
Output:  /home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/ozone-mr/result/hadoop31.xml
removed 'hadoop31/result/robot-hadoop31-hadoop31-createmrenv-scm-1.xml'
removed 'hadoop31/result/robot-hadoop31-hadoop31-createmrenv-scm-2.xml'
removed 'hadoop31/result/robot-hadoop31-hadoop31-createmrenv-scm-3.xml'
removed 'hadoop31/result/robot-hadoop31-hadoop31-createmrenv-scm-4.xml'
removed 'hadoop31/result/robot-hadoop31-hadoop31-createmrenv-scm.xml'
removed 'hadoop31/result/log.html'
removed 'hadoop31/result/report.html'
renamed 'hadoop31/result/dn-audit-5f36cfa43fe3.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/ozone-mr/result/hadoop31/dn-audit-5f36cfa43fe3.log'
renamed 'hadoop31/result/dn-audit-86d663e27c94.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/ozone-mr/result/hadoop31/dn-audit-86d663e27c94.log'
renamed 'hadoop31/result/dn-audit-a1baf3d827c9.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/ozone-mr/result/hadoop31/dn-audit-a1baf3d827c9.log'
renamed 'hadoop31/result/docker-hadoop31-hadoop31-createmrenv-scm.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/ozone-mr/result/hadoop31/docker-hadoop31-hadoop31-createmrenv-scm.log'
renamed 'hadoop31/result/om-audit-om.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/ozone-mr/result/hadoop31/om-audit-om.log'
renamed 'hadoop31/result/s3g-audit-s3g.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/ozone-mr/result/hadoop31/s3g-audit-s3g.log'
renamed 'hadoop31/result/scm-audit-scm.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/ozone-mr/result/hadoop31/scm-audit-scm.log'
Executing test in hadoop32
Removing network hadoop32_default
Network hadoop32_default not found.
Creating network "hadoop32_default" with the default driver
Pulling rm (flokkr/hadoop:3.2.2)...
3.2.2: Pulling from flokkr/hadoop
Digest: sha256:958a6c5a3af4a01b3347ccc57052df78033e401fd9dff965148b0939782e2c9e
Status: Downloaded newer image for flokkr/hadoop:3.2.2
Creating hadoop32_om_1 ... 
Creating hadoop32_nm_1 ... 
Creating hadoop32_rm_1 ... 
Creating hadoop32_datanode_1 ... 
Creating hadoop32_datanode_2 ... 
Creating hadoop32_s3g_1      ... 
Creating hadoop32_scm_1      ... 
Creating hadoop32_datanode_3 ... 
Creating hadoop32_nm_1       ... done
Creating hadoop32_om_1       ... done
Creating hadoop32_s3g_1      ... done
Creating hadoop32_scm_1      ... done
Creating hadoop32_rm_1       ... done
Creating hadoop32_datanode_1 ... done
Creating hadoop32_datanode_3 ... done
Creating hadoop32_datanode_2 ... done
SECONDS: 50
com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm/172.20.0.5 to scm:9860 failed on connection exception: java.net.ConnectException: Connection refused; For more details see: http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy20.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.20.0.5:9860 after 1 failover attempts. Trying to failover after sleeping for 2000ms. com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm/172.20.0.5 to scm:9860 failed on connection exception: java.net.ConnectException: Connection refused; For more details see: http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy20.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.20.0.5:9860 after 2 failover attempts. Trying to failover after sleeping for 2000ms. com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:d50cbf49-a336-4196-94ba-16f98e862a34 is not the leader. Could not determine the leader node. at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109) at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246) at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:191) at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:61195) at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:423) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966) , while invoking $Proxy20.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.20.0.5:9860 after 3 failover attempts. Trying to failover after sleeping for 2000ms. com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:d50cbf49-a336-4196-94ba-16f98e862a34 is not the leader. Could not determine the leader node. at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109) at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246) at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:191) at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:61195) at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:423) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966) , while invoking $Proxy20.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.20.0.5:9860 after 4 failover attempts. Trying to failover after sleeping for 2000ms. com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:d50cbf49-a336-4196-94ba-16f98e862a34 is not the leader. Could not determine the leader node. at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109) at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246) at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:191) at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:61195) at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:423) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966) , while invoking $Proxy20.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.20.0.5:9860 after 5 failover attempts. Trying to failover after sleeping for 2000ms. SCM is in safe mode. validated:true, DataNodeSafeModeRule, registered datanodes (=3) >= required datanodes (=3) validated:false, HealthyPipelineSafeModeRule, healthy Ratis/THREE pipelines (=0) >= healthyPipelineThresholdCount (=1) validated:true, ContainerSafeModeRule, % of containers with at least one reported replica (=1.00) >= safeModeCutoff (=0.99) validated:true, AtleastOneDatanodeReportedRule, reported Ratis/THREE pipelines with at least one datanode (=0) >= threshold (=0)
SECONDS: 64
SCM is out of safe mode.
Safe mode is off
No OM HA service, no need to wait
==============================================================================
Createmrenv :: Create directories required for MR test                        
==============================================================================
Create test volume, bucket and key                                    | PASS |
------------------------------------------------------------------------------
Create user dir for hadoop                                            | PASS |
------------------------------------------------------------------------------
Createmrenv :: Create directories required for MR test                | PASS |
2 tests, 2 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/hadoop32/result/robot-hadoop32-hadoop32-createmrenv-scm.xml
==============================================================================
hadoopfs-o3fs :: Test ozone fs with hadoopfs                                  
==============================================================================
Test hadoop dfs                                                       | PASS |
------------------------------------------------------------------------------
hadoopfs-o3fs :: Test ozone fs with hadoopfs                          | PASS |
1 critical test, 1 passed, 0 failed
1 test total, 1 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/hadoop32/result/robot-hadoop32-hadoop32-createmrenv-scm-1.xml
==============================================================================
mapreduce-o3fs :: Execute MR jobs                                             
==============================================================================
Execute PI calculation                                                | PASS |
------------------------------------------------------------------------------
Execute WordCount                                                     | PASS |
------------------------------------------------------------------------------
mapreduce-o3fs :: Execute MR jobs                                     | PASS |
2 critical tests, 2 passed, 0 failed
2 tests total, 2 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/hadoop32/result/robot-hadoop32-hadoop32-createmrenv-scm-2.xml
==============================================================================
hadoopfs-ofs :: Test ozone fs with hadoopfs                                   
==============================================================================
Test hadoop dfs                                                       | PASS |
------------------------------------------------------------------------------
hadoopfs-ofs :: Test ozone fs with hadoopfs                           | PASS |
1 critical test, 1 passed, 0 failed
1 test total, 1 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/hadoop32/result/robot-hadoop32-hadoop32-createmrenv-scm-3.xml
==============================================================================
mapreduce-ofs :: Execute MR jobs                                              
==============================================================================
Execute PI calculation                                                | PASS |
------------------------------------------------------------------------------
Execute WordCount                                                     | PASS |
------------------------------------------------------------------------------
mapreduce-ofs :: Execute MR jobs                                      | PASS |
2 critical tests, 2 passed, 0 failed
2 tests total, 2 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/hadoop32/result/robot-hadoop32-hadoop32-createmrenv-scm-4.xml
Stopping hadoop32_datanode_3 ... 
Stopping hadoop32_datanode_1 ... 
Stopping hadoop32_datanode_2 ... 
Stopping hadoop32_s3g_1      ... 
Stopping hadoop32_scm_1      ... 
Stopping hadoop32_rm_1       ... 
Stopping hadoop32_nm_1       ... 
Stopping hadoop32_om_1       ... 
Stopping hadoop32_nm_1       ... done
Stopping hadoop32_rm_1       ... done
Stopping hadoop32_s3g_1      ... done
Stopping hadoop32_om_1       ... done
Stopping hadoop32_datanode_2 ... done
Stopping hadoop32_datanode_1 ... done
Stopping hadoop32_datanode_3 ... done
Stopping hadoop32_scm_1      ... done
Removing hadoop32_datanode_3 ... 
Removing hadoop32_datanode_1 ... 
Removing hadoop32_datanode_2 ... 
Removing hadoop32_s3g_1      ... 
Removing hadoop32_scm_1      ... 
Removing hadoop32_rm_1       ... 
Removing hadoop32_nm_1       ... 
Removing hadoop32_om_1       ... 
Removing hadoop32_s3g_1      ... done
Removing hadoop32_scm_1      ... done
Removing hadoop32_rm_1       ... done
Removing hadoop32_om_1       ... done
Removing hadoop32_datanode_3 ... done
Removing hadoop32_datanode_1 ... done
Removing hadoop32_datanode_2 ... done
Removing hadoop32_nm_1       ... done
Removing network hadoop32_default
Log:     /home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/ozone-mr/hadoop32/result/log.html
Report:  /home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/ozone-mr/hadoop32/result/report.html
Output:  /home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/ozone-mr/result/hadoop32.xml
removed 'hadoop32/result/robot-hadoop32-hadoop32-createmrenv-scm-1.xml'
removed 'hadoop32/result/robot-hadoop32-hadoop32-createmrenv-scm-2.xml'
removed 'hadoop32/result/robot-hadoop32-hadoop32-createmrenv-scm-3.xml'
removed 'hadoop32/result/robot-hadoop32-hadoop32-createmrenv-scm-4.xml'
removed 'hadoop32/result/robot-hadoop32-hadoop32-createmrenv-scm.xml'
removed 'hadoop32/result/log.html'
removed 'hadoop32/result/report.html'
renamed 'hadoop32/result/dn-audit-0d9cc4e3323b.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/ozone-mr/result/hadoop32/dn-audit-0d9cc4e3323b.log'
renamed 'hadoop32/result/dn-audit-908b909ecb40.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/ozone-mr/result/hadoop32/dn-audit-908b909ecb40.log'
renamed 'hadoop32/result/dn-audit-c8bef8fe68a6.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/ozone-mr/result/hadoop32/dn-audit-c8bef8fe68a6.log'
renamed 'hadoop32/result/docker-hadoop32-hadoop32-createmrenv-scm.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/ozone-mr/result/hadoop32/docker-hadoop32-hadoop32-createmrenv-scm.log'
renamed 'hadoop32/result/om-audit-om.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/ozone-mr/result/hadoop32/om-audit-om.log'
renamed 'hadoop32/result/s3g-audit-s3g.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/ozone-mr/result/hadoop32/s3g-audit-s3g.log'
renamed 'hadoop32/result/scm-audit-scm.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/ozone-mr/result/hadoop32/scm-audit-scm.log'
Executing test in hadoop33
Removing network hadoop33_default
Network hadoop33_default not found.
Creating network "hadoop33_default" with the default driver
Pulling rm (flokkr/hadoop:3.3.1)...
3.3.1: Pulling from flokkr/hadoop
Digest: sha256:2dd21ee3789687f6c297b43d618a0ff2b7ffd9e8a97a77b08643603ab8c3556d
Status: Downloaded newer image for flokkr/hadoop:3.3.1
Creating hadoop33_rm_1 ... 
Creating hadoop33_om_1 ... 
Creating hadoop33_s3g_1 ... 
Creating hadoop33_scm_1 ... 
Creating hadoop33_nm_1  ... 
Creating hadoop33_datanode_1 ... 
Creating hadoop33_datanode_2 ... 
Creating hadoop33_datanode_3 ... 
Creating hadoop33_rm_1       ... done
Creating hadoop33_s3g_1      ... done
Creating hadoop33_datanode_3 ... done
Creating hadoop33_datanode_1 ... done
Creating hadoop33_nm_1       ... done
Creating hadoop33_datanode_2 ... done
Creating hadoop33_om_1       ... done
Creating hadoop33_scm_1      ... done
SECONDS: 56
com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm/172.21.0.6 to scm:9860 failed on connection exception: java.net.ConnectException: Connection refused; For more details see: http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy20.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.21.0.6:9860 after 1 failover attempts. Trying to failover after sleeping for 2000ms. com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm/172.21.0.6 to scm:9860 failed on connection exception: java.net.ConnectException: Connection refused; For more details see: http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy20.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.21.0.6:9860 after 2 failover attempts. Trying to failover after sleeping for 2000ms. com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm/172.21.0.6 to scm:9860 failed on connection exception: java.net.ConnectException: Connection refused; For more details see: http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy20.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.21.0.6:9860 after 3 failover attempts. Trying to failover after sleeping for 2000ms. com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm/172.21.0.6 to scm:9860 failed on connection exception: java.net.ConnectException: Connection refused; For more details see: http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy20.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.21.0.6:9860 after 4 failover attempts. Trying to failover after sleeping for 2000ms. com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:ee8285d8-8be5-4be5-bcb8-3722d9065ec7 is not the leader. Could not determine the leader node. at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109) at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246) at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:191) at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:61195) at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:423) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966) , while invoking $Proxy20.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.21.0.6:9860 after 5 failover attempts. Trying to failover after sleeping for 2000ms. com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:ee8285d8-8be5-4be5-bcb8-3722d9065ec7 is not the leader. Could not determine the leader node. at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109) at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246) at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:191) at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:61195) at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:423) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966) , while invoking $Proxy20.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.21.0.6:9860 after 6 failover attempts. Trying to failover after sleeping for 2000ms. SCM is in safe mode. validated:false, DataNodeSafeModeRule, registered datanodes (=0) >= required datanodes (=3) validated:false, HealthyPipelineSafeModeRule, healthy Ratis/THREE pipelines (=0) >= healthyPipelineThresholdCount (=1) validated:true, ContainerSafeModeRule, % of containers with at least one reported replica (=1.00) >= safeModeCutoff (=0.99) validated:true, AtleastOneDatanodeReportedRule, reported Ratis/THREE pipelines with at least one datanode (=0) >= threshold (=0)
SECONDS: 72
SCM is in safe mode. validated:true, DataNodeSafeModeRule, registered datanodes (=3) >= required datanodes (=3) validated:true, HealthyPipelineSafeModeRule, healthy Ratis/THREE pipelines (=1) >= healthyPipelineThresholdCount (=1) validated:true, ContainerSafeModeRule, % of containers with at least one reported replica (=1.00) >= safeModeCutoff (=0.99) validated:true, AtleastOneDatanodeReportedRule, reported Ratis/THREE pipelines with at least one datanode (=0) >= threshold (=0)
SECONDS: 79
SCM is out of safe mode.
Safe mode is off
No OM HA service, no need to wait
==============================================================================
Createmrenv :: Create directories required for MR test                        
==============================================================================
Create test volume, bucket and key                                    | PASS |
------------------------------------------------------------------------------
Create user dir for hadoop                                            | PASS |
------------------------------------------------------------------------------
Createmrenv :: Create directories required for MR test                | PASS |
2 tests, 2 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/hadoop33/result/robot-hadoop33-hadoop33-createmrenv-scm.xml
==============================================================================
hadoopfs-o3fs :: Test ozone fs with hadoopfs                                  
==============================================================================
Test hadoop dfs                                                       | PASS |
------------------------------------------------------------------------------
hadoopfs-o3fs :: Test ozone fs with hadoopfs                          | PASS |
1 critical test, 1 passed, 0 failed
1 test total, 1 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/hadoop33/result/robot-hadoop33-hadoop33-createmrenv-scm-1.xml
==============================================================================
mapreduce-o3fs :: Execute MR jobs                                             
==============================================================================
Execute PI calculation                                                | PASS |
------------------------------------------------------------------------------
Execute WordCount                                                     | PASS |
------------------------------------------------------------------------------
mapreduce-o3fs :: Execute MR jobs                                     | PASS |
2 critical tests, 2 passed, 0 failed
2 tests total, 2 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/hadoop33/result/robot-hadoop33-hadoop33-createmrenv-scm-2.xml
==============================================================================
hadoopfs-ofs :: Test ozone fs with hadoopfs                                   
==============================================================================
Test hadoop dfs                                                       | PASS |
------------------------------------------------------------------------------
hadoopfs-ofs :: Test ozone fs with hadoopfs                           | PASS |
1 critical test, 1 passed, 0 failed
1 test total, 1 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/hadoop33/result/robot-hadoop33-hadoop33-createmrenv-scm-3.xml
==============================================================================
mapreduce-ofs :: Execute MR jobs                                              
==============================================================================
Execute PI calculation                                                | PASS |
------------------------------------------------------------------------------
Execute WordCount                                                     | PASS |
------------------------------------------------------------------------------
mapreduce-ofs :: Execute MR jobs                                      | PASS |
2 critical tests, 2 passed, 0 failed
2 tests total, 2 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/hadoop33/result/robot-hadoop33-hadoop33-createmrenv-scm-4.xml
Stopping hadoop33_datanode_1 ... 
Stopping hadoop33_datanode_3 ... 
Stopping hadoop33_nm_1       ... 
Stopping hadoop33_scm_1      ... 
Stopping hadoop33_datanode_2 ... 
Stopping hadoop33_s3g_1      ... 
Stopping hadoop33_om_1       ... 
Stopping hadoop33_rm_1       ... 
Stopping hadoop33_rm_1       ... done
Stopping hadoop33_nm_1       ... done
Stopping hadoop33_s3g_1      ... done
Stopping hadoop33_om_1       ... done
Stopping hadoop33_scm_1      ... done
Stopping hadoop33_datanode_2 ... done
Stopping hadoop33_datanode_1 ... done
Stopping hadoop33_datanode_3 ... done
Removing hadoop33_datanode_1 ... 
Removing hadoop33_datanode_3 ... 
Removing hadoop33_nm_1       ... 
Removing hadoop33_scm_1      ... 
Removing hadoop33_datanode_2 ... 
Removing hadoop33_s3g_1      ... 
Removing hadoop33_om_1       ... 
Removing hadoop33_rm_1       ... 
Removing hadoop33_scm_1      ... done
Removing hadoop33_s3g_1      ... done
Removing hadoop33_rm_1       ... done
Removing hadoop33_datanode_3 ... done
Removing hadoop33_om_1       ... done
Removing hadoop33_datanode_1 ... done
Removing hadoop33_datanode_2 ... done
Removing hadoop33_nm_1       ... done
Removing network hadoop33_default
Log:     /home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/ozone-mr/hadoop33/result/log.html
Report:  /home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/ozone-mr/hadoop33/result/report.html
Output:  /home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/ozone-mr/result/hadoop33.xml
removed 'hadoop33/result/robot-hadoop33-hadoop33-createmrenv-scm-1.xml'
removed 'hadoop33/result/robot-hadoop33-hadoop33-createmrenv-scm-2.xml'
removed 'hadoop33/result/robot-hadoop33-hadoop33-createmrenv-scm-3.xml'
removed 'hadoop33/result/robot-hadoop33-hadoop33-createmrenv-scm-4.xml'
removed 'hadoop33/result/robot-hadoop33-hadoop33-createmrenv-scm.xml'
removed 'hadoop33/result/log.html'
removed 'hadoop33/result/report.html'
renamed 'hadoop33/result/dn-audit-4e7417316f72.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/ozone-mr/result/hadoop33/dn-audit-4e7417316f72.log'
renamed 'hadoop33/result/dn-audit-9cc96ff958e9.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/ozone-mr/result/hadoop33/dn-audit-9cc96ff958e9.log'
renamed 'hadoop33/result/dn-audit-d5e8cdede85f.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/ozone-mr/result/hadoop33/dn-audit-d5e8cdede85f.log'
renamed 'hadoop33/result/docker-hadoop33-hadoop33-createmrenv-scm.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/ozone-mr/result/hadoop33/docker-hadoop33-hadoop33-createmrenv-scm.log'
renamed 'hadoop33/result/om-audit-om.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/ozone-mr/result/hadoop33/om-audit-om.log'
renamed 'hadoop33/result/s3g-audit-s3g.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/ozone-mr/result/hadoop33/s3g-audit-s3g.log'
renamed 'hadoop33/result/scm-audit-scm.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/ozone-mr/result/hadoop33/scm-audit-scm.log'
Log:     /home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/ozone-mr/result/log.html
Report:  /home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/ozone-mr/result/report.html
Output:  /home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozone-mr.xml
removed 'ozone-mr/result/hadoop27.xml'
removed 'ozone-mr/result/hadoop31.xml'
removed 'ozone-mr/result/hadoop32.xml'
removed 'ozone-mr/result/hadoop33.xml'
removed 'ozone-mr/result/log.html'
removed 'ozone-mr/result/report.html'
renamed 'ozone-mr/result/hadoop27' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozone-mr/hadoop27'
renamed 'ozone-mr/result/hadoop31' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozone-mr/hadoop31'
renamed 'ozone-mr/result/hadoop32' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozone-mr/hadoop32'
renamed 'ozone-mr/result/hadoop33' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozone-mr/hadoop33'
Executing test in ozonesecure-mr
Removing network ozone
Network ozone not found.
Creating network "ozone" with the default driver
Pulling kdc (apache/ozone-testkrb5:20210419-1)...
20210419-1: Pulling from apache/ozone-testkrb5
Digest: sha256:ba7a04b9f7605b9ac64f34400f426f1e9938ad2b5be93365685097ba962ed19a
Status: Downloaded newer image for apache/ozone-testkrb5:20210419-1
Creating ozonesecure-mr_rm_1 ... 
Creating ozonesecure-mr_scm_1 ... 
Creating ozonesecure-mr_s3g_1 ... 
Creating jhs                  ... 
Creating ozonesecure-mr_kms_1 ... 
Creating ozonesecure-mr_nm_1  ... 
Creating ozonesecure-mr_datanode_1 ... 
Creating ozonesecure-mr_datanode_2 ... 
Creating ozonesecure-mr_datanode_3 ... 
Creating ozonesecure-mr_kdc_1      ... 
Creating ozonesecure-mr_om_1       ... 
Creating jhs                       ... done
Creating ozonesecure-mr_rm_1       ... done
Creating ozonesecure-mr_nm_1       ... done
Creating ozonesecure-mr_scm_1      ... done
Creating ozonesecure-mr_s3g_1      ... done
Creating ozonesecure-mr_datanode_3 ... done
Creating ozonesecure-mr_datanode_1 ... done
Creating ozonesecure-mr_kdc_1      ... done
Creating ozonesecure-mr_datanode_2 ... done
Creating ozonesecure-mr_om_1       ... done
Creating ozonesecure-mr_kms_1      ... done
ozone.scm.client.address should be set in ozone-site.xml or with the --scm option
SECONDS: 35

SECONDS: 87
com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm/172.22.0.4 to scm:9860 failed on connection exception: java.net.ConnectException: Connection refused; For more details see: http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy20.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.22.0.4:9860 after 1 failover attempts. Trying to failover after sleeping for 2000ms. com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm/172.22.0.4 to scm:9860 failed on connection exception: java.net.ConnectException: Connection refused; For more details see: http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy20.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.22.0.4:9860 after 2 failover attempts. Trying to failover after sleeping for 2000ms. com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm/172.22.0.4 to scm:9860 failed on connection exception: java.net.ConnectException: Connection refused; For more details see: http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy20.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.22.0.4:9860 after 3 failover attempts. Trying to failover after sleeping for 2000ms. com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm/172.22.0.4 to scm:9860 failed on connection exception: java.net.ConnectException: Connection refused; For more details see: http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy20.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.22.0.4:9860 after 4 failover attempts. Trying to failover after sleeping for 2000ms. com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm/172.22.0.4 to scm:9860 failed on connection exception: java.net.ConnectException: Connection refused; For more details see: http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy20.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.22.0.4:9860 after 5 failover attempts. Trying to failover after sleeping for 2000ms. com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm/172.22.0.4 to scm:9860 failed on connection exception: java.net.ConnectException: Connection refused; For more details see: http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy20.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.22.0.4:9860 after 6 failover attempts. Trying to failover after sleeping for 2000ms. com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm/172.22.0.4 to scm:9860 failed on connection exception: java.net.ConnectException: Connection refused; For more details see: http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy20.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.22.0.4:9860 after 7 failover attempts. Trying to failover after sleeping for 2000ms. com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:d0e3996c-1320-4a04-a8c1-d1051766a1b8 is not the leader. Could not determine the leader node. at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109) at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246) at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:191) at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:61195) at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:423) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966) , while invoking $Proxy20.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.22.0.4:9860 after 8 failover attempts. Trying to failover after sleeping for 2000ms. com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:d0e3996c-1320-4a04-a8c1-d1051766a1b8 is not the leader. Could not determine the leader node. at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109) at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246) at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:191) at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:61195) at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:423) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966) , while invoking $Proxy20.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.22.0.4:9860 after 9 failover attempts. Trying to failover after sleeping for 2000ms. SCM is in safe mode. validated:false, DataNodeSafeModeRule, registered datanodes (=0) >= required datanodes (=3) validated:false, HealthyPipelineSafeModeRule, healthy Ratis/THREE pipelines (=0) >= healthyPipelineThresholdCount (=1) validated:true, ContainerSafeModeRule, % of containers with at least one reported replica (=1.00) >= safeModeCutoff (=0.99) validated:true, AtleastOneDatanodeReportedRule, reported Ratis/THREE pipelines with at least one datanode (=0) >= threshold (=0)
SECONDS: 116
SCM is in safe mode. validated:true, DataNodeSafeModeRule, registered datanodes (=3) >= required datanodes (=3) validated:false, HealthyPipelineSafeModeRule, healthy Ratis/THREE pipelines (=0) >= healthyPipelineThresholdCount (=1) validated:true, ContainerSafeModeRule, % of containers with at least one reported replica (=1.00) >= safeModeCutoff (=0.99) validated:true, AtleastOneDatanodeReportedRule, reported Ratis/THREE pipelines with at least one datanode (=0) >= threshold (=0)
SECONDS: 134
SCM is out of safe mode.
Safe mode is off
No OM HA service, no need to wait
==============================================================================
Kinit :: Kinit test user                                                      
==============================================================================
Kinit                                                                 | PASS |
------------------------------------------------------------------------------
Kinit :: Kinit test user                                              | PASS |
1 test, 1 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/ozonesecure-mr/result/robot-ozonesecure-mr-ozonesecure-mr-kinit-om.xml
==============================================================================
Createmrenv :: Create directories required for MR test                        
==============================================================================
Create test volume, bucket and key                                    | PASS |
------------------------------------------------------------------------------
Create user dir for hadoop                                            | PASS |
------------------------------------------------------------------------------
Createmrenv :: Create directories required for MR test                | PASS |
2 tests, 2 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/ozonesecure-mr/result/robot-ozonesecure-mr-ozonesecure-mr-kinit-om-1.xml
==============================================================================
Kinit-Hadoop :: Kinit test user                                               
==============================================================================
Kinit                                                                 | PASS |
------------------------------------------------------------------------------
Kinit-Hadoop :: Kinit test user                                       | PASS |
1 critical test, 1 passed, 0 failed
1 test total, 1 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/ozonesecure-mr/result/robot-ozonesecure-mr-ozonesecure-mr-kinit-om-2.xml
==============================================================================
hadoopfs-o3fs :: Test ozone fs with hadoopfs                                  
==============================================================================
Test hadoop dfs                                                       | PASS |
------------------------------------------------------------------------------
hadoopfs-o3fs :: Test ozone fs with hadoopfs                          | PASS |
1 critical test, 1 passed, 0 failed
1 test total, 1 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/ozonesecure-mr/result/robot-ozonesecure-mr-ozonesecure-mr-kinit-om-3.xml
==============================================================================
mapreduce-o3fs :: Execute MR jobs                                             
==============================================================================
Execute PI calculation                                                | PASS |
------------------------------------------------------------------------------
Execute WordCount                                                     | PASS |
------------------------------------------------------------------------------
mapreduce-o3fs :: Execute MR jobs                                     | PASS |
2 critical tests, 2 passed, 0 failed
2 tests total, 2 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/ozonesecure-mr/result/robot-ozonesecure-mr-ozonesecure-mr-kinit-om-4.xml
==============================================================================
hadoopfs-ofs :: Test ozone fs with hadoopfs                                   
==============================================================================
Test hadoop dfs                                                       | PASS |
------------------------------------------------------------------------------
hadoopfs-ofs :: Test ozone fs with hadoopfs                           | PASS |
1 critical test, 1 passed, 0 failed
1 test total, 1 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/ozonesecure-mr/result/robot-ozonesecure-mr-ozonesecure-mr-kinit-om-5.xml
==============================================================================
mapreduce-ofs :: Execute MR jobs                                              
==============================================================================
Execute PI calculation                                                | PASS |
------------------------------------------------------------------------------
Execute WordCount                                                     | FAIL |
Test timeout 4 minutes exceeded.
------------------------------------------------------------------------------
mapreduce-ofs :: Execute MR jobs                                      | FAIL |
2 critical tests, 1 passed, 1 failed
2 tests total, 1 passed, 1 failed
==============================================================================
Output:  /tmp/smoketest/ozonesecure-mr/result/robot-ozonesecure-mr-ozonesecure-mr-kinit-om-6.xml
jstack 7 > /home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/ozonesecure-mr/result/ozonesecure-mr_datanode_1_HddsDatanodeService.stack
jstack 6 > /home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/ozonesecure-mr/result/ozonesecure-mr_datanode_2_HddsDatanodeService.stack
jstack 7 > /home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/ozonesecure-mr/result/ozonesecure-mr_datanode_3_HddsDatanodeService.stack
jstack 7 > /home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/ozonesecure-mr/result/ozonesecure-mr_om_1_OzoneManagerStarter.stack
jstack 7 > /home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/ozonesecure-mr/result/ozonesecure-mr_s3g_1_Gateway.stack
jstack 6 > /home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/ozonesecure-mr/result/ozonesecure-mr_scm_1_StorageContainerManagerStarter.stack
Stopping ozonesecure-mr_kdc_1      ... 
Stopping ozonesecure-mr_om_1       ... 
Stopping ozonesecure-mr_datanode_1 ... 
Stopping ozonesecure-mr_nm_1       ... 
Stopping ozonesecure-mr_datanode_3 ... 
Stopping ozonesecure-mr_datanode_2 ... 
Stopping ozonesecure-mr_kms_1      ... 
Stopping ozonesecure-mr_s3g_1      ... 
Stopping jhs                       ... 
Stopping ozonesecure-mr_scm_1      ... 
Stopping ozonesecure-mr_rm_1       ... 
Stopping ozonesecure-mr_kdc_1      ... done
Stopping ozonesecure-mr_kms_1      ... done
Stopping ozonesecure-mr_nm_1       ... done
Stopping jhs                       ... done
Stopping ozonesecure-mr_rm_1       ... done
Stopping ozonesecure-mr_s3g_1      ... done
Stopping ozonesecure-mr_om_1       ... done
Stopping ozonesecure-mr_datanode_3 ... done
Stopping ozonesecure-mr_datanode_1 ... done
Stopping ozonesecure-mr_scm_1      ... done
Stopping ozonesecure-mr_datanode_2 ... done
Removing ozonesecure-mr_kdc_1      ... 
Removing ozonesecure-mr_om_1       ... 
Removing ozonesecure-mr_datanode_1 ... 
Removing ozonesecure-mr_nm_1       ... 
Removing ozonesecure-mr_datanode_3 ... 
Removing ozonesecure-mr_datanode_2 ... 
Removing ozonesecure-mr_kms_1      ... 
Removing ozonesecure-mr_s3g_1      ... 
Removing jhs                       ... 
Removing ozonesecure-mr_scm_1      ... 
Removing ozonesecure-mr_rm_1       ... 
Removing ozonesecure-mr_s3g_1      ... done
Removing ozonesecure-mr_om_1       ... done
Removing ozonesecure-mr_kms_1      ... done
Removing ozonesecure-mr_kdc_1      ... done
Removing jhs                       ... done
Removing ozonesecure-mr_rm_1       ... done
Removing ozonesecure-mr_scm_1      ... done
Removing ozonesecure-mr_datanode_1 ... done
Removing ozonesecure-mr_nm_1       ... done
Removing ozonesecure-mr_datanode_3 ... done
Removing ozonesecure-mr_datanode_2 ... done
Removing network ozone
ERROR: Test execution of ozonesecure-mr is FAILED!!!!
Output:  /home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozonesecure-mr.xml
removed 'ozonesecure-mr/result/robot-ozonesecure-mr-ozonesecure-mr-kinit-om-1.xml'
removed 'ozonesecure-mr/result/robot-ozonesecure-mr-ozonesecure-mr-kinit-om-2.xml'
removed 'ozonesecure-mr/result/robot-ozonesecure-mr-ozonesecure-mr-kinit-om-3.xml'
removed 'ozonesecure-mr/result/robot-ozonesecure-mr-ozonesecure-mr-kinit-om-4.xml'
removed 'ozonesecure-mr/result/robot-ozonesecure-mr-ozonesecure-mr-kinit-om-5.xml'
removed 'ozonesecure-mr/result/robot-ozonesecure-mr-ozonesecure-mr-kinit-om-6.xml'
removed 'ozonesecure-mr/result/robot-ozonesecure-mr-ozonesecure-mr-kinit-om.xml'
renamed 'ozonesecure-mr/result/dn-audit-35cf6cab5410.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozonesecure-mr/dn-audit-35cf6cab5410.log'
renamed 'ozonesecure-mr/result/dn-audit-79f75592f8be.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozonesecure-mr/dn-audit-79f75592f8be.log'
renamed 'ozonesecure-mr/result/dn-audit-eadd7dad9462.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozonesecure-mr/dn-audit-eadd7dad9462.log'
renamed 'ozonesecure-mr/result/docker-ozonesecure-mr-ozonesecure-mr-kinit-om.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozonesecure-mr/docker-ozonesecure-mr-ozonesecure-mr-kinit-om.log'
renamed 'ozonesecure-mr/result/om-audit-om.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozonesecure-mr/om-audit-om.log'
renamed 'ozonesecure-mr/result/ozonesecure-mr_datanode_1_HddsDatanodeService.stack' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozonesecure-mr/ozonesecure-mr_datanode_1_HddsDatanodeService.stack'
renamed 'ozonesecure-mr/result/ozonesecure-mr_datanode_2_HddsDatanodeService.stack' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozonesecure-mr/ozonesecure-mr_datanode_2_HddsDatanodeService.stack'
renamed 'ozonesecure-mr/result/ozonesecure-mr_datanode_3_HddsDatanodeService.stack' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozonesecure-mr/ozonesecure-mr_datanode_3_HddsDatanodeService.stack'
renamed 'ozonesecure-mr/result/ozonesecure-mr_om_1_OzoneManagerStarter.stack' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozonesecure-mr/ozonesecure-mr_om_1_OzoneManagerStarter.stack'
renamed 'ozonesecure-mr/result/ozonesecure-mr_s3g_1_Gateway.stack' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozonesecure-mr/ozonesecure-mr_s3g_1_Gateway.stack'
renamed 'ozonesecure-mr/result/ozonesecure-mr_scm_1_StorageContainerManagerStarter.stack' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozonesecure-mr/ozonesecure-mr_scm_1_StorageContainerManagerStarter.stack'
renamed 'ozonesecure-mr/result/s3g-audit-s3g.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozonesecure-mr/s3g-audit-s3g.log'
renamed 'ozonesecure-mr/result/scm-audit-scm.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozonesecure-mr/scm-audit-scm.log'
Log:     /home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/log.html
Report:  /home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/report.html
